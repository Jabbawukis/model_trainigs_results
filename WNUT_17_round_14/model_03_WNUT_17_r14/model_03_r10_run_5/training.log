2022-05-13 17:02:48,244 ----------------------------------------------------------------------------------------------------
2022-05-13 17:02:48,245 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4922, out_features=4922, bias=True)
  (rnn): LSTM(4922, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-05-13 17:02:48,245 ----------------------------------------------------------------------------------------------------
2022-05-13 17:02:48,245 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-05-13 17:02:48,245 ----------------------------------------------------------------------------------------------------
2022-05-13 17:02:48,245 Parameters:
2022-05-13 17:02:48,245  - learning_rate: "0.100000"
2022-05-13 17:02:48,245  - mini_batch_size: "32"
2022-05-13 17:02:48,245  - patience: "3"
2022-05-13 17:02:48,245  - anneal_factor: "0.5"
2022-05-13 17:02:48,245  - max_epochs: "150"
2022-05-13 17:02:48,245  - shuffle: "True"
2022-05-13 17:02:48,245  - train_with_dev: "False"
2022-05-13 17:02:48,245  - batch_growth_annealing: "False"
2022-05-13 17:02:48,245 ----------------------------------------------------------------------------------------------------
2022-05-13 17:02:48,245 Model training base path: "resources/taggers/model_03_r10_run_5"
2022-05-13 17:02:48,245 ----------------------------------------------------------------------------------------------------
2022-05-13 17:02:48,245 Device: cuda:0
2022-05-13 17:02:48,245 ----------------------------------------------------------------------------------------------------
2022-05-13 17:02:48,245 Embeddings storage mode: cpu
2022-05-13 17:02:48,245 ----------------------------------------------------------------------------------------------------
2022-05-13 17:02:50,608 epoch 1 - iter 10/107 - loss 0.98852797 - samples/sec: 135.51 - lr: 0.100000
2022-05-13 17:02:53,168 epoch 1 - iter 20/107 - loss 0.63675289 - samples/sec: 125.04 - lr: 0.100000
2022-05-13 17:02:55,763 epoch 1 - iter 30/107 - loss 0.52191345 - samples/sec: 123.35 - lr: 0.100000
2022-05-13 17:02:58,320 epoch 1 - iter 40/107 - loss 0.45880259 - samples/sec: 125.23 - lr: 0.100000
2022-05-13 17:03:00,895 epoch 1 - iter 50/107 - loss 0.40936165 - samples/sec: 124.29 - lr: 0.100000
2022-05-13 17:03:03,440 epoch 1 - iter 60/107 - loss 0.38933163 - samples/sec: 125.82 - lr: 0.100000
2022-05-13 17:03:06,056 epoch 1 - iter 70/107 - loss 0.37332091 - samples/sec: 122.35 - lr: 0.100000
2022-05-13 17:03:08,411 epoch 1 - iter 80/107 - loss 0.36626282 - samples/sec: 135.93 - lr: 0.100000
2022-05-13 17:03:10,575 epoch 1 - iter 90/107 - loss 0.36045226 - samples/sec: 147.98 - lr: 0.100000
2022-05-13 17:03:12,828 epoch 1 - iter 100/107 - loss 0.35353203 - samples/sec: 142.07 - lr: 0.100000
2022-05-13 17:03:14,156 ----------------------------------------------------------------------------------------------------
2022-05-13 17:03:14,156 EPOCH 1 done: loss 0.3468 - lr 0.100000
2022-05-13 17:03:21,868 Evaluating as a multi-label problem: False
2022-05-13 17:03:21,878 DEV : loss 0.4362984597682953 - f1-score (micro avg)  0.0924
2022-05-13 17:03:21,956 BAD EPOCHS (no improvement): 0
2022-05-13 17:03:21,958 saving best model
2022-05-13 17:03:57,912 ----------------------------------------------------------------------------------------------------
2022-05-13 17:04:00,480 epoch 2 - iter 10/107 - loss 0.20510478 - samples/sec: 124.73 - lr: 0.100000
2022-05-13 17:04:02,884 epoch 2 - iter 20/107 - loss 0.21644626 - samples/sec: 133.15 - lr: 0.100000
2022-05-13 17:04:05,315 epoch 2 - iter 30/107 - loss 0.21541296 - samples/sec: 131.72 - lr: 0.100000
2022-05-13 17:04:07,752 epoch 2 - iter 40/107 - loss 0.21790524 - samples/sec: 131.37 - lr: 0.100000
2022-05-13 17:04:10,178 epoch 2 - iter 50/107 - loss 0.21452353 - samples/sec: 131.94 - lr: 0.100000
2022-05-13 17:04:12,670 epoch 2 - iter 60/107 - loss 0.20975241 - samples/sec: 128.48 - lr: 0.100000
2022-05-13 17:04:15,122 epoch 2 - iter 70/107 - loss 0.20131397 - samples/sec: 130.55 - lr: 0.100000
2022-05-13 17:04:17,722 epoch 2 - iter 80/107 - loss 0.20087437 - samples/sec: 123.13 - lr: 0.100000
2022-05-13 17:04:20,267 epoch 2 - iter 90/107 - loss 0.19642830 - samples/sec: 125.78 - lr: 0.100000
2022-05-13 17:04:22,821 epoch 2 - iter 100/107 - loss 0.19243901 - samples/sec: 125.34 - lr: 0.100000
2022-05-13 17:04:24,305 ----------------------------------------------------------------------------------------------------
2022-05-13 17:04:24,305 EPOCH 2 done: loss 0.1945 - lr 0.100000
2022-05-13 17:04:31,864 Evaluating as a multi-label problem: False
2022-05-13 17:04:31,874 DEV : loss 0.2862037122249603 - f1-score (micro avg)  0.3703
2022-05-13 17:04:31,950 BAD EPOCHS (no improvement): 0
2022-05-13 17:04:31,952 saving best model
2022-05-13 17:05:06,453 ----------------------------------------------------------------------------------------------------
2022-05-13 17:05:09,025 epoch 3 - iter 10/107 - loss 0.17191282 - samples/sec: 124.53 - lr: 0.100000
2022-05-13 17:05:11,587 epoch 3 - iter 20/107 - loss 0.16934652 - samples/sec: 124.96 - lr: 0.100000
2022-05-13 17:05:14,012 epoch 3 - iter 30/107 - loss 0.16737969 - samples/sec: 132.04 - lr: 0.100000
2022-05-13 17:05:16,475 epoch 3 - iter 40/107 - loss 0.16073466 - samples/sec: 129.96 - lr: 0.100000
2022-05-13 17:05:18,998 epoch 3 - iter 50/107 - loss 0.16159070 - samples/sec: 126.90 - lr: 0.100000
2022-05-13 17:05:21,495 epoch 3 - iter 60/107 - loss 0.16208624 - samples/sec: 128.17 - lr: 0.100000
2022-05-13 17:05:23,949 epoch 3 - iter 70/107 - loss 0.16443143 - samples/sec: 130.46 - lr: 0.100000
2022-05-13 17:05:26,450 epoch 3 - iter 80/107 - loss 0.16442619 - samples/sec: 128.00 - lr: 0.100000
2022-05-13 17:05:28,796 epoch 3 - iter 90/107 - loss 0.16373025 - samples/sec: 136.47 - lr: 0.100000
2022-05-13 17:05:31,159 epoch 3 - iter 100/107 - loss 0.16335234 - samples/sec: 135.47 - lr: 0.100000
2022-05-13 17:05:32,632 ----------------------------------------------------------------------------------------------------
2022-05-13 17:05:32,632 EPOCH 3 done: loss 0.1630 - lr 0.100000
2022-05-13 17:05:40,033 Evaluating as a multi-label problem: False
2022-05-13 17:05:40,044 DEV : loss 0.2940382957458496 - f1-score (micro avg)  0.3828
2022-05-13 17:05:40,118 BAD EPOCHS (no improvement): 0
2022-05-13 17:05:40,121 saving best model
2022-05-13 17:06:18,264 ----------------------------------------------------------------------------------------------------
2022-05-13 17:06:20,822 epoch 4 - iter 10/107 - loss 0.15639417 - samples/sec: 125.23 - lr: 0.100000
2022-05-13 17:06:23,307 epoch 4 - iter 20/107 - loss 0.14556507 - samples/sec: 128.83 - lr: 0.100000
2022-05-13 17:06:25,724 epoch 4 - iter 30/107 - loss 0.15158578 - samples/sec: 132.43 - lr: 0.100000
2022-05-13 17:06:28,200 epoch 4 - iter 40/107 - loss 0.14345762 - samples/sec: 129.28 - lr: 0.100000
2022-05-13 17:06:30,707 epoch 4 - iter 50/107 - loss 0.14232161 - samples/sec: 127.68 - lr: 0.100000
2022-05-13 17:06:33,162 epoch 4 - iter 60/107 - loss 0.14170631 - samples/sec: 130.43 - lr: 0.100000
2022-05-13 17:06:35,682 epoch 4 - iter 70/107 - loss 0.14005975 - samples/sec: 127.02 - lr: 0.100000
2022-05-13 17:06:38,217 epoch 4 - iter 80/107 - loss 0.13891697 - samples/sec: 126.26 - lr: 0.100000
2022-05-13 17:06:40,807 epoch 4 - iter 90/107 - loss 0.13930072 - samples/sec: 123.60 - lr: 0.100000
2022-05-13 17:06:43,259 epoch 4 - iter 100/107 - loss 0.13776364 - samples/sec: 130.58 - lr: 0.100000
2022-05-13 17:06:44,757 ----------------------------------------------------------------------------------------------------
2022-05-13 17:06:44,757 EPOCH 4 done: loss 0.1414 - lr 0.100000
2022-05-13 17:06:52,446 Evaluating as a multi-label problem: False
2022-05-13 17:06:52,457 DEV : loss 0.21156002581119537 - f1-score (micro avg)  0.5157
2022-05-13 17:06:52,531 BAD EPOCHS (no improvement): 0
2022-05-13 17:06:52,533 saving best model
2022-05-13 17:07:26,654 ----------------------------------------------------------------------------------------------------
2022-05-13 17:07:29,142 epoch 5 - iter 10/107 - loss 0.13974255 - samples/sec: 128.74 - lr: 0.100000
2022-05-13 17:07:31,656 epoch 5 - iter 20/107 - loss 0.12638077 - samples/sec: 127.33 - lr: 0.100000
2022-05-13 17:07:34,126 epoch 5 - iter 30/107 - loss 0.12855637 - samples/sec: 129.62 - lr: 0.100000
2022-05-13 17:07:36,610 epoch 5 - iter 40/107 - loss 0.12813654 - samples/sec: 128.86 - lr: 0.100000
2022-05-13 17:07:39,086 epoch 5 - iter 50/107 - loss 0.12834367 - samples/sec: 129.27 - lr: 0.100000
2022-05-13 17:07:41,456 epoch 5 - iter 60/107 - loss 0.13122877 - samples/sec: 135.13 - lr: 0.100000
2022-05-13 17:07:43,986 epoch 5 - iter 70/107 - loss 0.12788167 - samples/sec: 126.51 - lr: 0.100000
2022-05-13 17:07:46,557 epoch 5 - iter 80/107 - loss 0.12814364 - samples/sec: 124.50 - lr: 0.100000
2022-05-13 17:07:48,945 epoch 5 - iter 90/107 - loss 0.13205621 - samples/sec: 134.09 - lr: 0.100000
2022-05-13 17:07:51,490 epoch 5 - iter 100/107 - loss 0.13111691 - samples/sec: 125.77 - lr: 0.100000
2022-05-13 17:07:52,995 ----------------------------------------------------------------------------------------------------
2022-05-13 17:07:52,995 EPOCH 5 done: loss 0.1309 - lr 0.100000
2022-05-13 17:08:00,635 Evaluating as a multi-label problem: False
2022-05-13 17:08:00,645 DEV : loss 0.3013143241405487 - f1-score (micro avg)  0.3407
2022-05-13 17:08:00,719 BAD EPOCHS (no improvement): 1
2022-05-13 17:08:00,721 ----------------------------------------------------------------------------------------------------
2022-05-13 17:08:03,226 epoch 6 - iter 10/107 - loss 0.13126380 - samples/sec: 127.83 - lr: 0.100000
2022-05-13 17:08:05,680 epoch 6 - iter 20/107 - loss 0.13165114 - samples/sec: 130.48 - lr: 0.100000
2022-05-13 17:08:08,159 epoch 6 - iter 30/107 - loss 0.12863057 - samples/sec: 129.12 - lr: 0.100000
2022-05-13 17:08:10,547 epoch 6 - iter 40/107 - loss 0.12513802 - samples/sec: 134.03 - lr: 0.100000
2022-05-13 17:08:13,082 epoch 6 - iter 50/107 - loss 0.12507461 - samples/sec: 126.28 - lr: 0.100000
2022-05-13 17:08:15,641 epoch 6 - iter 60/107 - loss 0.12342090 - samples/sec: 125.12 - lr: 0.100000
2022-05-13 17:08:18,072 epoch 6 - iter 70/107 - loss 0.12521270 - samples/sec: 131.70 - lr: 0.100000
2022-05-13 17:08:20,570 epoch 6 - iter 80/107 - loss 0.12561560 - samples/sec: 128.12 - lr: 0.100000
2022-05-13 17:08:23,009 epoch 6 - iter 90/107 - loss 0.12477785 - samples/sec: 131.26 - lr: 0.100000
2022-05-13 17:08:25,477 epoch 6 - iter 100/107 - loss 0.12168538 - samples/sec: 129.71 - lr: 0.100000
2022-05-13 17:08:27,009 ----------------------------------------------------------------------------------------------------
2022-05-13 17:08:27,009 EPOCH 6 done: loss 0.1219 - lr 0.100000
2022-05-13 17:08:34,675 Evaluating as a multi-label problem: False
2022-05-13 17:08:34,685 DEV : loss 0.26607295870780945 - f1-score (micro avg)  0.3734
2022-05-13 17:08:34,758 BAD EPOCHS (no improvement): 2
2022-05-13 17:08:34,762 ----------------------------------------------------------------------------------------------------
2022-05-13 17:08:37,308 epoch 7 - iter 10/107 - loss 0.13089168 - samples/sec: 125.73 - lr: 0.100000
2022-05-13 17:08:39,763 epoch 7 - iter 20/107 - loss 0.10915886 - samples/sec: 130.42 - lr: 0.100000
2022-05-13 17:08:42,248 epoch 7 - iter 30/107 - loss 0.11161359 - samples/sec: 128.84 - lr: 0.100000
2022-05-13 17:08:44,631 epoch 7 - iter 40/107 - loss 0.11089170 - samples/sec: 134.32 - lr: 0.100000
2022-05-13 17:08:47,116 epoch 7 - iter 50/107 - loss 0.11117746 - samples/sec: 128.85 - lr: 0.100000
2022-05-13 17:08:49,497 epoch 7 - iter 60/107 - loss 0.11088807 - samples/sec: 134.45 - lr: 0.100000
2022-05-13 17:08:51,964 epoch 7 - iter 70/107 - loss 0.11028330 - samples/sec: 129.74 - lr: 0.100000
2022-05-13 17:08:54,409 epoch 7 - iter 80/107 - loss 0.10949246 - samples/sec: 130.94 - lr: 0.100000
2022-05-13 17:08:56,864 epoch 7 - iter 90/107 - loss 0.10988268 - samples/sec: 130.40 - lr: 0.100000
2022-05-13 17:08:59,415 epoch 7 - iter 100/107 - loss 0.11052426 - samples/sec: 125.48 - lr: 0.100000
2022-05-13 17:09:00,962 ----------------------------------------------------------------------------------------------------
2022-05-13 17:09:00,962 EPOCH 7 done: loss 0.1098 - lr 0.100000
2022-05-13 17:09:08,638 Evaluating as a multi-label problem: False
2022-05-13 17:09:08,648 DEV : loss 0.2696634531021118 - f1-score (micro avg)  0.3272
2022-05-13 17:09:08,723 BAD EPOCHS (no improvement): 3
2022-05-13 17:09:08,724 ----------------------------------------------------------------------------------------------------
2022-05-13 17:09:11,208 epoch 8 - iter 10/107 - loss 0.09736687 - samples/sec: 128.89 - lr: 0.100000
2022-05-13 17:09:13,717 epoch 8 - iter 20/107 - loss 0.11427952 - samples/sec: 127.59 - lr: 0.100000
2022-05-13 17:09:16,284 epoch 8 - iter 30/107 - loss 0.10996446 - samples/sec: 124.68 - lr: 0.100000
2022-05-13 17:09:18,751 epoch 8 - iter 40/107 - loss 0.10903178 - samples/sec: 129.79 - lr: 0.100000
2022-05-13 17:09:21,273 epoch 8 - iter 50/107 - loss 0.10893538 - samples/sec: 126.90 - lr: 0.100000
2022-05-13 17:09:23,739 epoch 8 - iter 60/107 - loss 0.10401195 - samples/sec: 129.84 - lr: 0.100000
2022-05-13 17:09:26,275 epoch 8 - iter 70/107 - loss 0.10574907 - samples/sec: 126.23 - lr: 0.100000
2022-05-13 17:09:28,714 epoch 8 - iter 80/107 - loss 0.10578008 - samples/sec: 131.25 - lr: 0.100000
2022-05-13 17:09:31,197 epoch 8 - iter 90/107 - loss 0.10345700 - samples/sec: 128.98 - lr: 0.100000
2022-05-13 17:09:33,619 epoch 8 - iter 100/107 - loss 0.10237408 - samples/sec: 132.15 - lr: 0.100000
2022-05-13 17:09:35,106 ----------------------------------------------------------------------------------------------------
2022-05-13 17:09:35,106 EPOCH 8 done: loss 0.1033 - lr 0.100000
2022-05-13 17:09:42,755 Evaluating as a multi-label problem: False
2022-05-13 17:09:42,766 DEV : loss 0.24583090841770172 - f1-score (micro avg)  0.4277
2022-05-13 17:09:42,840 Epoch     8: reducing learning rate of group 0 to 5.0000e-02.
2022-05-13 17:09:42,840 BAD EPOCHS (no improvement): 4
2022-05-13 17:09:42,842 ----------------------------------------------------------------------------------------------------
2022-05-13 17:09:45,386 epoch 9 - iter 10/107 - loss 0.09963838 - samples/sec: 125.87 - lr: 0.050000
2022-05-13 17:09:47,860 epoch 9 - iter 20/107 - loss 0.09670346 - samples/sec: 129.40 - lr: 0.050000
2022-05-13 17:09:50,377 epoch 9 - iter 30/107 - loss 0.09253630 - samples/sec: 127.16 - lr: 0.050000
2022-05-13 17:09:52,923 epoch 9 - iter 40/107 - loss 0.09214476 - samples/sec: 125.74 - lr: 0.050000
2022-05-13 17:09:55,508 epoch 9 - iter 50/107 - loss 0.09146654 - samples/sec: 123.86 - lr: 0.050000
2022-05-13 17:09:57,883 epoch 9 - iter 60/107 - loss 0.08962597 - samples/sec: 134.79 - lr: 0.050000
2022-05-13 17:10:00,329 epoch 9 - iter 70/107 - loss 0.09066349 - samples/sec: 130.85 - lr: 0.050000
2022-05-13 17:10:02,807 epoch 9 - iter 80/107 - loss 0.09016559 - samples/sec: 129.23 - lr: 0.050000
2022-05-13 17:10:05,275 epoch 9 - iter 90/107 - loss 0.09004725 - samples/sec: 129.68 - lr: 0.050000
2022-05-13 17:10:07,772 epoch 9 - iter 100/107 - loss 0.09209912 - samples/sec: 128.19 - lr: 0.050000
2022-05-13 17:10:09,326 ----------------------------------------------------------------------------------------------------
2022-05-13 17:10:09,326 EPOCH 9 done: loss 0.0928 - lr 0.050000
2022-05-13 17:10:17,014 Evaluating as a multi-label problem: False
2022-05-13 17:10:17,025 DEV : loss 0.20721882581710815 - f1-score (micro avg)  0.48
2022-05-13 17:10:17,100 BAD EPOCHS (no improvement): 1
2022-05-13 17:10:17,101 ----------------------------------------------------------------------------------------------------
2022-05-13 17:10:19,579 epoch 10 - iter 10/107 - loss 0.10269409 - samples/sec: 129.22 - lr: 0.050000
2022-05-13 17:10:22,066 epoch 10 - iter 20/107 - loss 0.09307925 - samples/sec: 128.75 - lr: 0.050000
2022-05-13 17:10:24,792 epoch 10 - iter 30/107 - loss 0.09150917 - samples/sec: 117.44 - lr: 0.050000
2022-05-13 17:10:27,763 epoch 10 - iter 40/107 - loss 0.09061934 - samples/sec: 107.75 - lr: 0.050000
2022-05-13 17:10:30,717 epoch 10 - iter 50/107 - loss 0.08730844 - samples/sec: 108.41 - lr: 0.050000
2022-05-13 17:10:33,322 epoch 10 - iter 60/107 - loss 0.08540922 - samples/sec: 122.92 - lr: 0.050000
2022-05-13 17:10:35,899 epoch 10 - iter 70/107 - loss 0.08411195 - samples/sec: 124.27 - lr: 0.050000
2022-05-13 17:10:38,561 epoch 10 - iter 80/107 - loss 0.08552042 - samples/sec: 120.29 - lr: 0.050000
2022-05-13 17:10:41,165 epoch 10 - iter 90/107 - loss 0.08524377 - samples/sec: 122.93 - lr: 0.050000
2022-05-13 17:10:43,744 epoch 10 - iter 100/107 - loss 0.08460132 - samples/sec: 124.14 - lr: 0.050000
2022-05-13 17:10:45,345 ----------------------------------------------------------------------------------------------------
2022-05-13 17:10:45,345 EPOCH 10 done: loss 0.0840 - lr 0.050000
2022-05-13 17:10:53,081 Evaluating as a multi-label problem: False
2022-05-13 17:10:53,092 DEV : loss 0.21363478899002075 - f1-score (micro avg)  0.4843
2022-05-13 17:10:53,172 BAD EPOCHS (no improvement): 2
2022-05-13 17:10:53,174 ----------------------------------------------------------------------------------------------------
2022-05-13 17:10:55,450 epoch 11 - iter 10/107 - loss 0.06658265 - samples/sec: 140.68 - lr: 0.050000
2022-05-13 17:10:57,929 epoch 11 - iter 20/107 - loss 0.07351150 - samples/sec: 129.14 - lr: 0.050000
2022-05-13 17:11:00,309 epoch 11 - iter 30/107 - loss 0.07620206 - samples/sec: 134.52 - lr: 0.050000
2022-05-13 17:11:02,661 epoch 11 - iter 40/107 - loss 0.08035802 - samples/sec: 136.14 - lr: 0.050000
2022-05-13 17:11:05,269 epoch 11 - iter 50/107 - loss 0.07829410 - samples/sec: 122.72 - lr: 0.050000
2022-05-13 17:11:07,721 epoch 11 - iter 60/107 - loss 0.08080181 - samples/sec: 130.58 - lr: 0.050000
2022-05-13 17:11:10,214 epoch 11 - iter 70/107 - loss 0.08049571 - samples/sec: 128.39 - lr: 0.050000
2022-05-13 17:11:12,842 epoch 11 - iter 80/107 - loss 0.08058365 - samples/sec: 121.84 - lr: 0.050000
2022-05-13 17:11:15,376 epoch 11 - iter 90/107 - loss 0.08127440 - samples/sec: 126.34 - lr: 0.050000
2022-05-13 17:11:17,858 epoch 11 - iter 100/107 - loss 0.08143125 - samples/sec: 128.99 - lr: 0.050000
2022-05-13 17:11:19,415 ----------------------------------------------------------------------------------------------------
2022-05-13 17:11:19,416 EPOCH 11 done: loss 0.0814 - lr 0.050000
2022-05-13 17:11:27,737 Evaluating as a multi-label problem: False
2022-05-13 17:11:27,751 DEV : loss 0.2140236496925354 - f1-score (micro avg)  0.4896
2022-05-13 17:11:27,845 BAD EPOCHS (no improvement): 3
2022-05-13 17:11:27,884 ----------------------------------------------------------------------------------------------------
2022-05-13 17:11:30,761 epoch 12 - iter 10/107 - loss 0.07686162 - samples/sec: 111.29 - lr: 0.050000
2022-05-13 17:11:33,633 epoch 12 - iter 20/107 - loss 0.07361644 - samples/sec: 111.48 - lr: 0.050000
2022-05-13 17:11:36,409 epoch 12 - iter 30/107 - loss 0.07650906 - samples/sec: 115.33 - lr: 0.050000
2022-05-13 17:11:39,208 epoch 12 - iter 40/107 - loss 0.07847318 - samples/sec: 114.36 - lr: 0.050000
2022-05-13 17:11:42,038 epoch 12 - iter 50/107 - loss 0.08147802 - samples/sec: 113.15 - lr: 0.050000
2022-05-13 17:11:44,899 epoch 12 - iter 60/107 - loss 0.08030142 - samples/sec: 111.86 - lr: 0.050000
2022-05-13 17:11:47,736 epoch 12 - iter 70/107 - loss 0.08126714 - samples/sec: 112.85 - lr: 0.050000
2022-05-13 17:11:50,431 epoch 12 - iter 80/107 - loss 0.08084784 - samples/sec: 118.82 - lr: 0.050000
2022-05-13 17:11:53,048 epoch 12 - iter 90/107 - loss 0.08130406 - samples/sec: 122.34 - lr: 0.050000
2022-05-13 17:11:55,692 epoch 12 - iter 100/107 - loss 0.08093728 - samples/sec: 121.08 - lr: 0.050000
2022-05-13 17:11:57,246 ----------------------------------------------------------------------------------------------------
2022-05-13 17:11:57,246 EPOCH 12 done: loss 0.0811 - lr 0.050000
2022-05-13 17:12:05,514 Evaluating as a multi-label problem: False
2022-05-13 17:12:05,526 DEV : loss 0.2206224799156189 - f1-score (micro avg)  0.4678
2022-05-13 17:12:05,613 Epoch    12: reducing learning rate of group 0 to 2.5000e-02.
2022-05-13 17:12:05,613 BAD EPOCHS (no improvement): 4
2022-05-13 17:12:05,615 ----------------------------------------------------------------------------------------------------
2022-05-13 17:12:08,305 epoch 13 - iter 10/107 - loss 0.08155815 - samples/sec: 119.09 - lr: 0.025000
2022-05-13 17:12:10,979 epoch 13 - iter 20/107 - loss 0.07624666 - samples/sec: 119.70 - lr: 0.025000
2022-05-13 17:12:13,572 epoch 13 - iter 30/107 - loss 0.07801884 - samples/sec: 123.46 - lr: 0.025000
2022-05-13 17:12:16,148 epoch 13 - iter 40/107 - loss 0.07422418 - samples/sec: 124.32 - lr: 0.025000
2022-05-13 17:12:18,666 epoch 13 - iter 50/107 - loss 0.07422565 - samples/sec: 127.15 - lr: 0.025000
2022-05-13 17:12:21,204 epoch 13 - iter 60/107 - loss 0.07469188 - samples/sec: 126.16 - lr: 0.025000
2022-05-13 17:12:23,704 epoch 13 - iter 70/107 - loss 0.07317096 - samples/sec: 128.06 - lr: 0.025000
2022-05-13 17:12:26,228 epoch 13 - iter 80/107 - loss 0.07195658 - samples/sec: 126.87 - lr: 0.025000
2022-05-13 17:12:28,795 epoch 13 - iter 90/107 - loss 0.07348227 - samples/sec: 124.68 - lr: 0.025000
2022-05-13 17:12:31,269 epoch 13 - iter 100/107 - loss 0.07462613 - samples/sec: 129.39 - lr: 0.025000
2022-05-13 17:12:32,888 ----------------------------------------------------------------------------------------------------
2022-05-13 17:12:32,888 EPOCH 13 done: loss 0.0742 - lr 0.025000
2022-05-13 17:12:41,053 Evaluating as a multi-label problem: False
2022-05-13 17:12:41,065 DEV : loss 0.2124706506729126 - f1-score (micro avg)  0.4628
2022-05-13 17:12:41,152 BAD EPOCHS (no improvement): 1
2022-05-13 17:12:41,170 ----------------------------------------------------------------------------------------------------
2022-05-13 17:12:43,906 epoch 14 - iter 10/107 - loss 0.07781415 - samples/sec: 117.03 - lr: 0.025000
2022-05-13 17:12:46,542 epoch 14 - iter 20/107 - loss 0.07657104 - samples/sec: 121.50 - lr: 0.025000
2022-05-13 17:12:49,196 epoch 14 - iter 30/107 - loss 0.07668559 - samples/sec: 120.67 - lr: 0.025000
2022-05-13 17:12:51,971 epoch 14 - iter 40/107 - loss 0.07409684 - samples/sec: 115.34 - lr: 0.025000
2022-05-13 17:12:54,527 epoch 14 - iter 50/107 - loss 0.07327318 - samples/sec: 125.26 - lr: 0.025000
2022-05-13 17:12:57,213 epoch 14 - iter 60/107 - loss 0.07438348 - samples/sec: 119.20 - lr: 0.025000
2022-05-13 17:12:59,909 epoch 14 - iter 70/107 - loss 0.07148190 - samples/sec: 118.73 - lr: 0.025000
2022-05-13 17:13:02,398 epoch 14 - iter 80/107 - loss 0.07279837 - samples/sec: 128.69 - lr: 0.025000
2022-05-13 17:13:04,923 epoch 14 - iter 90/107 - loss 0.07252236 - samples/sec: 126.80 - lr: 0.025000
2022-05-13 17:13:07,438 epoch 14 - iter 100/107 - loss 0.07222103 - samples/sec: 127.31 - lr: 0.025000
2022-05-13 17:13:09,118 ----------------------------------------------------------------------------------------------------
2022-05-13 17:13:09,118 EPOCH 14 done: loss 0.0710 - lr 0.025000
2022-05-13 17:13:17,338 Evaluating as a multi-label problem: False
2022-05-13 17:13:17,350 DEV : loss 0.2173798531293869 - f1-score (micro avg)  0.4739
2022-05-13 17:13:17,440 BAD EPOCHS (no improvement): 2
2022-05-13 17:13:17,445 ----------------------------------------------------------------------------------------------------
2022-05-13 17:13:20,246 epoch 15 - iter 10/107 - loss 0.07370796 - samples/sec: 114.30 - lr: 0.025000
2022-05-13 17:13:22,936 epoch 15 - iter 20/107 - loss 0.06910277 - samples/sec: 119.04 - lr: 0.025000
2022-05-13 17:13:25,419 epoch 15 - iter 30/107 - loss 0.07189245 - samples/sec: 128.99 - lr: 0.025000
2022-05-13 17:13:28,049 epoch 15 - iter 40/107 - loss 0.07201212 - samples/sec: 121.75 - lr: 0.025000
2022-05-13 17:13:30,631 epoch 15 - iter 50/107 - loss 0.07370163 - samples/sec: 123.96 - lr: 0.025000
2022-05-13 17:13:33,189 epoch 15 - iter 60/107 - loss 0.07378323 - samples/sec: 125.16 - lr: 0.025000
2022-05-13 17:13:35,719 epoch 15 - iter 70/107 - loss 0.07358094 - samples/sec: 126.58 - lr: 0.025000
2022-05-13 17:13:38,225 epoch 15 - iter 80/107 - loss 0.07395668 - samples/sec: 127.77 - lr: 0.025000
2022-05-13 17:13:40,782 epoch 15 - iter 90/107 - loss 0.07355732 - samples/sec: 125.19 - lr: 0.025000
2022-05-13 17:13:43,315 epoch 15 - iter 100/107 - loss 0.07141357 - samples/sec: 126.38 - lr: 0.025000
2022-05-13 17:13:44,982 ----------------------------------------------------------------------------------------------------
2022-05-13 17:13:44,982 EPOCH 15 done: loss 0.0713 - lr 0.025000
2022-05-13 17:13:52,824 Evaluating as a multi-label problem: False
2022-05-13 17:13:52,836 DEV : loss 0.1992460936307907 - f1-score (micro avg)  0.4972
2022-05-13 17:13:52,911 BAD EPOCHS (no improvement): 3
2022-05-13 17:13:52,913 ----------------------------------------------------------------------------------------------------
2022-05-13 17:13:55,573 epoch 16 - iter 10/107 - loss 0.06471165 - samples/sec: 120.34 - lr: 0.025000
2022-05-13 17:13:58,125 epoch 16 - iter 20/107 - loss 0.06737379 - samples/sec: 125.44 - lr: 0.025000
2022-05-13 17:14:00,688 epoch 16 - iter 30/107 - loss 0.07222700 - samples/sec: 124.96 - lr: 0.025000
2022-05-13 17:14:03,288 epoch 16 - iter 40/107 - loss 0.07263728 - samples/sec: 123.13 - lr: 0.025000
2022-05-13 17:14:05,763 epoch 16 - iter 50/107 - loss 0.07070423 - samples/sec: 129.31 - lr: 0.025000
2022-05-13 17:14:08,184 epoch 16 - iter 60/107 - loss 0.06901719 - samples/sec: 132.23 - lr: 0.025000
2022-05-13 17:14:10,667 epoch 16 - iter 70/107 - loss 0.06728608 - samples/sec: 128.96 - lr: 0.025000
2022-05-13 17:14:13,143 epoch 16 - iter 80/107 - loss 0.06748519 - samples/sec: 129.27 - lr: 0.025000
2022-05-13 17:14:15,596 epoch 16 - iter 90/107 - loss 0.06816085 - samples/sec: 130.49 - lr: 0.025000
2022-05-13 17:14:18,125 epoch 16 - iter 100/107 - loss 0.06863673 - samples/sec: 126.58 - lr: 0.025000
2022-05-13 17:14:19,740 ----------------------------------------------------------------------------------------------------
2022-05-13 17:14:19,740 EPOCH 16 done: loss 0.0683 - lr 0.025000
2022-05-13 17:14:27,428 Evaluating as a multi-label problem: False
2022-05-13 17:14:27,439 DEV : loss 0.2040998786687851 - f1-score (micro avg)  0.4925
2022-05-13 17:14:27,513 Epoch    16: reducing learning rate of group 0 to 1.2500e-02.
2022-05-13 17:14:27,513 BAD EPOCHS (no improvement): 4
2022-05-13 17:14:27,525 ----------------------------------------------------------------------------------------------------
2022-05-13 17:14:30,162 epoch 17 - iter 10/107 - loss 0.06507154 - samples/sec: 121.40 - lr: 0.012500
2022-05-13 17:14:33,022 epoch 17 - iter 20/107 - loss 0.06925411 - samples/sec: 111.94 - lr: 0.012500
2022-05-13 17:14:36,020 epoch 17 - iter 30/107 - loss 0.06713799 - samples/sec: 106.78 - lr: 0.012500
2022-05-13 17:14:39,079 epoch 17 - iter 40/107 - loss 0.06389951 - samples/sec: 104.68 - lr: 0.012500
2022-05-13 17:14:42,040 epoch 17 - iter 50/107 - loss 0.06240038 - samples/sec: 108.19 - lr: 0.012500
2022-05-13 17:14:44,858 epoch 17 - iter 60/107 - loss 0.06358544 - samples/sec: 113.60 - lr: 0.012500
2022-05-13 17:14:47,927 epoch 17 - iter 70/107 - loss 0.06406798 - samples/sec: 104.33 - lr: 0.012500
2022-05-13 17:14:50,870 epoch 17 - iter 80/107 - loss 0.06454631 - samples/sec: 108.76 - lr: 0.012500
2022-05-13 17:14:53,659 epoch 17 - iter 90/107 - loss 0.06478288 - samples/sec: 114.80 - lr: 0.012500
2022-05-13 17:14:56,477 epoch 17 - iter 100/107 - loss 0.06418050 - samples/sec: 113.63 - lr: 0.012500
2022-05-13 17:14:58,161 ----------------------------------------------------------------------------------------------------
2022-05-13 17:14:58,161 EPOCH 17 done: loss 0.0647 - lr 0.012500
2022-05-13 17:15:12,568 Evaluating as a multi-label problem: False
2022-05-13 17:15:12,579 DEV : loss 0.21387197077274323 - f1-score (micro avg)  0.4883
2022-05-13 17:15:12,655 BAD EPOCHS (no improvement): 1
2022-05-13 17:15:12,659 ----------------------------------------------------------------------------------------------------
2022-05-13 17:15:15,276 epoch 18 - iter 10/107 - loss 0.05426267 - samples/sec: 122.30 - lr: 0.012500
2022-05-13 17:15:17,864 epoch 18 - iter 20/107 - loss 0.05910633 - samples/sec: 123.70 - lr: 0.012500
2022-05-13 17:15:20,526 epoch 18 - iter 30/107 - loss 0.06430053 - samples/sec: 120.30 - lr: 0.012500
2022-05-13 17:15:22,905 epoch 18 - iter 40/107 - loss 0.06103867 - samples/sec: 134.51 - lr: 0.012500
2022-05-13 17:15:25,397 epoch 18 - iter 50/107 - loss 0.06113529 - samples/sec: 128.49 - lr: 0.012500
2022-05-13 17:15:27,914 epoch 18 - iter 60/107 - loss 0.06059795 - samples/sec: 127.21 - lr: 0.012500
2022-05-13 17:15:30,474 epoch 18 - iter 70/107 - loss 0.05957688 - samples/sec: 125.07 - lr: 0.012500
2022-05-13 17:15:32,907 epoch 18 - iter 80/107 - loss 0.05945904 - samples/sec: 131.58 - lr: 0.012500
2022-05-13 17:15:35,479 epoch 18 - iter 90/107 - loss 0.06043532 - samples/sec: 124.43 - lr: 0.012500
2022-05-13 17:15:37,957 epoch 18 - iter 100/107 - loss 0.06200963 - samples/sec: 129.20 - lr: 0.012500
2022-05-13 17:15:39,516 ----------------------------------------------------------------------------------------------------
2022-05-13 17:15:39,517 EPOCH 18 done: loss 0.0633 - lr 0.012500
2022-05-13 17:15:47,493 Evaluating as a multi-label problem: False
2022-05-13 17:15:47,504 DEV : loss 0.1944246143102646 - f1-score (micro avg)  0.5131
2022-05-13 17:15:47,579 BAD EPOCHS (no improvement): 2
2022-05-13 17:15:47,584 ----------------------------------------------------------------------------------------------------
2022-05-13 17:15:50,051 epoch 19 - iter 10/107 - loss 0.06348749 - samples/sec: 129.76 - lr: 0.012500
2022-05-13 17:15:52,578 epoch 19 - iter 20/107 - loss 0.06802421 - samples/sec: 126.70 - lr: 0.012500
2022-05-13 17:15:55,184 epoch 19 - iter 30/107 - loss 0.06753591 - samples/sec: 122.86 - lr: 0.012500
2022-05-13 17:15:57,715 epoch 19 - iter 40/107 - loss 0.06780235 - samples/sec: 126.51 - lr: 0.012500
2022-05-13 17:16:00,278 epoch 19 - iter 50/107 - loss 0.06736879 - samples/sec: 124.87 - lr: 0.012500
2022-05-13 17:16:02,723 epoch 19 - iter 60/107 - loss 0.06613299 - samples/sec: 130.98 - lr: 0.012500
2022-05-13 17:16:05,246 epoch 19 - iter 70/107 - loss 0.06554158 - samples/sec: 126.86 - lr: 0.012500
2022-05-13 17:16:07,705 epoch 19 - iter 80/107 - loss 0.06575357 - samples/sec: 130.18 - lr: 0.012500
2022-05-13 17:16:10,132 epoch 19 - iter 90/107 - loss 0.06592487 - samples/sec: 131.89 - lr: 0.012500
2022-05-13 17:16:12,745 epoch 19 - iter 100/107 - loss 0.06538987 - samples/sec: 122.52 - lr: 0.012500
2022-05-13 17:16:14,276 ----------------------------------------------------------------------------------------------------
2022-05-13 17:16:14,276 EPOCH 19 done: loss 0.0652 - lr 0.012500
2022-05-13 17:16:21,722 Evaluating as a multi-label problem: False
2022-05-13 17:16:21,734 DEV : loss 0.21669968962669373 - f1-score (micro avg)  0.4832
2022-05-13 17:16:21,807 BAD EPOCHS (no improvement): 3
2022-05-13 17:16:21,809 ----------------------------------------------------------------------------------------------------
2022-05-13 17:16:24,322 epoch 20 - iter 10/107 - loss 0.06677405 - samples/sec: 127.42 - lr: 0.012500
2022-05-13 17:16:26,556 epoch 20 - iter 20/107 - loss 0.06558516 - samples/sec: 143.32 - lr: 0.012500
2022-05-13 17:16:28,987 epoch 20 - iter 30/107 - loss 0.06834399 - samples/sec: 131.67 - lr: 0.012500
2022-05-13 17:16:31,489 epoch 20 - iter 40/107 - loss 0.06788278 - samples/sec: 127.92 - lr: 0.012500
2022-05-13 17:16:34,067 epoch 20 - iter 50/107 - loss 0.06589616 - samples/sec: 124.17 - lr: 0.012500
2022-05-13 17:16:36,571 epoch 20 - iter 60/107 - loss 0.06488314 - samples/sec: 127.86 - lr: 0.012500
2022-05-13 17:16:38,984 epoch 20 - iter 70/107 - loss 0.06510175 - samples/sec: 132.69 - lr: 0.012500
2022-05-13 17:16:41,540 epoch 20 - iter 80/107 - loss 0.06416382 - samples/sec: 125.27 - lr: 0.012500
2022-05-13 17:16:44,148 epoch 20 - iter 90/107 - loss 0.06356758 - samples/sec: 122.73 - lr: 0.012500
2022-05-13 17:16:46,714 epoch 20 - iter 100/107 - loss 0.06408340 - samples/sec: 124.79 - lr: 0.012500
2022-05-13 17:16:48,350 ----------------------------------------------------------------------------------------------------
2022-05-13 17:16:48,350 EPOCH 20 done: loss 0.0637 - lr 0.012500
2022-05-13 17:16:56,251 Evaluating as a multi-label problem: False
2022-05-13 17:16:56,262 DEV : loss 0.20027658343315125 - f1-score (micro avg)  0.498
2022-05-13 17:16:56,344 Epoch    20: reducing learning rate of group 0 to 6.2500e-03.
2022-05-13 17:16:56,345 BAD EPOCHS (no improvement): 4
2022-05-13 17:16:56,346 ----------------------------------------------------------------------------------------------------
2022-05-13 17:16:58,886 epoch 21 - iter 10/107 - loss 0.06116163 - samples/sec: 126.07 - lr: 0.006250
2022-05-13 17:17:01,464 epoch 21 - iter 20/107 - loss 0.05772169 - samples/sec: 124.22 - lr: 0.006250
2022-05-13 17:17:03,951 epoch 21 - iter 30/107 - loss 0.05897277 - samples/sec: 128.77 - lr: 0.006250
2022-05-13 17:17:06,574 epoch 21 - iter 40/107 - loss 0.05888410 - samples/sec: 122.02 - lr: 0.006250
2022-05-13 17:17:09,076 epoch 21 - iter 50/107 - loss 0.05877260 - samples/sec: 127.98 - lr: 0.006250
2022-05-13 17:17:11,677 epoch 21 - iter 60/107 - loss 0.05875802 - samples/sec: 123.07 - lr: 0.006250
2022-05-13 17:17:14,334 epoch 21 - iter 70/107 - loss 0.05806571 - samples/sec: 120.50 - lr: 0.006250
2022-05-13 17:17:16,861 epoch 21 - iter 80/107 - loss 0.05934550 - samples/sec: 126.66 - lr: 0.006250
2022-05-13 17:17:19,429 epoch 21 - iter 90/107 - loss 0.05981249 - samples/sec: 124.69 - lr: 0.006250
2022-05-13 17:17:22,064 epoch 21 - iter 100/107 - loss 0.05979254 - samples/sec: 121.53 - lr: 0.006250
2022-05-13 17:17:23,629 ----------------------------------------------------------------------------------------------------
2022-05-13 17:17:23,629 EPOCH 21 done: loss 0.0602 - lr 0.006250
2022-05-13 17:17:31,523 Evaluating as a multi-label problem: False
2022-05-13 17:17:31,534 DEV : loss 0.20581814646720886 - f1-score (micro avg)  0.4885
2022-05-13 17:17:31,611 BAD EPOCHS (no improvement): 1
2022-05-13 17:17:31,612 ----------------------------------------------------------------------------------------------------
2022-05-13 17:17:34,163 epoch 22 - iter 10/107 - loss 0.06177294 - samples/sec: 125.51 - lr: 0.006250
2022-05-13 17:17:36,714 epoch 22 - iter 20/107 - loss 0.06171217 - samples/sec: 125.47 - lr: 0.006250
2022-05-13 17:17:39,185 epoch 22 - iter 30/107 - loss 0.06008374 - samples/sec: 129.56 - lr: 0.006250
2022-05-13 17:17:41,615 epoch 22 - iter 40/107 - loss 0.05853575 - samples/sec: 131.76 - lr: 0.006250
2022-05-13 17:17:44,159 epoch 22 - iter 50/107 - loss 0.06100866 - samples/sec: 125.82 - lr: 0.006250
2022-05-13 17:17:46,669 epoch 22 - iter 60/107 - loss 0.05906432 - samples/sec: 127.58 - lr: 0.006250
2022-05-13 17:17:49,180 epoch 22 - iter 70/107 - loss 0.05989689 - samples/sec: 127.47 - lr: 0.006250
2022-05-13 17:17:51,683 epoch 22 - iter 80/107 - loss 0.05961354 - samples/sec: 127.92 - lr: 0.006250
2022-05-13 17:17:54,185 epoch 22 - iter 90/107 - loss 0.05994421 - samples/sec: 127.95 - lr: 0.006250
2022-05-13 17:17:56,687 epoch 22 - iter 100/107 - loss 0.06104516 - samples/sec: 127.92 - lr: 0.006250
2022-05-13 17:17:58,168 ----------------------------------------------------------------------------------------------------
2022-05-13 17:17:58,168 EPOCH 22 done: loss 0.0604 - lr 0.006250
2022-05-13 17:18:05,994 Evaluating as a multi-label problem: False
2022-05-13 17:18:06,005 DEV : loss 0.20928078889846802 - f1-score (micro avg)  0.4891
2022-05-13 17:18:06,080 BAD EPOCHS (no improvement): 2
2022-05-13 17:18:06,083 ----------------------------------------------------------------------------------------------------
2022-05-13 17:18:08,634 epoch 23 - iter 10/107 - loss 0.04955631 - samples/sec: 125.50 - lr: 0.006250
2022-05-13 17:18:11,098 epoch 23 - iter 20/107 - loss 0.05632887 - samples/sec: 129.91 - lr: 0.006250
2022-05-13 17:18:13,544 epoch 23 - iter 30/107 - loss 0.05702378 - samples/sec: 130.88 - lr: 0.006250
2022-05-13 17:18:16,081 epoch 23 - iter 40/107 - loss 0.05807841 - samples/sec: 126.20 - lr: 0.006250
2022-05-13 17:18:18,596 epoch 23 - iter 50/107 - loss 0.05970381 - samples/sec: 127.26 - lr: 0.006250
2022-05-13 17:18:21,032 epoch 23 - iter 60/107 - loss 0.05956768 - samples/sec: 131.45 - lr: 0.006250
2022-05-13 17:18:23,531 epoch 23 - iter 70/107 - loss 0.05992172 - samples/sec: 128.07 - lr: 0.006250
2022-05-13 17:18:25,898 epoch 23 - iter 80/107 - loss 0.06049203 - samples/sec: 135.26 - lr: 0.006250
2022-05-13 17:18:28,375 epoch 23 - iter 90/107 - loss 0.05938209 - samples/sec: 129.22 - lr: 0.006250
2022-05-13 17:18:30,825 epoch 23 - iter 100/107 - loss 0.05903097 - samples/sec: 130.70 - lr: 0.006250
2022-05-13 17:18:32,404 ----------------------------------------------------------------------------------------------------
2022-05-13 17:18:32,405 EPOCH 23 done: loss 0.0600 - lr 0.006250
2022-05-13 17:18:40,119 Evaluating as a multi-label problem: False
2022-05-13 17:18:40,130 DEV : loss 0.20363834500312805 - f1-score (micro avg)  0.4893
2022-05-13 17:18:40,202 BAD EPOCHS (no improvement): 3
2022-05-13 17:18:40,204 ----------------------------------------------------------------------------------------------------
2022-05-13 17:18:42,741 epoch 24 - iter 10/107 - loss 0.06629291 - samples/sec: 126.17 - lr: 0.006250
2022-05-13 17:18:45,275 epoch 24 - iter 20/107 - loss 0.05923600 - samples/sec: 126.34 - lr: 0.006250
2022-05-13 17:18:47,668 epoch 24 - iter 30/107 - loss 0.05930407 - samples/sec: 133.77 - lr: 0.006250
2022-05-13 17:18:50,208 epoch 24 - iter 40/107 - loss 0.05971933 - samples/sec: 126.03 - lr: 0.006250
2022-05-13 17:18:52,555 epoch 24 - iter 50/107 - loss 0.05802077 - samples/sec: 136.39 - lr: 0.006250
2022-05-13 17:18:55,042 epoch 24 - iter 60/107 - loss 0.05814191 - samples/sec: 128.72 - lr: 0.006250
2022-05-13 17:18:57,490 epoch 24 - iter 70/107 - loss 0.05799101 - samples/sec: 130.77 - lr: 0.006250
2022-05-13 17:19:00,057 epoch 24 - iter 80/107 - loss 0.05971246 - samples/sec: 124.71 - lr: 0.006250
2022-05-13 17:19:02,518 epoch 24 - iter 90/107 - loss 0.05890300 - samples/sec: 130.10 - lr: 0.006250
2022-05-13 17:19:05,006 epoch 24 - iter 100/107 - loss 0.06073703 - samples/sec: 128.64 - lr: 0.006250
2022-05-13 17:19:06,457 ----------------------------------------------------------------------------------------------------
2022-05-13 17:19:06,457 EPOCH 24 done: loss 0.0604 - lr 0.006250
2022-05-13 17:19:14,153 Evaluating as a multi-label problem: False
2022-05-13 17:19:14,164 DEV : loss 0.20353978872299194 - f1-score (micro avg)  0.4864
2022-05-13 17:19:14,238 Epoch    24: reducing learning rate of group 0 to 3.1250e-03.
2022-05-13 17:19:14,238 BAD EPOCHS (no improvement): 4
2022-05-13 17:19:14,240 ----------------------------------------------------------------------------------------------------
2022-05-13 17:19:16,748 epoch 25 - iter 10/107 - loss 0.05554121 - samples/sec: 127.66 - lr: 0.003125
2022-05-13 17:19:19,106 epoch 25 - iter 20/107 - loss 0.05296781 - samples/sec: 135.76 - lr: 0.003125
2022-05-13 17:19:21,735 epoch 25 - iter 30/107 - loss 0.05838771 - samples/sec: 121.78 - lr: 0.003125
2022-05-13 17:19:24,194 epoch 25 - iter 40/107 - loss 0.05678004 - samples/sec: 130.19 - lr: 0.003125
2022-05-13 17:19:26,730 epoch 25 - iter 50/107 - loss 0.05562000 - samples/sec: 126.25 - lr: 0.003125
2022-05-13 17:19:29,001 epoch 25 - iter 60/107 - loss 0.05643890 - samples/sec: 140.93 - lr: 0.003125
2022-05-13 17:19:31,422 epoch 25 - iter 70/107 - loss 0.05710259 - samples/sec: 132.22 - lr: 0.003125
2022-05-13 17:19:33,891 epoch 25 - iter 80/107 - loss 0.05870010 - samples/sec: 129.66 - lr: 0.003125
2022-05-13 17:19:36,271 epoch 25 - iter 90/107 - loss 0.05917155 - samples/sec: 134.51 - lr: 0.003125
2022-05-13 17:19:38,812 epoch 25 - iter 100/107 - loss 0.05904847 - samples/sec: 125.99 - lr: 0.003125
2022-05-13 17:19:40,332 ----------------------------------------------------------------------------------------------------
2022-05-13 17:19:40,332 EPOCH 25 done: loss 0.0586 - lr 0.003125
2022-05-13 17:19:48,073 Evaluating as a multi-label problem: False
2022-05-13 17:19:48,084 DEV : loss 0.20729725062847137 - f1-score (micro avg)  0.4869
2022-05-13 17:19:48,157 BAD EPOCHS (no improvement): 1
2022-05-13 17:19:48,159 ----------------------------------------------------------------------------------------------------
2022-05-13 17:19:50,659 epoch 26 - iter 10/107 - loss 0.05504603 - samples/sec: 128.04 - lr: 0.003125
2022-05-13 17:19:53,085 epoch 26 - iter 20/107 - loss 0.05467079 - samples/sec: 132.00 - lr: 0.003125
2022-05-13 17:19:55,516 epoch 26 - iter 30/107 - loss 0.05475898 - samples/sec: 131.66 - lr: 0.003125
2022-05-13 17:19:58,023 epoch 26 - iter 40/107 - loss 0.05420930 - samples/sec: 127.69 - lr: 0.003125
2022-05-13 17:20:00,557 epoch 26 - iter 50/107 - loss 0.05521160 - samples/sec: 126.32 - lr: 0.003125
2022-05-13 17:20:03,076 epoch 26 - iter 60/107 - loss 0.05588682 - samples/sec: 127.09 - lr: 0.003125
2022-05-13 17:20:05,607 epoch 26 - iter 70/107 - loss 0.05631608 - samples/sec: 126.46 - lr: 0.003125
2022-05-13 17:20:08,115 epoch 26 - iter 80/107 - loss 0.05646074 - samples/sec: 127.66 - lr: 0.003125
2022-05-13 17:20:10,680 epoch 26 - iter 90/107 - loss 0.05598476 - samples/sec: 124.81 - lr: 0.003125
2022-05-13 17:20:13,172 epoch 26 - iter 100/107 - loss 0.05604775 - samples/sec: 128.48 - lr: 0.003125
2022-05-13 17:20:14,604 ----------------------------------------------------------------------------------------------------
2022-05-13 17:20:14,604 EPOCH 26 done: loss 0.0570 - lr 0.003125
2022-05-13 17:20:22,302 Evaluating as a multi-label problem: False
2022-05-13 17:20:22,313 DEV : loss 0.20649923384189606 - f1-score (micro avg)  0.4881
2022-05-13 17:20:22,387 BAD EPOCHS (no improvement): 2
2022-05-13 17:20:22,388 ----------------------------------------------------------------------------------------------------
2022-05-13 17:20:24,905 epoch 27 - iter 10/107 - loss 0.06275703 - samples/sec: 127.19 - lr: 0.003125
2022-05-13 17:20:27,445 epoch 27 - iter 20/107 - loss 0.05719940 - samples/sec: 126.03 - lr: 0.003125
2022-05-13 17:20:29,923 epoch 27 - iter 30/107 - loss 0.05703963 - samples/sec: 129.18 - lr: 0.003125
2022-05-13 17:20:32,411 epoch 27 - iter 40/107 - loss 0.05409845 - samples/sec: 128.71 - lr: 0.003125
2022-05-13 17:20:34,945 epoch 27 - iter 50/107 - loss 0.05700149 - samples/sec: 126.32 - lr: 0.003125
2022-05-13 17:20:37,373 epoch 27 - iter 60/107 - loss 0.05693538 - samples/sec: 131.83 - lr: 0.003125
2022-05-13 17:20:39,757 epoch 27 - iter 70/107 - loss 0.05911312 - samples/sec: 134.26 - lr: 0.003125
2022-05-13 17:20:42,257 epoch 27 - iter 80/107 - loss 0.05968795 - samples/sec: 128.04 - lr: 0.003125
2022-05-13 17:20:44,755 epoch 27 - iter 90/107 - loss 0.05954872 - samples/sec: 128.19 - lr: 0.003125
2022-05-13 17:20:47,276 epoch 27 - iter 100/107 - loss 0.05938873 - samples/sec: 126.98 - lr: 0.003125
2022-05-13 17:20:48,735 ----------------------------------------------------------------------------------------------------
2022-05-13 17:20:48,735 EPOCH 27 done: loss 0.0592 - lr 0.003125
2022-05-13 17:20:56,481 Evaluating as a multi-label problem: False
2022-05-13 17:20:56,491 DEV : loss 0.205481618642807 - f1-score (micro avg)  0.4905
2022-05-13 17:20:56,568 BAD EPOCHS (no improvement): 3
2022-05-13 17:20:56,570 ----------------------------------------------------------------------------------------------------
2022-05-13 17:20:59,032 epoch 28 - iter 10/107 - loss 0.05457254 - samples/sec: 130.08 - lr: 0.003125
2022-05-13 17:21:01,509 epoch 28 - iter 20/107 - loss 0.05258820 - samples/sec: 129.22 - lr: 0.003125
2022-05-13 17:21:03,940 epoch 28 - iter 30/107 - loss 0.05230428 - samples/sec: 131.72 - lr: 0.003125
2022-05-13 17:21:06,382 epoch 28 - iter 40/107 - loss 0.05193032 - samples/sec: 131.05 - lr: 0.003125
2022-05-13 17:21:08,920 epoch 28 - iter 50/107 - loss 0.05291648 - samples/sec: 126.15 - lr: 0.003125
2022-05-13 17:21:11,412 epoch 28 - iter 60/107 - loss 0.05196668 - samples/sec: 128.46 - lr: 0.003125
2022-05-13 17:21:13,828 epoch 28 - iter 70/107 - loss 0.05251680 - samples/sec: 132.51 - lr: 0.003125
2022-05-13 17:21:16,371 epoch 28 - iter 80/107 - loss 0.05445701 - samples/sec: 125.86 - lr: 0.003125
2022-05-13 17:21:18,845 epoch 28 - iter 90/107 - loss 0.05668298 - samples/sec: 129.40 - lr: 0.003125
2022-05-13 17:21:21,387 epoch 28 - iter 100/107 - loss 0.05723539 - samples/sec: 125.93 - lr: 0.003125
2022-05-13 17:21:22,927 ----------------------------------------------------------------------------------------------------
2022-05-13 17:21:22,928 EPOCH 28 done: loss 0.0579 - lr 0.003125
2022-05-13 17:21:30,675 Evaluating as a multi-label problem: False
2022-05-13 17:21:30,686 DEV : loss 0.2085418850183487 - f1-score (micro avg)  0.49
2022-05-13 17:21:30,759 Epoch    28: reducing learning rate of group 0 to 1.5625e-03.
2022-05-13 17:21:30,759 BAD EPOCHS (no improvement): 4
2022-05-13 17:21:30,761 ----------------------------------------------------------------------------------------------------
2022-05-13 17:21:33,131 epoch 29 - iter 10/107 - loss 0.06109204 - samples/sec: 135.11 - lr: 0.001563
2022-05-13 17:21:35,474 epoch 29 - iter 20/107 - loss 0.06128010 - samples/sec: 136.65 - lr: 0.001563
2022-05-13 17:21:37,872 epoch 29 - iter 30/107 - loss 0.05736244 - samples/sec: 133.51 - lr: 0.001563
2022-05-13 17:21:40,174 epoch 29 - iter 40/107 - loss 0.05775278 - samples/sec: 139.02 - lr: 0.001563
2022-05-13 17:21:42,432 epoch 29 - iter 50/107 - loss 0.05670545 - samples/sec: 141.79 - lr: 0.001563
2022-05-13 17:21:44,806 epoch 29 - iter 60/107 - loss 0.05552642 - samples/sec: 134.84 - lr: 0.001563
2022-05-13 17:21:47,316 epoch 29 - iter 70/107 - loss 0.05599496 - samples/sec: 127.56 - lr: 0.001563
2022-05-13 17:21:49,833 epoch 29 - iter 80/107 - loss 0.05609487 - samples/sec: 127.20 - lr: 0.001563
2022-05-13 17:21:52,309 epoch 29 - iter 90/107 - loss 0.05572681 - samples/sec: 129.26 - lr: 0.001563
2022-05-13 17:21:54,767 epoch 29 - iter 100/107 - loss 0.05501898 - samples/sec: 130.25 - lr: 0.001563
2022-05-13 17:21:56,294 ----------------------------------------------------------------------------------------------------
2022-05-13 17:21:56,294 EPOCH 29 done: loss 0.0552 - lr 0.001563
2022-05-13 17:22:03,989 Evaluating as a multi-label problem: False
2022-05-13 17:22:04,000 DEV : loss 0.2063164860010147 - f1-score (micro avg)  0.4921
2022-05-13 17:22:04,075 BAD EPOCHS (no improvement): 1
2022-05-13 17:22:04,077 ----------------------------------------------------------------------------------------------------
2022-05-13 17:22:06,658 epoch 30 - iter 10/107 - loss 0.04875905 - samples/sec: 124.03 - lr: 0.001563
2022-05-13 17:22:09,119 epoch 30 - iter 20/107 - loss 0.05230057 - samples/sec: 130.06 - lr: 0.001563
2022-05-13 17:22:11,597 epoch 30 - iter 30/107 - loss 0.05593482 - samples/sec: 129.18 - lr: 0.001563
2022-05-13 17:22:14,137 epoch 30 - iter 40/107 - loss 0.05779859 - samples/sec: 126.04 - lr: 0.001563
2022-05-13 17:22:16,631 epoch 30 - iter 50/107 - loss 0.05672037 - samples/sec: 128.35 - lr: 0.001563
2022-05-13 17:22:19,047 epoch 30 - iter 60/107 - loss 0.05725230 - samples/sec: 132.54 - lr: 0.001563
2022-05-13 17:22:21,490 epoch 30 - iter 70/107 - loss 0.05730058 - samples/sec: 130.99 - lr: 0.001563
2022-05-13 17:22:23,921 epoch 30 - iter 80/107 - loss 0.05701349 - samples/sec: 131.72 - lr: 0.001563
2022-05-13 17:22:26,434 epoch 30 - iter 90/107 - loss 0.05738844 - samples/sec: 127.39 - lr: 0.001563
2022-05-13 17:22:28,846 epoch 30 - iter 100/107 - loss 0.05706894 - samples/sec: 132.71 - lr: 0.001563
2022-05-13 17:22:30,337 ----------------------------------------------------------------------------------------------------
2022-05-13 17:22:30,338 EPOCH 30 done: loss 0.0573 - lr 0.001563
2022-05-13 17:22:38,075 Evaluating as a multi-label problem: False
2022-05-13 17:22:38,086 DEV : loss 0.20672044157981873 - f1-score (micro avg)  0.4913
2022-05-13 17:22:38,161 BAD EPOCHS (no improvement): 2
2022-05-13 17:22:38,340 ----------------------------------------------------------------------------------------------------
2022-05-13 17:22:40,856 epoch 31 - iter 10/107 - loss 0.05380237 - samples/sec: 127.58 - lr: 0.001563
2022-05-13 17:22:43,263 epoch 31 - iter 20/107 - loss 0.05378425 - samples/sec: 132.99 - lr: 0.001563
2022-05-13 17:22:45,817 epoch 31 - iter 30/107 - loss 0.05438159 - samples/sec: 125.34 - lr: 0.001563
2022-05-13 17:22:48,313 epoch 31 - iter 40/107 - loss 0.05402507 - samples/sec: 128.26 - lr: 0.001563
2022-05-13 17:22:50,821 epoch 31 - iter 50/107 - loss 0.05556431 - samples/sec: 127.69 - lr: 0.001563
2022-05-13 17:22:53,283 epoch 31 - iter 60/107 - loss 0.05566959 - samples/sec: 130.00 - lr: 0.001563
2022-05-13 17:22:55,796 epoch 31 - iter 70/107 - loss 0.05633001 - samples/sec: 127.38 - lr: 0.001563
2022-05-13 17:22:58,379 epoch 31 - iter 80/107 - loss 0.05690277 - samples/sec: 123.94 - lr: 0.001563
2022-05-13 17:23:00,796 epoch 31 - iter 90/107 - loss 0.05830390 - samples/sec: 132.45 - lr: 0.001563
2022-05-13 17:23:03,262 epoch 31 - iter 100/107 - loss 0.05804623 - samples/sec: 129.79 - lr: 0.001563
2022-05-13 17:23:04,842 ----------------------------------------------------------------------------------------------------
2022-05-13 17:23:04,842 EPOCH 31 done: loss 0.0586 - lr 0.001563
2022-05-13 17:23:12,642 Evaluating as a multi-label problem: False
2022-05-13 17:23:12,652 DEV : loss 0.20561954379081726 - f1-score (micro avg)  0.4953
2022-05-13 17:23:12,726 BAD EPOCHS (no improvement): 3
2022-05-13 17:23:12,728 ----------------------------------------------------------------------------------------------------
2022-05-13 17:23:15,248 epoch 32 - iter 10/107 - loss 0.05919478 - samples/sec: 127.03 - lr: 0.001563
2022-05-13 17:23:17,719 epoch 32 - iter 20/107 - loss 0.05598954 - samples/sec: 129.57 - lr: 0.001563
2022-05-13 17:23:20,221 epoch 32 - iter 30/107 - loss 0.05708789 - samples/sec: 127.96 - lr: 0.001563
2022-05-13 17:23:22,752 epoch 32 - iter 40/107 - loss 0.05818037 - samples/sec: 126.44 - lr: 0.001563
2022-05-13 17:23:25,183 epoch 32 - iter 50/107 - loss 0.05745374 - samples/sec: 131.71 - lr: 0.001563
2022-05-13 17:23:27,596 epoch 32 - iter 60/107 - loss 0.05985675 - samples/sec: 132.67 - lr: 0.001563
2022-05-13 17:23:30,045 epoch 32 - iter 70/107 - loss 0.06008921 - samples/sec: 130.75 - lr: 0.001563
2022-05-13 17:23:32,471 epoch 32 - iter 80/107 - loss 0.05839916 - samples/sec: 131.95 - lr: 0.001563
2022-05-13 17:23:34,882 epoch 32 - iter 90/107 - loss 0.05866566 - samples/sec: 132.76 - lr: 0.001563
2022-05-13 17:23:37,381 epoch 32 - iter 100/107 - loss 0.05944199 - samples/sec: 128.12 - lr: 0.001563
2022-05-13 17:23:38,892 ----------------------------------------------------------------------------------------------------
2022-05-13 17:23:38,892 EPOCH 32 done: loss 0.0581 - lr 0.001563
2022-05-13 17:23:46,632 Evaluating as a multi-label problem: False
2022-05-13 17:23:46,643 DEV : loss 0.20745837688446045 - f1-score (micro avg)  0.4905
2022-05-13 17:23:46,721 Epoch    32: reducing learning rate of group 0 to 7.8125e-04.
2022-05-13 17:23:46,721 BAD EPOCHS (no improvement): 4
2022-05-13 17:23:46,722 ----------------------------------------------------------------------------------------------------
2022-05-13 17:23:49,298 epoch 33 - iter 10/107 - loss 0.05820272 - samples/sec: 124.32 - lr: 0.000781
2022-05-13 17:23:51,753 epoch 33 - iter 20/107 - loss 0.05878752 - samples/sec: 130.37 - lr: 0.000781
2022-05-13 17:23:54,108 epoch 33 - iter 30/107 - loss 0.06509059 - samples/sec: 135.92 - lr: 0.000781
2022-05-13 17:23:56,628 epoch 33 - iter 40/107 - loss 0.06334607 - samples/sec: 127.04 - lr: 0.000781
2022-05-13 17:23:59,092 epoch 33 - iter 50/107 - loss 0.06061032 - samples/sec: 129.92 - lr: 0.000781
2022-05-13 17:24:01,612 epoch 33 - iter 60/107 - loss 0.05973515 - samples/sec: 127.04 - lr: 0.000781
2022-05-13 17:24:04,047 epoch 33 - iter 70/107 - loss 0.05822393 - samples/sec: 131.48 - lr: 0.000781
2022-05-13 17:24:06,609 epoch 33 - iter 80/107 - loss 0.05787730 - samples/sec: 124.94 - lr: 0.000781
2022-05-13 17:24:09,122 epoch 33 - iter 90/107 - loss 0.05799799 - samples/sec: 127.40 - lr: 0.000781
2022-05-13 17:24:11,623 epoch 33 - iter 100/107 - loss 0.05835055 - samples/sec: 127.96 - lr: 0.000781
2022-05-13 17:24:13,083 ----------------------------------------------------------------------------------------------------
2022-05-13 17:24:13,083 EPOCH 33 done: loss 0.0579 - lr 0.000781
2022-05-13 17:24:20,845 Evaluating as a multi-label problem: False
2022-05-13 17:24:20,856 DEV : loss 0.2077806442975998 - f1-score (micro avg)  0.4909
2022-05-13 17:24:20,932 BAD EPOCHS (no improvement): 1
2022-05-13 17:24:20,934 ----------------------------------------------------------------------------------------------------
2022-05-13 17:24:23,516 epoch 34 - iter 10/107 - loss 0.05367676 - samples/sec: 124.00 - lr: 0.000781
2022-05-13 17:24:25,939 epoch 34 - iter 20/107 - loss 0.05665732 - samples/sec: 132.15 - lr: 0.000781
2022-05-13 17:24:28,327 epoch 34 - iter 30/107 - loss 0.05922508 - samples/sec: 134.04 - lr: 0.000781
2022-05-13 17:24:30,779 epoch 34 - iter 40/107 - loss 0.05853861 - samples/sec: 130.55 - lr: 0.000781
2022-05-13 17:24:33,273 epoch 34 - iter 50/107 - loss 0.05812860 - samples/sec: 128.38 - lr: 0.000781
2022-05-13 17:24:35,716 epoch 34 - iter 60/107 - loss 0.05804366 - samples/sec: 131.01 - lr: 0.000781
2022-05-13 17:24:38,275 epoch 34 - iter 70/107 - loss 0.05711816 - samples/sec: 125.12 - lr: 0.000781
2022-05-13 17:24:40,738 epoch 34 - iter 80/107 - loss 0.05685272 - samples/sec: 129.96 - lr: 0.000781
2022-05-13 17:24:43,266 epoch 34 - iter 90/107 - loss 0.05727025 - samples/sec: 126.63 - lr: 0.000781
2022-05-13 17:24:45,692 epoch 34 - iter 100/107 - loss 0.05670666 - samples/sec: 131.93 - lr: 0.000781
2022-05-13 17:24:47,191 ----------------------------------------------------------------------------------------------------
2022-05-13 17:24:47,191 EPOCH 34 done: loss 0.0563 - lr 0.000781
2022-05-13 17:24:54,867 Evaluating as a multi-label problem: False
2022-05-13 17:24:54,878 DEV : loss 0.20750316977500916 - f1-score (micro avg)  0.4925
2022-05-13 17:24:54,951 BAD EPOCHS (no improvement): 2
2022-05-13 17:24:54,954 ----------------------------------------------------------------------------------------------------
2022-05-13 17:24:57,527 epoch 35 - iter 10/107 - loss 0.05466803 - samples/sec: 124.39 - lr: 0.000781
2022-05-13 17:24:59,981 epoch 35 - iter 20/107 - loss 0.06232699 - samples/sec: 130.44 - lr: 0.000781
2022-05-13 17:25:02,529 epoch 35 - iter 30/107 - loss 0.06099729 - samples/sec: 125.67 - lr: 0.000781
2022-05-13 17:25:04,989 epoch 35 - iter 40/107 - loss 0.05665926 - samples/sec: 130.13 - lr: 0.000781
2022-05-13 17:25:07,497 epoch 35 - iter 50/107 - loss 0.05402921 - samples/sec: 127.65 - lr: 0.000781
2022-05-13 17:25:09,870 epoch 35 - iter 60/107 - loss 0.05300817 - samples/sec: 134.89 - lr: 0.000781
2022-05-13 17:25:12,344 epoch 35 - iter 70/107 - loss 0.05467784 - samples/sec: 129.42 - lr: 0.000781
2022-05-13 17:25:14,766 epoch 35 - iter 80/107 - loss 0.05640333 - samples/sec: 132.17 - lr: 0.000781
2022-05-13 17:25:17,174 epoch 35 - iter 90/107 - loss 0.05552940 - samples/sec: 132.92 - lr: 0.000781
2022-05-13 17:25:19,694 epoch 35 - iter 100/107 - loss 0.05601296 - samples/sec: 127.06 - lr: 0.000781
2022-05-13 17:25:21,195 ----------------------------------------------------------------------------------------------------
2022-05-13 17:25:21,195 EPOCH 35 done: loss 0.0560 - lr 0.000781
2022-05-13 17:25:28,938 Evaluating as a multi-label problem: False
2022-05-13 17:25:28,949 DEV : loss 0.2071448266506195 - f1-score (micro avg)  0.4921
2022-05-13 17:25:29,025 BAD EPOCHS (no improvement): 3
2022-05-13 17:25:29,027 ----------------------------------------------------------------------------------------------------
2022-05-13 17:25:31,562 epoch 36 - iter 10/107 - loss 0.05602957 - samples/sec: 126.30 - lr: 0.000781
2022-05-13 17:25:34,074 epoch 36 - iter 20/107 - loss 0.05462656 - samples/sec: 127.41 - lr: 0.000781
2022-05-13 17:25:36,558 epoch 36 - iter 30/107 - loss 0.04922409 - samples/sec: 128.89 - lr: 0.000781
2022-05-13 17:25:39,022 epoch 36 - iter 40/107 - loss 0.05107957 - samples/sec: 129.90 - lr: 0.000781
2022-05-13 17:25:41,288 epoch 36 - iter 50/107 - loss 0.05020792 - samples/sec: 141.31 - lr: 0.000781
2022-05-13 17:25:43,592 epoch 36 - iter 60/107 - loss 0.05229353 - samples/sec: 138.92 - lr: 0.000781
2022-05-13 17:25:45,927 epoch 36 - iter 70/107 - loss 0.05132816 - samples/sec: 137.11 - lr: 0.000781
2022-05-13 17:25:48,227 epoch 36 - iter 80/107 - loss 0.05177177 - samples/sec: 139.16 - lr: 0.000781
2022-05-13 17:25:50,565 epoch 36 - iter 90/107 - loss 0.05333816 - samples/sec: 136.93 - lr: 0.000781
2022-05-13 17:25:52,977 epoch 36 - iter 100/107 - loss 0.05607303 - samples/sec: 132.72 - lr: 0.000781
2022-05-13 17:25:54,518 ----------------------------------------------------------------------------------------------------
2022-05-13 17:25:54,518 EPOCH 36 done: loss 0.0564 - lr 0.000781
2022-05-13 17:26:02,233 Evaluating as a multi-label problem: False
2022-05-13 17:26:02,244 DEV : loss 0.20702482759952545 - f1-score (micro avg)  0.4925
2022-05-13 17:26:02,319 Epoch    36: reducing learning rate of group 0 to 3.9063e-04.
2022-05-13 17:26:02,319 BAD EPOCHS (no improvement): 4
2022-05-13 17:26:02,321 ----------------------------------------------------------------------------------------------------
2022-05-13 17:26:04,889 epoch 37 - iter 10/107 - loss 0.05847354 - samples/sec: 124.69 - lr: 0.000391
2022-05-13 17:26:07,417 epoch 37 - iter 20/107 - loss 0.06035390 - samples/sec: 126.62 - lr: 0.000391
2022-05-13 17:26:09,816 epoch 37 - iter 30/107 - loss 0.05617981 - samples/sec: 133.46 - lr: 0.000391
2022-05-13 17:26:12,334 epoch 37 - iter 40/107 - loss 0.05741145 - samples/sec: 127.12 - lr: 0.000391
2022-05-13 17:26:14,791 epoch 37 - iter 50/107 - loss 0.05720361 - samples/sec: 130.26 - lr: 0.000391
2022-05-13 17:26:17,259 epoch 37 - iter 60/107 - loss 0.05646372 - samples/sec: 129.70 - lr: 0.000391
2022-05-13 17:26:19,842 epoch 37 - iter 70/107 - loss 0.05625548 - samples/sec: 123.97 - lr: 0.000391
2022-05-13 17:26:26,654 epoch 37 - iter 80/107 - loss 0.05514479 - samples/sec: 46.98 - lr: 0.000391
2022-05-13 17:26:29,126 epoch 37 - iter 90/107 - loss 0.05434457 - samples/sec: 129.51 - lr: 0.000391
2022-05-13 17:26:31,571 epoch 37 - iter 100/107 - loss 0.05525443 - samples/sec: 130.92 - lr: 0.000391
2022-05-13 17:26:33,069 ----------------------------------------------------------------------------------------------------
2022-05-13 17:26:33,069 EPOCH 37 done: loss 0.0560 - lr 0.000391
2022-05-13 17:26:40,814 Evaluating as a multi-label problem: False
2022-05-13 17:26:40,825 DEV : loss 0.2072025090456009 - f1-score (micro avg)  0.4917
2022-05-13 17:26:40,904 BAD EPOCHS (no improvement): 1
2022-05-13 17:26:40,907 ----------------------------------------------------------------------------------------------------
2022-05-13 17:26:43,519 epoch 38 - iter 10/107 - loss 0.05133178 - samples/sec: 122.55 - lr: 0.000391
2022-05-13 17:26:45,954 epoch 38 - iter 20/107 - loss 0.05062067 - samples/sec: 131.51 - lr: 0.000391
2022-05-13 17:26:48,418 epoch 38 - iter 30/107 - loss 0.05414234 - samples/sec: 129.89 - lr: 0.000391
2022-05-13 17:26:50,926 epoch 38 - iter 40/107 - loss 0.05612537 - samples/sec: 127.67 - lr: 0.000391
2022-05-13 17:26:53,392 epoch 38 - iter 50/107 - loss 0.05449252 - samples/sec: 129.81 - lr: 0.000391
2022-05-13 17:26:55,760 epoch 38 - iter 60/107 - loss 0.05420936 - samples/sec: 135.16 - lr: 0.000391
2022-05-13 17:26:58,160 epoch 38 - iter 70/107 - loss 0.05667982 - samples/sec: 133.43 - lr: 0.000391
2022-05-13 17:27:00,600 epoch 38 - iter 80/107 - loss 0.05527518 - samples/sec: 131.16 - lr: 0.000391
2022-05-13 17:27:03,154 epoch 38 - iter 90/107 - loss 0.05627309 - samples/sec: 125.37 - lr: 0.000391
2022-05-13 17:27:05,703 epoch 38 - iter 100/107 - loss 0.05718683 - samples/sec: 125.59 - lr: 0.000391
2022-05-13 17:27:07,252 ----------------------------------------------------------------------------------------------------
2022-05-13 17:27:07,252 EPOCH 38 done: loss 0.0560 - lr 0.000391
2022-05-13 17:27:15,024 Evaluating as a multi-label problem: False
2022-05-13 17:27:15,035 DEV : loss 0.2079254388809204 - f1-score (micro avg)  0.4913
2022-05-13 17:27:15,109 BAD EPOCHS (no improvement): 2
2022-05-13 17:27:15,110 ----------------------------------------------------------------------------------------------------
2022-05-13 17:27:17,635 epoch 39 - iter 10/107 - loss 0.06173199 - samples/sec: 126.80 - lr: 0.000391
2022-05-13 17:27:20,136 epoch 39 - iter 20/107 - loss 0.05821210 - samples/sec: 128.01 - lr: 0.000391
2022-05-13 17:27:22,575 epoch 39 - iter 30/107 - loss 0.05792753 - samples/sec: 131.27 - lr: 0.000391
2022-05-13 17:27:25,065 epoch 39 - iter 40/107 - loss 0.05605739 - samples/sec: 128.52 - lr: 0.000391
2022-05-13 17:27:27,511 epoch 39 - iter 50/107 - loss 0.05576941 - samples/sec: 130.88 - lr: 0.000391
2022-05-13 17:27:29,857 epoch 39 - iter 60/107 - loss 0.05407487 - samples/sec: 136.47 - lr: 0.000391
2022-05-13 17:27:32,199 epoch 39 - iter 70/107 - loss 0.05478245 - samples/sec: 136.69 - lr: 0.000391
2022-05-13 17:27:34,715 epoch 39 - iter 80/107 - loss 0.05566452 - samples/sec: 127.28 - lr: 0.000391
2022-05-13 17:27:37,257 epoch 39 - iter 90/107 - loss 0.05551296 - samples/sec: 125.94 - lr: 0.000391
2022-05-13 17:27:39,732 epoch 39 - iter 100/107 - loss 0.05520762 - samples/sec: 129.31 - lr: 0.000391
2022-05-13 17:27:41,241 ----------------------------------------------------------------------------------------------------
2022-05-13 17:27:41,241 EPOCH 39 done: loss 0.0550 - lr 0.000391
2022-05-13 17:27:48,957 Evaluating as a multi-label problem: False
2022-05-13 17:27:48,968 DEV : loss 0.20757050812244415 - f1-score (micro avg)  0.4925
2022-05-13 17:27:49,042 BAD EPOCHS (no improvement): 3
2022-05-13 17:27:49,043 ----------------------------------------------------------------------------------------------------
2022-05-13 17:27:51,509 epoch 40 - iter 10/107 - loss 0.04693477 - samples/sec: 129.84 - lr: 0.000391
2022-05-13 17:27:54,021 epoch 40 - iter 20/107 - loss 0.05406826 - samples/sec: 127.46 - lr: 0.000391
2022-05-13 17:27:56,431 epoch 40 - iter 30/107 - loss 0.05247684 - samples/sec: 132.81 - lr: 0.000391
2022-05-13 17:27:58,898 epoch 40 - iter 40/107 - loss 0.05351969 - samples/sec: 129.76 - lr: 0.000391
2022-05-13 17:28:01,422 epoch 40 - iter 50/107 - loss 0.05642876 - samples/sec: 126.84 - lr: 0.000391
2022-05-13 17:28:03,936 epoch 40 - iter 60/107 - loss 0.05817341 - samples/sec: 127.31 - lr: 0.000391
2022-05-13 17:28:06,430 epoch 40 - iter 70/107 - loss 0.05893412 - samples/sec: 128.36 - lr: 0.000391
2022-05-13 17:28:08,868 epoch 40 - iter 80/107 - loss 0.05783465 - samples/sec: 131.32 - lr: 0.000391
2022-05-13 17:28:11,452 epoch 40 - iter 90/107 - loss 0.05774309 - samples/sec: 123.88 - lr: 0.000391
2022-05-13 17:28:13,847 epoch 40 - iter 100/107 - loss 0.05700588 - samples/sec: 133.66 - lr: 0.000391
2022-05-13 17:28:15,410 ----------------------------------------------------------------------------------------------------
2022-05-13 17:28:15,410 EPOCH 40 done: loss 0.0574 - lr 0.000391
2022-05-13 17:28:23,172 Evaluating as a multi-label problem: False
2022-05-13 17:28:23,183 DEV : loss 0.20765171945095062 - f1-score (micro avg)  0.4937
2022-05-13 17:28:23,257 Epoch    40: reducing learning rate of group 0 to 1.9531e-04.
2022-05-13 17:28:23,258 BAD EPOCHS (no improvement): 4
2022-05-13 17:28:23,259 ----------------------------------------------------------------------------------------------------
2022-05-13 17:28:25,714 epoch 41 - iter 10/107 - loss 0.05768943 - samples/sec: 130.46 - lr: 0.000195
2022-05-13 17:28:28,204 epoch 41 - iter 20/107 - loss 0.05666584 - samples/sec: 128.53 - lr: 0.000195
2022-05-13 17:28:30,653 epoch 41 - iter 30/107 - loss 0.05671313 - samples/sec: 130.72 - lr: 0.000195
2022-05-13 17:28:33,042 epoch 41 - iter 40/107 - loss 0.05628834 - samples/sec: 134.00 - lr: 0.000195
2022-05-13 17:28:35,485 epoch 41 - iter 50/107 - loss 0.05746120 - samples/sec: 131.08 - lr: 0.000195
2022-05-13 17:28:37,960 epoch 41 - iter 60/107 - loss 0.05624477 - samples/sec: 129.33 - lr: 0.000195
2022-05-13 17:28:40,507 epoch 41 - iter 70/107 - loss 0.05590536 - samples/sec: 125.69 - lr: 0.000195
2022-05-13 17:28:43,005 epoch 41 - iter 80/107 - loss 0.05568599 - samples/sec: 128.15 - lr: 0.000195
2022-05-13 17:28:45,495 epoch 41 - iter 90/107 - loss 0.05564529 - samples/sec: 128.53 - lr: 0.000195
2022-05-13 17:28:47,978 epoch 41 - iter 100/107 - loss 0.05604936 - samples/sec: 128.94 - lr: 0.000195
2022-05-13 17:28:49,511 ----------------------------------------------------------------------------------------------------
2022-05-13 17:28:49,511 EPOCH 41 done: loss 0.0560 - lr 0.000195
2022-05-13 17:28:57,241 Evaluating as a multi-label problem: False
2022-05-13 17:28:57,251 DEV : loss 0.2074528932571411 - f1-score (micro avg)  0.4945
2022-05-13 17:28:57,325 BAD EPOCHS (no improvement): 1
2022-05-13 17:28:57,327 ----------------------------------------------------------------------------------------------------
2022-05-13 17:28:59,769 epoch 42 - iter 10/107 - loss 0.07330996 - samples/sec: 131.11 - lr: 0.000195
2022-05-13 17:29:02,360 epoch 42 - iter 20/107 - loss 0.06006764 - samples/sec: 123.56 - lr: 0.000195
2022-05-13 17:29:04,878 epoch 42 - iter 30/107 - loss 0.05827333 - samples/sec: 127.14 - lr: 0.000195
2022-05-13 17:29:07,304 epoch 42 - iter 40/107 - loss 0.05599976 - samples/sec: 131.95 - lr: 0.000195
2022-05-13 17:29:09,804 epoch 42 - iter 50/107 - loss 0.05667526 - samples/sec: 128.02 - lr: 0.000195
2022-05-13 17:29:12,283 epoch 42 - iter 60/107 - loss 0.05627869 - samples/sec: 129.17 - lr: 0.000195
2022-05-13 17:29:14,673 epoch 42 - iter 70/107 - loss 0.05728278 - samples/sec: 133.92 - lr: 0.000195
2022-05-13 17:29:17,222 epoch 42 - iter 80/107 - loss 0.05666902 - samples/sec: 125.60 - lr: 0.000195
2022-05-13 17:29:19,665 epoch 42 - iter 90/107 - loss 0.05720042 - samples/sec: 131.05 - lr: 0.000195
2022-05-13 17:29:22,153 epoch 42 - iter 100/107 - loss 0.05724748 - samples/sec: 128.70 - lr: 0.000195
2022-05-13 17:29:23,670 ----------------------------------------------------------------------------------------------------
2022-05-13 17:29:23,670 EPOCH 42 done: loss 0.0576 - lr 0.000195
2022-05-13 17:29:31,397 Evaluating as a multi-label problem: False
2022-05-13 17:29:31,408 DEV : loss 0.20737425982952118 - f1-score (micro avg)  0.4949
2022-05-13 17:29:31,482 BAD EPOCHS (no improvement): 2
2022-05-13 17:29:31,484 ----------------------------------------------------------------------------------------------------
2022-05-13 17:29:34,002 epoch 43 - iter 10/107 - loss 0.05679287 - samples/sec: 127.17 - lr: 0.000195
2022-05-13 17:29:36,550 epoch 43 - iter 20/107 - loss 0.05357230 - samples/sec: 125.61 - lr: 0.000195
2022-05-13 17:29:38,957 epoch 43 - iter 30/107 - loss 0.05211214 - samples/sec: 133.02 - lr: 0.000195
2022-05-13 17:29:41,400 epoch 43 - iter 40/107 - loss 0.05387549 - samples/sec: 131.04 - lr: 0.000195
2022-05-13 17:29:43,873 epoch 43 - iter 50/107 - loss 0.05354282 - samples/sec: 129.45 - lr: 0.000195
2022-05-13 17:29:46,277 epoch 43 - iter 60/107 - loss 0.05824196 - samples/sec: 133.14 - lr: 0.000195
2022-05-13 17:29:48,825 epoch 43 - iter 70/107 - loss 0.05727566 - samples/sec: 125.65 - lr: 0.000195
2022-05-13 17:29:51,351 epoch 43 - iter 80/107 - loss 0.05677599 - samples/sec: 126.72 - lr: 0.000195
2022-05-13 17:29:53,753 epoch 43 - iter 90/107 - loss 0.05777384 - samples/sec: 133.28 - lr: 0.000195
2022-05-13 17:29:56,255 epoch 43 - iter 100/107 - loss 0.05664931 - samples/sec: 127.97 - lr: 0.000195
2022-05-13 17:29:57,808 ----------------------------------------------------------------------------------------------------
2022-05-13 17:29:57,808 EPOCH 43 done: loss 0.0572 - lr 0.000195
2022-05-13 17:30:05,577 Evaluating as a multi-label problem: False
2022-05-13 17:30:05,588 DEV : loss 0.2070980817079544 - f1-score (micro avg)  0.4949
2022-05-13 17:30:05,663 BAD EPOCHS (no improvement): 3
2022-05-13 17:30:05,665 ----------------------------------------------------------------------------------------------------
2022-05-13 17:30:08,157 epoch 44 - iter 10/107 - loss 0.06921063 - samples/sec: 128.53 - lr: 0.000195
2022-05-13 17:30:10,686 epoch 44 - iter 20/107 - loss 0.06209742 - samples/sec: 126.57 - lr: 0.000195
2022-05-13 17:30:13,219 epoch 44 - iter 30/107 - loss 0.06040338 - samples/sec: 126.38 - lr: 0.000195
2022-05-13 17:30:15,627 epoch 44 - iter 40/107 - loss 0.05907553 - samples/sec: 132.92 - lr: 0.000195
2022-05-13 17:30:18,096 epoch 44 - iter 50/107 - loss 0.06148448 - samples/sec: 129.69 - lr: 0.000195
2022-05-13 17:30:20,544 epoch 44 - iter 60/107 - loss 0.06064057 - samples/sec: 130.74 - lr: 0.000195
2022-05-13 17:30:23,085 epoch 44 - iter 70/107 - loss 0.05802703 - samples/sec: 126.01 - lr: 0.000195
2022-05-13 17:30:25,538 epoch 44 - iter 80/107 - loss 0.05735439 - samples/sec: 130.47 - lr: 0.000195
2022-05-13 17:30:28,058 epoch 44 - iter 90/107 - loss 0.05707779 - samples/sec: 127.07 - lr: 0.000195
2022-05-13 17:30:30,490 epoch 44 - iter 100/107 - loss 0.05684141 - samples/sec: 131.59 - lr: 0.000195
2022-05-13 17:30:32,031 ----------------------------------------------------------------------------------------------------
2022-05-13 17:30:32,031 EPOCH 44 done: loss 0.0564 - lr 0.000195
2022-05-13 17:30:39,774 Evaluating as a multi-label problem: False
2022-05-13 17:30:39,784 DEV : loss 0.2069425731897354 - f1-score (micro avg)  0.4949
2022-05-13 17:30:39,858 Epoch    44: reducing learning rate of group 0 to 9.7656e-05.
2022-05-13 17:30:39,858 BAD EPOCHS (no improvement): 4
2022-05-13 17:30:39,859 ----------------------------------------------------------------------------------------------------
2022-05-13 17:30:39,860 ----------------------------------------------------------------------------------------------------
2022-05-13 17:30:39,860 learning rate too small - quitting training!
2022-05-13 17:30:39,860 ----------------------------------------------------------------------------------------------------
2022-05-13 17:31:15,731 ----------------------------------------------------------------------------------------------------
2022-05-13 17:31:15,732 loading file resources/taggers/model_03_r10_run_5/best-model.pt
2022-05-13 17:31:42,668 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-05-13 17:32:04,676 Evaluating as a multi-label problem: False
2022-05-13 17:32:04,689 0.5739	0.3058	0.399	0.2694
2022-05-13 17:32:04,689 
Results:
- F-score (micro) 0.399
- F-score (macro) 0.24
- Accuracy 0.2694

By class:
               precision    recall  f1-score   support

       person     0.6484    0.5245    0.5799       429
     location     0.4848    0.5333    0.5079       150
        group     0.5909    0.0788    0.1390       165
creative-work     0.6000    0.0211    0.0408       142
      product     0.6667    0.0157    0.0308       127
  corporation     0.2121    0.1061    0.1414        66

    micro avg     0.5739    0.3058    0.3990      1079
    macro avg     0.5338    0.2133    0.2400      1079
 weighted avg     0.5860    0.3058    0.3401      1079

2022-05-13 17:32:04,689 ----------------------------------------------------------------------------------------------------
