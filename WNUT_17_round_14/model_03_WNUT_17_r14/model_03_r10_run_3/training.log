2022-05-13 15:41:10,960 ----------------------------------------------------------------------------------------------------
2022-05-13 15:41:10,961 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4922, out_features=4922, bias=True)
  (rnn): LSTM(4922, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-05-13 15:41:10,961 ----------------------------------------------------------------------------------------------------
2022-05-13 15:41:10,961 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-05-13 15:41:10,961 ----------------------------------------------------------------------------------------------------
2022-05-13 15:41:10,961 Parameters:
2022-05-13 15:41:10,961  - learning_rate: "0.100000"
2022-05-13 15:41:10,961  - mini_batch_size: "32"
2022-05-13 15:41:10,961  - patience: "3"
2022-05-13 15:41:10,961  - anneal_factor: "0.5"
2022-05-13 15:41:10,961  - max_epochs: "150"
2022-05-13 15:41:10,961  - shuffle: "True"
2022-05-13 15:41:10,961  - train_with_dev: "False"
2022-05-13 15:41:10,961  - batch_growth_annealing: "False"
2022-05-13 15:41:10,961 ----------------------------------------------------------------------------------------------------
2022-05-13 15:41:10,961 Model training base path: "resources/taggers/model_03_r10_run_3"
2022-05-13 15:41:10,961 ----------------------------------------------------------------------------------------------------
2022-05-13 15:41:10,961 Device: cuda:0
2022-05-13 15:41:10,961 ----------------------------------------------------------------------------------------------------
2022-05-13 15:41:10,961 Embeddings storage mode: cpu
2022-05-13 15:41:10,961 ----------------------------------------------------------------------------------------------------
2022-05-13 15:41:14,679 epoch 1 - iter 10/107 - loss 0.98004102 - samples/sec: 86.11 - lr: 0.100000
2022-05-13 15:41:18,555 epoch 1 - iter 20/107 - loss 0.63060390 - samples/sec: 82.56 - lr: 0.100000
2022-05-13 15:41:22,540 epoch 1 - iter 30/107 - loss 0.51381231 - samples/sec: 80.34 - lr: 0.100000
2022-05-13 15:41:26,128 epoch 1 - iter 40/107 - loss 0.44882594 - samples/sec: 89.21 - lr: 0.100000
2022-05-13 15:41:29,776 epoch 1 - iter 50/107 - loss 0.40022304 - samples/sec: 87.74 - lr: 0.100000
2022-05-13 15:41:33,508 epoch 1 - iter 60/107 - loss 0.38022131 - samples/sec: 85.76 - lr: 0.100000
2022-05-13 15:41:36,816 epoch 1 - iter 70/107 - loss 0.36532002 - samples/sec: 96.77 - lr: 0.100000
2022-05-13 15:41:39,423 epoch 1 - iter 80/107 - loss 0.35665757 - samples/sec: 122.80 - lr: 0.100000
2022-05-13 15:41:41,890 epoch 1 - iter 90/107 - loss 0.34965957 - samples/sec: 129.78 - lr: 0.100000
2022-05-13 15:41:44,760 epoch 1 - iter 100/107 - loss 0.34348058 - samples/sec: 111.54 - lr: 0.100000
2022-05-13 15:41:46,634 ----------------------------------------------------------------------------------------------------
2022-05-13 15:41:46,634 EPOCH 1 done: loss 0.3368 - lr 0.100000
2022-05-13 15:41:57,237 Evaluating as a multi-label problem: False
2022-05-13 15:41:57,247 DEV : loss 0.43228718638420105 - f1-score (micro avg)  0.0754
2022-05-13 15:41:57,321 BAD EPOCHS (no improvement): 0
2022-05-13 15:41:57,323 saving best model
2022-05-13 15:42:32,134 ----------------------------------------------------------------------------------------------------
2022-05-13 15:42:35,455 epoch 2 - iter 10/107 - loss 0.22322235 - samples/sec: 96.42 - lr: 0.100000
2022-05-13 15:42:38,196 epoch 2 - iter 20/107 - loss 0.19981660 - samples/sec: 116.79 - lr: 0.100000
2022-05-13 15:42:41,044 epoch 2 - iter 30/107 - loss 0.20256975 - samples/sec: 112.42 - lr: 0.100000
2022-05-13 15:42:44,370 epoch 2 - iter 40/107 - loss 0.19987920 - samples/sec: 96.23 - lr: 0.100000
2022-05-13 15:42:47,938 epoch 2 - iter 50/107 - loss 0.20249919 - samples/sec: 89.71 - lr: 0.100000
2022-05-13 15:42:51,305 epoch 2 - iter 60/107 - loss 0.20290723 - samples/sec: 95.07 - lr: 0.100000
2022-05-13 15:42:54,943 epoch 2 - iter 70/107 - loss 0.20387543 - samples/sec: 87.98 - lr: 0.100000
2022-05-13 15:42:58,662 epoch 2 - iter 80/107 - loss 0.20228399 - samples/sec: 86.06 - lr: 0.100000
2022-05-13 15:43:01,855 epoch 2 - iter 90/107 - loss 0.20007683 - samples/sec: 100.26 - lr: 0.100000
2022-05-13 15:43:05,554 epoch 2 - iter 100/107 - loss 0.19456517 - samples/sec: 86.53 - lr: 0.100000
2022-05-13 15:43:07,653 ----------------------------------------------------------------------------------------------------
2022-05-13 15:43:07,653 EPOCH 2 done: loss 0.1917 - lr 0.100000
2022-05-13 15:43:16,223 Evaluating as a multi-label problem: False
2022-05-13 15:43:16,234 DEV : loss 0.25183260440826416 - f1-score (micro avg)  0.4833
2022-05-13 15:43:16,309 BAD EPOCHS (no improvement): 0
2022-05-13 15:43:16,321 saving best model
2022-05-13 15:43:50,974 ----------------------------------------------------------------------------------------------------
2022-05-13 15:43:54,505 epoch 3 - iter 10/107 - loss 0.17937039 - samples/sec: 90.67 - lr: 0.100000
2022-05-13 15:43:58,086 epoch 3 - iter 20/107 - loss 0.18406691 - samples/sec: 89.39 - lr: 0.100000
2022-05-13 15:44:01,657 epoch 3 - iter 30/107 - loss 0.17957570 - samples/sec: 89.64 - lr: 0.100000
2022-05-13 15:44:05,147 epoch 3 - iter 40/107 - loss 0.17373258 - samples/sec: 91.73 - lr: 0.100000
2022-05-13 15:44:08,580 epoch 3 - iter 50/107 - loss 0.17030351 - samples/sec: 93.23 - lr: 0.100000
2022-05-13 15:44:11,343 epoch 3 - iter 60/107 - loss 0.17025512 - samples/sec: 115.86 - lr: 0.100000
2022-05-13 15:44:14,074 epoch 3 - iter 70/107 - loss 0.16826491 - samples/sec: 117.22 - lr: 0.100000
2022-05-13 15:44:16,707 epoch 3 - iter 80/107 - loss 0.16464299 - samples/sec: 121.58 - lr: 0.100000
2022-05-13 15:44:20,177 epoch 3 - iter 90/107 - loss 0.16350697 - samples/sec: 92.24 - lr: 0.100000
2022-05-13 15:44:24,019 epoch 3 - iter 100/107 - loss 0.16215315 - samples/sec: 83.31 - lr: 0.100000
2022-05-13 15:44:26,003 ----------------------------------------------------------------------------------------------------
2022-05-13 15:44:26,003 EPOCH 3 done: loss 0.1610 - lr 0.100000
2022-05-13 15:44:36,679 Evaluating as a multi-label problem: False
2022-05-13 15:44:36,689 DEV : loss 0.2693447470664978 - f1-score (micro avg)  0.4355
2022-05-13 15:44:36,763 BAD EPOCHS (no improvement): 1
2022-05-13 15:44:36,765 ----------------------------------------------------------------------------------------------------
2022-05-13 15:44:40,275 epoch 4 - iter 10/107 - loss 0.14788694 - samples/sec: 91.19 - lr: 0.100000
2022-05-13 15:44:43,813 epoch 4 - iter 20/107 - loss 0.14289016 - samples/sec: 90.48 - lr: 0.100000
2022-05-13 15:44:46,675 epoch 4 - iter 30/107 - loss 0.15371138 - samples/sec: 111.86 - lr: 0.100000
2022-05-13 15:44:49,371 epoch 4 - iter 40/107 - loss 0.14804920 - samples/sec: 118.75 - lr: 0.100000
2022-05-13 15:44:52,091 epoch 4 - iter 50/107 - loss 0.15239956 - samples/sec: 117.67 - lr: 0.100000
2022-05-13 15:44:55,538 epoch 4 - iter 60/107 - loss 0.15185844 - samples/sec: 92.87 - lr: 0.100000
2022-05-13 15:44:59,210 epoch 4 - iter 70/107 - loss 0.14569946 - samples/sec: 87.18 - lr: 0.100000
2022-05-13 15:45:02,903 epoch 4 - iter 80/107 - loss 0.14741668 - samples/sec: 86.66 - lr: 0.100000
2022-05-13 15:45:06,379 epoch 4 - iter 90/107 - loss 0.14702606 - samples/sec: 92.09 - lr: 0.100000
2022-05-13 15:45:10,006 epoch 4 - iter 100/107 - loss 0.14661125 - samples/sec: 88.25 - lr: 0.100000
2022-05-13 15:45:11,933 ----------------------------------------------------------------------------------------------------
2022-05-13 15:45:11,933 EPOCH 4 done: loss 0.1452 - lr 0.100000
2022-05-13 15:45:21,932 Evaluating as a multi-label problem: False
2022-05-13 15:45:21,942 DEV : loss 0.2616751194000244 - f1-score (micro avg)  0.4313
2022-05-13 15:45:22,016 BAD EPOCHS (no improvement): 2
2022-05-13 15:45:22,018 ----------------------------------------------------------------------------------------------------
2022-05-13 15:45:24,664 epoch 5 - iter 10/107 - loss 0.14005297 - samples/sec: 120.99 - lr: 0.100000
2022-05-13 15:45:27,537 epoch 5 - iter 20/107 - loss 0.12935185 - samples/sec: 111.43 - lr: 0.100000
2022-05-13 15:45:31,070 epoch 5 - iter 30/107 - loss 0.13461744 - samples/sec: 90.59 - lr: 0.100000
2022-05-13 15:45:34,505 epoch 5 - iter 40/107 - loss 0.13361090 - samples/sec: 93.21 - lr: 0.100000
2022-05-13 15:45:38,141 epoch 5 - iter 50/107 - loss 0.12954911 - samples/sec: 88.03 - lr: 0.100000
2022-05-13 15:45:41,478 epoch 5 - iter 60/107 - loss 0.12812709 - samples/sec: 95.91 - lr: 0.100000
2022-05-13 15:45:45,052 epoch 5 - iter 70/107 - loss 0.12988480 - samples/sec: 89.57 - lr: 0.100000
2022-05-13 15:45:48,595 epoch 5 - iter 80/107 - loss 0.12945730 - samples/sec: 90.33 - lr: 0.100000
2022-05-13 15:45:52,091 epoch 5 - iter 90/107 - loss 0.12987574 - samples/sec: 91.56 - lr: 0.100000
2022-05-13 15:45:55,457 epoch 5 - iter 100/107 - loss 0.12771054 - samples/sec: 95.08 - lr: 0.100000
2022-05-13 15:45:57,377 ----------------------------------------------------------------------------------------------------
2022-05-13 15:45:57,404 EPOCH 5 done: loss 0.1273 - lr 0.100000
2022-05-13 15:46:06,432 Evaluating as a multi-label problem: False
2022-05-13 15:46:06,443 DEV : loss 0.2018902450799942 - f1-score (micro avg)  0.4848
2022-05-13 15:46:06,516 BAD EPOCHS (no improvement): 0
2022-05-13 15:46:06,518 saving best model
2022-05-13 15:46:41,032 ----------------------------------------------------------------------------------------------------
2022-05-13 15:46:44,621 epoch 6 - iter 10/107 - loss 0.12340609 - samples/sec: 89.22 - lr: 0.100000
2022-05-13 15:46:48,166 epoch 6 - iter 20/107 - loss 0.11923879 - samples/sec: 90.28 - lr: 0.100000
2022-05-13 15:46:51,568 epoch 6 - iter 30/107 - loss 0.11892146 - samples/sec: 94.10 - lr: 0.100000
2022-05-13 15:46:54,931 epoch 6 - iter 40/107 - loss 0.12411220 - samples/sec: 95.17 - lr: 0.100000
2022-05-13 15:46:57,791 epoch 6 - iter 50/107 - loss 0.12498591 - samples/sec: 111.93 - lr: 0.100000
2022-05-13 15:47:00,427 epoch 6 - iter 60/107 - loss 0.12323118 - samples/sec: 121.46 - lr: 0.100000
2022-05-13 15:47:03,577 epoch 6 - iter 70/107 - loss 0.12403253 - samples/sec: 101.62 - lr: 0.100000
2022-05-13 15:47:07,243 epoch 6 - iter 80/107 - loss 0.12048345 - samples/sec: 87.31 - lr: 0.100000
2022-05-13 15:47:10,589 epoch 6 - iter 90/107 - loss 0.11870206 - samples/sec: 95.67 - lr: 0.100000
2022-05-13 15:47:14,041 epoch 6 - iter 100/107 - loss 0.11725747 - samples/sec: 92.72 - lr: 0.100000
2022-05-13 15:47:16,284 ----------------------------------------------------------------------------------------------------
2022-05-13 15:47:16,284 EPOCH 6 done: loss 0.1164 - lr 0.100000
2022-05-13 15:47:27,244 Evaluating as a multi-label problem: False
2022-05-13 15:47:27,254 DEV : loss 0.2574152648448944 - f1-score (micro avg)  0.4314
2022-05-13 15:47:27,330 BAD EPOCHS (no improvement): 1
2022-05-13 15:47:27,333 ----------------------------------------------------------------------------------------------------
2022-05-13 15:47:30,411 epoch 7 - iter 10/107 - loss 0.10662116 - samples/sec: 104.00 - lr: 0.100000
2022-05-13 15:47:33,598 epoch 7 - iter 20/107 - loss 0.11297748 - samples/sec: 100.43 - lr: 0.100000
2022-05-13 15:47:36,881 epoch 7 - iter 30/107 - loss 0.11030410 - samples/sec: 97.51 - lr: 0.100000
2022-05-13 15:47:40,348 epoch 7 - iter 40/107 - loss 0.10731370 - samples/sec: 92.30 - lr: 0.100000
2022-05-13 15:47:43,868 epoch 7 - iter 50/107 - loss 0.10437229 - samples/sec: 90.94 - lr: 0.100000
2022-05-13 15:47:46,728 epoch 7 - iter 60/107 - loss 0.10932087 - samples/sec: 111.92 - lr: 0.100000
2022-05-13 15:47:50,191 epoch 7 - iter 70/107 - loss 0.10799534 - samples/sec: 92.44 - lr: 0.100000
2022-05-13 15:47:53,900 epoch 7 - iter 80/107 - loss 0.10937623 - samples/sec: 86.29 - lr: 0.100000
2022-05-13 15:47:57,585 epoch 7 - iter 90/107 - loss 0.10962898 - samples/sec: 86.86 - lr: 0.100000
2022-05-13 15:48:01,316 epoch 7 - iter 100/107 - loss 0.10969973 - samples/sec: 85.80 - lr: 0.100000
2022-05-13 15:48:03,152 ----------------------------------------------------------------------------------------------------
2022-05-13 15:48:03,152 EPOCH 7 done: loss 0.1085 - lr 0.100000
2022-05-13 15:48:12,855 Evaluating as a multi-label problem: False
2022-05-13 15:48:12,865 DEV : loss 0.21710382401943207 - f1-score (micro avg)  0.4676
2022-05-13 15:48:12,942 BAD EPOCHS (no improvement): 2
2022-05-13 15:48:12,945 ----------------------------------------------------------------------------------------------------
2022-05-13 15:48:16,645 epoch 8 - iter 10/107 - loss 0.09675242 - samples/sec: 86.50 - lr: 0.100000
2022-05-13 15:48:20,395 epoch 8 - iter 20/107 - loss 0.10597720 - samples/sec: 85.35 - lr: 0.100000
2022-05-13 15:48:23,974 epoch 8 - iter 30/107 - loss 0.11012599 - samples/sec: 89.45 - lr: 0.100000
2022-05-13 15:48:27,664 epoch 8 - iter 40/107 - loss 0.10849448 - samples/sec: 86.73 - lr: 0.100000
2022-05-13 15:48:31,134 epoch 8 - iter 50/107 - loss 0.10577244 - samples/sec: 92.23 - lr: 0.100000
2022-05-13 15:48:34,202 epoch 8 - iter 60/107 - loss 0.10342724 - samples/sec: 104.35 - lr: 0.100000
2022-05-13 15:48:37,111 epoch 8 - iter 70/107 - loss 0.10253407 - samples/sec: 110.03 - lr: 0.100000
2022-05-13 15:48:40,212 epoch 8 - iter 80/107 - loss 0.10125731 - samples/sec: 103.23 - lr: 0.100000
2022-05-13 15:48:43,619 epoch 8 - iter 90/107 - loss 0.10155527 - samples/sec: 93.96 - lr: 0.100000
2022-05-13 15:48:47,063 epoch 8 - iter 100/107 - loss 0.10031892 - samples/sec: 92.94 - lr: 0.100000
2022-05-13 15:48:49,262 ----------------------------------------------------------------------------------------------------
2022-05-13 15:48:49,262 EPOCH 8 done: loss 0.1009 - lr 0.100000
2022-05-13 15:49:00,051 Evaluating as a multi-label problem: False
2022-05-13 15:49:00,062 DEV : loss 0.2458776831626892 - f1-score (micro avg)  0.4448
2022-05-13 15:49:00,138 BAD EPOCHS (no improvement): 3
2022-05-13 15:49:00,139 ----------------------------------------------------------------------------------------------------
2022-05-13 15:49:03,604 epoch 9 - iter 10/107 - loss 0.09230252 - samples/sec: 92.41 - lr: 0.100000
2022-05-13 15:49:06,810 epoch 9 - iter 20/107 - loss 0.09208436 - samples/sec: 99.82 - lr: 0.100000
2022-05-13 15:49:09,808 epoch 9 - iter 30/107 - loss 0.09319787 - samples/sec: 106.77 - lr: 0.100000
2022-05-13 15:49:13,322 epoch 9 - iter 40/107 - loss 0.09508601 - samples/sec: 91.11 - lr: 0.100000
2022-05-13 15:49:17,015 epoch 9 - iter 50/107 - loss 0.09550385 - samples/sec: 86.66 - lr: 0.100000
2022-05-13 15:49:20,833 epoch 9 - iter 60/107 - loss 0.09566546 - samples/sec: 84.79 - lr: 0.100000
2022-05-13 15:49:24,537 epoch 9 - iter 70/107 - loss 0.09635842 - samples/sec: 86.40 - lr: 0.100000
2022-05-13 15:49:28,184 epoch 9 - iter 80/107 - loss 0.09469676 - samples/sec: 87.78 - lr: 0.100000
2022-05-13 15:49:31,827 epoch 9 - iter 90/107 - loss 0.09576292 - samples/sec: 87.88 - lr: 0.100000
2022-05-13 15:49:35,075 epoch 9 - iter 100/107 - loss 0.09550095 - samples/sec: 98.53 - lr: 0.100000
2022-05-13 15:49:36,967 ----------------------------------------------------------------------------------------------------
2022-05-13 15:49:36,967 EPOCH 9 done: loss 0.0945 - lr 0.100000
2022-05-13 15:49:47,046 Evaluating as a multi-label problem: False
2022-05-13 15:49:47,059 DEV : loss 0.200239896774292 - f1-score (micro avg)  0.4765
2022-05-13 15:49:47,135 Epoch     9: reducing learning rate of group 0 to 5.0000e-02.
2022-05-13 15:49:47,135 BAD EPOCHS (no improvement): 4
2022-05-13 15:49:47,138 ----------------------------------------------------------------------------------------------------
2022-05-13 15:49:50,842 epoch 10 - iter 10/107 - loss 0.08802325 - samples/sec: 86.44 - lr: 0.050000
2022-05-13 15:49:54,684 epoch 10 - iter 20/107 - loss 0.08787875 - samples/sec: 83.30 - lr: 0.050000
2022-05-13 15:49:58,248 epoch 10 - iter 30/107 - loss 0.08326587 - samples/sec: 89.81 - lr: 0.050000
2022-05-13 15:50:01,949 epoch 10 - iter 40/107 - loss 0.08762682 - samples/sec: 86.49 - lr: 0.050000
2022-05-13 15:50:05,372 epoch 10 - iter 50/107 - loss 0.08815099 - samples/sec: 93.51 - lr: 0.050000
2022-05-13 15:50:08,452 epoch 10 - iter 60/107 - loss 0.08455365 - samples/sec: 103.91 - lr: 0.050000
2022-05-13 15:50:11,330 epoch 10 - iter 70/107 - loss 0.08454808 - samples/sec: 111.24 - lr: 0.050000
2022-05-13 15:50:14,900 epoch 10 - iter 80/107 - loss 0.08359477 - samples/sec: 89.68 - lr: 0.050000
2022-05-13 15:50:18,459 epoch 10 - iter 90/107 - loss 0.08383281 - samples/sec: 89.94 - lr: 0.050000
2022-05-13 15:50:22,104 epoch 10 - iter 100/107 - loss 0.08397703 - samples/sec: 87.82 - lr: 0.050000
2022-05-13 15:50:24,333 ----------------------------------------------------------------------------------------------------
2022-05-13 15:50:24,333 EPOCH 10 done: loss 0.0842 - lr 0.050000
2022-05-13 15:50:34,998 Evaluating as a multi-label problem: False
2022-05-13 15:50:35,009 DEV : loss 0.18722069263458252 - f1-score (micro avg)  0.5074
2022-05-13 15:50:35,085 BAD EPOCHS (no improvement): 0
2022-05-13 15:50:35,092 saving best model
2022-05-13 15:51:10,391 ----------------------------------------------------------------------------------------------------
2022-05-13 15:51:14,117 epoch 11 - iter 10/107 - loss 0.07301998 - samples/sec: 85.93 - lr: 0.050000
2022-05-13 15:51:17,722 epoch 11 - iter 20/107 - loss 0.07034332 - samples/sec: 88.80 - lr: 0.050000
2022-05-13 15:51:21,394 epoch 11 - iter 30/107 - loss 0.07128129 - samples/sec: 87.16 - lr: 0.050000
2022-05-13 15:51:24,447 epoch 11 - iter 40/107 - loss 0.07299975 - samples/sec: 104.86 - lr: 0.050000
2022-05-13 15:51:27,597 epoch 11 - iter 50/107 - loss 0.07587394 - samples/sec: 101.61 - lr: 0.050000
2022-05-13 15:51:30,979 epoch 11 - iter 60/107 - loss 0.07641657 - samples/sec: 94.64 - lr: 0.050000
2022-05-13 15:51:34,746 epoch 11 - iter 70/107 - loss 0.07810621 - samples/sec: 84.99 - lr: 0.050000
2022-05-13 15:51:38,252 epoch 11 - iter 80/107 - loss 0.07883934 - samples/sec: 91.27 - lr: 0.050000
2022-05-13 15:51:41,888 epoch 11 - iter 90/107 - loss 0.07925497 - samples/sec: 88.05 - lr: 0.050000
2022-05-13 15:51:45,315 epoch 11 - iter 100/107 - loss 0.08121819 - samples/sec: 93.42 - lr: 0.050000
2022-05-13 15:51:47,686 ----------------------------------------------------------------------------------------------------
2022-05-13 15:51:47,686 EPOCH 11 done: loss 0.0810 - lr 0.050000
2022-05-13 15:51:57,635 Evaluating as a multi-label problem: False
2022-05-13 15:51:57,647 DEV : loss 0.20901629328727722 - f1-score (micro avg)  0.5012
2022-05-13 15:51:57,721 BAD EPOCHS (no improvement): 1
2022-05-13 15:51:57,723 ----------------------------------------------------------------------------------------------------
2022-05-13 15:52:00,977 epoch 12 - iter 10/107 - loss 0.06972201 - samples/sec: 98.41 - lr: 0.050000
2022-05-13 15:52:04,710 epoch 12 - iter 20/107 - loss 0.07462631 - samples/sec: 85.75 - lr: 0.050000
2022-05-13 15:52:08,468 epoch 12 - iter 30/107 - loss 0.07137013 - samples/sec: 85.16 - lr: 0.050000
2022-05-13 15:52:12,007 epoch 12 - iter 40/107 - loss 0.06950748 - samples/sec: 90.46 - lr: 0.050000
2022-05-13 15:52:15,612 epoch 12 - iter 50/107 - loss 0.07253042 - samples/sec: 88.77 - lr: 0.050000
2022-05-13 15:52:19,314 epoch 12 - iter 60/107 - loss 0.07512971 - samples/sec: 86.47 - lr: 0.050000
2022-05-13 15:52:22,782 epoch 12 - iter 70/107 - loss 0.07728380 - samples/sec: 92.28 - lr: 0.050000
2022-05-13 15:52:26,093 epoch 12 - iter 80/107 - loss 0.07694902 - samples/sec: 96.70 - lr: 0.050000
2022-05-13 15:52:29,008 epoch 12 - iter 90/107 - loss 0.07607733 - samples/sec: 109.81 - lr: 0.050000
2022-05-13 15:52:32,224 epoch 12 - iter 100/107 - loss 0.07698857 - samples/sec: 99.53 - lr: 0.050000
2022-05-13 15:52:34,426 ----------------------------------------------------------------------------------------------------
2022-05-13 15:52:34,426 EPOCH 12 done: loss 0.0778 - lr 0.050000
2022-05-13 15:52:45,095 Evaluating as a multi-label problem: False
2022-05-13 15:52:45,106 DEV : loss 0.18501022458076477 - f1-score (micro avg)  0.5027
2022-05-13 15:52:45,179 BAD EPOCHS (no improvement): 2
2022-05-13 15:52:45,183 ----------------------------------------------------------------------------------------------------
2022-05-13 15:52:48,942 epoch 13 - iter 10/107 - loss 0.06938418 - samples/sec: 85.15 - lr: 0.050000
2022-05-13 15:52:52,636 epoch 13 - iter 20/107 - loss 0.07070310 - samples/sec: 86.66 - lr: 0.050000
2022-05-13 15:52:56,020 epoch 13 - iter 30/107 - loss 0.06921203 - samples/sec: 94.60 - lr: 0.050000
2022-05-13 15:52:59,263 epoch 13 - iter 40/107 - loss 0.07130539 - samples/sec: 98.68 - lr: 0.050000
2022-05-13 15:53:02,257 epoch 13 - iter 50/107 - loss 0.07218050 - samples/sec: 106.93 - lr: 0.050000
2022-05-13 15:53:05,688 epoch 13 - iter 60/107 - loss 0.07180021 - samples/sec: 93.29 - lr: 0.050000
2022-05-13 15:53:09,177 epoch 13 - iter 70/107 - loss 0.07068930 - samples/sec: 91.75 - lr: 0.050000
2022-05-13 15:53:12,783 epoch 13 - iter 80/107 - loss 0.07154850 - samples/sec: 88.76 - lr: 0.050000
2022-05-13 15:53:16,321 epoch 13 - iter 90/107 - loss 0.07079863 - samples/sec: 90.47 - lr: 0.050000
2022-05-13 15:53:19,938 epoch 13 - iter 100/107 - loss 0.07128852 - samples/sec: 88.51 - lr: 0.050000
2022-05-13 15:53:22,228 ----------------------------------------------------------------------------------------------------
2022-05-13 15:53:22,228 EPOCH 13 done: loss 0.0719 - lr 0.050000
2022-05-13 15:53:32,015 Evaluating as a multi-label problem: False
2022-05-13 15:53:32,025 DEV : loss 0.22549067437648773 - f1-score (micro avg)  0.4619
2022-05-13 15:53:32,099 BAD EPOCHS (no improvement): 3
2022-05-13 15:53:32,153 ----------------------------------------------------------------------------------------------------
2022-05-13 15:53:35,341 epoch 14 - iter 10/107 - loss 0.07099770 - samples/sec: 100.44 - lr: 0.050000
2022-05-13 15:53:38,793 epoch 14 - iter 20/107 - loss 0.07335689 - samples/sec: 92.71 - lr: 0.050000
2022-05-13 15:53:42,513 epoch 14 - iter 30/107 - loss 0.07392226 - samples/sec: 86.04 - lr: 0.050000
2022-05-13 15:53:46,283 epoch 14 - iter 40/107 - loss 0.07384712 - samples/sec: 84.92 - lr: 0.050000
2022-05-13 15:53:49,755 epoch 14 - iter 50/107 - loss 0.07642460 - samples/sec: 92.17 - lr: 0.050000
2022-05-13 15:53:53,424 epoch 14 - iter 60/107 - loss 0.07695619 - samples/sec: 87.25 - lr: 0.050000
2022-05-13 15:53:57,049 epoch 14 - iter 70/107 - loss 0.07321151 - samples/sec: 88.31 - lr: 0.050000
2022-05-13 15:54:00,275 epoch 14 - iter 80/107 - loss 0.07294601 - samples/sec: 99.20 - lr: 0.050000
2022-05-13 15:54:03,308 epoch 14 - iter 90/107 - loss 0.07268852 - samples/sec: 105.57 - lr: 0.050000
2022-05-13 15:54:06,565 epoch 14 - iter 100/107 - loss 0.07231758 - samples/sec: 98.29 - lr: 0.050000
2022-05-13 15:54:08,831 ----------------------------------------------------------------------------------------------------
2022-05-13 15:54:08,831 EPOCH 14 done: loss 0.0717 - lr 0.050000
2022-05-13 15:54:19,416 Evaluating as a multi-label problem: False
2022-05-13 15:54:19,427 DEV : loss 0.20845068991184235 - f1-score (micro avg)  0.4772
2022-05-13 15:54:19,499 Epoch    14: reducing learning rate of group 0 to 2.5000e-02.
2022-05-13 15:54:19,499 BAD EPOCHS (no improvement): 4
2022-05-13 15:54:19,501 ----------------------------------------------------------------------------------------------------
2022-05-13 15:54:23,045 epoch 15 - iter 10/107 - loss 0.06561266 - samples/sec: 90.33 - lr: 0.025000
2022-05-13 15:54:26,789 epoch 15 - iter 20/107 - loss 0.06323210 - samples/sec: 85.48 - lr: 0.025000
2022-05-13 15:54:30,288 epoch 15 - iter 30/107 - loss 0.06515544 - samples/sec: 91.49 - lr: 0.025000
2022-05-13 15:54:33,406 epoch 15 - iter 40/107 - loss 0.06601716 - samples/sec: 102.65 - lr: 0.025000
2022-05-13 15:54:36,410 epoch 15 - iter 50/107 - loss 0.06506290 - samples/sec: 106.56 - lr: 0.025000
2022-05-13 15:54:39,979 epoch 15 - iter 60/107 - loss 0.06445505 - samples/sec: 89.67 - lr: 0.025000
2022-05-13 15:54:43,389 epoch 15 - iter 70/107 - loss 0.06389039 - samples/sec: 93.88 - lr: 0.025000
2022-05-13 15:54:46,916 epoch 15 - iter 80/107 - loss 0.06366095 - samples/sec: 90.75 - lr: 0.025000
2022-05-13 15:54:50,585 epoch 15 - iter 90/107 - loss 0.06485536 - samples/sec: 87.26 - lr: 0.025000
2022-05-13 15:54:54,258 epoch 15 - iter 100/107 - loss 0.06598533 - samples/sec: 87.14 - lr: 0.025000
2022-05-13 15:54:56,599 ----------------------------------------------------------------------------------------------------
2022-05-13 15:54:56,599 EPOCH 15 done: loss 0.0660 - lr 0.025000
2022-05-13 15:55:05,818 Evaluating as a multi-label problem: False
2022-05-13 15:55:05,829 DEV : loss 0.19650804996490479 - f1-score (micro avg)  0.5035
2022-05-13 15:55:05,903 BAD EPOCHS (no improvement): 1
2022-05-13 15:55:05,921 ----------------------------------------------------------------------------------------------------
2022-05-13 15:55:09,264 epoch 16 - iter 10/107 - loss 0.06507849 - samples/sec: 95.75 - lr: 0.025000
2022-05-13 15:55:12,969 epoch 16 - iter 20/107 - loss 0.05890428 - samples/sec: 86.39 - lr: 0.025000
2022-05-13 15:55:16,635 epoch 16 - iter 30/107 - loss 0.06057405 - samples/sec: 87.32 - lr: 0.025000
2022-05-13 15:55:20,186 epoch 16 - iter 40/107 - loss 0.05975671 - samples/sec: 90.12 - lr: 0.025000
2022-05-13 15:55:23,737 epoch 16 - iter 50/107 - loss 0.06125097 - samples/sec: 90.14 - lr: 0.025000
2022-05-13 15:55:27,333 epoch 16 - iter 60/107 - loss 0.06268247 - samples/sec: 89.02 - lr: 0.025000
2022-05-13 15:55:30,929 epoch 16 - iter 70/107 - loss 0.06489514 - samples/sec: 89.02 - lr: 0.025000
2022-05-13 15:55:34,321 epoch 16 - iter 80/107 - loss 0.06567322 - samples/sec: 94.36 - lr: 0.025000
2022-05-13 15:55:37,243 epoch 16 - iter 90/107 - loss 0.06633243 - samples/sec: 109.55 - lr: 0.025000
2022-05-13 15:55:40,310 epoch 16 - iter 100/107 - loss 0.06593843 - samples/sec: 104.38 - lr: 0.025000
2022-05-13 15:55:42,511 ----------------------------------------------------------------------------------------------------
2022-05-13 15:55:42,512 EPOCH 16 done: loss 0.0655 - lr 0.025000
2022-05-13 15:55:53,461 Evaluating as a multi-label problem: False
2022-05-13 15:55:53,472 DEV : loss 0.2053554207086563 - f1-score (micro avg)  0.4815
2022-05-13 15:55:53,545 BAD EPOCHS (no improvement): 2
2022-05-13 15:55:53,548 ----------------------------------------------------------------------------------------------------
2022-05-13 15:55:57,458 epoch 17 - iter 10/107 - loss 0.07420056 - samples/sec: 81.86 - lr: 0.025000
2022-05-13 15:56:01,267 epoch 17 - iter 20/107 - loss 0.06747649 - samples/sec: 84.03 - lr: 0.025000
2022-05-13 15:56:04,926 epoch 17 - iter 30/107 - loss 0.06896106 - samples/sec: 87.48 - lr: 0.025000
2022-05-13 15:56:07,737 epoch 17 - iter 40/107 - loss 0.06557946 - samples/sec: 113.88 - lr: 0.025000
2022-05-13 15:56:10,624 epoch 17 - iter 50/107 - loss 0.06307897 - samples/sec: 110.88 - lr: 0.025000
2022-05-13 15:56:14,111 epoch 17 - iter 60/107 - loss 0.06525973 - samples/sec: 91.78 - lr: 0.025000
2022-05-13 15:56:17,723 epoch 17 - iter 70/107 - loss 0.06419354 - samples/sec: 88.62 - lr: 0.025000
2022-05-13 15:56:21,228 epoch 17 - iter 80/107 - loss 0.06456092 - samples/sec: 91.32 - lr: 0.025000
2022-05-13 15:56:25,057 epoch 17 - iter 90/107 - loss 0.06283419 - samples/sec: 83.62 - lr: 0.025000
2022-05-13 15:56:28,524 epoch 17 - iter 100/107 - loss 0.06232203 - samples/sec: 92.33 - lr: 0.025000
2022-05-13 15:56:30,825 ----------------------------------------------------------------------------------------------------
2022-05-13 15:56:30,825 EPOCH 17 done: loss 0.0623 - lr 0.025000
2022-05-13 15:56:40,358 Evaluating as a multi-label problem: False
2022-05-13 15:56:40,369 DEV : loss 0.2036769688129425 - f1-score (micro avg)  0.4956
2022-05-13 15:56:40,442 BAD EPOCHS (no improvement): 3
2022-05-13 15:56:40,444 ----------------------------------------------------------------------------------------------------
2022-05-13 15:56:43,933 epoch 18 - iter 10/107 - loss 0.06821651 - samples/sec: 91.75 - lr: 0.025000
2022-05-13 15:56:47,494 epoch 18 - iter 20/107 - loss 0.06276802 - samples/sec: 89.89 - lr: 0.025000
2022-05-13 15:56:51,213 epoch 18 - iter 30/107 - loss 0.06077888 - samples/sec: 86.05 - lr: 0.025000
2022-05-13 15:56:54,933 epoch 18 - iter 40/107 - loss 0.05999667 - samples/sec: 86.04 - lr: 0.025000
2022-05-13 15:56:58,527 epoch 18 - iter 50/107 - loss 0.06252179 - samples/sec: 89.06 - lr: 0.025000
2022-05-13 15:57:02,192 epoch 18 - iter 60/107 - loss 0.06133097 - samples/sec: 87.35 - lr: 0.025000
2022-05-13 15:57:05,712 epoch 18 - iter 70/107 - loss 0.06084458 - samples/sec: 90.92 - lr: 0.025000
2022-05-13 15:57:08,845 epoch 18 - iter 80/107 - loss 0.06023808 - samples/sec: 102.16 - lr: 0.025000
2022-05-13 15:57:11,796 epoch 18 - iter 90/107 - loss 0.06148753 - samples/sec: 108.49 - lr: 0.025000
2022-05-13 15:57:15,184 epoch 18 - iter 100/107 - loss 0.06101463 - samples/sec: 94.48 - lr: 0.025000
2022-05-13 15:57:17,271 ----------------------------------------------------------------------------------------------------
2022-05-13 15:57:17,272 EPOCH 18 done: loss 0.0614 - lr 0.025000
2022-05-13 15:57:28,087 Evaluating as a multi-label problem: False
2022-05-13 15:57:28,097 DEV : loss 0.1993129998445511 - f1-score (micro avg)  0.5008
2022-05-13 15:57:28,172 Epoch    18: reducing learning rate of group 0 to 1.2500e-02.
2022-05-13 15:57:28,172 BAD EPOCHS (no improvement): 4
2022-05-13 15:57:28,174 ----------------------------------------------------------------------------------------------------
2022-05-13 15:57:31,945 epoch 19 - iter 10/107 - loss 0.05282553 - samples/sec: 84.89 - lr: 0.012500
2022-05-13 15:57:35,595 epoch 19 - iter 20/107 - loss 0.05662018 - samples/sec: 87.69 - lr: 0.012500
2022-05-13 15:57:38,774 epoch 19 - iter 30/107 - loss 0.05561389 - samples/sec: 100.68 - lr: 0.012500
2022-05-13 15:57:41,773 epoch 19 - iter 40/107 - loss 0.05409240 - samples/sec: 106.74 - lr: 0.012500
2022-05-13 15:57:45,097 epoch 19 - iter 50/107 - loss 0.05567382 - samples/sec: 96.29 - lr: 0.012500
2022-05-13 15:57:48,893 epoch 19 - iter 60/107 - loss 0.05748476 - samples/sec: 84.33 - lr: 0.012500
2022-05-13 15:57:52,342 epoch 19 - iter 70/107 - loss 0.05800277 - samples/sec: 92.79 - lr: 0.012500
2022-05-13 15:57:56,040 epoch 19 - iter 80/107 - loss 0.05710026 - samples/sec: 86.58 - lr: 0.012500
2022-05-13 15:57:59,731 epoch 19 - iter 90/107 - loss 0.05724912 - samples/sec: 86.71 - lr: 0.012500
2022-05-13 15:58:03,400 epoch 19 - iter 100/107 - loss 0.05632348 - samples/sec: 87.25 - lr: 0.012500
2022-05-13 15:58:05,657 ----------------------------------------------------------------------------------------------------
2022-05-13 15:58:05,657 EPOCH 19 done: loss 0.0566 - lr 0.012500
2022-05-13 15:58:15,057 Evaluating as a multi-label problem: False
2022-05-13 15:58:15,068 DEV : loss 0.21393869817256927 - f1-score (micro avg)  0.4793
2022-05-13 15:58:15,145 BAD EPOCHS (no improvement): 1
2022-05-13 15:58:15,155 ----------------------------------------------------------------------------------------------------
2022-05-13 15:58:18,736 epoch 20 - iter 10/107 - loss 0.05368065 - samples/sec: 89.38 - lr: 0.012500
2022-05-13 15:58:22,521 epoch 20 - iter 20/107 - loss 0.05243175 - samples/sec: 84.58 - lr: 0.012500
2022-05-13 15:58:26,088 epoch 20 - iter 30/107 - loss 0.05627703 - samples/sec: 89.73 - lr: 0.012500
2022-05-13 15:58:29,790 epoch 20 - iter 40/107 - loss 0.05643663 - samples/sec: 86.47 - lr: 0.012500
2022-05-13 15:58:33,521 epoch 20 - iter 50/107 - loss 0.05643993 - samples/sec: 85.78 - lr: 0.012500
2022-05-13 15:58:36,939 epoch 20 - iter 60/107 - loss 0.05703620 - samples/sec: 93.64 - lr: 0.012500
2022-05-13 15:58:40,237 epoch 20 - iter 70/107 - loss 0.05802063 - samples/sec: 97.06 - lr: 0.012500
2022-05-13 15:58:43,190 epoch 20 - iter 80/107 - loss 0.05685707 - samples/sec: 108.42 - lr: 0.012500
2022-05-13 15:58:46,276 epoch 20 - iter 90/107 - loss 0.05633484 - samples/sec: 103.72 - lr: 0.012500
2022-05-13 15:58:50,021 epoch 20 - iter 100/107 - loss 0.05687327 - samples/sec: 85.46 - lr: 0.012500
2022-05-13 15:58:52,279 ----------------------------------------------------------------------------------------------------
2022-05-13 15:58:52,280 EPOCH 20 done: loss 0.0567 - lr 0.012500
2022-05-13 15:59:02,895 Evaluating as a multi-label problem: False
2022-05-13 15:59:02,905 DEV : loss 0.20289412140846252 - f1-score (micro avg)  0.4992
2022-05-13 15:59:02,981 BAD EPOCHS (no improvement): 2
2022-05-13 15:59:02,983 ----------------------------------------------------------------------------------------------------
2022-05-13 15:59:06,562 epoch 21 - iter 10/107 - loss 0.06399490 - samples/sec: 89.44 - lr: 0.012500
2022-05-13 15:59:10,071 epoch 21 - iter 20/107 - loss 0.06026565 - samples/sec: 91.21 - lr: 0.012500
2022-05-13 15:59:13,191 epoch 21 - iter 30/107 - loss 0.06112311 - samples/sec: 102.61 - lr: 0.012500
2022-05-13 15:59:16,210 epoch 21 - iter 40/107 - loss 0.05957997 - samples/sec: 106.02 - lr: 0.012500
2022-05-13 15:59:19,936 epoch 21 - iter 50/107 - loss 0.05852593 - samples/sec: 85.90 - lr: 0.012500
2022-05-13 15:59:23,332 epoch 21 - iter 60/107 - loss 0.05816443 - samples/sec: 94.28 - lr: 0.012500
2022-05-13 15:59:26,987 epoch 21 - iter 70/107 - loss 0.05787787 - samples/sec: 87.56 - lr: 0.012500
2022-05-13 15:59:30,586 epoch 21 - iter 80/107 - loss 0.05785424 - samples/sec: 88.95 - lr: 0.012500
2022-05-13 15:59:34,365 epoch 21 - iter 90/107 - loss 0.05766772 - samples/sec: 84.71 - lr: 0.012500
2022-05-13 15:59:38,110 epoch 21 - iter 100/107 - loss 0.05668635 - samples/sec: 85.47 - lr: 0.012500
2022-05-13 15:59:40,331 ----------------------------------------------------------------------------------------------------
2022-05-13 15:59:40,331 EPOCH 21 done: loss 0.0563 - lr 0.012500
2022-05-13 15:59:49,653 Evaluating as a multi-label problem: False
2022-05-13 15:59:49,665 DEV : loss 0.21205784380435944 - f1-score (micro avg)  0.4936
2022-05-13 15:59:49,741 BAD EPOCHS (no improvement): 3
2022-05-13 15:59:49,809 ----------------------------------------------------------------------------------------------------
2022-05-13 15:59:53,264 epoch 22 - iter 10/107 - loss 0.04624972 - samples/sec: 92.66 - lr: 0.012500
2022-05-13 15:59:56,946 epoch 22 - iter 20/107 - loss 0.05178066 - samples/sec: 86.93 - lr: 0.012500
2022-05-13 16:00:00,561 epoch 22 - iter 30/107 - loss 0.04700489 - samples/sec: 88.52 - lr: 0.012500
2022-05-13 16:00:04,039 epoch 22 - iter 40/107 - loss 0.04960760 - samples/sec: 92.05 - lr: 0.012500
2022-05-13 16:00:07,896 epoch 22 - iter 50/107 - loss 0.05136097 - samples/sec: 82.99 - lr: 0.012500
2022-05-13 16:00:11,339 epoch 22 - iter 60/107 - loss 0.05279735 - samples/sec: 92.97 - lr: 0.012500
2022-05-13 16:00:14,582 epoch 22 - iter 70/107 - loss 0.05338070 - samples/sec: 98.70 - lr: 0.012500
2022-05-13 16:00:17,692 epoch 22 - iter 80/107 - loss 0.05408980 - samples/sec: 102.91 - lr: 0.012500
2022-05-13 16:00:21,002 epoch 22 - iter 90/107 - loss 0.05458572 - samples/sec: 96.71 - lr: 0.012500
2022-05-13 16:00:24,572 epoch 22 - iter 100/107 - loss 0.05554348 - samples/sec: 89.68 - lr: 0.012500
2022-05-13 16:00:26,824 ----------------------------------------------------------------------------------------------------
2022-05-13 16:00:26,824 EPOCH 22 done: loss 0.0552 - lr 0.012500
2022-05-13 16:00:37,727 Evaluating as a multi-label problem: False
2022-05-13 16:00:37,739 DEV : loss 0.2068699449300766 - f1-score (micro avg)  0.4904
2022-05-13 16:00:37,816 Epoch    22: reducing learning rate of group 0 to 6.2500e-03.
2022-05-13 16:00:37,816 BAD EPOCHS (no improvement): 4
2022-05-13 16:00:37,859 ----------------------------------------------------------------------------------------------------
2022-05-13 16:00:41,370 epoch 23 - iter 10/107 - loss 0.06210497 - samples/sec: 91.18 - lr: 0.006250
2022-05-13 16:00:44,620 epoch 23 - iter 20/107 - loss 0.05315666 - samples/sec: 98.47 - lr: 0.006250
2022-05-13 16:00:47,494 epoch 23 - iter 30/107 - loss 0.05307312 - samples/sec: 111.40 - lr: 0.006250
2022-05-13 16:00:50,671 epoch 23 - iter 40/107 - loss 0.05384967 - samples/sec: 100.76 - lr: 0.006250
2022-05-13 16:00:54,425 epoch 23 - iter 50/107 - loss 0.05408672 - samples/sec: 85.25 - lr: 0.006250
2022-05-13 16:00:57,972 epoch 23 - iter 60/107 - loss 0.05438169 - samples/sec: 90.25 - lr: 0.006250
2022-05-13 16:01:01,922 epoch 23 - iter 70/107 - loss 0.05246293 - samples/sec: 81.02 - lr: 0.006250
2022-05-13 16:01:05,702 epoch 23 - iter 80/107 - loss 0.05291652 - samples/sec: 84.68 - lr: 0.006250
2022-05-13 16:01:09,530 epoch 23 - iter 90/107 - loss 0.05334659 - samples/sec: 83.63 - lr: 0.006250
2022-05-13 16:01:12,935 epoch 23 - iter 100/107 - loss 0.05280772 - samples/sec: 94.01 - lr: 0.006250
2022-05-13 16:01:14,869 ----------------------------------------------------------------------------------------------------
2022-05-13 16:01:14,869 EPOCH 23 done: loss 0.0529 - lr 0.006250
2022-05-13 16:01:23,154 Evaluating as a multi-label problem: False
2022-05-13 16:01:23,165 DEV : loss 0.20513908565044403 - f1-score (micro avg)  0.4897
2022-05-13 16:01:23,241 BAD EPOCHS (no improvement): 1
2022-05-13 16:01:23,243 ----------------------------------------------------------------------------------------------------
2022-05-13 16:01:25,860 epoch 24 - iter 10/107 - loss 0.04589607 - samples/sec: 122.35 - lr: 0.006250
2022-05-13 16:01:28,441 epoch 24 - iter 20/107 - loss 0.04965140 - samples/sec: 124.00 - lr: 0.006250
2022-05-13 16:01:30,920 epoch 24 - iter 30/107 - loss 0.05355272 - samples/sec: 129.16 - lr: 0.006250
2022-05-13 16:01:33,324 epoch 24 - iter 40/107 - loss 0.05238478 - samples/sec: 133.18 - lr: 0.006250
2022-05-13 16:01:35,714 epoch 24 - iter 50/107 - loss 0.05110588 - samples/sec: 133.94 - lr: 0.006250
2022-05-13 16:01:38,212 epoch 24 - iter 60/107 - loss 0.05229938 - samples/sec: 128.12 - lr: 0.006250
2022-05-13 16:01:40,688 epoch 24 - iter 70/107 - loss 0.05290169 - samples/sec: 129.29 - lr: 0.006250
2022-05-13 16:01:43,246 epoch 24 - iter 80/107 - loss 0.05319161 - samples/sec: 125.15 - lr: 0.006250
2022-05-13 16:01:45,760 epoch 24 - iter 90/107 - loss 0.05320022 - samples/sec: 127.33 - lr: 0.006250
2022-05-13 16:01:48,153 epoch 24 - iter 100/107 - loss 0.05387593 - samples/sec: 133.77 - lr: 0.006250
2022-05-13 16:01:49,673 ----------------------------------------------------------------------------------------------------
2022-05-13 16:01:49,674 EPOCH 24 done: loss 0.0543 - lr 0.006250
2022-05-13 16:01:58,441 Evaluating as a multi-label problem: False
2022-05-13 16:01:58,454 DEV : loss 0.20445460081100464 - f1-score (micro avg)  0.4968
2022-05-13 16:01:58,528 BAD EPOCHS (no improvement): 2
2022-05-13 16:01:58,542 ----------------------------------------------------------------------------------------------------
2022-05-13 16:02:04,098 epoch 25 - iter 10/107 - loss 0.05767866 - samples/sec: 57.61 - lr: 0.006250
2022-05-13 16:02:08,957 epoch 25 - iter 20/107 - loss 0.05530311 - samples/sec: 65.87 - lr: 0.006250
2022-05-13 16:02:14,495 epoch 25 - iter 30/107 - loss 0.05647834 - samples/sec: 57.79 - lr: 0.006250
2022-05-13 16:02:18,702 epoch 25 - iter 40/107 - loss 0.05680021 - samples/sec: 76.09 - lr: 0.006250
2022-05-13 16:02:22,312 epoch 25 - iter 50/107 - loss 0.05520711 - samples/sec: 88.67 - lr: 0.006250
2022-05-13 16:02:25,980 epoch 25 - iter 60/107 - loss 0.05450920 - samples/sec: 87.26 - lr: 0.006250
2022-05-13 16:02:29,568 epoch 25 - iter 70/107 - loss 0.05525710 - samples/sec: 89.20 - lr: 0.006250
2022-05-13 16:02:33,061 epoch 25 - iter 80/107 - loss 0.05461279 - samples/sec: 91.63 - lr: 0.006250
2022-05-13 16:02:36,868 epoch 25 - iter 90/107 - loss 0.05493060 - samples/sec: 84.10 - lr: 0.006250
2022-05-13 16:02:40,841 epoch 25 - iter 100/107 - loss 0.05428452 - samples/sec: 80.56 - lr: 0.006250
2022-05-13 16:02:42,783 ----------------------------------------------------------------------------------------------------
2022-05-13 16:02:42,783 EPOCH 25 done: loss 0.0533 - lr 0.006250
2022-05-13 16:02:51,106 Evaluating as a multi-label problem: False
2022-05-13 16:02:51,117 DEV : loss 0.20826835930347443 - f1-score (micro avg)  0.5016
2022-05-13 16:02:51,191 BAD EPOCHS (no improvement): 3
2022-05-13 16:02:51,201 ----------------------------------------------------------------------------------------------------
2022-05-13 16:02:53,785 epoch 26 - iter 10/107 - loss 0.05177761 - samples/sec: 123.88 - lr: 0.006250
2022-05-13 16:02:56,226 epoch 26 - iter 20/107 - loss 0.05157139 - samples/sec: 131.18 - lr: 0.006250
2022-05-13 16:02:58,715 epoch 26 - iter 30/107 - loss 0.05089086 - samples/sec: 128.59 - lr: 0.006250
2022-05-13 16:03:01,097 epoch 26 - iter 40/107 - loss 0.05286409 - samples/sec: 134.43 - lr: 0.006250
2022-05-13 16:03:03,552 epoch 26 - iter 50/107 - loss 0.05108801 - samples/sec: 130.36 - lr: 0.006250
2022-05-13 16:03:06,056 epoch 26 - iter 60/107 - loss 0.05226786 - samples/sec: 127.87 - lr: 0.006250
2022-05-13 16:03:08,568 epoch 26 - iter 70/107 - loss 0.05290671 - samples/sec: 127.41 - lr: 0.006250
2022-05-13 16:03:12,181 epoch 26 - iter 80/107 - loss 0.05176513 - samples/sec: 88.59 - lr: 0.006250
2022-05-13 16:03:15,796 epoch 26 - iter 90/107 - loss 0.05162736 - samples/sec: 88.53 - lr: 0.006250
2022-05-13 16:03:19,386 epoch 26 - iter 100/107 - loss 0.05218603 - samples/sec: 89.18 - lr: 0.006250
2022-05-13 16:03:21,649 ----------------------------------------------------------------------------------------------------
2022-05-13 16:03:21,649 EPOCH 26 done: loss 0.0522 - lr 0.006250
2022-05-13 16:03:32,436 Evaluating as a multi-label problem: False
2022-05-13 16:03:32,447 DEV : loss 0.20282791554927826 - f1-score (micro avg)  0.5023
2022-05-13 16:03:32,521 Epoch    26: reducing learning rate of group 0 to 3.1250e-03.
2022-05-13 16:03:32,521 BAD EPOCHS (no improvement): 4
2022-05-13 16:03:32,523 ----------------------------------------------------------------------------------------------------
2022-05-13 16:03:35,675 epoch 27 - iter 10/107 - loss 0.04757593 - samples/sec: 101.56 - lr: 0.003125
2022-05-13 16:03:38,899 epoch 27 - iter 20/107 - loss 0.04952826 - samples/sec: 99.31 - lr: 0.003125
2022-05-13 16:03:41,450 epoch 27 - iter 30/107 - loss 0.05052105 - samples/sec: 125.47 - lr: 0.003125
2022-05-13 16:03:43,755 epoch 27 - iter 40/107 - loss 0.05344478 - samples/sec: 138.92 - lr: 0.003125
2022-05-13 16:03:46,290 epoch 27 - iter 50/107 - loss 0.05266170 - samples/sec: 126.27 - lr: 0.003125
2022-05-13 16:03:48,739 epoch 27 - iter 60/107 - loss 0.05364605 - samples/sec: 130.70 - lr: 0.003125
2022-05-13 16:03:51,172 epoch 27 - iter 70/107 - loss 0.05505559 - samples/sec: 131.60 - lr: 0.003125
2022-05-13 16:03:53,594 epoch 27 - iter 80/107 - loss 0.05345610 - samples/sec: 132.19 - lr: 0.003125
2022-05-13 16:03:56,218 epoch 27 - iter 90/107 - loss 0.05473236 - samples/sec: 121.98 - lr: 0.003125
2022-05-13 16:03:58,647 epoch 27 - iter 100/107 - loss 0.05386146 - samples/sec: 131.78 - lr: 0.003125
2022-05-13 16:04:00,199 ----------------------------------------------------------------------------------------------------
2022-05-13 16:04:00,199 EPOCH 27 done: loss 0.0537 - lr 0.003125
2022-05-13 16:04:10,601 Evaluating as a multi-label problem: False
2022-05-13 16:04:10,612 DEV : loss 0.20645812153816223 - f1-score (micro avg)  0.4972
2022-05-13 16:04:10,687 BAD EPOCHS (no improvement): 1
2022-05-13 16:04:10,689 ----------------------------------------------------------------------------------------------------
2022-05-13 16:04:14,244 epoch 28 - iter 10/107 - loss 0.05346540 - samples/sec: 90.05 - lr: 0.003125
2022-05-13 16:04:17,857 epoch 28 - iter 20/107 - loss 0.04995517 - samples/sec: 88.61 - lr: 0.003125
2022-05-13 16:04:21,598 epoch 28 - iter 30/107 - loss 0.04843162 - samples/sec: 85.55 - lr: 0.003125
2022-05-13 16:04:29,512 epoch 28 - iter 40/107 - loss 0.04921855 - samples/sec: 40.44 - lr: 0.003125
2022-05-13 16:04:33,053 epoch 28 - iter 50/107 - loss 0.05010470 - samples/sec: 90.38 - lr: 0.003125
2022-05-13 16:04:36,627 epoch 28 - iter 60/107 - loss 0.04900994 - samples/sec: 89.56 - lr: 0.003125
2022-05-13 16:04:40,226 epoch 28 - iter 70/107 - loss 0.04871335 - samples/sec: 88.94 - lr: 0.003125
2022-05-13 16:04:43,808 epoch 28 - iter 80/107 - loss 0.04847964 - samples/sec: 89.37 - lr: 0.003125
2022-05-13 16:04:47,585 epoch 28 - iter 90/107 - loss 0.04962147 - samples/sec: 84.74 - lr: 0.003125
2022-05-13 16:04:51,064 epoch 28 - iter 100/107 - loss 0.04971745 - samples/sec: 92.01 - lr: 0.003125
2022-05-13 16:04:53,295 ----------------------------------------------------------------------------------------------------
2022-05-13 16:04:53,296 EPOCH 28 done: loss 0.0501 - lr 0.003125
2022-05-13 16:05:02,202 Evaluating as a multi-label problem: False
2022-05-13 16:05:02,213 DEV : loss 0.2029736340045929 - f1-score (micro avg)  0.5
2022-05-13 16:05:02,286 BAD EPOCHS (no improvement): 2
2022-05-13 16:05:02,288 ----------------------------------------------------------------------------------------------------
2022-05-13 16:05:04,658 epoch 29 - iter 10/107 - loss 0.04738035 - samples/sec: 135.12 - lr: 0.003125
2022-05-13 16:05:07,062 epoch 29 - iter 20/107 - loss 0.05367577 - samples/sec: 133.16 - lr: 0.003125
2022-05-13 16:05:09,533 epoch 29 - iter 30/107 - loss 0.05058410 - samples/sec: 129.57 - lr: 0.003125
2022-05-13 16:05:12,026 epoch 29 - iter 40/107 - loss 0.05128469 - samples/sec: 128.41 - lr: 0.003125
2022-05-13 16:05:14,592 epoch 29 - iter 50/107 - loss 0.05168512 - samples/sec: 124.76 - lr: 0.003125
2022-05-13 16:05:17,015 epoch 29 - iter 60/107 - loss 0.05216907 - samples/sec: 132.13 - lr: 0.003125
2022-05-13 16:05:19,387 epoch 29 - iter 70/107 - loss 0.05134294 - samples/sec: 134.97 - lr: 0.003125
2022-05-13 16:05:21,666 epoch 29 - iter 80/107 - loss 0.05209686 - samples/sec: 140.44 - lr: 0.003125
2022-05-13 16:05:25,250 epoch 29 - iter 90/107 - loss 0.05152032 - samples/sec: 89.30 - lr: 0.003125
2022-05-13 16:05:28,925 epoch 29 - iter 100/107 - loss 0.05095467 - samples/sec: 87.11 - lr: 0.003125
2022-05-13 16:05:30,976 ----------------------------------------------------------------------------------------------------
2022-05-13 16:05:30,976 EPOCH 29 done: loss 0.0513 - lr 0.003125
2022-05-13 16:05:41,929 Evaluating as a multi-label problem: False
2022-05-13 16:05:41,940 DEV : loss 0.2062501758337021 - f1-score (micro avg)  0.5008
2022-05-13 16:05:42,016 BAD EPOCHS (no improvement): 3
2022-05-13 16:05:42,065 ----------------------------------------------------------------------------------------------------
2022-05-13 16:05:45,448 epoch 30 - iter 10/107 - loss 0.05629961 - samples/sec: 94.63 - lr: 0.003125
2022-05-13 16:05:48,534 epoch 30 - iter 20/107 - loss 0.05426216 - samples/sec: 103.73 - lr: 0.003125
2022-05-13 16:05:51,482 epoch 30 - iter 30/107 - loss 0.05690042 - samples/sec: 108.57 - lr: 0.003125
2022-05-13 16:05:53,662 epoch 30 - iter 40/107 - loss 0.05516125 - samples/sec: 146.84 - lr: 0.003125
2022-05-13 16:05:56,103 epoch 30 - iter 50/107 - loss 0.05453460 - samples/sec: 131.18 - lr: 0.003125
2022-05-13 16:05:58,612 epoch 30 - iter 60/107 - loss 0.05405138 - samples/sec: 127.55 - lr: 0.003125
2022-05-13 16:06:01,088 epoch 30 - iter 70/107 - loss 0.05395444 - samples/sec: 129.31 - lr: 0.003125
2022-05-13 16:06:03,476 epoch 30 - iter 80/107 - loss 0.05418074 - samples/sec: 134.04 - lr: 0.003125
2022-05-13 16:06:05,912 epoch 30 - iter 90/107 - loss 0.05383882 - samples/sec: 131.41 - lr: 0.003125
2022-05-13 16:06:08,470 epoch 30 - iter 100/107 - loss 0.05359582 - samples/sec: 125.16 - lr: 0.003125
2022-05-13 16:06:09,940 ----------------------------------------------------------------------------------------------------
2022-05-13 16:06:09,940 EPOCH 30 done: loss 0.0527 - lr 0.003125
2022-05-13 16:06:19,137 Evaluating as a multi-label problem: False
2022-05-13 16:06:19,147 DEV : loss 0.203858882188797 - f1-score (micro avg)  0.5031
2022-05-13 16:06:19,221 Epoch    30: reducing learning rate of group 0 to 1.5625e-03.
2022-05-13 16:06:19,221 BAD EPOCHS (no improvement): 4
2022-05-13 16:06:19,222 ----------------------------------------------------------------------------------------------------
2022-05-13 16:06:22,511 epoch 31 - iter 10/107 - loss 0.04975136 - samples/sec: 97.35 - lr: 0.001563
2022-05-13 16:06:25,930 epoch 31 - iter 20/107 - loss 0.04952995 - samples/sec: 93.61 - lr: 0.001563
2022-05-13 16:06:29,631 epoch 31 - iter 30/107 - loss 0.04657617 - samples/sec: 86.50 - lr: 0.001563
2022-05-13 16:06:33,282 epoch 31 - iter 40/107 - loss 0.04919747 - samples/sec: 87.67 - lr: 0.001563
2022-05-13 16:06:36,965 epoch 31 - iter 50/107 - loss 0.04985802 - samples/sec: 86.92 - lr: 0.001563
2022-05-13 16:06:40,627 epoch 31 - iter 60/107 - loss 0.05019081 - samples/sec: 87.39 - lr: 0.001563
2022-05-13 16:06:43,569 epoch 31 - iter 70/107 - loss 0.05190096 - samples/sec: 108.80 - lr: 0.001563
2022-05-13 16:06:46,321 epoch 31 - iter 80/107 - loss 0.05142094 - samples/sec: 116.35 - lr: 0.001563
2022-05-13 16:06:49,029 epoch 31 - iter 90/107 - loss 0.05067016 - samples/sec: 118.21 - lr: 0.001563
2022-05-13 16:06:51,279 epoch 31 - iter 100/107 - loss 0.05190494 - samples/sec: 142.22 - lr: 0.001563
2022-05-13 16:06:52,588 ----------------------------------------------------------------------------------------------------
2022-05-13 16:06:52,588 EPOCH 31 done: loss 0.0514 - lr 0.001563
2022-05-13 16:07:00,240 Evaluating as a multi-label problem: False
2022-05-13 16:07:00,251 DEV : loss 0.20495517551898956 - f1-score (micro avg)  0.5039
2022-05-13 16:07:00,325 BAD EPOCHS (no improvement): 1
2022-05-13 16:07:00,328 ----------------------------------------------------------------------------------------------------
2022-05-13 16:07:02,880 epoch 32 - iter 10/107 - loss 0.05061727 - samples/sec: 125.47 - lr: 0.001563
2022-05-13 16:07:05,414 epoch 32 - iter 20/107 - loss 0.05726340 - samples/sec: 126.33 - lr: 0.001563
2022-05-13 16:07:07,815 epoch 32 - iter 30/107 - loss 0.05180416 - samples/sec: 133.33 - lr: 0.001563
2022-05-13 16:07:10,315 epoch 32 - iter 40/107 - loss 0.05128224 - samples/sec: 128.05 - lr: 0.001563
2022-05-13 16:07:13,706 epoch 32 - iter 50/107 - loss 0.05010497 - samples/sec: 94.40 - lr: 0.001563
2022-05-13 16:07:17,354 epoch 32 - iter 60/107 - loss 0.04898074 - samples/sec: 87.73 - lr: 0.001563
2022-05-13 16:07:20,777 epoch 32 - iter 70/107 - loss 0.04963517 - samples/sec: 93.52 - lr: 0.001563
2022-05-13 16:07:24,250 epoch 32 - iter 80/107 - loss 0.04967469 - samples/sec: 92.17 - lr: 0.001563
2022-05-13 16:07:27,801 epoch 32 - iter 90/107 - loss 0.04954934 - samples/sec: 90.14 - lr: 0.001563
2022-05-13 16:07:31,423 epoch 32 - iter 100/107 - loss 0.05014097 - samples/sec: 88.36 - lr: 0.001563
2022-05-13 16:07:33,624 ----------------------------------------------------------------------------------------------------
2022-05-13 16:07:33,624 EPOCH 32 done: loss 0.0502 - lr 0.001563
2022-05-13 16:07:43,646 Evaluating as a multi-label problem: False
2022-05-13 16:07:43,659 DEV : loss 0.20462863147258759 - f1-score (micro avg)  0.5016
2022-05-13 16:07:43,733 BAD EPOCHS (no improvement): 2
2022-05-13 16:07:43,788 ----------------------------------------------------------------------------------------------------
2022-05-13 16:07:46,705 epoch 33 - iter 10/107 - loss 0.04999199 - samples/sec: 109.75 - lr: 0.001563
2022-05-13 16:07:50,306 epoch 33 - iter 20/107 - loss 0.04794497 - samples/sec: 88.89 - lr: 0.001563
2022-05-13 16:07:53,583 epoch 33 - iter 30/107 - loss 0.05112068 - samples/sec: 97.67 - lr: 0.001563
2022-05-13 16:07:57,241 epoch 33 - iter 40/107 - loss 0.05040091 - samples/sec: 87.51 - lr: 0.001563
2022-05-13 16:08:00,721 epoch 33 - iter 50/107 - loss 0.05201807 - samples/sec: 91.97 - lr: 0.001563
2022-05-13 16:08:04,336 epoch 33 - iter 60/107 - loss 0.05071287 - samples/sec: 88.57 - lr: 0.001563
2022-05-13 16:08:07,767 epoch 33 - iter 70/107 - loss 0.04967001 - samples/sec: 93.28 - lr: 0.001563
2022-05-13 16:08:11,073 epoch 33 - iter 80/107 - loss 0.05079139 - samples/sec: 96.83 - lr: 0.001563
2022-05-13 16:08:14,516 epoch 33 - iter 90/107 - loss 0.05062752 - samples/sec: 92.98 - lr: 0.001563
2022-05-13 16:08:17,751 epoch 33 - iter 100/107 - loss 0.04909743 - samples/sec: 98.95 - lr: 0.001563
2022-05-13 16:08:19,483 ----------------------------------------------------------------------------------------------------
2022-05-13 16:08:19,483 EPOCH 33 done: loss 0.0496 - lr 0.001563
2022-05-13 16:08:29,911 Evaluating as a multi-label problem: False
2022-05-13 16:08:29,922 DEV : loss 0.20650853216648102 - f1-score (micro avg)  0.5008
2022-05-13 16:08:29,995 BAD EPOCHS (no improvement): 3
2022-05-13 16:08:29,997 ----------------------------------------------------------------------------------------------------
2022-05-13 16:08:33,538 epoch 34 - iter 10/107 - loss 0.05468394 - samples/sec: 90.40 - lr: 0.001563
2022-05-13 16:08:37,375 epoch 34 - iter 20/107 - loss 0.05067863 - samples/sec: 83.42 - lr: 0.001563
2022-05-13 16:08:41,186 epoch 34 - iter 30/107 - loss 0.05242637 - samples/sec: 83.98 - lr: 0.001563
2022-05-13 16:08:44,736 epoch 34 - iter 40/107 - loss 0.04999237 - samples/sec: 90.18 - lr: 0.001563
2022-05-13 16:08:47,911 epoch 34 - iter 50/107 - loss 0.04954455 - samples/sec: 100.80 - lr: 0.001563
2022-05-13 16:08:50,839 epoch 34 - iter 60/107 - loss 0.04967432 - samples/sec: 109.35 - lr: 0.001563
2022-05-13 16:08:54,307 epoch 34 - iter 70/107 - loss 0.04953680 - samples/sec: 92.29 - lr: 0.001563
2022-05-13 16:08:57,966 epoch 34 - iter 80/107 - loss 0.04985463 - samples/sec: 87.49 - lr: 0.001563
2022-05-13 16:09:01,703 epoch 34 - iter 90/107 - loss 0.05022718 - samples/sec: 85.64 - lr: 0.001563
2022-05-13 16:09:05,173 epoch 34 - iter 100/107 - loss 0.04927985 - samples/sec: 92.24 - lr: 0.001563
2022-05-13 16:09:07,347 ----------------------------------------------------------------------------------------------------
2022-05-13 16:09:07,347 EPOCH 34 done: loss 0.0494 - lr 0.001563
2022-05-13 16:09:18,062 Evaluating as a multi-label problem: False
2022-05-13 16:09:18,074 DEV : loss 0.20589183270931244 - f1-score (micro avg)  0.4996
2022-05-13 16:09:18,148 Epoch    34: reducing learning rate of group 0 to 7.8125e-04.
2022-05-13 16:09:18,148 BAD EPOCHS (no improvement): 4
2022-05-13 16:09:18,151 ----------------------------------------------------------------------------------------------------
2022-05-13 16:09:21,140 epoch 35 - iter 10/107 - loss 0.05406239 - samples/sec: 107.09 - lr: 0.000781
2022-05-13 16:09:24,247 epoch 35 - iter 20/107 - loss 0.05015092 - samples/sec: 103.04 - lr: 0.000781
2022-05-13 16:09:27,862 epoch 35 - iter 30/107 - loss 0.04924726 - samples/sec: 88.53 - lr: 0.000781
2022-05-13 16:09:31,494 epoch 35 - iter 40/107 - loss 0.04902339 - samples/sec: 88.12 - lr: 0.000781
2022-05-13 16:09:35,300 epoch 35 - iter 50/107 - loss 0.05039547 - samples/sec: 84.11 - lr: 0.000781
2022-05-13 16:09:38,744 epoch 35 - iter 60/107 - loss 0.05198331 - samples/sec: 92.96 - lr: 0.000781
2022-05-13 16:09:42,424 epoch 35 - iter 70/107 - loss 0.05003995 - samples/sec: 86.97 - lr: 0.000781
2022-05-13 16:09:45,944 epoch 35 - iter 80/107 - loss 0.04764739 - samples/sec: 90.95 - lr: 0.000781
2022-05-13 16:09:49,326 epoch 35 - iter 90/107 - loss 0.04931265 - samples/sec: 94.63 - lr: 0.000781
2022-05-13 16:09:52,346 epoch 35 - iter 100/107 - loss 0.04899508 - samples/sec: 105.99 - lr: 0.000781
2022-05-13 16:09:54,357 ----------------------------------------------------------------------------------------------------
2022-05-13 16:09:54,357 EPOCH 35 done: loss 0.0495 - lr 0.000781
2022-05-13 16:10:05,295 Evaluating as a multi-label problem: False
2022-05-13 16:10:05,307 DEV : loss 0.20597906410694122 - f1-score (micro avg)  0.5036
2022-05-13 16:10:05,382 BAD EPOCHS (no improvement): 1
2022-05-13 16:10:05,424 ----------------------------------------------------------------------------------------------------
2022-05-13 16:10:09,169 epoch 36 - iter 10/107 - loss 0.04225419 - samples/sec: 85.48 - lr: 0.000781
2022-05-13 16:10:12,807 epoch 36 - iter 20/107 - loss 0.04205007 - samples/sec: 87.98 - lr: 0.000781
2022-05-13 16:10:16,719 epoch 36 - iter 30/107 - loss 0.04335838 - samples/sec: 81.81 - lr: 0.000781
2022-05-13 16:10:19,893 epoch 36 - iter 40/107 - loss 0.04536674 - samples/sec: 100.84 - lr: 0.000781
2022-05-13 16:10:23,095 epoch 36 - iter 50/107 - loss 0.04579947 - samples/sec: 99.99 - lr: 0.000781
2022-05-13 16:10:26,174 epoch 36 - iter 60/107 - loss 0.04817865 - samples/sec: 103.95 - lr: 0.000781
2022-05-13 16:10:29,793 epoch 36 - iter 70/107 - loss 0.04797342 - samples/sec: 88.46 - lr: 0.000781
2022-05-13 16:10:33,568 epoch 36 - iter 80/107 - loss 0.04817623 - samples/sec: 84.79 - lr: 0.000781
2022-05-13 16:10:37,325 epoch 36 - iter 90/107 - loss 0.04978187 - samples/sec: 85.20 - lr: 0.000781
2022-05-13 16:10:41,089 epoch 36 - iter 100/107 - loss 0.04929178 - samples/sec: 85.02 - lr: 0.000781
2022-05-13 16:10:43,372 ----------------------------------------------------------------------------------------------------
2022-05-13 16:10:43,372 EPOCH 36 done: loss 0.0488 - lr 0.000781
2022-05-13 16:10:53,575 Evaluating as a multi-label problem: False
2022-05-13 16:10:53,587 DEV : loss 0.20770007371902466 - f1-score (micro avg)  0.502
2022-05-13 16:10:53,661 BAD EPOCHS (no improvement): 2
2022-05-13 16:10:53,665 ----------------------------------------------------------------------------------------------------
2022-05-13 16:10:56,761 epoch 37 - iter 10/107 - loss 0.04867575 - samples/sec: 103.39 - lr: 0.000781
2022-05-13 16:11:00,528 epoch 37 - iter 20/107 - loss 0.04980770 - samples/sec: 84.97 - lr: 0.000781
2022-05-13 16:11:04,423 epoch 37 - iter 30/107 - loss 0.04948501 - samples/sec: 82.19 - lr: 0.000781
2022-05-13 16:11:08,080 epoch 37 - iter 40/107 - loss 0.04865412 - samples/sec: 87.53 - lr: 0.000781
2022-05-13 16:11:11,585 epoch 37 - iter 50/107 - loss 0.05145799 - samples/sec: 91.33 - lr: 0.000781
2022-05-13 16:11:15,118 epoch 37 - iter 60/107 - loss 0.05032723 - samples/sec: 90.59 - lr: 0.000781
2022-05-13 16:11:18,615 epoch 37 - iter 70/107 - loss 0.05179914 - samples/sec: 91.53 - lr: 0.000781
2022-05-13 16:11:22,099 epoch 37 - iter 80/107 - loss 0.04999273 - samples/sec: 91.88 - lr: 0.000781
2022-05-13 16:11:25,270 epoch 37 - iter 90/107 - loss 0.04985782 - samples/sec: 100.93 - lr: 0.000781
2022-05-13 16:11:28,511 epoch 37 - iter 100/107 - loss 0.05068039 - samples/sec: 98.79 - lr: 0.000781
2022-05-13 16:11:30,560 ----------------------------------------------------------------------------------------------------
2022-05-13 16:11:30,560 EPOCH 37 done: loss 0.0506 - lr 0.000781
2022-05-13 16:11:41,429 Evaluating as a multi-label problem: False
2022-05-13 16:11:41,442 DEV : loss 0.20619536936283112 - f1-score (micro avg)  0.5036
2022-05-13 16:11:41,516 BAD EPOCHS (no improvement): 3
2022-05-13 16:11:41,518 ----------------------------------------------------------------------------------------------------
2022-05-13 16:11:45,290 epoch 38 - iter 10/107 - loss 0.06155096 - samples/sec: 84.86 - lr: 0.000781
2022-05-13 16:11:48,925 epoch 38 - iter 20/107 - loss 0.05228397 - samples/sec: 88.06 - lr: 0.000781
2022-05-13 16:11:52,523 epoch 38 - iter 30/107 - loss 0.05097765 - samples/sec: 88.97 - lr: 0.000781
2022-05-13 16:11:55,483 epoch 38 - iter 40/107 - loss 0.04952821 - samples/sec: 108.14 - lr: 0.000781
2022-05-13 16:11:58,383 epoch 38 - iter 50/107 - loss 0.05043257 - samples/sec: 110.38 - lr: 0.000781
2022-05-13 16:12:01,904 epoch 38 - iter 60/107 - loss 0.04950536 - samples/sec: 90.90 - lr: 0.000781
2022-05-13 16:12:05,580 epoch 38 - iter 70/107 - loss 0.04996609 - samples/sec: 87.08 - lr: 0.000781
2022-05-13 16:12:09,334 epoch 38 - iter 80/107 - loss 0.04876813 - samples/sec: 85.27 - lr: 0.000781
2022-05-13 16:12:13,069 epoch 38 - iter 90/107 - loss 0.04913086 - samples/sec: 85.69 - lr: 0.000781
2022-05-13 16:12:16,784 epoch 38 - iter 100/107 - loss 0.05013882 - samples/sec: 86.17 - lr: 0.000781
2022-05-13 16:12:19,128 ----------------------------------------------------------------------------------------------------
2022-05-13 16:12:19,128 EPOCH 38 done: loss 0.0498 - lr 0.000781
2022-05-13 16:12:28,930 Evaluating as a multi-label problem: False
2022-05-13 16:12:28,941 DEV : loss 0.20614367723464966 - f1-score (micro avg)  0.5032
2022-05-13 16:12:29,015 Epoch    38: reducing learning rate of group 0 to 3.9063e-04.
2022-05-13 16:12:29,015 BAD EPOCHS (no improvement): 4
2022-05-13 16:12:29,018 ----------------------------------------------------------------------------------------------------
2022-05-13 16:12:32,403 epoch 39 - iter 10/107 - loss 0.04989618 - samples/sec: 94.57 - lr: 0.000391
2022-05-13 16:12:36,235 epoch 39 - iter 20/107 - loss 0.04637300 - samples/sec: 83.52 - lr: 0.000391
2022-05-13 16:12:39,866 epoch 39 - iter 30/107 - loss 0.04817923 - samples/sec: 88.16 - lr: 0.000391
2022-05-13 16:12:43,613 epoch 39 - iter 40/107 - loss 0.04794608 - samples/sec: 85.42 - lr: 0.000391
2022-05-13 16:12:47,071 epoch 39 - iter 50/107 - loss 0.04775515 - samples/sec: 92.57 - lr: 0.000391
2022-05-13 16:12:50,518 epoch 39 - iter 60/107 - loss 0.04679379 - samples/sec: 92.86 - lr: 0.000391
2022-05-13 16:12:54,399 epoch 39 - iter 70/107 - loss 0.04642879 - samples/sec: 82.47 - lr: 0.000391
2022-05-13 16:12:57,420 epoch 39 - iter 80/107 - loss 0.04815941 - samples/sec: 105.98 - lr: 0.000391
2022-05-13 16:13:00,372 epoch 39 - iter 90/107 - loss 0.04853874 - samples/sec: 108.42 - lr: 0.000391
2022-05-13 16:13:03,760 epoch 39 - iter 100/107 - loss 0.04860617 - samples/sec: 94.48 - lr: 0.000391
2022-05-13 16:13:05,992 ----------------------------------------------------------------------------------------------------
2022-05-13 16:13:05,992 EPOCH 39 done: loss 0.0491 - lr 0.000391
2022-05-13 16:13:16,941 Evaluating as a multi-label problem: False
2022-05-13 16:13:16,952 DEV : loss 0.20636329054832458 - f1-score (micro avg)  0.5028
2022-05-13 16:13:17,025 BAD EPOCHS (no improvement): 1
2022-05-13 16:13:17,031 ----------------------------------------------------------------------------------------------------
2022-05-13 16:13:20,783 epoch 40 - iter 10/107 - loss 0.05638941 - samples/sec: 85.31 - lr: 0.000391
2022-05-13 16:13:24,529 epoch 40 - iter 20/107 - loss 0.05481400 - samples/sec: 85.44 - lr: 0.000391
2022-05-13 16:13:27,970 epoch 40 - iter 30/107 - loss 0.05495773 - samples/sec: 93.03 - lr: 0.000391
2022-05-13 16:13:30,833 epoch 40 - iter 40/107 - loss 0.05185698 - samples/sec: 111.81 - lr: 0.000391
2022-05-13 16:13:33,648 epoch 40 - iter 50/107 - loss 0.05203137 - samples/sec: 113.74 - lr: 0.000391
2022-05-13 16:13:35,932 epoch 40 - iter 60/107 - loss 0.05126021 - samples/sec: 140.18 - lr: 0.000391
2022-05-13 16:13:38,372 epoch 40 - iter 70/107 - loss 0.05179790 - samples/sec: 131.19 - lr: 0.000391
2022-05-13 16:13:40,853 epoch 40 - iter 80/107 - loss 0.05115012 - samples/sec: 129.01 - lr: 0.000391
2022-05-13 16:13:43,342 epoch 40 - iter 90/107 - loss 0.04962908 - samples/sec: 128.60 - lr: 0.000391
2022-05-13 16:13:45,749 epoch 40 - iter 100/107 - loss 0.04906363 - samples/sec: 133.00 - lr: 0.000391
2022-05-13 16:13:47,258 ----------------------------------------------------------------------------------------------------
2022-05-13 16:13:47,258 EPOCH 40 done: loss 0.0494 - lr 0.000391
2022-05-13 16:13:55,491 Evaluating as a multi-label problem: False
2022-05-13 16:13:55,502 DEV : loss 0.20597891509532928 - f1-score (micro avg)  0.502
2022-05-13 16:13:55,576 BAD EPOCHS (no improvement): 2
2022-05-13 16:13:55,582 ----------------------------------------------------------------------------------------------------
2022-05-13 16:13:59,323 epoch 41 - iter 10/107 - loss 0.05965556 - samples/sec: 85.56 - lr: 0.000391
2022-05-13 16:14:02,925 epoch 41 - iter 20/107 - loss 0.06070302 - samples/sec: 88.86 - lr: 0.000391
2022-05-13 16:14:06,737 epoch 41 - iter 30/107 - loss 0.05731263 - samples/sec: 83.96 - lr: 0.000391
2022-05-13 16:14:10,329 epoch 41 - iter 40/107 - loss 0.05551904 - samples/sec: 89.12 - lr: 0.000391
2022-05-13 16:14:13,930 epoch 41 - iter 50/107 - loss 0.05513101 - samples/sec: 88.89 - lr: 0.000391
2022-05-13 16:14:17,467 epoch 41 - iter 60/107 - loss 0.05359703 - samples/sec: 90.49 - lr: 0.000391
2022-05-13 16:14:20,670 epoch 41 - iter 70/107 - loss 0.05213993 - samples/sec: 99.97 - lr: 0.000391
2022-05-13 16:14:23,762 epoch 41 - iter 80/107 - loss 0.05130562 - samples/sec: 103.51 - lr: 0.000391
2022-05-13 16:14:26,864 epoch 41 - iter 90/107 - loss 0.05173310 - samples/sec: 103.19 - lr: 0.000391
2022-05-13 16:14:30,321 epoch 41 - iter 100/107 - loss 0.05121229 - samples/sec: 92.61 - lr: 0.000391
2022-05-13 16:14:32,721 ----------------------------------------------------------------------------------------------------
2022-05-13 16:14:32,721 EPOCH 41 done: loss 0.0505 - lr 0.000391
2022-05-13 16:14:43,326 Evaluating as a multi-label problem: False
2022-05-13 16:14:43,339 DEV : loss 0.20605507493019104 - f1-score (micro avg)  0.5039
2022-05-13 16:14:43,413 BAD EPOCHS (no improvement): 3
2022-05-13 16:14:43,415 ----------------------------------------------------------------------------------------------------
2022-05-13 16:14:47,287 epoch 42 - iter 10/107 - loss 0.04023940 - samples/sec: 82.68 - lr: 0.000391
2022-05-13 16:14:50,815 epoch 42 - iter 20/107 - loss 0.04488582 - samples/sec: 90.72 - lr: 0.000391
2022-05-13 16:14:53,278 epoch 42 - iter 30/107 - loss 0.04839542 - samples/sec: 129.97 - lr: 0.000391
2022-05-13 16:14:56,466 epoch 42 - iter 40/107 - loss 0.04983795 - samples/sec: 100.40 - lr: 0.000391
2022-05-13 16:14:59,876 epoch 42 - iter 50/107 - loss 0.04919838 - samples/sec: 93.86 - lr: 0.000391
2022-05-13 16:15:03,665 epoch 42 - iter 60/107 - loss 0.04835370 - samples/sec: 84.49 - lr: 0.000391
2022-05-13 16:15:07,316 epoch 42 - iter 70/107 - loss 0.04930247 - samples/sec: 87.67 - lr: 0.000391
2022-05-13 16:15:10,877 epoch 42 - iter 80/107 - loss 0.04973279 - samples/sec: 89.88 - lr: 0.000391
2022-05-13 16:15:14,621 epoch 42 - iter 90/107 - loss 0.05078792 - samples/sec: 85.50 - lr: 0.000391
2022-05-13 16:15:18,269 epoch 42 - iter 100/107 - loss 0.05096326 - samples/sec: 87.75 - lr: 0.000391
2022-05-13 16:15:20,580 ----------------------------------------------------------------------------------------------------
2022-05-13 16:15:20,580 EPOCH 42 done: loss 0.0507 - lr 0.000391
2022-05-13 16:15:30,637 Evaluating as a multi-label problem: False
2022-05-13 16:15:30,648 DEV : loss 0.20606982707977295 - f1-score (micro avg)  0.5036
2022-05-13 16:15:30,722 Epoch    42: reducing learning rate of group 0 to 1.9531e-04.
2022-05-13 16:15:30,722 BAD EPOCHS (no improvement): 4
2022-05-13 16:15:30,725 ----------------------------------------------------------------------------------------------------
2022-05-13 16:15:34,249 epoch 43 - iter 10/107 - loss 0.05014610 - samples/sec: 90.83 - lr: 0.000195
2022-05-13 16:15:38,104 epoch 43 - iter 20/107 - loss 0.05206577 - samples/sec: 83.02 - lr: 0.000195
2022-05-13 16:15:41,674 epoch 43 - iter 30/107 - loss 0.05201252 - samples/sec: 89.68 - lr: 0.000195
2022-05-13 16:15:45,416 epoch 43 - iter 40/107 - loss 0.05293763 - samples/sec: 85.54 - lr: 0.000195
2022-05-13 16:15:48,965 epoch 43 - iter 50/107 - loss 0.05258487 - samples/sec: 90.18 - lr: 0.000195
2022-05-13 16:15:52,848 epoch 43 - iter 60/107 - loss 0.05122108 - samples/sec: 82.44 - lr: 0.000195
2022-05-13 16:15:56,285 epoch 43 - iter 70/107 - loss 0.05227007 - samples/sec: 93.12 - lr: 0.000195
2022-05-13 16:15:59,170 epoch 43 - iter 80/107 - loss 0.05131642 - samples/sec: 110.98 - lr: 0.000195
2022-05-13 16:16:02,540 epoch 43 - iter 90/107 - loss 0.05075122 - samples/sec: 94.98 - lr: 0.000195
2022-05-13 16:16:06,068 epoch 43 - iter 100/107 - loss 0.05011817 - samples/sec: 90.71 - lr: 0.000195
2022-05-13 16:16:08,156 ----------------------------------------------------------------------------------------------------
2022-05-13 16:16:08,156 EPOCH 43 done: loss 0.0495 - lr 0.000195
2022-05-13 16:16:19,388 Evaluating as a multi-label problem: False
2022-05-13 16:16:19,399 DEV : loss 0.20627616345882416 - f1-score (micro avg)  0.5039
2022-05-13 16:16:19,473 BAD EPOCHS (no improvement): 1
2022-05-13 16:16:19,476 ----------------------------------------------------------------------------------------------------
2022-05-13 16:16:23,111 epoch 44 - iter 10/107 - loss 0.04942527 - samples/sec: 88.07 - lr: 0.000195
2022-05-13 16:16:26,172 epoch 44 - iter 20/107 - loss 0.04993875 - samples/sec: 104.57 - lr: 0.000195
2022-05-13 16:16:29,045 epoch 44 - iter 30/107 - loss 0.05068633 - samples/sec: 111.40 - lr: 0.000195
2022-05-13 16:16:32,607 epoch 44 - iter 40/107 - loss 0.04956813 - samples/sec: 89.86 - lr: 0.000195
2022-05-13 16:16:36,324 epoch 44 - iter 50/107 - loss 0.04852333 - samples/sec: 86.12 - lr: 0.000195
2022-05-13 16:16:39,975 epoch 44 - iter 60/107 - loss 0.04979687 - samples/sec: 87.69 - lr: 0.000195
2022-05-13 16:16:43,684 epoch 44 - iter 70/107 - loss 0.04966790 - samples/sec: 86.30 - lr: 0.000195
2022-05-13 16:16:47,501 epoch 44 - iter 80/107 - loss 0.04989456 - samples/sec: 83.86 - lr: 0.000195
2022-05-13 16:16:51,300 epoch 44 - iter 90/107 - loss 0.04972124 - samples/sec: 84.25 - lr: 0.000195
2022-05-13 16:16:54,851 epoch 44 - iter 100/107 - loss 0.04936114 - samples/sec: 90.13 - lr: 0.000195
2022-05-13 16:16:56,671 ----------------------------------------------------------------------------------------------------
2022-05-13 16:16:56,671 EPOCH 44 done: loss 0.0493 - lr 0.000195
2022-05-13 16:17:06,242 Evaluating as a multi-label problem: False
2022-05-13 16:17:06,253 DEV : loss 0.2064036726951599 - f1-score (micro avg)  0.5039
2022-05-13 16:17:06,326 BAD EPOCHS (no improvement): 2
2022-05-13 16:17:06,329 ----------------------------------------------------------------------------------------------------
2022-05-13 16:17:10,079 epoch 45 - iter 10/107 - loss 0.04704346 - samples/sec: 85.35 - lr: 0.000195
2022-05-13 16:17:13,580 epoch 45 - iter 20/107 - loss 0.04491557 - samples/sec: 91.43 - lr: 0.000195
2022-05-13 16:17:17,282 epoch 45 - iter 30/107 - loss 0.04586778 - samples/sec: 86.45 - lr: 0.000195
2022-05-13 16:17:20,944 epoch 45 - iter 40/107 - loss 0.04768782 - samples/sec: 87.41 - lr: 0.000195
2022-05-13 16:17:24,347 epoch 45 - iter 50/107 - loss 0.04788268 - samples/sec: 94.07 - lr: 0.000195
2022-05-13 16:17:27,683 epoch 45 - iter 60/107 - loss 0.04769118 - samples/sec: 95.96 - lr: 0.000195
2022-05-13 16:17:30,570 epoch 45 - iter 70/107 - loss 0.04839102 - samples/sec: 110.89 - lr: 0.000195
2022-05-13 16:17:33,701 epoch 45 - iter 80/107 - loss 0.04831945 - samples/sec: 102.22 - lr: 0.000195
2022-05-13 16:17:37,268 epoch 45 - iter 90/107 - loss 0.04873152 - samples/sec: 89.75 - lr: 0.000195
2022-05-13 16:17:41,100 epoch 45 - iter 100/107 - loss 0.04882720 - samples/sec: 83.51 - lr: 0.000195
2022-05-13 16:17:43,370 ----------------------------------------------------------------------------------------------------
2022-05-13 16:17:43,370 EPOCH 45 done: loss 0.0492 - lr 0.000195
2022-05-13 16:17:54,513 Evaluating as a multi-label problem: False
2022-05-13 16:17:54,524 DEV : loss 0.20637179911136627 - f1-score (micro avg)  0.5039
2022-05-13 16:17:54,598 BAD EPOCHS (no improvement): 3
2022-05-13 16:17:54,599 ----------------------------------------------------------------------------------------------------
2022-05-13 16:17:57,799 epoch 46 - iter 10/107 - loss 0.05282395 - samples/sec: 100.06 - lr: 0.000195
2022-05-13 16:18:00,988 epoch 46 - iter 20/107 - loss 0.05203603 - samples/sec: 100.36 - lr: 0.000195
2022-05-13 16:18:04,023 epoch 46 - iter 30/107 - loss 0.05247333 - samples/sec: 105.47 - lr: 0.000195
2022-05-13 16:18:07,543 epoch 46 - iter 40/107 - loss 0.05281768 - samples/sec: 90.94 - lr: 0.000195
2022-05-13 16:18:11,278 epoch 46 - iter 50/107 - loss 0.05109188 - samples/sec: 85.70 - lr: 0.000195
2022-05-13 16:18:14,770 epoch 46 - iter 60/107 - loss 0.05068071 - samples/sec: 91.68 - lr: 0.000195
2022-05-13 16:18:18,477 epoch 46 - iter 70/107 - loss 0.04903150 - samples/sec: 86.35 - lr: 0.000195
2022-05-13 16:18:22,142 epoch 46 - iter 80/107 - loss 0.04903310 - samples/sec: 87.33 - lr: 0.000195
2022-05-13 16:18:25,726 epoch 46 - iter 90/107 - loss 0.04863866 - samples/sec: 89.29 - lr: 0.000195
2022-05-13 16:18:29,141 epoch 46 - iter 100/107 - loss 0.04838349 - samples/sec: 93.75 - lr: 0.000195
2022-05-13 16:18:31,111 ----------------------------------------------------------------------------------------------------
2022-05-13 16:18:31,111 EPOCH 46 done: loss 0.0480 - lr 0.000195
2022-05-13 16:18:40,850 Evaluating as a multi-label problem: False
2022-05-13 16:18:40,861 DEV : loss 0.20635750889778137 - f1-score (micro avg)  0.5039
2022-05-13 16:18:40,935 Epoch    46: reducing learning rate of group 0 to 9.7656e-05.
2022-05-13 16:18:40,935 BAD EPOCHS (no improvement): 4
2022-05-13 16:18:40,937 ----------------------------------------------------------------------------------------------------
2022-05-13 16:18:40,937 ----------------------------------------------------------------------------------------------------
2022-05-13 16:18:40,937 learning rate too small - quitting training!
2022-05-13 16:18:40,937 ----------------------------------------------------------------------------------------------------
2022-05-13 16:19:17,725 ----------------------------------------------------------------------------------------------------
2022-05-13 16:19:17,726 loading file resources/taggers/model_03_r10_run_3/best-model.pt
2022-05-13 16:19:41,743 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-05-13 16:20:06,046 Evaluating as a multi-label problem: False
2022-05-13 16:20:06,059 0.6689	0.279	0.3937	0.2604
2022-05-13 16:20:06,059 
Results:
- F-score (micro) 0.3937
- F-score (macro) 0.2736
- Accuracy 0.2604

By class:
               precision    recall  f1-score   support

       person     0.7875    0.4406    0.5650       429
     location     0.6032    0.5067    0.5507       150
        group     0.6111    0.0667    0.1202       165
creative-work     0.8182    0.0634    0.1176       142
      product     0.2222    0.0315    0.0552       127
  corporation     0.3243    0.1818    0.2330        66

    micro avg     0.6689    0.2790    0.3937      1079
    macro avg     0.5611    0.2151    0.2736      1079
 weighted avg     0.6441    0.2790    0.3558      1079

2022-05-13 16:20:06,059 ----------------------------------------------------------------------------------------------------
