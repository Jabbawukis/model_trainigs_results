2022-05-13 16:30:03,755 ----------------------------------------------------------------------------------------------------
2022-05-13 16:30:03,755 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4262, out_features=4262, bias=True)
  (rnn): LSTM(4262, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-05-13 16:30:03,755 ----------------------------------------------------------------------------------------------------
2022-05-13 16:30:03,755 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-05-13 16:30:03,755 ----------------------------------------------------------------------------------------------------
2022-05-13 16:30:03,755 Parameters:
2022-05-13 16:30:03,755  - learning_rate: "0.100000"
2022-05-13 16:30:03,755  - mini_batch_size: "32"
2022-05-13 16:30:03,755  - patience: "3"
2022-05-13 16:30:03,755  - anneal_factor: "0.5"
2022-05-13 16:30:03,755  - max_epochs: "150"
2022-05-13 16:30:03,755  - shuffle: "True"
2022-05-13 16:30:03,756  - train_with_dev: "False"
2022-05-13 16:30:03,756  - batch_growth_annealing: "False"
2022-05-13 16:30:03,756 ----------------------------------------------------------------------------------------------------
2022-05-13 16:30:03,756 Model training base path: "resources/taggers/model_04_r10_run_6"
2022-05-13 16:30:03,756 ----------------------------------------------------------------------------------------------------
2022-05-13 16:30:03,756 Device: cuda:0
2022-05-13 16:30:03,756 ----------------------------------------------------------------------------------------------------
2022-05-13 16:30:03,756 Embeddings storage mode: cpu
2022-05-13 16:30:03,756 ----------------------------------------------------------------------------------------------------
2022-05-13 16:30:05,830 epoch 1 - iter 10/107 - loss 0.94358995 - samples/sec: 154.31 - lr: 0.100000
2022-05-13 16:30:07,930 epoch 1 - iter 20/107 - loss 0.61252525 - samples/sec: 152.44 - lr: 0.100000
2022-05-13 16:30:10,189 epoch 1 - iter 30/107 - loss 0.50191800 - samples/sec: 141.73 - lr: 0.100000
2022-05-13 16:30:12,266 epoch 1 - iter 40/107 - loss 0.44308665 - samples/sec: 154.13 - lr: 0.100000
2022-05-13 16:30:14,622 epoch 1 - iter 50/107 - loss 0.39688909 - samples/sec: 135.87 - lr: 0.100000
2022-05-13 16:30:16,951 epoch 1 - iter 60/107 - loss 0.37831428 - samples/sec: 137.45 - lr: 0.100000
2022-05-13 16:30:19,306 epoch 1 - iter 70/107 - loss 0.36458001 - samples/sec: 135.94 - lr: 0.100000
2022-05-13 16:30:21,373 epoch 1 - iter 80/107 - loss 0.35759187 - samples/sec: 154.91 - lr: 0.100000
2022-05-13 16:30:23,172 epoch 1 - iter 90/107 - loss 0.35156578 - samples/sec: 177.90 - lr: 0.100000
2022-05-13 16:30:24,980 epoch 1 - iter 100/107 - loss 0.34421158 - samples/sec: 177.07 - lr: 0.100000
2022-05-13 16:30:26,203 ----------------------------------------------------------------------------------------------------
2022-05-13 16:30:26,204 EPOCH 1 done: loss 0.3379 - lr 0.100000
2022-05-13 16:30:33,458 Evaluating as a multi-label problem: False
2022-05-13 16:30:33,468 DEV : loss 0.4136539399623871 - f1-score (micro avg)  0.0982
2022-05-13 16:30:33,536 BAD EPOCHS (no improvement): 0
2022-05-13 16:30:33,539 saving best model
2022-05-13 16:30:54,751 ----------------------------------------------------------------------------------------------------
2022-05-13 16:30:56,981 epoch 2 - iter 10/107 - loss 0.25394692 - samples/sec: 143.65 - lr: 0.100000
2022-05-13 16:30:59,169 epoch 2 - iter 20/107 - loss 0.23555948 - samples/sec: 146.32 - lr: 0.100000
2022-05-13 16:31:01,618 epoch 2 - iter 30/107 - loss 0.22509942 - samples/sec: 130.69 - lr: 0.100000
2022-05-13 16:31:03,990 epoch 2 - iter 40/107 - loss 0.21444805 - samples/sec: 134.99 - lr: 0.100000
2022-05-13 16:31:06,273 epoch 2 - iter 50/107 - loss 0.21022239 - samples/sec: 140.21 - lr: 0.100000
2022-05-13 16:31:08,570 epoch 2 - iter 60/107 - loss 0.20583054 - samples/sec: 139.37 - lr: 0.100000
2022-05-13 16:31:10,890 epoch 2 - iter 70/107 - loss 0.20533933 - samples/sec: 137.95 - lr: 0.100000
2022-05-13 16:31:13,232 epoch 2 - iter 80/107 - loss 0.20121269 - samples/sec: 136.72 - lr: 0.100000
2022-05-13 16:31:15,677 epoch 2 - iter 90/107 - loss 0.19984065 - samples/sec: 130.93 - lr: 0.100000
2022-05-13 16:31:17,842 epoch 2 - iter 100/107 - loss 0.19732893 - samples/sec: 147.90 - lr: 0.100000
2022-05-13 16:31:19,189 ----------------------------------------------------------------------------------------------------
2022-05-13 16:31:19,190 EPOCH 2 done: loss 0.1948 - lr 0.100000
2022-05-13 16:31:26,681 Evaluating as a multi-label problem: False
2022-05-13 16:31:26,691 DEV : loss 0.3544377088546753 - f1-score (micro avg)  0.2734
2022-05-13 16:31:26,759 BAD EPOCHS (no improvement): 0
2022-05-13 16:31:26,762 saving best model
2022-05-13 16:31:47,781 ----------------------------------------------------------------------------------------------------
2022-05-13 16:31:50,128 epoch 3 - iter 10/107 - loss 0.19089521 - samples/sec: 136.46 - lr: 0.100000
2022-05-13 16:31:52,376 epoch 3 - iter 20/107 - loss 0.18428937 - samples/sec: 142.40 - lr: 0.100000
2022-05-13 16:31:54,732 epoch 3 - iter 30/107 - loss 0.18559393 - samples/sec: 135.90 - lr: 0.100000
2022-05-13 16:31:56,958 epoch 3 - iter 40/107 - loss 0.18737992 - samples/sec: 143.77 - lr: 0.100000
2022-05-13 16:31:59,305 epoch 3 - iter 50/107 - loss 0.17402904 - samples/sec: 136.40 - lr: 0.100000
2022-05-13 16:32:01,665 epoch 3 - iter 60/107 - loss 0.17026723 - samples/sec: 135.63 - lr: 0.100000
2022-05-13 16:32:03,978 epoch 3 - iter 70/107 - loss 0.16577644 - samples/sec: 138.45 - lr: 0.100000
2022-05-13 16:32:06,252 epoch 3 - iter 80/107 - loss 0.16510056 - samples/sec: 140.78 - lr: 0.100000
2022-05-13 16:32:08,302 epoch 3 - iter 90/107 - loss 0.16203952 - samples/sec: 156.16 - lr: 0.100000
2022-05-13 16:32:10,532 epoch 3 - iter 100/107 - loss 0.16095226 - samples/sec: 143.57 - lr: 0.100000
2022-05-13 16:32:11,772 ----------------------------------------------------------------------------------------------------
2022-05-13 16:32:11,772 EPOCH 3 done: loss 0.1602 - lr 0.100000
2022-05-13 16:32:18,631 Evaluating as a multi-label problem: False
2022-05-13 16:32:18,641 DEV : loss 0.3318638205528259 - f1-score (micro avg)  0.2314
2022-05-13 16:32:18,710 BAD EPOCHS (no improvement): 1
2022-05-13 16:32:18,712 ----------------------------------------------------------------------------------------------------
2022-05-13 16:32:20,966 epoch 4 - iter 10/107 - loss 0.12059140 - samples/sec: 142.02 - lr: 0.100000
2022-05-13 16:32:23,265 epoch 4 - iter 20/107 - loss 0.13534037 - samples/sec: 139.26 - lr: 0.100000
2022-05-13 16:32:25,536 epoch 4 - iter 30/107 - loss 0.13840992 - samples/sec: 140.95 - lr: 0.100000
2022-05-13 16:32:27,648 epoch 4 - iter 40/107 - loss 0.13934363 - samples/sec: 151.59 - lr: 0.100000
2022-05-13 16:32:30,003 epoch 4 - iter 50/107 - loss 0.14379393 - samples/sec: 135.94 - lr: 0.100000
2022-05-13 16:32:32,388 epoch 4 - iter 60/107 - loss 0.13940091 - samples/sec: 134.23 - lr: 0.100000
2022-05-13 16:32:34,643 epoch 4 - iter 70/107 - loss 0.14192804 - samples/sec: 141.94 - lr: 0.100000
2022-05-13 16:32:36,911 epoch 4 - iter 80/107 - loss 0.14299580 - samples/sec: 141.17 - lr: 0.100000
2022-05-13 16:32:39,151 epoch 4 - iter 90/107 - loss 0.14325301 - samples/sec: 142.89 - lr: 0.100000
2022-05-13 16:32:41,488 epoch 4 - iter 100/107 - loss 0.14083381 - samples/sec: 137.02 - lr: 0.100000
2022-05-13 16:32:42,855 ----------------------------------------------------------------------------------------------------
2022-05-13 16:32:42,856 EPOCH 4 done: loss 0.1399 - lr 0.100000
2022-05-13 16:32:50,181 Evaluating as a multi-label problem: False
2022-05-13 16:32:50,191 DEV : loss 0.25140559673309326 - f1-score (micro avg)  0.4361
2022-05-13 16:32:50,259 BAD EPOCHS (no improvement): 0
2022-05-13 16:32:50,299 saving best model
2022-05-13 16:33:11,485 ----------------------------------------------------------------------------------------------------
2022-05-13 16:33:13,768 epoch 5 - iter 10/107 - loss 0.12673344 - samples/sec: 140.26 - lr: 0.100000
2022-05-13 16:33:16,047 epoch 5 - iter 20/107 - loss 0.13871416 - samples/sec: 140.46 - lr: 0.100000
2022-05-13 16:33:18,406 epoch 5 - iter 30/107 - loss 0.13271693 - samples/sec: 135.75 - lr: 0.100000
2022-05-13 16:33:20,485 epoch 5 - iter 40/107 - loss 0.13062692 - samples/sec: 153.93 - lr: 0.100000
2022-05-13 16:33:22,802 epoch 5 - iter 50/107 - loss 0.12660749 - samples/sec: 138.19 - lr: 0.100000
2022-05-13 16:33:25,071 epoch 5 - iter 60/107 - loss 0.12275312 - samples/sec: 141.09 - lr: 0.100000
2022-05-13 16:33:27,281 epoch 5 - iter 70/107 - loss 0.12467838 - samples/sec: 144.81 - lr: 0.100000
2022-05-13 16:33:29,473 epoch 5 - iter 80/107 - loss 0.12845636 - samples/sec: 146.04 - lr: 0.100000
2022-05-13 16:33:31,829 epoch 5 - iter 90/107 - loss 0.12829874 - samples/sec: 135.89 - lr: 0.100000
2022-05-13 16:33:34,105 epoch 5 - iter 100/107 - loss 0.13108204 - samples/sec: 140.63 - lr: 0.100000
2022-05-13 16:33:35,460 ----------------------------------------------------------------------------------------------------
2022-05-13 16:33:35,460 EPOCH 5 done: loss 0.1281 - lr 0.100000
2022-05-13 16:33:42,096 Evaluating as a multi-label problem: False
2022-05-13 16:33:42,106 DEV : loss 0.2554595470428467 - f1-score (micro avg)  0.4298
2022-05-13 16:33:42,175 BAD EPOCHS (no improvement): 1
2022-05-13 16:33:42,177 ----------------------------------------------------------------------------------------------------
2022-05-13 16:33:44,219 epoch 6 - iter 10/107 - loss 0.12861084 - samples/sec: 156.81 - lr: 0.100000
2022-05-13 16:33:46,571 epoch 6 - iter 20/107 - loss 0.12357103 - samples/sec: 136.09 - lr: 0.100000
2022-05-13 16:33:48,854 epoch 6 - iter 30/107 - loss 0.12469158 - samples/sec: 140.24 - lr: 0.100000
2022-05-13 16:33:51,086 epoch 6 - iter 40/107 - loss 0.12780742 - samples/sec: 143.40 - lr: 0.100000
2022-05-13 16:33:53,339 epoch 6 - iter 50/107 - loss 0.12840277 - samples/sec: 142.08 - lr: 0.100000
2022-05-13 16:33:55,686 epoch 6 - iter 60/107 - loss 0.12333542 - samples/sec: 136.42 - lr: 0.100000
2022-05-13 16:33:57,905 epoch 6 - iter 70/107 - loss 0.12047879 - samples/sec: 144.27 - lr: 0.100000
2022-05-13 16:34:00,200 epoch 6 - iter 80/107 - loss 0.11819708 - samples/sec: 139.50 - lr: 0.100000
2022-05-13 16:34:02,368 epoch 6 - iter 90/107 - loss 0.12031078 - samples/sec: 147.63 - lr: 0.100000
2022-05-13 16:34:04,668 epoch 6 - iter 100/107 - loss 0.11791195 - samples/sec: 139.18 - lr: 0.100000
2022-05-13 16:34:06,082 ----------------------------------------------------------------------------------------------------
2022-05-13 16:34:06,083 EPOCH 6 done: loss 0.1178 - lr 0.100000
2022-05-13 16:34:13,650 Evaluating as a multi-label problem: False
2022-05-13 16:34:13,660 DEV : loss 0.2485847771167755 - f1-score (micro avg)  0.3813
2022-05-13 16:34:13,729 BAD EPOCHS (no improvement): 2
2022-05-13 16:34:13,731 ----------------------------------------------------------------------------------------------------
2022-05-13 16:34:16,047 epoch 7 - iter 10/107 - loss 0.11999824 - samples/sec: 138.24 - lr: 0.100000
2022-05-13 16:34:18,238 epoch 7 - iter 20/107 - loss 0.11687088 - samples/sec: 146.11 - lr: 0.100000
2022-05-13 16:34:20,500 epoch 7 - iter 30/107 - loss 0.11721356 - samples/sec: 141.50 - lr: 0.100000
2022-05-13 16:34:22,619 epoch 7 - iter 40/107 - loss 0.11462733 - samples/sec: 151.06 - lr: 0.100000
2022-05-13 16:34:24,765 epoch 7 - iter 50/107 - loss 0.11279077 - samples/sec: 149.20 - lr: 0.100000
2022-05-13 16:34:26,673 epoch 7 - iter 60/107 - loss 0.10886012 - samples/sec: 167.78 - lr: 0.100000
2022-05-13 16:34:28,769 epoch 7 - iter 70/107 - loss 0.10891171 - samples/sec: 152.73 - lr: 0.100000
2022-05-13 16:34:30,895 epoch 7 - iter 80/107 - loss 0.10772251 - samples/sec: 150.56 - lr: 0.100000
2022-05-13 16:34:33,129 epoch 7 - iter 90/107 - loss 0.10881116 - samples/sec: 143.31 - lr: 0.100000
2022-05-13 16:34:35,208 epoch 7 - iter 100/107 - loss 0.11051964 - samples/sec: 154.04 - lr: 0.100000
2022-05-13 16:34:36,634 ----------------------------------------------------------------------------------------------------
2022-05-13 16:34:36,634 EPOCH 7 done: loss 0.1091 - lr 0.100000
2022-05-13 16:34:43,932 Evaluating as a multi-label problem: False
2022-05-13 16:34:43,943 DEV : loss 0.24885542690753937 - f1-score (micro avg)  0.3897
2022-05-13 16:34:44,013 BAD EPOCHS (no improvement): 3
2022-05-13 16:34:44,015 ----------------------------------------------------------------------------------------------------
2022-05-13 16:34:46,195 epoch 8 - iter 10/107 - loss 0.08950775 - samples/sec: 146.88 - lr: 0.100000
2022-05-13 16:34:48,455 epoch 8 - iter 20/107 - loss 0.10027937 - samples/sec: 141.64 - lr: 0.100000
2022-05-13 16:34:50,906 epoch 8 - iter 30/107 - loss 0.10649330 - samples/sec: 130.60 - lr: 0.100000
2022-05-13 16:34:53,187 epoch 8 - iter 40/107 - loss 0.10227423 - samples/sec: 140.36 - lr: 0.100000
2022-05-13 16:34:55,475 epoch 8 - iter 50/107 - loss 0.10356066 - samples/sec: 139.88 - lr: 0.100000
2022-05-13 16:34:57,690 epoch 8 - iter 60/107 - loss 0.10117866 - samples/sec: 144.53 - lr: 0.100000
2022-05-13 16:34:59,994 epoch 8 - iter 70/107 - loss 0.10094343 - samples/sec: 138.97 - lr: 0.100000
2022-05-13 16:35:02,268 epoch 8 - iter 80/107 - loss 0.10161788 - samples/sec: 140.74 - lr: 0.100000
2022-05-13 16:35:04,604 epoch 8 - iter 90/107 - loss 0.10232969 - samples/sec: 137.06 - lr: 0.100000
2022-05-13 16:35:06,762 epoch 8 - iter 100/107 - loss 0.10303400 - samples/sec: 148.33 - lr: 0.100000
2022-05-13 16:35:08,090 ----------------------------------------------------------------------------------------------------
2022-05-13 16:35:08,091 EPOCH 8 done: loss 0.1021 - lr 0.100000
2022-05-13 16:35:14,903 Evaluating as a multi-label problem: False
2022-05-13 16:35:14,914 DEV : loss 0.2605830132961273 - f1-score (micro avg)  0.4345
2022-05-13 16:35:14,983 Epoch     8: reducing learning rate of group 0 to 5.0000e-02.
2022-05-13 16:35:14,983 BAD EPOCHS (no improvement): 4
2022-05-13 16:35:14,986 ----------------------------------------------------------------------------------------------------
2022-05-13 16:35:16,931 epoch 9 - iter 10/107 - loss 0.08885293 - samples/sec: 164.58 - lr: 0.050000
2022-05-13 16:35:19,098 epoch 9 - iter 20/107 - loss 0.07974660 - samples/sec: 147.73 - lr: 0.050000
2022-05-13 16:35:21,398 epoch 9 - iter 30/107 - loss 0.08792952 - samples/sec: 139.19 - lr: 0.050000
2022-05-13 16:35:23,746 epoch 9 - iter 40/107 - loss 0.09020677 - samples/sec: 136.33 - lr: 0.050000
2022-05-13 16:35:25,999 epoch 9 - iter 50/107 - loss 0.09108856 - samples/sec: 142.13 - lr: 0.050000
2022-05-13 16:35:28,391 epoch 9 - iter 60/107 - loss 0.09309260 - samples/sec: 133.83 - lr: 0.050000
2022-05-13 16:35:30,675 epoch 9 - iter 70/107 - loss 0.09175144 - samples/sec: 140.12 - lr: 0.050000
2022-05-13 16:35:32,810 epoch 9 - iter 80/107 - loss 0.09383268 - samples/sec: 150.01 - lr: 0.050000
2022-05-13 16:35:35,130 epoch 9 - iter 90/107 - loss 0.09154049 - samples/sec: 137.98 - lr: 0.050000
2022-05-13 16:35:37,378 epoch 9 - iter 100/107 - loss 0.09035622 - samples/sec: 142.39 - lr: 0.050000
2022-05-13 16:35:38,754 ----------------------------------------------------------------------------------------------------
2022-05-13 16:35:38,754 EPOCH 9 done: loss 0.0914 - lr 0.050000
2022-05-13 16:35:46,150 Evaluating as a multi-label problem: False
2022-05-13 16:35:46,161 DEV : loss 0.1993323564529419 - f1-score (micro avg)  0.4895
2022-05-13 16:35:46,229 BAD EPOCHS (no improvement): 0
2022-05-13 16:35:46,231 saving best model
2022-05-13 16:36:08,224 ----------------------------------------------------------------------------------------------------
2022-05-13 16:36:10,559 epoch 10 - iter 10/107 - loss 0.07775458 - samples/sec: 137.12 - lr: 0.050000
2022-05-13 16:36:12,722 epoch 10 - iter 20/107 - loss 0.08391984 - samples/sec: 147.99 - lr: 0.050000
2022-05-13 16:36:15,043 epoch 10 - iter 30/107 - loss 0.08069996 - samples/sec: 137.91 - lr: 0.050000
2022-05-13 16:36:17,297 epoch 10 - iter 40/107 - loss 0.08077209 - samples/sec: 142.03 - lr: 0.050000
2022-05-13 16:36:19,489 epoch 10 - iter 50/107 - loss 0.08399087 - samples/sec: 146.07 - lr: 0.050000
2022-05-13 16:36:21,730 epoch 10 - iter 60/107 - loss 0.08555439 - samples/sec: 142.85 - lr: 0.050000
2022-05-13 16:36:24,060 epoch 10 - iter 70/107 - loss 0.08573592 - samples/sec: 137.38 - lr: 0.050000
2022-05-13 16:36:26,322 epoch 10 - iter 80/107 - loss 0.08712019 - samples/sec: 141.55 - lr: 0.050000
2022-05-13 16:36:28,544 epoch 10 - iter 90/107 - loss 0.08776176 - samples/sec: 144.08 - lr: 0.050000
2022-05-13 16:36:30,837 epoch 10 - iter 100/107 - loss 0.08722993 - samples/sec: 139.59 - lr: 0.050000
2022-05-13 16:36:32,350 ----------------------------------------------------------------------------------------------------
2022-05-13 16:36:32,350 EPOCH 10 done: loss 0.0871 - lr 0.050000
2022-05-13 16:36:39,539 Evaluating as a multi-label problem: False
2022-05-13 16:36:39,550 DEV : loss 0.21580614149570465 - f1-score (micro avg)  0.4567
2022-05-13 16:36:39,631 BAD EPOCHS (no improvement): 1
2022-05-13 16:36:39,633 ----------------------------------------------------------------------------------------------------
2022-05-13 16:36:42,074 epoch 11 - iter 10/107 - loss 0.07014899 - samples/sec: 131.14 - lr: 0.050000
2022-05-13 16:36:44,562 epoch 11 - iter 20/107 - loss 0.08841932 - samples/sec: 128.71 - lr: 0.050000
2022-05-13 16:36:47,251 epoch 11 - iter 30/107 - loss 0.08569958 - samples/sec: 119.02 - lr: 0.050000
2022-05-13 16:36:49,721 epoch 11 - iter 40/107 - loss 0.08426042 - samples/sec: 129.60 - lr: 0.050000
2022-05-13 16:36:52,305 epoch 11 - iter 50/107 - loss 0.08314451 - samples/sec: 123.89 - lr: 0.050000
2022-05-13 16:36:54,799 epoch 11 - iter 60/107 - loss 0.08434602 - samples/sec: 128.32 - lr: 0.050000
2022-05-13 16:36:57,452 epoch 11 - iter 70/107 - loss 0.08329675 - samples/sec: 120.69 - lr: 0.050000
2022-05-13 16:37:00,132 epoch 11 - iter 80/107 - loss 0.08081840 - samples/sec: 119.42 - lr: 0.050000
2022-05-13 16:37:02,707 epoch 11 - iter 90/107 - loss 0.08246866 - samples/sec: 124.33 - lr: 0.050000
2022-05-13 16:37:05,230 epoch 11 - iter 100/107 - loss 0.08101180 - samples/sec: 126.91 - lr: 0.050000
2022-05-13 16:37:06,868 ----------------------------------------------------------------------------------------------------
2022-05-13 16:37:06,868 EPOCH 11 done: loss 0.0816 - lr 0.050000
2022-05-13 16:37:15,299 Evaluating as a multi-label problem: False
2022-05-13 16:37:15,310 DEV : loss 0.20204786956310272 - f1-score (micro avg)  0.4939
2022-05-13 16:37:15,393 BAD EPOCHS (no improvement): 0
2022-05-13 16:37:15,396 saving best model
2022-05-13 16:37:36,704 ----------------------------------------------------------------------------------------------------
2022-05-13 16:37:38,648 epoch 12 - iter 10/107 - loss 0.07130934 - samples/sec: 164.74 - lr: 0.050000
2022-05-13 16:37:40,655 epoch 12 - iter 20/107 - loss 0.07409430 - samples/sec: 159.51 - lr: 0.050000
2022-05-13 16:37:42,500 epoch 12 - iter 30/107 - loss 0.07551055 - samples/sec: 173.54 - lr: 0.050000
2022-05-13 16:37:44,417 epoch 12 - iter 40/107 - loss 0.07477381 - samples/sec: 167.05 - lr: 0.050000
2022-05-13 16:37:46,266 epoch 12 - iter 50/107 - loss 0.07609402 - samples/sec: 173.14 - lr: 0.050000
2022-05-13 16:37:48,153 epoch 12 - iter 60/107 - loss 0.07627669 - samples/sec: 169.68 - lr: 0.050000
2022-05-13 16:37:49,944 epoch 12 - iter 70/107 - loss 0.07942723 - samples/sec: 178.76 - lr: 0.050000
2022-05-13 16:37:51,912 epoch 12 - iter 80/107 - loss 0.07903634 - samples/sec: 162.68 - lr: 0.050000
2022-05-13 16:37:53,867 epoch 12 - iter 90/107 - loss 0.07949799 - samples/sec: 163.77 - lr: 0.050000
2022-05-13 16:37:55,781 epoch 12 - iter 100/107 - loss 0.07856950 - samples/sec: 167.24 - lr: 0.050000
2022-05-13 16:37:56,976 ----------------------------------------------------------------------------------------------------
2022-05-13 16:37:56,976 EPOCH 12 done: loss 0.0794 - lr 0.050000
2022-05-13 16:38:03,812 Evaluating as a multi-label problem: False
2022-05-13 16:38:03,823 DEV : loss 0.19098246097564697 - f1-score (micro avg)  0.5235
2022-05-13 16:38:03,892 BAD EPOCHS (no improvement): 0
2022-05-13 16:38:03,920 saving best model
2022-05-13 16:38:24,931 ----------------------------------------------------------------------------------------------------
2022-05-13 16:38:27,264 epoch 13 - iter 10/107 - loss 0.06665494 - samples/sec: 137.22 - lr: 0.050000
2022-05-13 16:38:29,393 epoch 13 - iter 20/107 - loss 0.06567799 - samples/sec: 150.33 - lr: 0.050000
2022-05-13 16:38:31,410 epoch 13 - iter 30/107 - loss 0.06815862 - samples/sec: 158.71 - lr: 0.050000
2022-05-13 16:38:33,449 epoch 13 - iter 40/107 - loss 0.06578816 - samples/sec: 157.00 - lr: 0.050000
2022-05-13 16:38:34,840 epoch 13 - iter 50/107 - loss 0.06792450 - samples/sec: 230.34 - lr: 0.050000
2022-05-13 16:38:36,319 epoch 13 - iter 60/107 - loss 0.06910301 - samples/sec: 216.40 - lr: 0.050000
2022-05-13 16:38:38,142 epoch 13 - iter 70/107 - loss 0.06970516 - samples/sec: 175.63 - lr: 0.050000
2022-05-13 16:38:40,189 epoch 13 - iter 80/107 - loss 0.07112666 - samples/sec: 156.39 - lr: 0.050000
2022-05-13 16:38:42,057 epoch 13 - iter 90/107 - loss 0.07268165 - samples/sec: 171.41 - lr: 0.050000
2022-05-13 16:38:44,196 epoch 13 - iter 100/107 - loss 0.07419537 - samples/sec: 149.67 - lr: 0.050000
2022-05-13 16:38:45,661 ----------------------------------------------------------------------------------------------------
2022-05-13 16:38:45,661 EPOCH 13 done: loss 0.0748 - lr 0.050000
2022-05-13 16:38:53,035 Evaluating as a multi-label problem: False
2022-05-13 16:38:53,046 DEV : loss 0.2180037945508957 - f1-score (micro avg)  0.4658
2022-05-13 16:38:53,114 BAD EPOCHS (no improvement): 1
2022-05-13 16:38:53,116 ----------------------------------------------------------------------------------------------------
2022-05-13 16:38:55,521 epoch 14 - iter 10/107 - loss 0.08174787 - samples/sec: 133.08 - lr: 0.050000
2022-05-13 16:38:57,804 epoch 14 - iter 20/107 - loss 0.08342437 - samples/sec: 140.25 - lr: 0.050000
2022-05-13 16:38:59,931 epoch 14 - iter 30/107 - loss 0.07949345 - samples/sec: 150.47 - lr: 0.050000
2022-05-13 16:39:02,402 epoch 14 - iter 40/107 - loss 0.08111172 - samples/sec: 129.54 - lr: 0.050000
2022-05-13 16:39:04,613 epoch 14 - iter 50/107 - loss 0.07925362 - samples/sec: 144.82 - lr: 0.050000
2022-05-13 16:39:06,834 epoch 14 - iter 60/107 - loss 0.07783299 - samples/sec: 144.14 - lr: 0.050000
2022-05-13 16:39:09,056 epoch 14 - iter 70/107 - loss 0.07486964 - samples/sec: 144.08 - lr: 0.050000
2022-05-13 16:39:11,282 epoch 14 - iter 80/107 - loss 0.07472060 - samples/sec: 143.83 - lr: 0.050000
2022-05-13 16:39:13,540 epoch 14 - iter 90/107 - loss 0.07519291 - samples/sec: 141.75 - lr: 0.050000
2022-05-13 16:39:15,767 epoch 14 - iter 100/107 - loss 0.07620595 - samples/sec: 143.76 - lr: 0.050000
2022-05-13 16:39:17,205 ----------------------------------------------------------------------------------------------------
2022-05-13 16:39:17,205 EPOCH 14 done: loss 0.0762 - lr 0.050000
2022-05-13 16:39:23,952 Evaluating as a multi-label problem: False
2022-05-13 16:39:23,963 DEV : loss 0.18882665038108826 - f1-score (micro avg)  0.5058
2022-05-13 16:39:24,032 BAD EPOCHS (no improvement): 2
2022-05-13 16:39:24,033 ----------------------------------------------------------------------------------------------------
2022-05-13 16:39:26,084 epoch 15 - iter 10/107 - loss 0.06653659 - samples/sec: 156.14 - lr: 0.050000
2022-05-13 16:39:28,055 epoch 15 - iter 20/107 - loss 0.07143237 - samples/sec: 162.48 - lr: 0.050000
2022-05-13 16:39:30,205 epoch 15 - iter 30/107 - loss 0.06966641 - samples/sec: 148.89 - lr: 0.050000
2022-05-13 16:39:32,595 epoch 15 - iter 40/107 - loss 0.07063427 - samples/sec: 133.92 - lr: 0.050000
2022-05-13 16:39:34,730 epoch 15 - iter 50/107 - loss 0.07318025 - samples/sec: 149.94 - lr: 0.050000
2022-05-13 16:39:37,010 epoch 15 - iter 60/107 - loss 0.07328648 - samples/sec: 140.41 - lr: 0.050000
2022-05-13 16:39:39,237 epoch 15 - iter 70/107 - loss 0.07272670 - samples/sec: 143.77 - lr: 0.050000
2022-05-13 16:39:41,447 epoch 15 - iter 80/107 - loss 0.07327196 - samples/sec: 144.84 - lr: 0.050000
2022-05-13 16:39:43,797 epoch 15 - iter 90/107 - loss 0.07342168 - samples/sec: 136.23 - lr: 0.050000
2022-05-13 16:39:46,157 epoch 15 - iter 100/107 - loss 0.07443544 - samples/sec: 135.65 - lr: 0.050000
2022-05-13 16:39:47,477 ----------------------------------------------------------------------------------------------------
2022-05-13 16:39:47,477 EPOCH 15 done: loss 0.0732 - lr 0.050000
2022-05-13 16:39:55,092 Evaluating as a multi-label problem: False
2022-05-13 16:39:55,103 DEV : loss 0.18883201479911804 - f1-score (micro avg)  0.5138
2022-05-13 16:39:55,171 BAD EPOCHS (no improvement): 3
2022-05-13 16:39:55,193 ----------------------------------------------------------------------------------------------------
2022-05-13 16:39:57,502 epoch 16 - iter 10/107 - loss 0.07706901 - samples/sec: 138.63 - lr: 0.050000
2022-05-13 16:39:59,752 epoch 16 - iter 20/107 - loss 0.06890947 - samples/sec: 142.29 - lr: 0.050000
2022-05-13 16:40:02,040 epoch 16 - iter 30/107 - loss 0.06736108 - samples/sec: 139.87 - lr: 0.050000
2022-05-13 16:40:04,287 epoch 16 - iter 40/107 - loss 0.07130224 - samples/sec: 142.53 - lr: 0.050000
2022-05-13 16:40:06,698 epoch 16 - iter 50/107 - loss 0.07072120 - samples/sec: 132.75 - lr: 0.050000
2022-05-13 16:40:08,776 epoch 16 - iter 60/107 - loss 0.07206400 - samples/sec: 154.06 - lr: 0.050000
2022-05-13 16:40:10,749 epoch 16 - iter 70/107 - loss 0.07158528 - samples/sec: 162.22 - lr: 0.050000
2022-05-13 16:40:12,737 epoch 16 - iter 80/107 - loss 0.07065870 - samples/sec: 161.11 - lr: 0.050000
2022-05-13 16:40:14,806 epoch 16 - iter 90/107 - loss 0.06941334 - samples/sec: 154.73 - lr: 0.050000
2022-05-13 16:40:16,977 epoch 16 - iter 100/107 - loss 0.06836734 - samples/sec: 147.46 - lr: 0.050000
2022-05-13 16:40:17,976 ----------------------------------------------------------------------------------------------------
2022-05-13 16:40:17,976 EPOCH 16 done: loss 0.0682 - lr 0.050000
2022-05-13 16:40:23,289 Evaluating as a multi-label problem: False
2022-05-13 16:40:23,299 DEV : loss 0.20211146771907806 - f1-score (micro avg)  0.504
2022-05-13 16:40:23,369 Epoch    16: reducing learning rate of group 0 to 2.5000e-02.
2022-05-13 16:40:23,369 BAD EPOCHS (no improvement): 4
2022-05-13 16:40:23,372 ----------------------------------------------------------------------------------------------------
2022-05-13 16:40:25,089 epoch 17 - iter 10/107 - loss 0.05972630 - samples/sec: 186.48 - lr: 0.025000
2022-05-13 16:40:26,536 epoch 17 - iter 20/107 - loss 0.06186002 - samples/sec: 221.26 - lr: 0.025000
2022-05-13 16:40:27,985 epoch 17 - iter 30/107 - loss 0.06403760 - samples/sec: 221.01 - lr: 0.025000
2022-05-13 16:40:29,440 epoch 17 - iter 40/107 - loss 0.06016264 - samples/sec: 219.95 - lr: 0.025000
2022-05-13 16:40:30,867 epoch 17 - iter 50/107 - loss 0.06076193 - samples/sec: 224.49 - lr: 0.025000
2022-05-13 16:40:32,420 epoch 17 - iter 60/107 - loss 0.06036937 - samples/sec: 206.14 - lr: 0.025000
2022-05-13 16:40:33,950 epoch 17 - iter 70/107 - loss 0.06196488 - samples/sec: 209.23 - lr: 0.025000
2022-05-13 16:40:35,437 epoch 17 - iter 80/107 - loss 0.06333962 - samples/sec: 215.39 - lr: 0.025000
2022-05-13 16:40:36,930 epoch 17 - iter 90/107 - loss 0.06301323 - samples/sec: 214.46 - lr: 0.025000
2022-05-13 16:40:38,462 epoch 17 - iter 100/107 - loss 0.06369853 - samples/sec: 209.01 - lr: 0.025000
2022-05-13 16:40:39,409 ----------------------------------------------------------------------------------------------------
2022-05-13 16:40:39,410 EPOCH 17 done: loss 0.0644 - lr 0.025000
2022-05-13 16:40:44,804 Evaluating as a multi-label problem: False
2022-05-13 16:40:44,814 DEV : loss 0.21091461181640625 - f1-score (micro avg)  0.4976
2022-05-13 16:40:44,882 BAD EPOCHS (no improvement): 1
2022-05-13 16:40:44,883 ----------------------------------------------------------------------------------------------------
2022-05-13 16:40:46,512 epoch 18 - iter 10/107 - loss 0.08182062 - samples/sec: 196.60 - lr: 0.025000
2022-05-13 16:40:48,039 epoch 18 - iter 20/107 - loss 0.07248658 - samples/sec: 209.62 - lr: 0.025000
2022-05-13 16:40:49,503 epoch 18 - iter 30/107 - loss 0.06730773 - samples/sec: 218.73 - lr: 0.025000
2022-05-13 16:40:50,951 epoch 18 - iter 40/107 - loss 0.06287806 - samples/sec: 221.23 - lr: 0.025000
2022-05-13 16:40:52,444 epoch 18 - iter 50/107 - loss 0.06015418 - samples/sec: 214.43 - lr: 0.025000
2022-05-13 16:40:54,293 epoch 18 - iter 60/107 - loss 0.06122204 - samples/sec: 173.18 - lr: 0.025000
2022-05-13 16:40:56,661 epoch 18 - iter 70/107 - loss 0.06313464 - samples/sec: 135.14 - lr: 0.025000
2022-05-13 16:40:58,961 epoch 18 - iter 80/107 - loss 0.06283056 - samples/sec: 139.19 - lr: 0.025000
2022-05-13 16:41:01,398 epoch 18 - iter 90/107 - loss 0.06299322 - samples/sec: 131.35 - lr: 0.025000
2022-05-13 16:41:03,668 epoch 18 - iter 100/107 - loss 0.06396638 - samples/sec: 141.03 - lr: 0.025000
2022-05-13 16:41:05,107 ----------------------------------------------------------------------------------------------------
2022-05-13 16:41:05,108 EPOCH 18 done: loss 0.0641 - lr 0.025000
2022-05-13 16:41:12,524 Evaluating as a multi-label problem: False
2022-05-13 16:41:12,535 DEV : loss 0.1937655210494995 - f1-score (micro avg)  0.5129
2022-05-13 16:41:12,604 BAD EPOCHS (no improvement): 2
2022-05-13 16:41:12,606 ----------------------------------------------------------------------------------------------------
2022-05-13 16:41:14,727 epoch 19 - iter 10/107 - loss 0.04927972 - samples/sec: 150.99 - lr: 0.025000
2022-05-13 16:41:17,044 epoch 19 - iter 20/107 - loss 0.05663902 - samples/sec: 138.15 - lr: 0.025000
2022-05-13 16:41:19,325 epoch 19 - iter 30/107 - loss 0.05579256 - samples/sec: 140.30 - lr: 0.025000
2022-05-13 16:41:21,529 epoch 19 - iter 40/107 - loss 0.05441362 - samples/sec: 145.29 - lr: 0.025000
2022-05-13 16:41:23,898 epoch 19 - iter 50/107 - loss 0.05509704 - samples/sec: 135.14 - lr: 0.025000
2022-05-13 16:41:26,101 epoch 19 - iter 60/107 - loss 0.05676208 - samples/sec: 145.30 - lr: 0.025000
2022-05-13 16:41:28,389 epoch 19 - iter 70/107 - loss 0.05810869 - samples/sec: 139.93 - lr: 0.025000
2022-05-13 16:41:30,564 epoch 19 - iter 80/107 - loss 0.05875496 - samples/sec: 147.18 - lr: 0.025000
2022-05-13 16:41:32,682 epoch 19 - iter 90/107 - loss 0.05982196 - samples/sec: 151.14 - lr: 0.025000
2022-05-13 16:41:34,732 epoch 19 - iter 100/107 - loss 0.05985136 - samples/sec: 156.16 - lr: 0.025000
2022-05-13 16:41:36,075 ----------------------------------------------------------------------------------------------------
2022-05-13 16:41:36,075 EPOCH 19 done: loss 0.0612 - lr 0.025000
2022-05-13 16:41:43,160 Evaluating as a multi-label problem: False
2022-05-13 16:41:43,171 DEV : loss 0.1915552020072937 - f1-score (micro avg)  0.5115
2022-05-13 16:41:43,240 BAD EPOCHS (no improvement): 3
2022-05-13 16:41:43,242 ----------------------------------------------------------------------------------------------------
2022-05-13 16:41:45,472 epoch 20 - iter 10/107 - loss 0.06544767 - samples/sec: 143.58 - lr: 0.025000
2022-05-13 16:41:47,724 epoch 20 - iter 20/107 - loss 0.06426441 - samples/sec: 142.14 - lr: 0.025000
2022-05-13 16:41:50,189 epoch 20 - iter 30/107 - loss 0.05932795 - samples/sec: 129.88 - lr: 0.025000
2022-05-13 16:41:52,416 epoch 20 - iter 40/107 - loss 0.05673826 - samples/sec: 143.74 - lr: 0.025000
2022-05-13 16:41:54,599 epoch 20 - iter 50/107 - loss 0.05732471 - samples/sec: 146.64 - lr: 0.025000
2022-05-13 16:41:56,848 epoch 20 - iter 60/107 - loss 0.05590279 - samples/sec: 142.33 - lr: 0.025000
2022-05-13 16:41:59,093 epoch 20 - iter 70/107 - loss 0.05665634 - samples/sec: 142.62 - lr: 0.025000
2022-05-13 16:42:01,523 epoch 20 - iter 80/107 - loss 0.05768170 - samples/sec: 131.76 - lr: 0.025000
2022-05-13 16:42:03,753 epoch 20 - iter 90/107 - loss 0.05878206 - samples/sec: 143.56 - lr: 0.025000
2022-05-13 16:42:05,968 epoch 20 - iter 100/107 - loss 0.05977012 - samples/sec: 144.49 - lr: 0.025000
2022-05-13 16:42:07,509 ----------------------------------------------------------------------------------------------------
2022-05-13 16:42:07,509 EPOCH 20 done: loss 0.0604 - lr 0.025000
2022-05-13 16:42:15,023 Evaluating as a multi-label problem: False
2022-05-13 16:42:15,033 DEV : loss 0.21333733201026917 - f1-score (micro avg)  0.4975
2022-05-13 16:42:15,101 Epoch    20: reducing learning rate of group 0 to 1.2500e-02.
2022-05-13 16:42:15,102 BAD EPOCHS (no improvement): 4
2022-05-13 16:42:15,103 ----------------------------------------------------------------------------------------------------
2022-05-13 16:42:17,554 epoch 21 - iter 10/107 - loss 0.05217553 - samples/sec: 130.63 - lr: 0.012500
2022-05-13 16:42:19,640 epoch 21 - iter 20/107 - loss 0.05539138 - samples/sec: 153.48 - lr: 0.012500
2022-05-13 16:42:21,577 epoch 21 - iter 30/107 - loss 0.05804159 - samples/sec: 165.27 - lr: 0.012500
2022-05-13 16:42:23,543 epoch 21 - iter 40/107 - loss 0.05369967 - samples/sec: 162.79 - lr: 0.012500
2022-05-13 16:42:25,549 epoch 21 - iter 50/107 - loss 0.05624427 - samples/sec: 159.60 - lr: 0.012500
2022-05-13 16:42:27,840 epoch 21 - iter 60/107 - loss 0.05641989 - samples/sec: 139.76 - lr: 0.012500
2022-05-13 16:42:29,963 epoch 21 - iter 70/107 - loss 0.05820327 - samples/sec: 150.79 - lr: 0.012500
2022-05-13 16:42:32,245 epoch 21 - iter 80/107 - loss 0.05872916 - samples/sec: 140.28 - lr: 0.012500
2022-05-13 16:42:34,294 epoch 21 - iter 90/107 - loss 0.05783287 - samples/sec: 156.25 - lr: 0.012500
2022-05-13 16:42:36,676 epoch 21 - iter 100/107 - loss 0.05711094 - samples/sec: 134.39 - lr: 0.012500
2022-05-13 16:42:38,071 ----------------------------------------------------------------------------------------------------
2022-05-13 16:42:38,071 EPOCH 21 done: loss 0.0574 - lr 0.012500
2022-05-13 16:42:45,608 Evaluating as a multi-label problem: False
2022-05-13 16:42:45,618 DEV : loss 0.19431845843791962 - f1-score (micro avg)  0.5157
2022-05-13 16:42:45,687 BAD EPOCHS (no improvement): 1
2022-05-13 16:42:45,826 ----------------------------------------------------------------------------------------------------
2022-05-13 16:42:48,081 epoch 22 - iter 10/107 - loss 0.04731539 - samples/sec: 142.02 - lr: 0.012500
2022-05-13 16:42:50,283 epoch 22 - iter 20/107 - loss 0.05586471 - samples/sec: 145.37 - lr: 0.012500
2022-05-13 16:42:52,599 epoch 22 - iter 30/107 - loss 0.05696434 - samples/sec: 138.22 - lr: 0.012500
2022-05-13 16:42:54,808 epoch 22 - iter 40/107 - loss 0.05645968 - samples/sec: 144.94 - lr: 0.012500
2022-05-13 16:42:57,119 epoch 22 - iter 50/107 - loss 0.05635939 - samples/sec: 138.49 - lr: 0.012500
2022-05-13 16:42:59,588 epoch 22 - iter 60/107 - loss 0.05756216 - samples/sec: 129.66 - lr: 0.012500
2022-05-13 16:43:01,840 epoch 22 - iter 70/107 - loss 0.05437843 - samples/sec: 142.12 - lr: 0.012500
2022-05-13 16:43:04,162 epoch 22 - iter 80/107 - loss 0.05516963 - samples/sec: 137.87 - lr: 0.012500
2022-05-13 16:43:06,346 epoch 22 - iter 90/107 - loss 0.05411663 - samples/sec: 146.62 - lr: 0.012500
2022-05-13 16:43:08,424 epoch 22 - iter 100/107 - loss 0.05570837 - samples/sec: 154.07 - lr: 0.012500
2022-05-13 16:43:09,602 ----------------------------------------------------------------------------------------------------
2022-05-13 16:43:09,602 EPOCH 22 done: loss 0.0562 - lr 0.012500
2022-05-13 16:43:16,456 Evaluating as a multi-label problem: False
2022-05-13 16:43:16,466 DEV : loss 0.19357305765151978 - f1-score (micro avg)  0.517
2022-05-13 16:43:16,535 BAD EPOCHS (no improvement): 2
2022-05-13 16:43:16,537 ----------------------------------------------------------------------------------------------------
2022-05-13 16:43:18,731 epoch 23 - iter 10/107 - loss 0.04819639 - samples/sec: 145.93 - lr: 0.012500
2022-05-13 16:43:20,948 epoch 23 - iter 20/107 - loss 0.05219479 - samples/sec: 144.40 - lr: 0.012500
2022-05-13 16:43:23,132 epoch 23 - iter 30/107 - loss 0.05194079 - samples/sec: 146.63 - lr: 0.012500
2022-05-13 16:43:25,494 epoch 23 - iter 40/107 - loss 0.05136101 - samples/sec: 135.51 - lr: 0.012500
2022-05-13 16:43:27,577 epoch 23 - iter 50/107 - loss 0.05222130 - samples/sec: 153.66 - lr: 0.012500
2022-05-13 16:43:29,911 epoch 23 - iter 60/107 - loss 0.05200240 - samples/sec: 137.14 - lr: 0.012500
2022-05-13 16:43:32,169 epoch 23 - iter 70/107 - loss 0.05291329 - samples/sec: 141.82 - lr: 0.012500
2022-05-13 16:43:34,501 epoch 23 - iter 80/107 - loss 0.05263836 - samples/sec: 137.23 - lr: 0.012500
2022-05-13 16:43:36,753 epoch 23 - iter 90/107 - loss 0.05297961 - samples/sec: 142.21 - lr: 0.012500
2022-05-13 16:43:39,067 epoch 23 - iter 100/107 - loss 0.05302282 - samples/sec: 138.30 - lr: 0.012500
2022-05-13 16:43:40,576 ----------------------------------------------------------------------------------------------------
2022-05-13 16:43:40,576 EPOCH 23 done: loss 0.0545 - lr 0.012500
2022-05-13 16:43:47,955 Evaluating as a multi-label problem: False
2022-05-13 16:43:47,965 DEV : loss 0.20695240795612335 - f1-score (micro avg)  0.5104
2022-05-13 16:43:48,034 BAD EPOCHS (no improvement): 3
2022-05-13 16:43:48,036 ----------------------------------------------------------------------------------------------------
2022-05-13 16:43:50,266 epoch 24 - iter 10/107 - loss 0.05792071 - samples/sec: 143.55 - lr: 0.012500
2022-05-13 16:43:52,566 epoch 24 - iter 20/107 - loss 0.05881960 - samples/sec: 139.17 - lr: 0.012500
2022-05-13 16:43:54,655 epoch 24 - iter 30/107 - loss 0.05644521 - samples/sec: 153.23 - lr: 0.012500
2022-05-13 16:43:56,695 epoch 24 - iter 40/107 - loss 0.05631808 - samples/sec: 156.96 - lr: 0.012500
2022-05-13 16:43:58,706 epoch 24 - iter 50/107 - loss 0.05643443 - samples/sec: 159.19 - lr: 0.012500
2022-05-13 16:44:00,676 epoch 24 - iter 60/107 - loss 0.05588626 - samples/sec: 162.49 - lr: 0.012500
2022-05-13 16:44:02,756 epoch 24 - iter 70/107 - loss 0.05598274 - samples/sec: 153.98 - lr: 0.012500
2022-05-13 16:44:04,920 epoch 24 - iter 80/107 - loss 0.05590490 - samples/sec: 147.90 - lr: 0.012500
2022-05-13 16:44:07,159 epoch 24 - iter 90/107 - loss 0.05537854 - samples/sec: 142.99 - lr: 0.012500
2022-05-13 16:44:09,375 epoch 24 - iter 100/107 - loss 0.05482500 - samples/sec: 144.46 - lr: 0.012500
2022-05-13 16:44:10,865 ----------------------------------------------------------------------------------------------------
2022-05-13 16:44:10,865 EPOCH 24 done: loss 0.0541 - lr 0.012500
2022-05-13 16:44:18,156 Evaluating as a multi-label problem: False
2022-05-13 16:44:18,166 DEV : loss 0.208414688706398 - f1-score (micro avg)  0.5104
2022-05-13 16:44:18,235 Epoch    24: reducing learning rate of group 0 to 6.2500e-03.
2022-05-13 16:44:18,235 BAD EPOCHS (no improvement): 4
2022-05-13 16:44:18,237 ----------------------------------------------------------------------------------------------------
2022-05-13 16:44:20,412 epoch 25 - iter 10/107 - loss 0.05237660 - samples/sec: 147.21 - lr: 0.006250
2022-05-13 16:44:22,661 epoch 25 - iter 20/107 - loss 0.05600905 - samples/sec: 142.33 - lr: 0.006250
2022-05-13 16:44:24,926 epoch 25 - iter 30/107 - loss 0.05384261 - samples/sec: 141.33 - lr: 0.006250
2022-05-13 16:44:27,181 epoch 25 - iter 40/107 - loss 0.05472652 - samples/sec: 141.94 - lr: 0.006250
2022-05-13 16:44:29,489 epoch 25 - iter 50/107 - loss 0.05402711 - samples/sec: 138.70 - lr: 0.006250
2022-05-13 16:44:31,639 epoch 25 - iter 60/107 - loss 0.05366897 - samples/sec: 148.90 - lr: 0.006250
2022-05-13 16:44:33,858 epoch 25 - iter 70/107 - loss 0.05408996 - samples/sec: 144.27 - lr: 0.006250
2022-05-13 16:44:36,345 epoch 25 - iter 80/107 - loss 0.05403369 - samples/sec: 128.71 - lr: 0.006250
2022-05-13 16:44:38,576 epoch 25 - iter 90/107 - loss 0.05400974 - samples/sec: 143.53 - lr: 0.006250
2022-05-13 16:44:40,786 epoch 25 - iter 100/107 - loss 0.05414790 - samples/sec: 144.81 - lr: 0.006250
2022-05-13 16:44:42,151 ----------------------------------------------------------------------------------------------------
2022-05-13 16:44:42,151 EPOCH 25 done: loss 0.0546 - lr 0.006250
2022-05-13 16:44:48,986 Evaluating as a multi-label problem: False
2022-05-13 16:44:48,997 DEV : loss 0.20282576978206635 - f1-score (micro avg)  0.5087
2022-05-13 16:44:49,065 BAD EPOCHS (no improvement): 1
2022-05-13 16:44:49,067 ----------------------------------------------------------------------------------------------------
2022-05-13 16:44:51,185 epoch 26 - iter 10/107 - loss 0.04386255 - samples/sec: 151.16 - lr: 0.006250
2022-05-13 16:44:53,457 epoch 26 - iter 20/107 - loss 0.05079695 - samples/sec: 140.95 - lr: 0.006250
2022-05-13 16:44:55,742 epoch 26 - iter 30/107 - loss 0.04826403 - samples/sec: 140.09 - lr: 0.006250
2022-05-13 16:44:58,107 epoch 26 - iter 40/107 - loss 0.05004218 - samples/sec: 135.36 - lr: 0.006250
2022-05-13 16:45:00,342 epoch 26 - iter 50/107 - loss 0.05125703 - samples/sec: 143.23 - lr: 0.006250
2022-05-13 16:45:02,555 epoch 26 - iter 60/107 - loss 0.05166810 - samples/sec: 144.64 - lr: 0.006250
2022-05-13 16:45:04,988 epoch 26 - iter 70/107 - loss 0.05245805 - samples/sec: 131.58 - lr: 0.006250
2022-05-13 16:45:07,297 epoch 26 - iter 80/107 - loss 0.05474367 - samples/sec: 138.65 - lr: 0.006250
2022-05-13 16:45:09,695 epoch 26 - iter 90/107 - loss 0.05563716 - samples/sec: 133.49 - lr: 0.006250
2022-05-13 16:45:11,912 epoch 26 - iter 100/107 - loss 0.05452188 - samples/sec: 144.35 - lr: 0.006250
2022-05-13 16:45:13,267 ----------------------------------------------------------------------------------------------------
2022-05-13 16:45:13,267 EPOCH 26 done: loss 0.0541 - lr 0.006250
2022-05-13 16:45:20,680 Evaluating as a multi-label problem: False
2022-05-13 16:45:20,690 DEV : loss 0.20642335712909698 - f1-score (micro avg)  0.5087
2022-05-13 16:45:20,758 BAD EPOCHS (no improvement): 2
2022-05-13 16:45:20,761 ----------------------------------------------------------------------------------------------------
2022-05-13 16:45:23,092 epoch 27 - iter 10/107 - loss 0.05864367 - samples/sec: 137.34 - lr: 0.006250
2022-05-13 16:45:25,392 epoch 27 - iter 20/107 - loss 0.05731656 - samples/sec: 139.16 - lr: 0.006250
2022-05-13 16:45:27,622 epoch 27 - iter 30/107 - loss 0.05447595 - samples/sec: 143.60 - lr: 0.006250
2022-05-13 16:45:29,586 epoch 27 - iter 40/107 - loss 0.05617449 - samples/sec: 162.99 - lr: 0.006250
2022-05-13 16:45:31,718 epoch 27 - iter 50/107 - loss 0.05834537 - samples/sec: 150.16 - lr: 0.006250
2022-05-13 16:45:33,666 epoch 27 - iter 60/107 - loss 0.05853421 - samples/sec: 164.38 - lr: 0.006250
2022-05-13 16:45:35,760 epoch 27 - iter 70/107 - loss 0.05668679 - samples/sec: 152.83 - lr: 0.006250
2022-05-13 16:45:37,707 epoch 27 - iter 80/107 - loss 0.05542701 - samples/sec: 164.45 - lr: 0.006250
2022-05-13 16:45:39,873 epoch 27 - iter 90/107 - loss 0.05518382 - samples/sec: 147.81 - lr: 0.006250
2022-05-13 16:45:42,165 epoch 27 - iter 100/107 - loss 0.05371785 - samples/sec: 139.66 - lr: 0.006250
2022-05-13 16:45:43,596 ----------------------------------------------------------------------------------------------------
2022-05-13 16:45:43,597 EPOCH 27 done: loss 0.0530 - lr 0.006250
2022-05-13 16:45:52,368 Evaluating as a multi-label problem: False
2022-05-13 16:45:52,379 DEV : loss 0.20717425644397736 - f1-score (micro avg)  0.5052
2022-05-13 16:45:52,447 BAD EPOCHS (no improvement): 3
2022-05-13 16:45:52,449 ----------------------------------------------------------------------------------------------------
2022-05-13 16:45:54,710 epoch 28 - iter 10/107 - loss 0.04052734 - samples/sec: 141.60 - lr: 0.006250
2022-05-13 16:45:56,933 epoch 28 - iter 20/107 - loss 0.05308938 - samples/sec: 144.00 - lr: 0.006250
2022-05-13 16:45:59,196 epoch 28 - iter 30/107 - loss 0.05560421 - samples/sec: 141.47 - lr: 0.006250
2022-05-13 16:46:01,591 epoch 28 - iter 40/107 - loss 0.05662588 - samples/sec: 133.64 - lr: 0.006250
2022-05-13 16:46:03,739 epoch 28 - iter 50/107 - loss 0.05569402 - samples/sec: 149.05 - lr: 0.006250
2022-05-13 16:46:06,061 epoch 28 - iter 60/107 - loss 0.05357086 - samples/sec: 137.85 - lr: 0.006250
2022-05-13 16:46:08,302 epoch 28 - iter 70/107 - loss 0.05280355 - samples/sec: 142.88 - lr: 0.006250
2022-05-13 16:46:10,582 epoch 28 - iter 80/107 - loss 0.05324141 - samples/sec: 140.42 - lr: 0.006250
2022-05-13 16:46:12,941 epoch 28 - iter 90/107 - loss 0.05404324 - samples/sec: 135.68 - lr: 0.006250
2022-05-13 16:46:15,108 epoch 28 - iter 100/107 - loss 0.05425564 - samples/sec: 147.71 - lr: 0.006250
2022-05-13 16:46:16,467 ----------------------------------------------------------------------------------------------------
2022-05-13 16:46:16,468 EPOCH 28 done: loss 0.0533 - lr 0.006250
2022-05-13 16:46:23,010 Evaluating as a multi-label problem: False
2022-05-13 16:46:23,021 DEV : loss 0.20436441898345947 - f1-score (micro avg)  0.5106
2022-05-13 16:46:23,090 Epoch    28: reducing learning rate of group 0 to 3.1250e-03.
2022-05-13 16:46:23,091 BAD EPOCHS (no improvement): 4
2022-05-13 16:46:23,093 ----------------------------------------------------------------------------------------------------
2022-05-13 16:46:25,336 epoch 29 - iter 10/107 - loss 0.04961687 - samples/sec: 142.75 - lr: 0.003125
2022-05-13 16:46:27,663 epoch 29 - iter 20/107 - loss 0.04824878 - samples/sec: 137.52 - lr: 0.003125
2022-05-13 16:46:29,872 epoch 29 - iter 30/107 - loss 0.05029332 - samples/sec: 144.93 - lr: 0.003125
2022-05-13 16:46:32,137 epoch 29 - iter 40/107 - loss 0.05043260 - samples/sec: 141.37 - lr: 0.003125
2022-05-13 16:46:34,456 epoch 29 - iter 50/107 - loss 0.05102735 - samples/sec: 138.03 - lr: 0.003125
2022-05-13 16:46:36,746 epoch 29 - iter 60/107 - loss 0.04988184 - samples/sec: 139.80 - lr: 0.003125
2022-05-13 16:46:38,926 epoch 29 - iter 70/107 - loss 0.04935758 - samples/sec: 146.85 - lr: 0.003125
2022-05-13 16:46:41,202 epoch 29 - iter 80/107 - loss 0.05035623 - samples/sec: 140.60 - lr: 0.003125
2022-05-13 16:46:43,408 epoch 29 - iter 90/107 - loss 0.04978247 - samples/sec: 145.14 - lr: 0.003125
2022-05-13 16:46:45,707 epoch 29 - iter 100/107 - loss 0.04996100 - samples/sec: 139.25 - lr: 0.003125
2022-05-13 16:46:47,130 ----------------------------------------------------------------------------------------------------
2022-05-13 16:46:47,130 EPOCH 29 done: loss 0.0503 - lr 0.003125
2022-05-13 16:46:54,437 Evaluating as a multi-label problem: False
2022-05-13 16:46:54,447 DEV : loss 0.20565840601921082 - f1-score (micro avg)  0.5051
2022-05-13 16:46:54,516 BAD EPOCHS (no improvement): 1
2022-05-13 16:46:54,517 ----------------------------------------------------------------------------------------------------
2022-05-13 16:46:56,849 epoch 30 - iter 10/107 - loss 0.05591168 - samples/sec: 137.33 - lr: 0.003125
2022-05-13 16:46:59,002 epoch 30 - iter 20/107 - loss 0.05746701 - samples/sec: 148.68 - lr: 0.003125
2022-05-13 16:47:01,211 epoch 30 - iter 30/107 - loss 0.05259159 - samples/sec: 144.89 - lr: 0.003125
2022-05-13 16:47:03,448 epoch 30 - iter 40/107 - loss 0.05139594 - samples/sec: 143.13 - lr: 0.003125
2022-05-13 16:47:05,568 epoch 30 - iter 50/107 - loss 0.05212533 - samples/sec: 151.04 - lr: 0.003125
2022-05-13 16:47:07,529 epoch 30 - iter 60/107 - loss 0.05119077 - samples/sec: 163.23 - lr: 0.003125
2022-05-13 16:47:09,658 epoch 30 - iter 70/107 - loss 0.05249268 - samples/sec: 150.38 - lr: 0.003125
2022-05-13 16:47:11,752 epoch 30 - iter 80/107 - loss 0.05178069 - samples/sec: 152.89 - lr: 0.003125
2022-05-13 16:47:13,998 epoch 30 - iter 90/107 - loss 0.05145790 - samples/sec: 142.50 - lr: 0.003125
2022-05-13 16:47:16,318 epoch 30 - iter 100/107 - loss 0.05156280 - samples/sec: 138.02 - lr: 0.003125
2022-05-13 16:47:17,736 ----------------------------------------------------------------------------------------------------
2022-05-13 16:47:17,736 EPOCH 30 done: loss 0.0511 - lr 0.003125
2022-05-13 16:47:25,148 Evaluating as a multi-label problem: False
2022-05-13 16:47:25,159 DEV : loss 0.2031317502260208 - f1-score (micro avg)  0.5094
2022-05-13 16:47:25,229 BAD EPOCHS (no improvement): 2
2022-05-13 16:47:25,232 ----------------------------------------------------------------------------------------------------
2022-05-13 16:47:27,585 epoch 31 - iter 10/107 - loss 0.05349009 - samples/sec: 136.07 - lr: 0.003125
2022-05-13 16:47:29,782 epoch 31 - iter 20/107 - loss 0.05135589 - samples/sec: 145.67 - lr: 0.003125
2022-05-13 16:47:32,106 epoch 31 - iter 30/107 - loss 0.05444515 - samples/sec: 137.75 - lr: 0.003125
2022-05-13 16:47:34,378 epoch 31 - iter 40/107 - loss 0.05311455 - samples/sec: 140.93 - lr: 0.003125
2022-05-13 16:47:36,690 epoch 31 - iter 50/107 - loss 0.04963537 - samples/sec: 138.42 - lr: 0.003125
2022-05-13 16:47:38,889 epoch 31 - iter 60/107 - loss 0.04949016 - samples/sec: 145.61 - lr: 0.003125
2022-05-13 16:47:41,119 epoch 31 - iter 70/107 - loss 0.04959508 - samples/sec: 143.57 - lr: 0.003125
2022-05-13 16:47:43,421 epoch 31 - iter 80/107 - loss 0.04881679 - samples/sec: 139.04 - lr: 0.003125
2022-05-13 16:47:45,740 epoch 31 - iter 90/107 - loss 0.04962222 - samples/sec: 138.04 - lr: 0.003125
2022-05-13 16:47:48,142 epoch 31 - iter 100/107 - loss 0.05032046 - samples/sec: 133.26 - lr: 0.003125
2022-05-13 16:47:49,345 ----------------------------------------------------------------------------------------------------
2022-05-13 16:47:49,345 EPOCH 31 done: loss 0.0506 - lr 0.003125
2022-05-13 16:47:55,811 Evaluating as a multi-label problem: False
2022-05-13 16:47:55,821 DEV : loss 0.20326189696788788 - f1-score (micro avg)  0.5071
2022-05-13 16:47:55,889 BAD EPOCHS (no improvement): 3
2022-05-13 16:47:55,891 ----------------------------------------------------------------------------------------------------
2022-05-13 16:47:57,969 epoch 32 - iter 10/107 - loss 0.05049961 - samples/sec: 154.09 - lr: 0.003125
2022-05-13 16:48:00,047 epoch 32 - iter 20/107 - loss 0.05070419 - samples/sec: 154.03 - lr: 0.003125
2022-05-13 16:48:02,370 epoch 32 - iter 30/107 - loss 0.05311009 - samples/sec: 137.78 - lr: 0.003125
2022-05-13 16:48:04,637 epoch 32 - iter 40/107 - loss 0.05472416 - samples/sec: 141.26 - lr: 0.003125
2022-05-13 16:48:06,858 epoch 32 - iter 50/107 - loss 0.05454294 - samples/sec: 144.12 - lr: 0.003125
2022-05-13 16:48:09,311 epoch 32 - iter 60/107 - loss 0.05347524 - samples/sec: 130.52 - lr: 0.003125
2022-05-13 16:48:11,680 epoch 32 - iter 70/107 - loss 0.05203171 - samples/sec: 135.09 - lr: 0.003125
2022-05-13 16:48:14,032 epoch 32 - iter 80/107 - loss 0.05043261 - samples/sec: 136.10 - lr: 0.003125
2022-05-13 16:48:16,148 epoch 32 - iter 90/107 - loss 0.05150102 - samples/sec: 151.29 - lr: 0.003125
2022-05-13 16:48:18,386 epoch 32 - iter 100/107 - loss 0.05194010 - samples/sec: 143.06 - lr: 0.003125
2022-05-13 16:48:19,810 ----------------------------------------------------------------------------------------------------
2022-05-13 16:48:19,810 EPOCH 32 done: loss 0.0523 - lr 0.003125
2022-05-13 16:48:27,510 Evaluating as a multi-label problem: False
2022-05-13 16:48:27,521 DEV : loss 0.2010992169380188 - f1-score (micro avg)  0.5078
2022-05-13 16:48:27,590 Epoch    32: reducing learning rate of group 0 to 1.5625e-03.
2022-05-13 16:48:27,590 BAD EPOCHS (no improvement): 4
2022-05-13 16:48:27,592 ----------------------------------------------------------------------------------------------------
2022-05-13 16:48:29,832 epoch 33 - iter 10/107 - loss 0.05477983 - samples/sec: 142.89 - lr: 0.001563
2022-05-13 16:48:32,337 epoch 33 - iter 20/107 - loss 0.04807635 - samples/sec: 127.81 - lr: 0.001563
2022-05-13 16:48:34,662 epoch 33 - iter 30/107 - loss 0.04842987 - samples/sec: 137.68 - lr: 0.001563
2022-05-13 16:48:36,808 epoch 33 - iter 40/107 - loss 0.04727553 - samples/sec: 149.21 - lr: 0.001563
2022-05-13 16:48:38,944 epoch 33 - iter 50/107 - loss 0.04872783 - samples/sec: 149.85 - lr: 0.001563
2022-05-13 16:48:41,053 epoch 33 - iter 60/107 - loss 0.04938803 - samples/sec: 151.76 - lr: 0.001563
2022-05-13 16:48:43,090 epoch 33 - iter 70/107 - loss 0.05092556 - samples/sec: 157.18 - lr: 0.001563
2022-05-13 16:48:45,095 epoch 33 - iter 80/107 - loss 0.04940496 - samples/sec: 159.70 - lr: 0.001563
2022-05-13 16:48:47,199 epoch 33 - iter 90/107 - loss 0.04911463 - samples/sec: 152.19 - lr: 0.001563
2022-05-13 16:48:49,418 epoch 33 - iter 100/107 - loss 0.04954657 - samples/sec: 144.25 - lr: 0.001563
2022-05-13 16:48:50,811 ----------------------------------------------------------------------------------------------------
2022-05-13 16:48:50,811 EPOCH 33 done: loss 0.0500 - lr 0.001563
2022-05-13 16:48:58,149 Evaluating as a multi-label problem: False
2022-05-13 16:48:58,160 DEV : loss 0.20336124300956726 - f1-score (micro avg)  0.5094
2022-05-13 16:48:58,228 BAD EPOCHS (no improvement): 1
2022-05-13 16:48:58,230 ----------------------------------------------------------------------------------------------------
2022-05-13 16:49:00,380 epoch 34 - iter 10/107 - loss 0.04543513 - samples/sec: 148.89 - lr: 0.001563
2022-05-13 16:49:02,709 epoch 34 - iter 20/107 - loss 0.04477607 - samples/sec: 137.48 - lr: 0.001563
2022-05-13 16:49:05,000 epoch 34 - iter 30/107 - loss 0.04583071 - samples/sec: 139.68 - lr: 0.001563
2022-05-13 16:49:07,303 epoch 34 - iter 40/107 - loss 0.04746937 - samples/sec: 139.04 - lr: 0.001563
2022-05-13 16:49:09,521 epoch 34 - iter 50/107 - loss 0.04757058 - samples/sec: 144.29 - lr: 0.001563
2022-05-13 16:49:11,686 epoch 34 - iter 60/107 - loss 0.05141718 - samples/sec: 147.88 - lr: 0.001563
2022-05-13 16:49:14,020 epoch 34 - iter 70/107 - loss 0.05276314 - samples/sec: 137.14 - lr: 0.001563
2022-05-13 16:49:16,292 epoch 34 - iter 80/107 - loss 0.05183859 - samples/sec: 140.95 - lr: 0.001563
2022-05-13 16:49:18,669 epoch 34 - iter 90/107 - loss 0.05122049 - samples/sec: 134.65 - lr: 0.001563
2022-05-13 16:49:20,980 epoch 34 - iter 100/107 - loss 0.05121570 - samples/sec: 138.51 - lr: 0.001563
2022-05-13 16:49:22,470 ----------------------------------------------------------------------------------------------------
2022-05-13 16:49:22,470 EPOCH 34 done: loss 0.0513 - lr 0.001563
2022-05-13 16:49:29,292 Evaluating as a multi-label problem: False
2022-05-13 16:49:29,303 DEV : loss 0.2046484500169754 - f1-score (micro avg)  0.5079
2022-05-13 16:49:29,371 BAD EPOCHS (no improvement): 2
2022-05-13 16:49:29,373 ----------------------------------------------------------------------------------------------------
2022-05-13 16:49:31,460 epoch 35 - iter 10/107 - loss 0.05233654 - samples/sec: 153.39 - lr: 0.001563
2022-05-13 16:49:33,578 epoch 35 - iter 20/107 - loss 0.05147409 - samples/sec: 151.15 - lr: 0.001563
2022-05-13 16:49:35,917 epoch 35 - iter 30/107 - loss 0.05105255 - samples/sec: 136.90 - lr: 0.001563
2022-05-13 16:49:38,098 epoch 35 - iter 40/107 - loss 0.05234049 - samples/sec: 146.74 - lr: 0.001563
2022-05-13 16:49:40,285 epoch 35 - iter 50/107 - loss 0.05211265 - samples/sec: 146.40 - lr: 0.001563
2022-05-13 16:49:42,522 epoch 35 - iter 60/107 - loss 0.05059571 - samples/sec: 143.13 - lr: 0.001563
2022-05-13 16:49:44,800 epoch 35 - iter 70/107 - loss 0.05218261 - samples/sec: 140.50 - lr: 0.001563
2022-05-13 16:49:47,018 epoch 35 - iter 80/107 - loss 0.05206086 - samples/sec: 144.34 - lr: 0.001563
2022-05-13 16:49:49,294 epoch 35 - iter 90/107 - loss 0.05161752 - samples/sec: 140.64 - lr: 0.001563
2022-05-13 16:49:51,628 epoch 35 - iter 100/107 - loss 0.05173449 - samples/sec: 137.16 - lr: 0.001563
2022-05-13 16:49:52,944 ----------------------------------------------------------------------------------------------------
2022-05-13 16:49:52,944 EPOCH 35 done: loss 0.0513 - lr 0.001563
2022-05-13 16:50:00,386 Evaluating as a multi-label problem: False
2022-05-13 16:50:00,397 DEV : loss 0.20328332483768463 - f1-score (micro avg)  0.5102
2022-05-13 16:50:00,465 BAD EPOCHS (no improvement): 3
2022-05-13 16:50:00,495 ----------------------------------------------------------------------------------------------------
2022-05-13 16:50:02,685 epoch 36 - iter 10/107 - loss 0.05281732 - samples/sec: 146.18 - lr: 0.001563
2022-05-13 16:50:04,921 epoch 36 - iter 20/107 - loss 0.05287585 - samples/sec: 143.14 - lr: 0.001563
2022-05-13 16:50:07,242 epoch 36 - iter 30/107 - loss 0.05318709 - samples/sec: 137.96 - lr: 0.001563
2022-05-13 16:50:09,537 epoch 36 - iter 40/107 - loss 0.05130765 - samples/sec: 139.50 - lr: 0.001563
2022-05-13 16:50:11,743 epoch 36 - iter 50/107 - loss 0.05161259 - samples/sec: 145.09 - lr: 0.001563
2022-05-13 16:50:14,060 epoch 36 - iter 60/107 - loss 0.05051820 - samples/sec: 138.16 - lr: 0.001563
2022-05-13 16:50:16,074 epoch 36 - iter 70/107 - loss 0.05089344 - samples/sec: 158.98 - lr: 0.001563
2022-05-13 16:50:18,102 epoch 36 - iter 80/107 - loss 0.05016989 - samples/sec: 157.89 - lr: 0.001563
2022-05-13 16:50:20,137 epoch 36 - iter 90/107 - loss 0.04986506 - samples/sec: 157.28 - lr: 0.001563
2022-05-13 16:50:22,295 epoch 36 - iter 100/107 - loss 0.04905415 - samples/sec: 148.31 - lr: 0.001563
2022-05-13 16:50:23,668 ----------------------------------------------------------------------------------------------------
2022-05-13 16:50:23,668 EPOCH 36 done: loss 0.0501 - lr 0.001563
2022-05-13 16:50:31,697 Evaluating as a multi-label problem: False
2022-05-13 16:50:31,708 DEV : loss 0.20548012852668762 - f1-score (micro avg)  0.5114
2022-05-13 16:50:31,776 Epoch    36: reducing learning rate of group 0 to 7.8125e-04.
2022-05-13 16:50:31,776 BAD EPOCHS (no improvement): 4
2022-05-13 16:50:31,778 ----------------------------------------------------------------------------------------------------
2022-05-13 16:50:34,036 epoch 37 - iter 10/107 - loss 0.04777670 - samples/sec: 141.76 - lr: 0.000781
2022-05-13 16:50:36,498 epoch 37 - iter 20/107 - loss 0.04974607 - samples/sec: 130.05 - lr: 0.000781
2022-05-13 16:50:38,633 epoch 37 - iter 30/107 - loss 0.05288484 - samples/sec: 149.93 - lr: 0.000781
2022-05-13 16:50:41,050 epoch 37 - iter 40/107 - loss 0.05342023 - samples/sec: 132.48 - lr: 0.000781
2022-05-13 16:50:43,408 epoch 37 - iter 50/107 - loss 0.05330309 - samples/sec: 135.73 - lr: 0.000781
2022-05-13 16:50:45,771 epoch 37 - iter 60/107 - loss 0.05265374 - samples/sec: 135.49 - lr: 0.000781
2022-05-13 16:50:47,945 epoch 37 - iter 70/107 - loss 0.05424516 - samples/sec: 147.25 - lr: 0.000781
2022-05-13 16:50:50,250 epoch 37 - iter 80/107 - loss 0.05297379 - samples/sec: 138.87 - lr: 0.000781
2022-05-13 16:50:52,549 epoch 37 - iter 90/107 - loss 0.05234775 - samples/sec: 139.23 - lr: 0.000781
2022-05-13 16:50:54,809 epoch 37 - iter 100/107 - loss 0.05153826 - samples/sec: 141.64 - lr: 0.000781
2022-05-13 16:50:56,364 ----------------------------------------------------------------------------------------------------
2022-05-13 16:50:56,364 EPOCH 37 done: loss 0.0512 - lr 0.000781
2022-05-13 16:51:03,440 Evaluating as a multi-label problem: False
2022-05-13 16:51:03,450 DEV : loss 0.20539306104183197 - f1-score (micro avg)  0.511
2022-05-13 16:51:03,519 BAD EPOCHS (no improvement): 1
2022-05-13 16:51:03,554 ----------------------------------------------------------------------------------------------------
2022-05-13 16:51:05,491 epoch 38 - iter 10/107 - loss 0.05289407 - samples/sec: 165.31 - lr: 0.000781
2022-05-13 16:51:07,707 epoch 38 - iter 20/107 - loss 0.04875327 - samples/sec: 144.45 - lr: 0.000781
2022-05-13 16:51:09,743 epoch 38 - iter 30/107 - loss 0.04849413 - samples/sec: 157.27 - lr: 0.000781
2022-05-13 16:51:11,978 epoch 38 - iter 40/107 - loss 0.04737995 - samples/sec: 143.23 - lr: 0.000781
2022-05-13 16:51:14,214 epoch 38 - iter 50/107 - loss 0.04853489 - samples/sec: 143.20 - lr: 0.000781
2022-05-13 16:51:16,650 epoch 38 - iter 60/107 - loss 0.04798709 - samples/sec: 131.37 - lr: 0.000781
2022-05-13 16:51:18,941 epoch 38 - iter 70/107 - loss 0.04727261 - samples/sec: 139.75 - lr: 0.000781
2022-05-13 16:51:21,201 epoch 38 - iter 80/107 - loss 0.04754693 - samples/sec: 141.66 - lr: 0.000781
2022-05-13 16:51:23,487 epoch 38 - iter 90/107 - loss 0.04813685 - samples/sec: 140.03 - lr: 0.000781
2022-05-13 16:51:25,633 epoch 38 - iter 100/107 - loss 0.04935072 - samples/sec: 149.20 - lr: 0.000781
2022-05-13 16:51:26,966 ----------------------------------------------------------------------------------------------------
2022-05-13 16:51:26,966 EPOCH 38 done: loss 0.0498 - lr 0.000781
2022-05-13 16:51:34,504 Evaluating as a multi-label problem: False
2022-05-13 16:51:34,514 DEV : loss 0.20264048874378204 - f1-score (micro avg)  0.5114
2022-05-13 16:51:34,582 BAD EPOCHS (no improvement): 2
2022-05-13 16:51:34,584 ----------------------------------------------------------------------------------------------------
2022-05-13 16:51:36,840 epoch 39 - iter 10/107 - loss 0.05188643 - samples/sec: 141.92 - lr: 0.000781
2022-05-13 16:51:39,139 epoch 39 - iter 20/107 - loss 0.05303242 - samples/sec: 139.25 - lr: 0.000781
2022-05-13 16:51:41,464 epoch 39 - iter 30/107 - loss 0.05167847 - samples/sec: 137.72 - lr: 0.000781
2022-05-13 16:51:43,636 epoch 39 - iter 40/107 - loss 0.05018035 - samples/sec: 147.39 - lr: 0.000781
2022-05-13 16:51:45,893 epoch 39 - iter 50/107 - loss 0.04974968 - samples/sec: 141.79 - lr: 0.000781
2022-05-13 16:51:48,087 epoch 39 - iter 60/107 - loss 0.05084657 - samples/sec: 145.96 - lr: 0.000781
2022-05-13 16:51:50,237 epoch 39 - iter 70/107 - loss 0.05176110 - samples/sec: 148.85 - lr: 0.000781
2022-05-13 16:51:52,337 epoch 39 - iter 80/107 - loss 0.05200155 - samples/sec: 152.49 - lr: 0.000781
2022-05-13 16:51:54,196 epoch 39 - iter 90/107 - loss 0.05159044 - samples/sec: 172.18 - lr: 0.000781
2022-05-13 16:51:56,223 epoch 39 - iter 100/107 - loss 0.05164068 - samples/sec: 157.94 - lr: 0.000781
2022-05-13 16:51:57,573 ----------------------------------------------------------------------------------------------------
2022-05-13 16:51:57,573 EPOCH 39 done: loss 0.0513 - lr 0.000781
2022-05-13 16:52:05,545 Evaluating as a multi-label problem: False
2022-05-13 16:52:05,556 DEV : loss 0.20255163311958313 - f1-score (micro avg)  0.5106
2022-05-13 16:52:05,625 BAD EPOCHS (no improvement): 3
2022-05-13 16:52:05,627 ----------------------------------------------------------------------------------------------------
2022-05-13 16:52:07,924 epoch 40 - iter 10/107 - loss 0.05505710 - samples/sec: 139.38 - lr: 0.000781
2022-05-13 16:52:10,294 epoch 40 - iter 20/107 - loss 0.05150146 - samples/sec: 135.04 - lr: 0.000781
2022-05-13 16:52:12,689 epoch 40 - iter 30/107 - loss 0.04617952 - samples/sec: 133.66 - lr: 0.000781
2022-05-13 16:52:15,051 epoch 40 - iter 40/107 - loss 0.04672034 - samples/sec: 135.56 - lr: 0.000781
2022-05-13 16:52:17,279 epoch 40 - iter 50/107 - loss 0.04680774 - samples/sec: 143.67 - lr: 0.000781
2022-05-13 16:52:19,617 epoch 40 - iter 60/107 - loss 0.04611107 - samples/sec: 136.92 - lr: 0.000781
2022-05-13 16:52:21,906 epoch 40 - iter 70/107 - loss 0.04654825 - samples/sec: 139.83 - lr: 0.000781
2022-05-13 16:52:24,207 epoch 40 - iter 80/107 - loss 0.04834039 - samples/sec: 139.14 - lr: 0.000781
2022-05-13 16:52:26,314 epoch 40 - iter 90/107 - loss 0.04852308 - samples/sec: 151.93 - lr: 0.000781
2022-05-13 16:52:28,566 epoch 40 - iter 100/107 - loss 0.04888178 - samples/sec: 142.17 - lr: 0.000781
2022-05-13 16:52:29,984 ----------------------------------------------------------------------------------------------------
2022-05-13 16:52:29,984 EPOCH 40 done: loss 0.0495 - lr 0.000781
2022-05-13 16:52:36,895 Evaluating as a multi-label problem: False
2022-05-13 16:52:36,906 DEV : loss 0.2034919708967209 - f1-score (micro avg)  0.511
2022-05-13 16:52:36,973 Epoch    40: reducing learning rate of group 0 to 3.9063e-04.
2022-05-13 16:52:36,974 BAD EPOCHS (no improvement): 4
2022-05-13 16:52:36,976 ----------------------------------------------------------------------------------------------------
2022-05-13 16:52:39,040 epoch 41 - iter 10/107 - loss 0.04858498 - samples/sec: 155.17 - lr: 0.000391
2022-05-13 16:52:41,041 epoch 41 - iter 20/107 - loss 0.04452228 - samples/sec: 159.93 - lr: 0.000391
2022-05-13 16:52:43,168 epoch 41 - iter 30/107 - loss 0.04456675 - samples/sec: 150.53 - lr: 0.000391
2022-05-13 16:52:45,414 epoch 41 - iter 40/107 - loss 0.04879280 - samples/sec: 142.53 - lr: 0.000391
2022-05-13 16:52:47,576 epoch 41 - iter 50/107 - loss 0.04908339 - samples/sec: 148.09 - lr: 0.000391
2022-05-13 16:52:49,714 epoch 41 - iter 60/107 - loss 0.04835602 - samples/sec: 149.74 - lr: 0.000391
2022-05-13 16:52:51,989 epoch 41 - iter 70/107 - loss 0.04919007 - samples/sec: 140.71 - lr: 0.000391
2022-05-13 16:52:54,410 epoch 41 - iter 80/107 - loss 0.04919060 - samples/sec: 132.21 - lr: 0.000391
2022-05-13 16:52:56,758 epoch 41 - iter 90/107 - loss 0.04870994 - samples/sec: 136.33 - lr: 0.000391
2022-05-13 16:52:58,974 epoch 41 - iter 100/107 - loss 0.04938401 - samples/sec: 144.45 - lr: 0.000391
2022-05-13 16:53:00,233 ----------------------------------------------------------------------------------------------------
2022-05-13 16:53:00,233 EPOCH 41 done: loss 0.0489 - lr 0.000391
2022-05-13 16:53:09,006 Evaluating as a multi-label problem: False
2022-05-13 16:53:09,016 DEV : loss 0.2042200118303299 - f1-score (micro avg)  0.5102
2022-05-13 16:53:09,084 BAD EPOCHS (no improvement): 1
2022-05-13 16:53:09,086 ----------------------------------------------------------------------------------------------------
2022-05-13 16:53:11,331 epoch 42 - iter 10/107 - loss 0.05251926 - samples/sec: 142.63 - lr: 0.000391
2022-05-13 16:53:13,617 epoch 42 - iter 20/107 - loss 0.04898560 - samples/sec: 140.03 - lr: 0.000391
2022-05-13 16:53:15,886 epoch 42 - iter 30/107 - loss 0.04969890 - samples/sec: 141.09 - lr: 0.000391
2022-05-13 16:53:18,202 epoch 42 - iter 40/107 - loss 0.04988142 - samples/sec: 138.20 - lr: 0.000391
2022-05-13 16:53:20,306 epoch 42 - iter 50/107 - loss 0.04726313 - samples/sec: 152.19 - lr: 0.000391
2022-05-13 16:53:22,332 epoch 42 - iter 60/107 - loss 0.04897986 - samples/sec: 157.97 - lr: 0.000391
2022-05-13 16:53:24,354 epoch 42 - iter 70/107 - loss 0.04784530 - samples/sec: 158.32 - lr: 0.000391
2022-05-13 16:53:26,314 epoch 42 - iter 80/107 - loss 0.04911705 - samples/sec: 163.39 - lr: 0.000391
2022-05-13 16:53:28,558 epoch 42 - iter 90/107 - loss 0.04891575 - samples/sec: 142.66 - lr: 0.000391
2022-05-13 16:53:30,594 epoch 42 - iter 100/107 - loss 0.04960038 - samples/sec: 157.21 - lr: 0.000391
2022-05-13 16:53:32,072 ----------------------------------------------------------------------------------------------------
2022-05-13 16:53:32,072 EPOCH 42 done: loss 0.0497 - lr 0.000391
2022-05-13 16:53:39,581 Evaluating as a multi-label problem: False
2022-05-13 16:53:39,591 DEV : loss 0.2032162845134735 - f1-score (micro avg)  0.5106
2022-05-13 16:53:39,661 BAD EPOCHS (no improvement): 2
2022-05-13 16:53:39,664 ----------------------------------------------------------------------------------------------------
2022-05-13 16:53:41,908 epoch 43 - iter 10/107 - loss 0.04252729 - samples/sec: 142.67 - lr: 0.000391
2022-05-13 16:53:44,210 epoch 43 - iter 20/107 - loss 0.04501269 - samples/sec: 139.06 - lr: 0.000391
2022-05-13 16:53:46,547 epoch 43 - iter 30/107 - loss 0.05033732 - samples/sec: 137.02 - lr: 0.000391
2022-05-13 16:53:48,733 epoch 43 - iter 40/107 - loss 0.05205910 - samples/sec: 146.45 - lr: 0.000391
2022-05-13 16:53:51,072 epoch 43 - iter 50/107 - loss 0.05036937 - samples/sec: 136.82 - lr: 0.000391
2022-05-13 16:53:53,334 epoch 43 - iter 60/107 - loss 0.04969775 - samples/sec: 141.54 - lr: 0.000391
2022-05-13 16:53:55,646 epoch 43 - iter 70/107 - loss 0.04938167 - samples/sec: 138.48 - lr: 0.000391
2022-05-13 16:53:58,070 epoch 43 - iter 80/107 - loss 0.05010118 - samples/sec: 132.08 - lr: 0.000391
2022-05-13 16:54:00,383 epoch 43 - iter 90/107 - loss 0.04996302 - samples/sec: 138.34 - lr: 0.000391
2022-05-13 16:54:02,637 epoch 43 - iter 100/107 - loss 0.05092464 - samples/sec: 142.08 - lr: 0.000391
2022-05-13 16:54:04,052 ----------------------------------------------------------------------------------------------------
2022-05-13 16:54:04,052 EPOCH 43 done: loss 0.0502 - lr 0.000391
2022-05-13 16:54:10,928 Evaluating as a multi-label problem: False
2022-05-13 16:54:10,939 DEV : loss 0.2032976895570755 - f1-score (micro avg)  0.509
2022-05-13 16:54:11,007 BAD EPOCHS (no improvement): 3
2022-05-13 16:54:11,012 ----------------------------------------------------------------------------------------------------
2022-05-13 16:54:13,051 epoch 44 - iter 10/107 - loss 0.04858482 - samples/sec: 157.07 - lr: 0.000391
2022-05-13 16:54:15,218 epoch 44 - iter 20/107 - loss 0.05019185 - samples/sec: 147.69 - lr: 0.000391
2022-05-13 16:54:17,294 epoch 44 - iter 30/107 - loss 0.05164617 - samples/sec: 154.25 - lr: 0.000391
2022-05-13 16:54:19,605 epoch 44 - iter 40/107 - loss 0.05166854 - samples/sec: 138.53 - lr: 0.000391
2022-05-13 16:54:21,736 epoch 44 - iter 50/107 - loss 0.05194043 - samples/sec: 150.25 - lr: 0.000391
2022-05-13 16:54:23,941 epoch 44 - iter 60/107 - loss 0.05268642 - samples/sec: 145.16 - lr: 0.000391
2022-05-13 16:54:25,562 epoch 44 - iter 70/107 - loss 0.05145101 - samples/sec: 197.57 - lr: 0.000391
2022-05-13 16:54:27,017 epoch 44 - iter 80/107 - loss 0.05134008 - samples/sec: 220.05 - lr: 0.000391
2022-05-13 16:54:28,547 epoch 44 - iter 90/107 - loss 0.05108349 - samples/sec: 209.21 - lr: 0.000391
2022-05-13 16:54:30,970 epoch 44 - iter 100/107 - loss 0.05096666 - samples/sec: 132.15 - lr: 0.000391
2022-05-13 16:54:32,377 ----------------------------------------------------------------------------------------------------
2022-05-13 16:54:32,378 EPOCH 44 done: loss 0.0510 - lr 0.000391
2022-05-13 16:54:39,891 Evaluating as a multi-label problem: False
2022-05-13 16:54:39,902 DEV : loss 0.2042008936405182 - f1-score (micro avg)  0.5078
2022-05-13 16:54:39,971 Epoch    44: reducing learning rate of group 0 to 1.9531e-04.
2022-05-13 16:54:39,972 BAD EPOCHS (no improvement): 4
2022-05-13 16:54:40,395 ----------------------------------------------------------------------------------------------------
2022-05-13 16:54:42,622 epoch 45 - iter 10/107 - loss 0.03685782 - samples/sec: 143.80 - lr: 0.000195
2022-05-13 16:54:44,872 epoch 45 - iter 20/107 - loss 0.03962739 - samples/sec: 142.24 - lr: 0.000195
2022-05-13 16:54:47,108 epoch 45 - iter 30/107 - loss 0.04363762 - samples/sec: 143.20 - lr: 0.000195
2022-05-13 16:54:49,439 epoch 45 - iter 40/107 - loss 0.04415284 - samples/sec: 137.31 - lr: 0.000195
2022-05-13 16:54:51,804 epoch 45 - iter 50/107 - loss 0.04370190 - samples/sec: 135.38 - lr: 0.000195
2022-05-13 16:54:54,004 epoch 45 - iter 60/107 - loss 0.04459803 - samples/sec: 145.49 - lr: 0.000195
2022-05-13 16:54:56,249 epoch 45 - iter 70/107 - loss 0.04621215 - samples/sec: 142.57 - lr: 0.000195
2022-05-13 16:54:58,661 epoch 45 - iter 80/107 - loss 0.04797642 - samples/sec: 132.75 - lr: 0.000195
2022-05-13 16:55:00,787 epoch 45 - iter 90/107 - loss 0.04787060 - samples/sec: 150.58 - lr: 0.000195
2022-05-13 16:55:02,892 epoch 45 - iter 100/107 - loss 0.04802479 - samples/sec: 152.04 - lr: 0.000195
2022-05-13 16:55:04,179 ----------------------------------------------------------------------------------------------------
2022-05-13 16:55:04,179 EPOCH 45 done: loss 0.0483 - lr 0.000195
2022-05-13 16:55:11,225 Evaluating as a multi-label problem: False
2022-05-13 16:55:11,235 DEV : loss 0.20425468683242798 - f1-score (micro avg)  0.5078
2022-05-13 16:55:11,303 BAD EPOCHS (no improvement): 1
2022-05-13 16:55:11,305 ----------------------------------------------------------------------------------------------------
2022-05-13 16:55:13,517 epoch 46 - iter 10/107 - loss 0.05121110 - samples/sec: 144.71 - lr: 0.000195
2022-05-13 16:55:15,853 epoch 46 - iter 20/107 - loss 0.04802523 - samples/sec: 137.03 - lr: 0.000195
2022-05-13 16:55:18,072 epoch 46 - iter 30/107 - loss 0.04809700 - samples/sec: 144.26 - lr: 0.000195
2022-05-13 16:55:20,317 epoch 46 - iter 40/107 - loss 0.04769152 - samples/sec: 142.59 - lr: 0.000195
2022-05-13 16:55:22,613 epoch 46 - iter 50/107 - loss 0.04691017 - samples/sec: 139.48 - lr: 0.000195
2022-05-13 16:55:24,886 epoch 46 - iter 60/107 - loss 0.04756290 - samples/sec: 140.79 - lr: 0.000195
2022-05-13 16:55:27,148 epoch 46 - iter 70/107 - loss 0.04753485 - samples/sec: 141.56 - lr: 0.000195
2022-05-13 16:55:29,488 epoch 46 - iter 80/107 - loss 0.04854955 - samples/sec: 136.79 - lr: 0.000195
2022-05-13 16:55:31,818 epoch 46 - iter 90/107 - loss 0.04885966 - samples/sec: 137.41 - lr: 0.000195
2022-05-13 16:55:34,192 epoch 46 - iter 100/107 - loss 0.04969479 - samples/sec: 134.83 - lr: 0.000195
2022-05-13 16:55:35,601 ----------------------------------------------------------------------------------------------------
2022-05-13 16:55:35,602 EPOCH 46 done: loss 0.0497 - lr 0.000195
2022-05-13 16:55:42,938 Evaluating as a multi-label problem: False
2022-05-13 16:55:42,949 DEV : loss 0.20416726171970367 - f1-score (micro avg)  0.5078
2022-05-13 16:55:43,017 BAD EPOCHS (no improvement): 2
2022-05-13 16:55:43,020 ----------------------------------------------------------------------------------------------------
2022-05-13 16:55:45,192 epoch 47 - iter 10/107 - loss 0.05321587 - samples/sec: 147.37 - lr: 0.000195
2022-05-13 16:55:47,505 epoch 47 - iter 20/107 - loss 0.04744082 - samples/sec: 138.43 - lr: 0.000195
2022-05-13 16:55:49,533 epoch 47 - iter 30/107 - loss 0.04654653 - samples/sec: 157.87 - lr: 0.000195
2022-05-13 16:55:51,502 epoch 47 - iter 40/107 - loss 0.04927984 - samples/sec: 162.54 - lr: 0.000195
2022-05-13 16:55:53,638 epoch 47 - iter 50/107 - loss 0.05086973 - samples/sec: 149.92 - lr: 0.000195
2022-05-13 16:55:55,789 epoch 47 - iter 60/107 - loss 0.05008676 - samples/sec: 148.78 - lr: 0.000195
2022-05-13 16:55:57,843 epoch 47 - iter 70/107 - loss 0.04873618 - samples/sec: 155.89 - lr: 0.000195
2022-05-13 16:56:00,175 epoch 47 - iter 80/107 - loss 0.04870698 - samples/sec: 137.25 - lr: 0.000195
2022-05-13 16:56:02,354 epoch 47 - iter 90/107 - loss 0.04795374 - samples/sec: 146.93 - lr: 0.000195
2022-05-13 16:56:04,620 epoch 47 - iter 100/107 - loss 0.04882314 - samples/sec: 141.27 - lr: 0.000195
2022-05-13 16:56:05,954 ----------------------------------------------------------------------------------------------------
2022-05-13 16:56:05,954 EPOCH 47 done: loss 0.0488 - lr 0.000195
2022-05-13 16:56:13,205 Evaluating as a multi-label problem: False
2022-05-13 16:56:13,216 DEV : loss 0.2043042927980423 - f1-score (micro avg)  0.5078
2022-05-13 16:56:13,284 BAD EPOCHS (no improvement): 3
2022-05-13 16:56:13,286 ----------------------------------------------------------------------------------------------------
2022-05-13 16:56:15,508 epoch 48 - iter 10/107 - loss 0.04999395 - samples/sec: 144.06 - lr: 0.000195
2022-05-13 16:56:17,706 epoch 48 - iter 20/107 - loss 0.05093232 - samples/sec: 145.66 - lr: 0.000195
2022-05-13 16:56:20,089 epoch 48 - iter 30/107 - loss 0.04990757 - samples/sec: 134.36 - lr: 0.000195
2022-05-13 16:56:22,399 epoch 48 - iter 40/107 - loss 0.04838187 - samples/sec: 138.56 - lr: 0.000195
2022-05-13 16:56:24,746 epoch 48 - iter 50/107 - loss 0.04858439 - samples/sec: 136.41 - lr: 0.000195
2022-05-13 16:56:26,950 epoch 48 - iter 60/107 - loss 0.04962416 - samples/sec: 145.25 - lr: 0.000195
2022-05-13 16:56:29,260 epoch 48 - iter 70/107 - loss 0.04955558 - samples/sec: 138.56 - lr: 0.000195
2022-05-13 16:56:31,589 epoch 48 - iter 80/107 - loss 0.04917049 - samples/sec: 137.48 - lr: 0.000195
2022-05-13 16:56:33,720 epoch 48 - iter 90/107 - loss 0.04872490 - samples/sec: 150.21 - lr: 0.000195
2022-05-13 16:56:35,911 epoch 48 - iter 100/107 - loss 0.04803924 - samples/sec: 146.07 - lr: 0.000195
2022-05-13 16:56:37,274 ----------------------------------------------------------------------------------------------------
2022-05-13 16:56:37,274 EPOCH 48 done: loss 0.0478 - lr 0.000195
2022-05-13 16:56:43,966 Evaluating as a multi-label problem: False
2022-05-13 16:56:43,977 DEV : loss 0.20455849170684814 - f1-score (micro avg)  0.5078
2022-05-13 16:56:44,045 Epoch    48: reducing learning rate of group 0 to 9.7656e-05.
2022-05-13 16:56:44,045 BAD EPOCHS (no improvement): 4
2022-05-13 16:56:44,047 ----------------------------------------------------------------------------------------------------
2022-05-13 16:56:44,047 ----------------------------------------------------------------------------------------------------
2022-05-13 16:56:44,047 learning rate too small - quitting training!
2022-05-13 16:56:44,047 ----------------------------------------------------------------------------------------------------
2022-05-13 16:57:05,245 ----------------------------------------------------------------------------------------------------
2022-05-13 16:57:05,246 loading file resources/taggers/model_04_r10_run_6/best-model.pt
2022-05-13 16:57:19,158 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-05-13 16:57:38,970 Evaluating as a multi-label problem: False
2022-05-13 16:57:38,982 0.6542	0.2929	0.4046	0.2701
2022-05-13 16:57:38,982 
Results:
- F-score (micro) 0.4046
- F-score (macro) 0.2718
- Accuracy 0.2701

By class:
               precision    recall  f1-score   support

       person     0.7556    0.4685    0.5784       429
     location     0.5625    0.5400    0.5510       150
        group     0.6429    0.0545    0.1006       165
creative-work     0.6000    0.0845    0.1481       142
      product     0.3077    0.0315    0.0571       127
  corporation     0.3462    0.1364    0.1957        66

    micro avg     0.6542    0.2929    0.4046      1079
    macro avg     0.5358    0.2192    0.2718      1079
 weighted avg     0.6133    0.2929    0.3601      1079

2022-05-13 16:57:38,982 ----------------------------------------------------------------------------------------------------
