2022-05-13 17:32:04,898 ----------------------------------------------------------------------------------------------------
2022-05-13 17:32:04,898 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4922, out_features=4922, bias=True)
  (rnn): LSTM(4922, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-05-13 17:32:04,899 ----------------------------------------------------------------------------------------------------
2022-05-13 17:32:04,899 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-05-13 17:32:04,899 ----------------------------------------------------------------------------------------------------
2022-05-13 17:32:04,899 Parameters:
2022-05-13 17:32:04,899  - learning_rate: "0.100000"
2022-05-13 17:32:04,899  - mini_batch_size: "32"
2022-05-13 17:32:04,899  - patience: "3"
2022-05-13 17:32:04,899  - anneal_factor: "0.5"
2022-05-13 17:32:04,899  - max_epochs: "150"
2022-05-13 17:32:04,899  - shuffle: "True"
2022-05-13 17:32:04,899  - train_with_dev: "False"
2022-05-13 17:32:04,899  - batch_growth_annealing: "False"
2022-05-13 17:32:04,899 ----------------------------------------------------------------------------------------------------
2022-05-13 17:32:04,899 Model training base path: "resources/taggers/model_03_r10_run_6"
2022-05-13 17:32:04,899 ----------------------------------------------------------------------------------------------------
2022-05-13 17:32:04,899 Device: cuda:0
2022-05-13 17:32:04,899 ----------------------------------------------------------------------------------------------------
2022-05-13 17:32:04,899 Embeddings storage mode: cpu
2022-05-13 17:32:04,899 ----------------------------------------------------------------------------------------------------
2022-05-13 17:32:07,557 epoch 1 - iter 10/107 - loss 0.75783573 - samples/sec: 120.46 - lr: 0.100000
2022-05-13 17:32:10,448 epoch 1 - iter 20/107 - loss 0.53003853 - samples/sec: 110.72 - lr: 0.100000
2022-05-13 17:32:13,340 epoch 1 - iter 30/107 - loss 0.44695264 - samples/sec: 110.68 - lr: 0.100000
2022-05-13 17:32:16,199 epoch 1 - iter 40/107 - loss 0.40269823 - samples/sec: 111.97 - lr: 0.100000
2022-05-13 17:32:19,093 epoch 1 - iter 50/107 - loss 0.36597941 - samples/sec: 110.62 - lr: 0.100000
2022-05-13 17:32:21,923 epoch 1 - iter 60/107 - loss 0.35341493 - samples/sec: 113.10 - lr: 0.100000
2022-05-13 17:32:24,794 epoch 1 - iter 70/107 - loss 0.34311916 - samples/sec: 111.52 - lr: 0.100000
2022-05-13 17:32:27,398 epoch 1 - iter 80/107 - loss 0.34037818 - samples/sec: 122.91 - lr: 0.100000
2022-05-13 17:32:29,800 epoch 1 - iter 90/107 - loss 0.33733616 - samples/sec: 133.33 - lr: 0.100000
2022-05-13 17:32:32,326 epoch 1 - iter 100/107 - loss 0.33300248 - samples/sec: 126.71 - lr: 0.100000
2022-05-13 17:32:33,851 ----------------------------------------------------------------------------------------------------
2022-05-13 17:32:33,851 EPOCH 1 done: loss 0.3265 - lr 0.100000
2022-05-13 17:32:42,870 Evaluating as a multi-label problem: False
2022-05-13 17:32:42,881 DEV : loss 0.3760056793689728 - f1-score (micro avg)  0.2139
2022-05-13 17:32:42,969 BAD EPOCHS (no improvement): 0
2022-05-13 17:32:42,974 saving best model
2022-05-13 17:33:18,088 ----------------------------------------------------------------------------------------------------
2022-05-13 17:33:20,874 epoch 2 - iter 10/107 - loss 0.23223859 - samples/sec: 114.95 - lr: 0.100000
2022-05-13 17:33:23,614 epoch 2 - iter 20/107 - loss 0.22554684 - samples/sec: 116.86 - lr: 0.100000
2022-05-13 17:33:26,244 epoch 2 - iter 30/107 - loss 0.22671396 - samples/sec: 121.68 - lr: 0.100000
2022-05-13 17:33:29,024 epoch 2 - iter 40/107 - loss 0.21717659 - samples/sec: 115.16 - lr: 0.100000
2022-05-13 17:33:31,890 epoch 2 - iter 50/107 - loss 0.21891387 - samples/sec: 111.70 - lr: 0.100000
2022-05-13 17:33:34,668 epoch 2 - iter 60/107 - loss 0.21665264 - samples/sec: 115.24 - lr: 0.100000
2022-05-13 17:33:37,395 epoch 2 - iter 70/107 - loss 0.21001000 - samples/sec: 117.52 - lr: 0.100000
2022-05-13 17:33:40,107 epoch 2 - iter 80/107 - loss 0.20474334 - samples/sec: 118.02 - lr: 0.100000
2022-05-13 17:33:42,897 epoch 2 - iter 90/107 - loss 0.20216209 - samples/sec: 114.72 - lr: 0.100000
2022-05-13 17:33:45,613 epoch 2 - iter 100/107 - loss 0.20137516 - samples/sec: 117.89 - lr: 0.100000
2022-05-13 17:33:47,249 ----------------------------------------------------------------------------------------------------
2022-05-13 17:33:47,249 EPOCH 2 done: loss 0.2011 - lr 0.100000
2022-05-13 17:33:56,262 Evaluating as a multi-label problem: False
2022-05-13 17:33:56,273 DEV : loss 0.2897801995277405 - f1-score (micro avg)  0.3946
2022-05-13 17:33:56,357 BAD EPOCHS (no improvement): 0
2022-05-13 17:33:56,359 saving best model
2022-05-13 17:34:31,286 ----------------------------------------------------------------------------------------------------
2022-05-13 17:34:34,101 epoch 3 - iter 10/107 - loss 0.18427147 - samples/sec: 113.75 - lr: 0.100000
2022-05-13 17:34:36,870 epoch 3 - iter 20/107 - loss 0.18089839 - samples/sec: 115.58 - lr: 0.100000
2022-05-13 17:34:39,692 epoch 3 - iter 30/107 - loss 0.18133963 - samples/sec: 113.47 - lr: 0.100000
2022-05-13 17:34:42,468 epoch 3 - iter 40/107 - loss 0.17519098 - samples/sec: 115.31 - lr: 0.100000
2022-05-13 17:34:45,191 epoch 3 - iter 50/107 - loss 0.17313896 - samples/sec: 117.56 - lr: 0.100000
2022-05-13 17:34:47,945 epoch 3 - iter 60/107 - loss 0.17653369 - samples/sec: 116.25 - lr: 0.100000
2022-05-13 17:34:50,660 epoch 3 - iter 70/107 - loss 0.17741624 - samples/sec: 117.89 - lr: 0.100000
2022-05-13 17:34:53,386 epoch 3 - iter 80/107 - loss 0.17502684 - samples/sec: 117.42 - lr: 0.100000
2022-05-13 17:34:56,107 epoch 3 - iter 90/107 - loss 0.17195830 - samples/sec: 117.68 - lr: 0.100000
2022-05-13 17:34:58,851 epoch 3 - iter 100/107 - loss 0.16882141 - samples/sec: 116.66 - lr: 0.100000
2022-05-13 17:35:00,541 ----------------------------------------------------------------------------------------------------
2022-05-13 17:35:00,541 EPOCH 3 done: loss 0.1684 - lr 0.100000
2022-05-13 17:35:09,606 Evaluating as a multi-label problem: False
2022-05-13 17:35:09,617 DEV : loss 0.23581856489181519 - f1-score (micro avg)  0.5012
2022-05-13 17:35:09,703 BAD EPOCHS (no improvement): 0
2022-05-13 17:35:09,706 saving best model
2022-05-13 17:35:44,003 ----------------------------------------------------------------------------------------------------
2022-05-13 17:35:46,725 epoch 4 - iter 10/107 - loss 0.15800151 - samples/sec: 117.65 - lr: 0.100000
2022-05-13 17:35:49,367 epoch 4 - iter 20/107 - loss 0.15345621 - samples/sec: 121.14 - lr: 0.100000
2022-05-13 17:35:52,198 epoch 4 - iter 30/107 - loss 0.15181280 - samples/sec: 113.11 - lr: 0.100000
2022-05-13 17:35:54,900 epoch 4 - iter 40/107 - loss 0.15343641 - samples/sec: 118.47 - lr: 0.100000
2022-05-13 17:35:57,610 epoch 4 - iter 50/107 - loss 0.14845331 - samples/sec: 118.11 - lr: 0.100000
2022-05-13 17:36:00,300 epoch 4 - iter 60/107 - loss 0.14814203 - samples/sec: 119.02 - lr: 0.100000
2022-05-13 17:36:03,079 epoch 4 - iter 70/107 - loss 0.15068603 - samples/sec: 115.16 - lr: 0.100000
2022-05-13 17:36:05,729 epoch 4 - iter 80/107 - loss 0.14906736 - samples/sec: 120.81 - lr: 0.100000
2022-05-13 17:36:08,611 epoch 4 - iter 90/107 - loss 0.15100884 - samples/sec: 111.09 - lr: 0.100000
2022-05-13 17:36:11,386 epoch 4 - iter 100/107 - loss 0.15025207 - samples/sec: 115.34 - lr: 0.100000
2022-05-13 17:36:13,055 ----------------------------------------------------------------------------------------------------
2022-05-13 17:36:13,055 EPOCH 4 done: loss 0.1490 - lr 0.100000
2022-05-13 17:36:22,046 Evaluating as a multi-label problem: False
2022-05-13 17:36:22,057 DEV : loss 0.2615734338760376 - f1-score (micro avg)  0.4614
2022-05-13 17:36:22,142 BAD EPOCHS (no improvement): 1
2022-05-13 17:36:22,144 ----------------------------------------------------------------------------------------------------
2022-05-13 17:36:24,924 epoch 5 - iter 10/107 - loss 0.12661384 - samples/sec: 115.17 - lr: 0.100000
2022-05-13 17:36:27,568 epoch 5 - iter 20/107 - loss 0.13222164 - samples/sec: 121.07 - lr: 0.100000
2022-05-13 17:36:30,438 epoch 5 - iter 30/107 - loss 0.12906715 - samples/sec: 111.54 - lr: 0.100000
2022-05-13 17:36:33,091 epoch 5 - iter 40/107 - loss 0.12754444 - samples/sec: 120.66 - lr: 0.100000
2022-05-13 17:36:35,907 epoch 5 - iter 50/107 - loss 0.12710363 - samples/sec: 113.69 - lr: 0.100000
2022-05-13 17:36:38,664 epoch 5 - iter 60/107 - loss 0.12607016 - samples/sec: 116.10 - lr: 0.100000
2022-05-13 17:36:41,432 epoch 5 - iter 70/107 - loss 0.13008246 - samples/sec: 115.67 - lr: 0.100000
2022-05-13 17:36:44,270 epoch 5 - iter 80/107 - loss 0.13227024 - samples/sec: 112.81 - lr: 0.100000
2022-05-13 17:36:47,061 epoch 5 - iter 90/107 - loss 0.13374935 - samples/sec: 114.66 - lr: 0.100000
2022-05-13 17:36:49,755 epoch 5 - iter 100/107 - loss 0.13315682 - samples/sec: 118.86 - lr: 0.100000
2022-05-13 17:36:51,427 ----------------------------------------------------------------------------------------------------
2022-05-13 17:36:51,427 EPOCH 5 done: loss 0.1342 - lr 0.100000
2022-05-13 17:37:00,429 Evaluating as a multi-label problem: False
2022-05-13 17:37:00,440 DEV : loss 0.2597461938858032 - f1-score (micro avg)  0.4346
2022-05-13 17:37:00,525 BAD EPOCHS (no improvement): 2
2022-05-13 17:37:00,527 ----------------------------------------------------------------------------------------------------
2022-05-13 17:37:03,327 epoch 6 - iter 10/107 - loss 0.14202512 - samples/sec: 114.33 - lr: 0.100000
2022-05-13 17:37:06,178 epoch 6 - iter 20/107 - loss 0.13177128 - samples/sec: 112.30 - lr: 0.100000
2022-05-13 17:37:08,851 epoch 6 - iter 30/107 - loss 0.13167305 - samples/sec: 119.77 - lr: 0.100000
2022-05-13 17:37:11,607 epoch 6 - iter 40/107 - loss 0.13058378 - samples/sec: 116.16 - lr: 0.100000
2022-05-13 17:37:14,356 epoch 6 - iter 50/107 - loss 0.12912526 - samples/sec: 116.47 - lr: 0.100000
2022-05-13 17:37:17,111 epoch 6 - iter 60/107 - loss 0.12338841 - samples/sec: 116.18 - lr: 0.100000
2022-05-13 17:37:19,863 epoch 6 - iter 70/107 - loss 0.12213112 - samples/sec: 116.32 - lr: 0.100000
2022-05-13 17:37:22,633 epoch 6 - iter 80/107 - loss 0.12291410 - samples/sec: 115.59 - lr: 0.100000
2022-05-13 17:37:25,431 epoch 6 - iter 90/107 - loss 0.12401695 - samples/sec: 114.41 - lr: 0.100000
2022-05-13 17:37:28,222 epoch 6 - iter 100/107 - loss 0.12457342 - samples/sec: 114.68 - lr: 0.100000
2022-05-13 17:37:29,768 ----------------------------------------------------------------------------------------------------
2022-05-13 17:37:29,769 EPOCH 6 done: loss 0.1236 - lr 0.100000
2022-05-13 17:37:39,076 Evaluating as a multi-label problem: False
2022-05-13 17:37:39,088 DEV : loss 0.22482453286647797 - f1-score (micro avg)  0.4836
2022-05-13 17:37:39,174 BAD EPOCHS (no improvement): 3
2022-05-13 17:37:39,176 ----------------------------------------------------------------------------------------------------
2022-05-13 17:37:42,021 epoch 7 - iter 10/107 - loss 0.09890514 - samples/sec: 112.52 - lr: 0.100000
2022-05-13 17:37:44,677 epoch 7 - iter 20/107 - loss 0.10514726 - samples/sec: 120.54 - lr: 0.100000
2022-05-13 17:37:47,309 epoch 7 - iter 30/107 - loss 0.10583706 - samples/sec: 121.63 - lr: 0.100000
2022-05-13 17:37:50,106 epoch 7 - iter 40/107 - loss 0.11182298 - samples/sec: 114.44 - lr: 0.100000
2022-05-13 17:37:52,973 epoch 7 - iter 50/107 - loss 0.11337401 - samples/sec: 111.67 - lr: 0.100000
2022-05-13 17:37:55,833 epoch 7 - iter 60/107 - loss 0.11236019 - samples/sec: 111.92 - lr: 0.100000
2022-05-13 17:37:58,575 epoch 7 - iter 70/107 - loss 0.11449434 - samples/sec: 116.76 - lr: 0.100000
2022-05-13 17:38:01,326 epoch 7 - iter 80/107 - loss 0.11263083 - samples/sec: 116.36 - lr: 0.100000
2022-05-13 17:38:04,078 epoch 7 - iter 90/107 - loss 0.11103112 - samples/sec: 116.34 - lr: 0.100000
2022-05-13 17:38:06,706 epoch 7 - iter 100/107 - loss 0.11514335 - samples/sec: 121.82 - lr: 0.100000
2022-05-13 17:38:08,419 ----------------------------------------------------------------------------------------------------
2022-05-13 17:38:08,420 EPOCH 7 done: loss 0.1152 - lr 0.100000
2022-05-13 17:38:17,441 Evaluating as a multi-label problem: False
2022-05-13 17:38:17,452 DEV : loss 0.22497083246707916 - f1-score (micro avg)  0.4832
2022-05-13 17:38:17,539 Epoch     7: reducing learning rate of group 0 to 5.0000e-02.
2022-05-13 17:38:17,539 BAD EPOCHS (no improvement): 4
2022-05-13 17:38:17,541 ----------------------------------------------------------------------------------------------------
2022-05-13 17:38:20,361 epoch 8 - iter 10/107 - loss 0.11180632 - samples/sec: 113.50 - lr: 0.050000
2022-05-13 17:38:23,065 epoch 8 - iter 20/107 - loss 0.10804066 - samples/sec: 118.38 - lr: 0.050000
2022-05-13 17:38:25,854 epoch 8 - iter 30/107 - loss 0.10280861 - samples/sec: 114.79 - lr: 0.050000
2022-05-13 17:38:28,619 epoch 8 - iter 40/107 - loss 0.10237336 - samples/sec: 115.78 - lr: 0.050000
2022-05-13 17:38:31,378 epoch 8 - iter 50/107 - loss 0.10178716 - samples/sec: 116.02 - lr: 0.050000
2022-05-13 17:38:34,157 epoch 8 - iter 60/107 - loss 0.10012395 - samples/sec: 115.17 - lr: 0.050000
2022-05-13 17:38:36,855 epoch 8 - iter 70/107 - loss 0.10170490 - samples/sec: 118.68 - lr: 0.050000
2022-05-13 17:38:39,669 epoch 8 - iter 80/107 - loss 0.10211307 - samples/sec: 113.73 - lr: 0.050000
2022-05-13 17:38:42,363 epoch 8 - iter 90/107 - loss 0.10270583 - samples/sec: 118.84 - lr: 0.050000
2022-05-13 17:38:45,102 epoch 8 - iter 100/107 - loss 0.10211604 - samples/sec: 116.89 - lr: 0.050000
2022-05-13 17:38:46,780 ----------------------------------------------------------------------------------------------------
2022-05-13 17:38:46,780 EPOCH 8 done: loss 0.1009 - lr 0.050000
2022-05-13 17:38:55,763 Evaluating as a multi-label problem: False
2022-05-13 17:38:55,774 DEV : loss 0.2197466343641281 - f1-score (micro avg)  0.4807
2022-05-13 17:38:55,859 BAD EPOCHS (no improvement): 1
2022-05-13 17:38:55,861 ----------------------------------------------------------------------------------------------------
2022-05-13 17:38:58,584 epoch 9 - iter 10/107 - loss 0.09848990 - samples/sec: 117.57 - lr: 0.050000
2022-05-13 17:39:01,465 epoch 9 - iter 20/107 - loss 0.10813906 - samples/sec: 111.13 - lr: 0.050000
2022-05-13 17:39:04,253 epoch 9 - iter 30/107 - loss 0.10191400 - samples/sec: 114.80 - lr: 0.050000
2022-05-13 17:39:07,041 epoch 9 - iter 40/107 - loss 0.10084026 - samples/sec: 114.84 - lr: 0.050000
2022-05-13 17:39:09,807 epoch 9 - iter 50/107 - loss 0.09938518 - samples/sec: 115.73 - lr: 0.050000
2022-05-13 17:39:12,483 epoch 9 - iter 60/107 - loss 0.09777804 - samples/sec: 119.61 - lr: 0.050000
2022-05-13 17:39:15,218 epoch 9 - iter 70/107 - loss 0.09549327 - samples/sec: 117.05 - lr: 0.050000
2022-05-13 17:39:17,887 epoch 9 - iter 80/107 - loss 0.09500577 - samples/sec: 119.94 - lr: 0.050000
2022-05-13 17:39:20,560 epoch 9 - iter 90/107 - loss 0.09561022 - samples/sec: 119.75 - lr: 0.050000
2022-05-13 17:39:23,438 epoch 9 - iter 100/107 - loss 0.09562482 - samples/sec: 111.24 - lr: 0.050000
2022-05-13 17:39:25,199 ----------------------------------------------------------------------------------------------------
2022-05-13 17:39:25,200 EPOCH 9 done: loss 0.0957 - lr 0.050000
2022-05-13 17:39:34,105 Evaluating as a multi-label problem: False
2022-05-13 17:39:34,116 DEV : loss 0.2241077572107315 - f1-score (micro avg)  0.4527
2022-05-13 17:39:34,201 BAD EPOCHS (no improvement): 2
2022-05-13 17:39:34,205 ----------------------------------------------------------------------------------------------------
2022-05-13 17:39:37,054 epoch 10 - iter 10/107 - loss 0.08920581 - samples/sec: 112.38 - lr: 0.050000
2022-05-13 17:39:39,810 epoch 10 - iter 20/107 - loss 0.09195141 - samples/sec: 116.14 - lr: 0.050000
2022-05-13 17:39:42,517 epoch 10 - iter 30/107 - loss 0.09668223 - samples/sec: 118.28 - lr: 0.050000
2022-05-13 17:39:45,225 epoch 10 - iter 40/107 - loss 0.09665990 - samples/sec: 118.19 - lr: 0.050000
2022-05-13 17:39:47,990 epoch 10 - iter 50/107 - loss 0.09688382 - samples/sec: 115.78 - lr: 0.050000
2022-05-13 17:39:50,823 epoch 10 - iter 60/107 - loss 0.09601819 - samples/sec: 113.00 - lr: 0.050000
2022-05-13 17:39:53,553 epoch 10 - iter 70/107 - loss 0.09320188 - samples/sec: 117.25 - lr: 0.050000
2022-05-13 17:39:56,324 epoch 10 - iter 80/107 - loss 0.09081735 - samples/sec: 115.53 - lr: 0.050000
2022-05-13 17:39:59,164 epoch 10 - iter 90/107 - loss 0.09059867 - samples/sec: 112.72 - lr: 0.050000
2022-05-13 17:40:01,799 epoch 10 - iter 100/107 - loss 0.09088724 - samples/sec: 121.48 - lr: 0.050000
2022-05-13 17:40:03,435 ----------------------------------------------------------------------------------------------------
2022-05-13 17:40:03,435 EPOCH 10 done: loss 0.0914 - lr 0.050000
2022-05-13 17:40:12,428 Evaluating as a multi-label problem: False
2022-05-13 17:40:12,440 DEV : loss 0.21961890161037445 - f1-score (micro avg)  0.4768
2022-05-13 17:40:12,525 BAD EPOCHS (no improvement): 3
2022-05-13 17:40:12,527 ----------------------------------------------------------------------------------------------------
2022-05-13 17:40:15,147 epoch 11 - iter 10/107 - loss 0.08801084 - samples/sec: 122.18 - lr: 0.050000
2022-05-13 17:40:17,710 epoch 11 - iter 20/107 - loss 0.08602091 - samples/sec: 124.95 - lr: 0.050000
2022-05-13 17:40:20,267 epoch 11 - iter 30/107 - loss 0.09443646 - samples/sec: 125.20 - lr: 0.050000
2022-05-13 17:40:22,792 epoch 11 - iter 40/107 - loss 0.09631428 - samples/sec: 126.78 - lr: 0.050000
2022-05-13 17:40:25,301 epoch 11 - iter 50/107 - loss 0.09324441 - samples/sec: 127.60 - lr: 0.050000
2022-05-13 17:40:27,868 epoch 11 - iter 60/107 - loss 0.09176677 - samples/sec: 124.66 - lr: 0.050000
2022-05-13 17:40:30,399 epoch 11 - iter 70/107 - loss 0.08844094 - samples/sec: 126.53 - lr: 0.050000
2022-05-13 17:40:32,838 epoch 11 - iter 80/107 - loss 0.08785931 - samples/sec: 131.25 - lr: 0.050000
2022-05-13 17:40:35,413 epoch 11 - iter 90/107 - loss 0.08905951 - samples/sec: 124.28 - lr: 0.050000
2022-05-13 17:40:37,983 epoch 11 - iter 100/107 - loss 0.08804305 - samples/sec: 124.57 - lr: 0.050000
2022-05-13 17:40:39,524 ----------------------------------------------------------------------------------------------------
2022-05-13 17:40:39,525 EPOCH 11 done: loss 0.0873 - lr 0.050000
2022-05-13 17:40:47,241 Evaluating as a multi-label problem: False
2022-05-13 17:40:47,252 DEV : loss 0.19820143282413483 - f1-score (micro avg)  0.4946
2022-05-13 17:40:47,326 Epoch    11: reducing learning rate of group 0 to 2.5000e-02.
2022-05-13 17:40:47,326 BAD EPOCHS (no improvement): 4
2022-05-13 17:40:47,328 ----------------------------------------------------------------------------------------------------
2022-05-13 17:40:49,872 epoch 12 - iter 10/107 - loss 0.07293891 - samples/sec: 125.84 - lr: 0.025000
2022-05-13 17:40:52,366 epoch 12 - iter 20/107 - loss 0.08484736 - samples/sec: 128.38 - lr: 0.025000
2022-05-13 17:40:54,899 epoch 12 - iter 30/107 - loss 0.08643978 - samples/sec: 126.38 - lr: 0.025000
2022-05-13 17:40:57,475 epoch 12 - iter 40/107 - loss 0.08430687 - samples/sec: 124.27 - lr: 0.025000
2022-05-13 17:41:00,083 epoch 12 - iter 50/107 - loss 0.08305261 - samples/sec: 122.74 - lr: 0.025000
2022-05-13 17:41:02,637 epoch 12 - iter 60/107 - loss 0.08237513 - samples/sec: 125.32 - lr: 0.025000
2022-05-13 17:41:05,022 epoch 12 - iter 70/107 - loss 0.08084662 - samples/sec: 134.23 - lr: 0.025000
2022-05-13 17:41:07,399 epoch 12 - iter 80/107 - loss 0.07943018 - samples/sec: 134.70 - lr: 0.025000
2022-05-13 17:41:09,784 epoch 12 - iter 90/107 - loss 0.07984966 - samples/sec: 134.27 - lr: 0.025000
2022-05-13 17:41:12,197 epoch 12 - iter 100/107 - loss 0.08121287 - samples/sec: 132.66 - lr: 0.025000
2022-05-13 17:41:13,793 ----------------------------------------------------------------------------------------------------
2022-05-13 17:41:13,793 EPOCH 12 done: loss 0.0807 - lr 0.025000
2022-05-13 17:41:21,500 Evaluating as a multi-label problem: False
2022-05-13 17:41:21,511 DEV : loss 0.2018606960773468 - f1-score (micro avg)  0.515
2022-05-13 17:41:21,585 BAD EPOCHS (no improvement): 0
2022-05-13 17:41:21,587 saving best model
2022-05-13 17:41:57,978 ----------------------------------------------------------------------------------------------------
2022-05-13 17:42:00,664 epoch 13 - iter 10/107 - loss 0.08242712 - samples/sec: 119.24 - lr: 0.025000
2022-05-13 17:42:03,308 epoch 13 - iter 20/107 - loss 0.08296747 - samples/sec: 121.12 - lr: 0.025000
2022-05-13 17:42:05,942 epoch 13 - iter 30/107 - loss 0.08041499 - samples/sec: 121.50 - lr: 0.025000
2022-05-13 17:42:08,620 epoch 13 - iter 40/107 - loss 0.07913274 - samples/sec: 119.57 - lr: 0.025000
2022-05-13 17:42:11,318 epoch 13 - iter 50/107 - loss 0.08054737 - samples/sec: 118.62 - lr: 0.025000
2022-05-13 17:42:14,003 epoch 13 - iter 60/107 - loss 0.08031630 - samples/sec: 119.25 - lr: 0.025000
2022-05-13 17:42:16,688 epoch 13 - iter 70/107 - loss 0.07816459 - samples/sec: 119.18 - lr: 0.025000
2022-05-13 17:42:19,467 epoch 13 - iter 80/107 - loss 0.07823290 - samples/sec: 115.20 - lr: 0.025000
2022-05-13 17:42:22,172 epoch 13 - iter 90/107 - loss 0.07810858 - samples/sec: 118.33 - lr: 0.025000
2022-05-13 17:42:24,934 epoch 13 - iter 100/107 - loss 0.07830016 - samples/sec: 115.93 - lr: 0.025000
2022-05-13 17:42:26,639 ----------------------------------------------------------------------------------------------------
2022-05-13 17:42:26,639 EPOCH 13 done: loss 0.0791 - lr 0.025000
2022-05-13 17:42:35,442 Evaluating as a multi-label problem: False
2022-05-13 17:42:35,454 DEV : loss 0.20306502282619476 - f1-score (micro avg)  0.5039
2022-05-13 17:42:35,538 BAD EPOCHS (no improvement): 1
2022-05-13 17:42:35,541 ----------------------------------------------------------------------------------------------------
2022-05-13 17:42:38,206 epoch 14 - iter 10/107 - loss 0.08450774 - samples/sec: 120.10 - lr: 0.025000
2022-05-13 17:42:40,839 epoch 14 - iter 20/107 - loss 0.07517262 - samples/sec: 121.56 - lr: 0.025000
2022-05-13 17:42:43,553 epoch 14 - iter 30/107 - loss 0.07384094 - samples/sec: 117.97 - lr: 0.025000
2022-05-13 17:42:46,354 epoch 14 - iter 40/107 - loss 0.07563185 - samples/sec: 114.30 - lr: 0.025000
2022-05-13 17:42:49,107 epoch 14 - iter 50/107 - loss 0.07435614 - samples/sec: 116.29 - lr: 0.025000
2022-05-13 17:42:51,825 epoch 14 - iter 60/107 - loss 0.07597473 - samples/sec: 117.73 - lr: 0.025000
2022-05-13 17:42:54,520 epoch 14 - iter 70/107 - loss 0.07571902 - samples/sec: 118.78 - lr: 0.025000
2022-05-13 17:42:57,203 epoch 14 - iter 80/107 - loss 0.07681774 - samples/sec: 119.34 - lr: 0.025000
2022-05-13 17:42:59,970 epoch 14 - iter 90/107 - loss 0.07580575 - samples/sec: 115.68 - lr: 0.025000
2022-05-13 17:43:02,709 epoch 14 - iter 100/107 - loss 0.07691276 - samples/sec: 116.84 - lr: 0.025000
2022-05-13 17:43:04,372 ----------------------------------------------------------------------------------------------------
2022-05-13 17:43:04,372 EPOCH 14 done: loss 0.0770 - lr 0.025000
2022-05-13 17:43:13,261 Evaluating as a multi-label problem: False
2022-05-13 17:43:13,272 DEV : loss 0.2116403579711914 - f1-score (micro avg)  0.4943
2022-05-13 17:43:13,356 BAD EPOCHS (no improvement): 2
2022-05-13 17:43:13,359 ----------------------------------------------------------------------------------------------------
2022-05-13 17:43:16,067 epoch 15 - iter 10/107 - loss 0.07183233 - samples/sec: 118.21 - lr: 0.025000
2022-05-13 17:43:18,844 epoch 15 - iter 20/107 - loss 0.06962258 - samples/sec: 115.29 - lr: 0.025000
2022-05-13 17:43:21,573 epoch 15 - iter 30/107 - loss 0.07296995 - samples/sec: 117.28 - lr: 0.025000
2022-05-13 17:43:24,318 epoch 15 - iter 40/107 - loss 0.07395119 - samples/sec: 116.63 - lr: 0.025000
2022-05-13 17:43:26,953 epoch 15 - iter 50/107 - loss 0.07310227 - samples/sec: 121.47 - lr: 0.025000
2022-05-13 17:43:29,780 epoch 15 - iter 60/107 - loss 0.07233938 - samples/sec: 113.24 - lr: 0.025000
2022-05-13 17:43:32,520 epoch 15 - iter 70/107 - loss 0.07426016 - samples/sec: 116.85 - lr: 0.025000
2022-05-13 17:43:35,223 epoch 15 - iter 80/107 - loss 0.07335965 - samples/sec: 118.42 - lr: 0.025000
2022-05-13 17:43:37,828 epoch 15 - iter 90/107 - loss 0.07364440 - samples/sec: 122.93 - lr: 0.025000
2022-05-13 17:43:40,530 epoch 15 - iter 100/107 - loss 0.07447063 - samples/sec: 118.45 - lr: 0.025000
2022-05-13 17:43:42,134 ----------------------------------------------------------------------------------------------------
2022-05-13 17:43:42,134 EPOCH 15 done: loss 0.0745 - lr 0.025000
2022-05-13 17:43:51,054 Evaluating as a multi-label problem: False
2022-05-13 17:43:51,065 DEV : loss 0.20867511630058289 - f1-score (micro avg)  0.4932
2022-05-13 17:43:51,155 BAD EPOCHS (no improvement): 3
2022-05-13 17:43:51,157 ----------------------------------------------------------------------------------------------------
2022-05-13 17:43:53,908 epoch 16 - iter 10/107 - loss 0.06682332 - samples/sec: 116.36 - lr: 0.025000
2022-05-13 17:43:56,675 epoch 16 - iter 20/107 - loss 0.07112174 - samples/sec: 115.72 - lr: 0.025000
2022-05-13 17:43:59,354 epoch 16 - iter 30/107 - loss 0.06978026 - samples/sec: 119.48 - lr: 0.025000
2022-05-13 17:44:02,081 epoch 16 - iter 40/107 - loss 0.06853765 - samples/sec: 117.38 - lr: 0.025000
2022-05-13 17:44:04,779 epoch 16 - iter 50/107 - loss 0.07180607 - samples/sec: 118.65 - lr: 0.025000
2022-05-13 17:44:07,499 epoch 16 - iter 60/107 - loss 0.07243737 - samples/sec: 117.69 - lr: 0.025000
2022-05-13 17:44:10,140 epoch 16 - iter 70/107 - loss 0.07344818 - samples/sec: 121.20 - lr: 0.025000
2022-05-13 17:44:12,821 epoch 16 - iter 80/107 - loss 0.07326904 - samples/sec: 119.37 - lr: 0.025000
2022-05-13 17:44:15,453 epoch 16 - iter 90/107 - loss 0.07308599 - samples/sec: 121.63 - lr: 0.025000
2022-05-13 17:44:18,296 epoch 16 - iter 100/107 - loss 0.07294354 - samples/sec: 112.59 - lr: 0.025000
2022-05-13 17:44:20,018 ----------------------------------------------------------------------------------------------------
2022-05-13 17:44:20,019 EPOCH 16 done: loss 0.0733 - lr 0.025000
2022-05-13 17:44:28,783 Evaluating as a multi-label problem: False
2022-05-13 17:44:28,794 DEV : loss 0.2019086331129074 - f1-score (micro avg)  0.5114
2022-05-13 17:44:28,878 Epoch    16: reducing learning rate of group 0 to 1.2500e-02.
2022-05-13 17:44:28,879 BAD EPOCHS (no improvement): 4
2022-05-13 17:44:28,881 ----------------------------------------------------------------------------------------------------
2022-05-13 17:44:31,694 epoch 17 - iter 10/107 - loss 0.07832614 - samples/sec: 113.80 - lr: 0.012500
2022-05-13 17:44:34,387 epoch 17 - iter 20/107 - loss 0.07058267 - samples/sec: 118.86 - lr: 0.012500
2022-05-13 17:44:37,075 epoch 17 - iter 30/107 - loss 0.06556309 - samples/sec: 119.12 - lr: 0.012500
2022-05-13 17:44:39,763 epoch 17 - iter 40/107 - loss 0.06804456 - samples/sec: 119.07 - lr: 0.012500
2022-05-13 17:44:42,533 epoch 17 - iter 50/107 - loss 0.06786814 - samples/sec: 115.58 - lr: 0.012500
2022-05-13 17:44:45,245 epoch 17 - iter 60/107 - loss 0.06874938 - samples/sec: 118.01 - lr: 0.012500
2022-05-13 17:44:47,969 epoch 17 - iter 70/107 - loss 0.07079123 - samples/sec: 117.50 - lr: 0.012500
2022-05-13 17:44:50,731 epoch 17 - iter 80/107 - loss 0.06905820 - samples/sec: 115.90 - lr: 0.012500
2022-05-13 17:44:53,315 epoch 17 - iter 90/107 - loss 0.06985896 - samples/sec: 123.88 - lr: 0.012500
2022-05-13 17:44:55,993 epoch 17 - iter 100/107 - loss 0.06907373 - samples/sec: 119.54 - lr: 0.012500
2022-05-13 17:44:57,623 ----------------------------------------------------------------------------------------------------
2022-05-13 17:44:57,624 EPOCH 17 done: loss 0.0692 - lr 0.012500
2022-05-13 17:45:06,505 Evaluating as a multi-label problem: False
2022-05-13 17:45:06,517 DEV : loss 0.20236940681934357 - f1-score (micro avg)  0.5078
2022-05-13 17:45:06,604 BAD EPOCHS (no improvement): 1
2022-05-13 17:45:06,605 ----------------------------------------------------------------------------------------------------
2022-05-13 17:45:09,301 epoch 18 - iter 10/107 - loss 0.06706755 - samples/sec: 118.80 - lr: 0.012500
2022-05-13 17:45:11,961 epoch 18 - iter 20/107 - loss 0.06299568 - samples/sec: 120.35 - lr: 0.012500
2022-05-13 17:45:14,487 epoch 18 - iter 30/107 - loss 0.06623119 - samples/sec: 126.71 - lr: 0.012500
2022-05-13 17:45:17,026 epoch 18 - iter 40/107 - loss 0.06734948 - samples/sec: 126.10 - lr: 0.012500
2022-05-13 17:45:19,666 epoch 18 - iter 50/107 - loss 0.06763151 - samples/sec: 121.28 - lr: 0.012500
2022-05-13 17:45:22,432 epoch 18 - iter 60/107 - loss 0.06858052 - samples/sec: 115.73 - lr: 0.012500
2022-05-13 17:45:25,184 epoch 18 - iter 70/107 - loss 0.07177258 - samples/sec: 116.29 - lr: 0.012500
2022-05-13 17:45:28,071 epoch 18 - iter 80/107 - loss 0.07094786 - samples/sec: 110.91 - lr: 0.012500
2022-05-13 17:45:30,737 epoch 18 - iter 90/107 - loss 0.06966791 - samples/sec: 120.06 - lr: 0.012500
2022-05-13 17:45:33,485 epoch 18 - iter 100/107 - loss 0.06997299 - samples/sec: 116.47 - lr: 0.012500
2022-05-13 17:45:35,090 ----------------------------------------------------------------------------------------------------
2022-05-13 17:45:35,090 EPOCH 18 done: loss 0.0694 - lr 0.012500
2022-05-13 17:45:43,981 Evaluating as a multi-label problem: False
2022-05-13 17:45:43,992 DEV : loss 0.20837432146072388 - f1-score (micro avg)  0.5012
2022-05-13 17:45:44,074 BAD EPOCHS (no improvement): 2
2022-05-13 17:45:44,076 ----------------------------------------------------------------------------------------------------
2022-05-13 17:45:46,871 epoch 19 - iter 10/107 - loss 0.05825140 - samples/sec: 114.57 - lr: 0.012500
2022-05-13 17:45:49,509 epoch 19 - iter 20/107 - loss 0.06137393 - samples/sec: 121.34 - lr: 0.012500
2022-05-13 17:45:52,226 epoch 19 - iter 30/107 - loss 0.06483827 - samples/sec: 117.80 - lr: 0.012500
2022-05-13 17:45:54,942 epoch 19 - iter 40/107 - loss 0.06662140 - samples/sec: 117.87 - lr: 0.012500
2022-05-13 17:45:57,723 epoch 19 - iter 50/107 - loss 0.06928416 - samples/sec: 115.12 - lr: 0.012500
2022-05-13 17:46:00,368 epoch 19 - iter 60/107 - loss 0.06855714 - samples/sec: 121.01 - lr: 0.012500
2022-05-13 17:46:03,122 epoch 19 - iter 70/107 - loss 0.07023400 - samples/sec: 116.26 - lr: 0.012500
2022-05-13 17:46:05,782 epoch 19 - iter 80/107 - loss 0.06958054 - samples/sec: 120.34 - lr: 0.012500
2022-05-13 17:46:08,481 epoch 19 - iter 90/107 - loss 0.06864119 - samples/sec: 118.60 - lr: 0.012500
2022-05-13 17:46:11,214 epoch 19 - iter 100/107 - loss 0.06735905 - samples/sec: 117.11 - lr: 0.012500
2022-05-13 17:46:12,798 ----------------------------------------------------------------------------------------------------
2022-05-13 17:46:12,798 EPOCH 19 done: loss 0.0672 - lr 0.012500
2022-05-13 17:46:21,684 Evaluating as a multi-label problem: False
2022-05-13 17:46:21,695 DEV : loss 0.21162648499011993 - f1-score (micro avg)  0.4927
2022-05-13 17:46:21,781 BAD EPOCHS (no improvement): 3
2022-05-13 17:46:21,784 ----------------------------------------------------------------------------------------------------
2022-05-13 17:46:24,524 epoch 20 - iter 10/107 - loss 0.06754679 - samples/sec: 116.80 - lr: 0.012500
2022-05-13 17:46:27,235 epoch 20 - iter 20/107 - loss 0.06291909 - samples/sec: 118.10 - lr: 0.012500
2022-05-13 17:46:29,903 epoch 20 - iter 30/107 - loss 0.06314261 - samples/sec: 119.98 - lr: 0.012500
2022-05-13 17:46:32,581 epoch 20 - iter 40/107 - loss 0.06891646 - samples/sec: 119.53 - lr: 0.012500
2022-05-13 17:46:35,313 epoch 20 - iter 50/107 - loss 0.06794647 - samples/sec: 117.17 - lr: 0.012500
2022-05-13 17:46:38,011 epoch 20 - iter 60/107 - loss 0.06627349 - samples/sec: 118.63 - lr: 0.012500
2022-05-13 17:46:40,672 epoch 20 - iter 70/107 - loss 0.06625664 - samples/sec: 120.29 - lr: 0.012500
2022-05-13 17:46:43,464 epoch 20 - iter 80/107 - loss 0.06497166 - samples/sec: 114.68 - lr: 0.012500
2022-05-13 17:46:46,120 epoch 20 - iter 90/107 - loss 0.06423706 - samples/sec: 120.54 - lr: 0.012500
2022-05-13 17:46:48,969 epoch 20 - iter 100/107 - loss 0.06496323 - samples/sec: 112.33 - lr: 0.012500
2022-05-13 17:46:50,602 ----------------------------------------------------------------------------------------------------
2022-05-13 17:46:50,602 EPOCH 20 done: loss 0.0652 - lr 0.012500
2022-05-13 17:46:59,456 Evaluating as a multi-label problem: False
2022-05-13 17:46:59,468 DEV : loss 0.20736868679523468 - f1-score (micro avg)  0.5048
2022-05-13 17:46:59,551 Epoch    20: reducing learning rate of group 0 to 6.2500e-03.
2022-05-13 17:46:59,551 BAD EPOCHS (no improvement): 4
2022-05-13 17:46:59,553 ----------------------------------------------------------------------------------------------------
2022-05-13 17:47:02,265 epoch 21 - iter 10/107 - loss 0.06585358 - samples/sec: 118.07 - lr: 0.006250
2022-05-13 17:47:04,976 epoch 21 - iter 20/107 - loss 0.06995575 - samples/sec: 118.06 - lr: 0.006250
2022-05-13 17:47:07,658 epoch 21 - iter 30/107 - loss 0.06442647 - samples/sec: 119.34 - lr: 0.006250
2022-05-13 17:47:10,396 epoch 21 - iter 40/107 - loss 0.06600091 - samples/sec: 116.94 - lr: 0.006250
2022-05-13 17:47:13,111 epoch 21 - iter 50/107 - loss 0.06551251 - samples/sec: 117.89 - lr: 0.006250
2022-05-13 17:47:15,763 epoch 21 - iter 60/107 - loss 0.06640721 - samples/sec: 120.73 - lr: 0.006250
2022-05-13 17:47:18,465 epoch 21 - iter 70/107 - loss 0.06730260 - samples/sec: 118.47 - lr: 0.006250
2022-05-13 17:47:21,158 epoch 21 - iter 80/107 - loss 0.06570067 - samples/sec: 118.87 - lr: 0.006250
2022-05-13 17:47:24,019 epoch 21 - iter 90/107 - loss 0.06576530 - samples/sec: 111.88 - lr: 0.006250
2022-05-13 17:47:26,736 epoch 21 - iter 100/107 - loss 0.06635051 - samples/sec: 117.79 - lr: 0.006250
2022-05-13 17:47:28,431 ----------------------------------------------------------------------------------------------------
2022-05-13 17:47:28,431 EPOCH 21 done: loss 0.0650 - lr 0.006250
2022-05-13 17:47:37,265 Evaluating as a multi-label problem: False
2022-05-13 17:47:37,276 DEV : loss 0.2164619117975235 - f1-score (micro avg)  0.4914
2022-05-13 17:47:37,362 BAD EPOCHS (no improvement): 1
2022-05-13 17:47:37,364 ----------------------------------------------------------------------------------------------------
2022-05-13 17:47:40,111 epoch 22 - iter 10/107 - loss 0.07150776 - samples/sec: 116.58 - lr: 0.006250
2022-05-13 17:47:42,773 epoch 22 - iter 20/107 - loss 0.06565195 - samples/sec: 120.26 - lr: 0.006250
2022-05-13 17:47:45,508 epoch 22 - iter 30/107 - loss 0.06966873 - samples/sec: 117.03 - lr: 0.006250
2022-05-13 17:47:48,174 epoch 22 - iter 40/107 - loss 0.06874707 - samples/sec: 120.08 - lr: 0.006250
2022-05-13 17:47:50,876 epoch 22 - iter 50/107 - loss 0.06612480 - samples/sec: 118.45 - lr: 0.006250
2022-05-13 17:47:53,622 epoch 22 - iter 60/107 - loss 0.06493398 - samples/sec: 116.57 - lr: 0.006250
2022-05-13 17:47:56,360 epoch 22 - iter 70/107 - loss 0.06500173 - samples/sec: 116.93 - lr: 0.006250
2022-05-13 17:47:59,030 epoch 22 - iter 80/107 - loss 0.06378585 - samples/sec: 119.86 - lr: 0.006250
2022-05-13 17:48:01,950 epoch 22 - iter 90/107 - loss 0.06340662 - samples/sec: 109.65 - lr: 0.006250
2022-05-13 17:48:04,527 epoch 22 - iter 100/107 - loss 0.06316250 - samples/sec: 124.23 - lr: 0.006250
2022-05-13 17:48:06,232 ----------------------------------------------------------------------------------------------------
2022-05-13 17:48:06,232 EPOCH 22 done: loss 0.0624 - lr 0.006250
2022-05-13 17:48:15,100 Evaluating as a multi-label problem: False
2022-05-13 17:48:15,111 DEV : loss 0.209546759724617 - f1-score (micro avg)  0.5036
2022-05-13 17:48:15,195 BAD EPOCHS (no improvement): 2
2022-05-13 17:48:15,254 ----------------------------------------------------------------------------------------------------
2022-05-13 17:48:18,052 epoch 23 - iter 10/107 - loss 0.06409150 - samples/sec: 114.42 - lr: 0.006250
2022-05-13 17:48:20,796 epoch 23 - iter 20/107 - loss 0.06945656 - samples/sec: 116.65 - lr: 0.006250
2022-05-13 17:48:23,549 epoch 23 - iter 30/107 - loss 0.06323070 - samples/sec: 116.30 - lr: 0.006250
2022-05-13 17:48:26,239 epoch 23 - iter 40/107 - loss 0.06230394 - samples/sec: 119.00 - lr: 0.006250
2022-05-13 17:48:29,018 epoch 23 - iter 50/107 - loss 0.06291892 - samples/sec: 115.23 - lr: 0.006250
2022-05-13 17:48:31,682 epoch 23 - iter 60/107 - loss 0.06424556 - samples/sec: 120.13 - lr: 0.006250
2022-05-13 17:48:34,435 epoch 23 - iter 70/107 - loss 0.06618818 - samples/sec: 116.30 - lr: 0.006250
2022-05-13 17:48:37,133 epoch 23 - iter 80/107 - loss 0.06557791 - samples/sec: 118.64 - lr: 0.006250
2022-05-13 17:48:39,855 epoch 23 - iter 90/107 - loss 0.06431259 - samples/sec: 117.59 - lr: 0.006250
2022-05-13 17:48:42,620 epoch 23 - iter 100/107 - loss 0.06497332 - samples/sec: 115.78 - lr: 0.006250
2022-05-13 17:48:44,233 ----------------------------------------------------------------------------------------------------
2022-05-13 17:48:44,233 EPOCH 23 done: loss 0.0640 - lr 0.006250
2022-05-13 17:48:53,163 Evaluating as a multi-label problem: False
2022-05-13 17:48:53,174 DEV : loss 0.2111680954694748 - f1-score (micro avg)  0.5012
2022-05-13 17:48:53,258 BAD EPOCHS (no improvement): 3
2022-05-13 17:48:53,266 ----------------------------------------------------------------------------------------------------
2022-05-13 17:48:55,953 epoch 24 - iter 10/107 - loss 0.05110994 - samples/sec: 119.16 - lr: 0.006250
2022-05-13 17:48:58,633 epoch 24 - iter 20/107 - loss 0.05531830 - samples/sec: 119.46 - lr: 0.006250
2022-05-13 17:49:01,347 epoch 24 - iter 30/107 - loss 0.06236231 - samples/sec: 117.93 - lr: 0.006250
2022-05-13 17:49:04,011 epoch 24 - iter 40/107 - loss 0.06345296 - samples/sec: 120.16 - lr: 0.006250
2022-05-13 17:49:06,667 epoch 24 - iter 50/107 - loss 0.06340502 - samples/sec: 120.50 - lr: 0.006250
2022-05-13 17:49:09,379 epoch 24 - iter 60/107 - loss 0.06459883 - samples/sec: 118.07 - lr: 0.006250
2022-05-13 17:49:12,238 epoch 24 - iter 70/107 - loss 0.06592950 - samples/sec: 111.94 - lr: 0.006250
2022-05-13 17:49:14,934 epoch 24 - iter 80/107 - loss 0.06618294 - samples/sec: 118.75 - lr: 0.006250
2022-05-13 17:49:17,738 epoch 24 - iter 90/107 - loss 0.06570409 - samples/sec: 114.18 - lr: 0.006250
2022-05-13 17:49:20,459 epoch 24 - iter 100/107 - loss 0.06528494 - samples/sec: 117.64 - lr: 0.006250
2022-05-13 17:49:22,189 ----------------------------------------------------------------------------------------------------
2022-05-13 17:49:22,190 EPOCH 24 done: loss 0.0641 - lr 0.006250
2022-05-13 17:49:35,192 Evaluating as a multi-label problem: False
2022-05-13 17:49:35,203 DEV : loss 0.21266651153564453 - f1-score (micro avg)  0.5008
2022-05-13 17:49:35,290 Epoch    24: reducing learning rate of group 0 to 3.1250e-03.
2022-05-13 17:49:35,291 BAD EPOCHS (no improvement): 4
2022-05-13 17:49:35,292 ----------------------------------------------------------------------------------------------------
2022-05-13 17:49:38,143 epoch 25 - iter 10/107 - loss 0.07865549 - samples/sec: 112.28 - lr: 0.003125
2022-05-13 17:49:40,950 epoch 25 - iter 20/107 - loss 0.06986280 - samples/sec: 114.05 - lr: 0.003125
2022-05-13 17:49:43,609 epoch 25 - iter 30/107 - loss 0.06855544 - samples/sec: 120.41 - lr: 0.003125
2022-05-13 17:49:46,491 epoch 25 - iter 40/107 - loss 0.06712777 - samples/sec: 111.07 - lr: 0.003125
2022-05-13 17:49:49,213 epoch 25 - iter 50/107 - loss 0.06510926 - samples/sec: 117.61 - lr: 0.003125
2022-05-13 17:49:51,935 epoch 25 - iter 60/107 - loss 0.06290009 - samples/sec: 117.57 - lr: 0.003125
2022-05-13 17:49:54,647 epoch 25 - iter 70/107 - loss 0.06254344 - samples/sec: 118.07 - lr: 0.003125
2022-05-13 17:49:57,356 epoch 25 - iter 80/107 - loss 0.06203301 - samples/sec: 118.14 - lr: 0.003125
2022-05-13 17:49:59,965 epoch 25 - iter 90/107 - loss 0.06218054 - samples/sec: 122.72 - lr: 0.003125
2022-05-13 17:50:02,854 epoch 25 - iter 100/107 - loss 0.06357094 - samples/sec: 110.80 - lr: 0.003125
2022-05-13 17:50:04,455 ----------------------------------------------------------------------------------------------------
2022-05-13 17:50:04,455 EPOCH 25 done: loss 0.0636 - lr 0.003125
2022-05-13 17:50:13,380 Evaluating as a multi-label problem: False
2022-05-13 17:50:13,391 DEV : loss 0.20938654243946075 - f1-score (micro avg)  0.5047
2022-05-13 17:50:13,475 BAD EPOCHS (no improvement): 1
2022-05-13 17:50:13,480 ----------------------------------------------------------------------------------------------------
2022-05-13 17:50:16,112 epoch 26 - iter 10/107 - loss 0.06619514 - samples/sec: 121.65 - lr: 0.003125
2022-05-13 17:50:18,831 epoch 26 - iter 20/107 - loss 0.05835961 - samples/sec: 117.77 - lr: 0.003125
2022-05-13 17:50:21,553 epoch 26 - iter 30/107 - loss 0.05915884 - samples/sec: 117.59 - lr: 0.003125
2022-05-13 17:50:24,348 epoch 26 - iter 40/107 - loss 0.06082795 - samples/sec: 114.53 - lr: 0.003125
2022-05-13 17:50:27,050 epoch 26 - iter 50/107 - loss 0.05981748 - samples/sec: 118.45 - lr: 0.003125
2022-05-13 17:50:29,753 epoch 26 - iter 60/107 - loss 0.06056401 - samples/sec: 118.42 - lr: 0.003125
2022-05-13 17:50:32,424 epoch 26 - iter 70/107 - loss 0.06174759 - samples/sec: 119.86 - lr: 0.003125
2022-05-13 17:50:35,140 epoch 26 - iter 80/107 - loss 0.06102864 - samples/sec: 117.87 - lr: 0.003125
2022-05-13 17:50:37,786 epoch 26 - iter 90/107 - loss 0.05968512 - samples/sec: 120.95 - lr: 0.003125
2022-05-13 17:50:40,543 epoch 26 - iter 100/107 - loss 0.06053322 - samples/sec: 116.14 - lr: 0.003125
2022-05-13 17:50:42,200 ----------------------------------------------------------------------------------------------------
2022-05-13 17:50:42,200 EPOCH 26 done: loss 0.0611 - lr 0.003125
2022-05-13 17:50:51,066 Evaluating as a multi-label problem: False
2022-05-13 17:50:51,077 DEV : loss 0.20549270510673523 - f1-score (micro avg)  0.511
2022-05-13 17:50:51,161 BAD EPOCHS (no improvement): 2
2022-05-13 17:50:51,163 ----------------------------------------------------------------------------------------------------
2022-05-13 17:50:53,886 epoch 27 - iter 10/107 - loss 0.05374108 - samples/sec: 117.61 - lr: 0.003125
2022-05-13 17:50:56,508 epoch 27 - iter 20/107 - loss 0.05326454 - samples/sec: 122.12 - lr: 0.003125
2022-05-13 17:50:59,191 epoch 27 - iter 30/107 - loss 0.05714059 - samples/sec: 119.29 - lr: 0.003125
2022-05-13 17:51:01,918 epoch 27 - iter 40/107 - loss 0.05902779 - samples/sec: 117.39 - lr: 0.003125
2022-05-13 17:51:04,724 epoch 27 - iter 50/107 - loss 0.05858287 - samples/sec: 114.11 - lr: 0.003125
2022-05-13 17:51:07,433 epoch 27 - iter 60/107 - loss 0.06102109 - samples/sec: 118.15 - lr: 0.003125
2022-05-13 17:51:10,123 epoch 27 - iter 70/107 - loss 0.06109118 - samples/sec: 118.99 - lr: 0.003125
2022-05-13 17:51:12,878 epoch 27 - iter 80/107 - loss 0.06181711 - samples/sec: 116.21 - lr: 0.003125
2022-05-13 17:51:15,574 epoch 27 - iter 90/107 - loss 0.06095306 - samples/sec: 118.73 - lr: 0.003125
2022-05-13 17:51:18,320 epoch 27 - iter 100/107 - loss 0.06097612 - samples/sec: 116.58 - lr: 0.003125
2022-05-13 17:51:20,033 ----------------------------------------------------------------------------------------------------
2022-05-13 17:51:20,034 EPOCH 27 done: loss 0.0609 - lr 0.003125
2022-05-13 17:51:28,934 Evaluating as a multi-label problem: False
2022-05-13 17:51:28,946 DEV : loss 0.20842909812927246 - f1-score (micro avg)  0.5055
2022-05-13 17:51:29,031 BAD EPOCHS (no improvement): 3
2022-05-13 17:51:29,033 ----------------------------------------------------------------------------------------------------
2022-05-13 17:51:31,870 epoch 28 - iter 10/107 - loss 0.03785170 - samples/sec: 112.86 - lr: 0.003125
2022-05-13 17:51:34,421 epoch 28 - iter 20/107 - loss 0.05185125 - samples/sec: 125.46 - lr: 0.003125
2022-05-13 17:51:36,944 epoch 28 - iter 30/107 - loss 0.05325479 - samples/sec: 126.88 - lr: 0.003125
2022-05-13 17:51:39,584 epoch 28 - iter 40/107 - loss 0.05377639 - samples/sec: 121.28 - lr: 0.003125
2022-05-13 17:51:42,125 epoch 28 - iter 50/107 - loss 0.05431745 - samples/sec: 125.98 - lr: 0.003125
2022-05-13 17:51:44,712 epoch 28 - iter 60/107 - loss 0.05741677 - samples/sec: 123.75 - lr: 0.003125
2022-05-13 17:51:47,365 epoch 28 - iter 70/107 - loss 0.05812552 - samples/sec: 120.66 - lr: 0.003125
2022-05-13 17:51:50,049 epoch 28 - iter 80/107 - loss 0.05758167 - samples/sec: 119.29 - lr: 0.003125
2022-05-13 17:51:52,814 epoch 28 - iter 90/107 - loss 0.05867707 - samples/sec: 115.77 - lr: 0.003125
2022-05-13 17:51:55,548 epoch 28 - iter 100/107 - loss 0.05933767 - samples/sec: 117.10 - lr: 0.003125
2022-05-13 17:51:57,178 ----------------------------------------------------------------------------------------------------
2022-05-13 17:51:57,179 EPOCH 28 done: loss 0.0607 - lr 0.003125
2022-05-13 17:52:06,043 Evaluating as a multi-label problem: False
2022-05-13 17:52:06,054 DEV : loss 0.21001076698303223 - f1-score (micro avg)  0.4992
2022-05-13 17:52:06,140 Epoch    28: reducing learning rate of group 0 to 1.5625e-03.
2022-05-13 17:52:06,140 BAD EPOCHS (no improvement): 4
2022-05-13 17:52:06,143 ----------------------------------------------------------------------------------------------------
2022-05-13 17:52:08,953 epoch 29 - iter 10/107 - loss 0.06781775 - samples/sec: 113.91 - lr: 0.001563
2022-05-13 17:52:11,610 epoch 29 - iter 20/107 - loss 0.06539806 - samples/sec: 120.51 - lr: 0.001563
2022-05-13 17:52:14,326 epoch 29 - iter 30/107 - loss 0.06169891 - samples/sec: 117.86 - lr: 0.001563
2022-05-13 17:52:17,041 epoch 29 - iter 40/107 - loss 0.05968138 - samples/sec: 117.87 - lr: 0.001563
2022-05-13 17:52:19,811 epoch 29 - iter 50/107 - loss 0.05952491 - samples/sec: 115.57 - lr: 0.001563
2022-05-13 17:52:22,419 epoch 29 - iter 60/107 - loss 0.05965983 - samples/sec: 122.75 - lr: 0.001563
2022-05-13 17:52:25,098 epoch 29 - iter 70/107 - loss 0.05999145 - samples/sec: 119.50 - lr: 0.001563
2022-05-13 17:52:27,713 epoch 29 - iter 80/107 - loss 0.06129077 - samples/sec: 122.39 - lr: 0.001563
2022-05-13 17:52:30,442 epoch 29 - iter 90/107 - loss 0.06172869 - samples/sec: 117.31 - lr: 0.001563
2022-05-13 17:52:33,176 epoch 29 - iter 100/107 - loss 0.06111478 - samples/sec: 117.07 - lr: 0.001563
2022-05-13 17:52:34,939 ----------------------------------------------------------------------------------------------------
2022-05-13 17:52:34,939 EPOCH 29 done: loss 0.0612 - lr 0.001563
2022-05-13 17:52:43,788 Evaluating as a multi-label problem: False
2022-05-13 17:52:43,800 DEV : loss 0.2093154639005661 - f1-score (micro avg)  0.5032
2022-05-13 17:52:43,883 BAD EPOCHS (no improvement): 1
2022-05-13 17:52:43,885 ----------------------------------------------------------------------------------------------------
2022-05-13 17:52:46,671 epoch 30 - iter 10/107 - loss 0.07386079 - samples/sec: 114.96 - lr: 0.001563
2022-05-13 17:52:49,404 epoch 30 - iter 20/107 - loss 0.07148850 - samples/sec: 117.09 - lr: 0.001563
2022-05-13 17:52:52,020 epoch 30 - iter 30/107 - loss 0.06727232 - samples/sec: 122.38 - lr: 0.001563
2022-05-13 17:52:54,813 epoch 30 - iter 40/107 - loss 0.06159350 - samples/sec: 114.63 - lr: 0.001563
2022-05-13 17:52:57,427 epoch 30 - iter 50/107 - loss 0.06110673 - samples/sec: 122.45 - lr: 0.001563
2022-05-13 17:53:00,220 epoch 30 - iter 60/107 - loss 0.06178335 - samples/sec: 114.63 - lr: 0.001563
2022-05-13 17:53:02,971 epoch 30 - iter 70/107 - loss 0.06352628 - samples/sec: 116.36 - lr: 0.001563
2022-05-13 17:53:05,768 epoch 30 - iter 80/107 - loss 0.06246516 - samples/sec: 114.44 - lr: 0.001563
2022-05-13 17:53:08,608 epoch 30 - iter 90/107 - loss 0.06292029 - samples/sec: 112.71 - lr: 0.001563
2022-05-13 17:53:11,417 epoch 30 - iter 100/107 - loss 0.06332700 - samples/sec: 113.99 - lr: 0.001563
2022-05-13 17:53:13,045 ----------------------------------------------------------------------------------------------------
2022-05-13 17:53:13,045 EPOCH 30 done: loss 0.0630 - lr 0.001563
2022-05-13 17:53:21,975 Evaluating as a multi-label problem: False
2022-05-13 17:53:21,986 DEV : loss 0.21092276275157928 - f1-score (micro avg)  0.504
2022-05-13 17:53:22,070 BAD EPOCHS (no improvement): 2
2022-05-13 17:53:22,072 ----------------------------------------------------------------------------------------------------
2022-05-13 17:53:24,742 epoch 31 - iter 10/107 - loss 0.06872237 - samples/sec: 119.92 - lr: 0.001563
2022-05-13 17:53:27,516 epoch 31 - iter 20/107 - loss 0.06518528 - samples/sec: 115.40 - lr: 0.001563
2022-05-13 17:53:30,190 epoch 31 - iter 30/107 - loss 0.06514161 - samples/sec: 119.74 - lr: 0.001563
2022-05-13 17:53:32,901 epoch 31 - iter 40/107 - loss 0.06417853 - samples/sec: 118.07 - lr: 0.001563
2022-05-13 17:53:35,727 epoch 31 - iter 50/107 - loss 0.06157062 - samples/sec: 113.29 - lr: 0.001563
2022-05-13 17:53:38,464 epoch 31 - iter 60/107 - loss 0.05911642 - samples/sec: 116.94 - lr: 0.001563
2022-05-13 17:53:41,135 epoch 31 - iter 70/107 - loss 0.06045292 - samples/sec: 119.85 - lr: 0.001563
2022-05-13 17:53:43,704 epoch 31 - iter 80/107 - loss 0.06036630 - samples/sec: 124.62 - lr: 0.001563
2022-05-13 17:53:46,476 epoch 31 - iter 90/107 - loss 0.05962938 - samples/sec: 115.47 - lr: 0.001563
2022-05-13 17:53:49,233 epoch 31 - iter 100/107 - loss 0.05948834 - samples/sec: 116.10 - lr: 0.001563
2022-05-13 17:53:50,897 ----------------------------------------------------------------------------------------------------
2022-05-13 17:53:50,897 EPOCH 31 done: loss 0.0598 - lr 0.001563
2022-05-13 17:53:59,823 Evaluating as a multi-label problem: False
2022-05-13 17:53:59,835 DEV : loss 0.21111051738262177 - f1-score (micro avg)  0.504
2022-05-13 17:53:59,918 BAD EPOCHS (no improvement): 3
2022-05-13 17:53:59,920 ----------------------------------------------------------------------------------------------------
2022-05-13 17:54:02,631 epoch 32 - iter 10/107 - loss 0.07017412 - samples/sec: 118.09 - lr: 0.001563
2022-05-13 17:54:05,353 epoch 32 - iter 20/107 - loss 0.06354687 - samples/sec: 117.62 - lr: 0.001563
2022-05-13 17:54:08,110 epoch 32 - iter 30/107 - loss 0.05921634 - samples/sec: 116.11 - lr: 0.001563
2022-05-13 17:54:10,815 epoch 32 - iter 40/107 - loss 0.05725991 - samples/sec: 118.30 - lr: 0.001563
2022-05-13 17:54:13,450 epoch 32 - iter 50/107 - loss 0.06229587 - samples/sec: 121.52 - lr: 0.001563
2022-05-13 17:54:16,145 epoch 32 - iter 60/107 - loss 0.06075682 - samples/sec: 118.76 - lr: 0.001563
2022-05-13 17:54:18,833 epoch 32 - iter 70/107 - loss 0.06067562 - samples/sec: 119.14 - lr: 0.001563
2022-05-13 17:54:21,603 epoch 32 - iter 80/107 - loss 0.05985307 - samples/sec: 115.57 - lr: 0.001563
2022-05-13 17:54:24,363 epoch 32 - iter 90/107 - loss 0.06077575 - samples/sec: 115.95 - lr: 0.001563
2022-05-13 17:54:27,034 epoch 32 - iter 100/107 - loss 0.06067493 - samples/sec: 119.87 - lr: 0.001563
2022-05-13 17:54:28,749 ----------------------------------------------------------------------------------------------------
2022-05-13 17:54:28,749 EPOCH 32 done: loss 0.0612 - lr 0.001563
2022-05-13 17:54:37,606 Evaluating as a multi-label problem: False
2022-05-13 17:54:37,617 DEV : loss 0.20949405431747437 - f1-score (micro avg)  0.5055
2022-05-13 17:54:37,706 Epoch    32: reducing learning rate of group 0 to 7.8125e-04.
2022-05-13 17:54:37,706 BAD EPOCHS (no improvement): 4
2022-05-13 17:54:37,708 ----------------------------------------------------------------------------------------------------
2022-05-13 17:54:40,442 epoch 33 - iter 10/107 - loss 0.06446973 - samples/sec: 117.10 - lr: 0.000781
2022-05-13 17:54:43,165 epoch 33 - iter 20/107 - loss 0.06027984 - samples/sec: 117.58 - lr: 0.000781
2022-05-13 17:54:45,870 epoch 33 - iter 30/107 - loss 0.05657748 - samples/sec: 118.33 - lr: 0.000781
2022-05-13 17:54:48,650 epoch 33 - iter 40/107 - loss 0.05709211 - samples/sec: 115.14 - lr: 0.000781
2022-05-13 17:54:51,326 epoch 33 - iter 50/107 - loss 0.05599365 - samples/sec: 119.64 - lr: 0.000781
2022-05-13 17:54:54,039 epoch 33 - iter 60/107 - loss 0.05679545 - samples/sec: 117.96 - lr: 0.000781
2022-05-13 17:54:56,738 epoch 33 - iter 70/107 - loss 0.05923521 - samples/sec: 118.63 - lr: 0.000781
2022-05-13 17:54:59,412 epoch 33 - iter 80/107 - loss 0.05856954 - samples/sec: 119.70 - lr: 0.000781
2022-05-13 17:55:02,177 epoch 33 - iter 90/107 - loss 0.06014191 - samples/sec: 115.78 - lr: 0.000781
2022-05-13 17:55:04,896 epoch 33 - iter 100/107 - loss 0.06068371 - samples/sec: 117.73 - lr: 0.000781
2022-05-13 17:55:06,572 ----------------------------------------------------------------------------------------------------
2022-05-13 17:55:06,573 EPOCH 33 done: loss 0.0618 - lr 0.000781
2022-05-13 17:55:15,259 Evaluating as a multi-label problem: False
2022-05-13 17:55:15,271 DEV : loss 0.20971354842185974 - f1-score (micro avg)  0.5055
2022-05-13 17:55:15,356 BAD EPOCHS (no improvement): 1
2022-05-13 17:55:15,368 ----------------------------------------------------------------------------------------------------
2022-05-13 17:55:18,006 epoch 34 - iter 10/107 - loss 0.07056792 - samples/sec: 121.38 - lr: 0.000781
2022-05-13 17:55:20,504 epoch 34 - iter 20/107 - loss 0.06807974 - samples/sec: 128.15 - lr: 0.000781
2022-05-13 17:55:22,991 epoch 34 - iter 30/107 - loss 0.06344263 - samples/sec: 128.73 - lr: 0.000781
2022-05-13 17:55:25,669 epoch 34 - iter 40/107 - loss 0.06233560 - samples/sec: 119.54 - lr: 0.000781
2022-05-13 17:55:28,365 epoch 34 - iter 50/107 - loss 0.06182362 - samples/sec: 118.75 - lr: 0.000781
2022-05-13 17:55:31,116 epoch 34 - iter 60/107 - loss 0.06116399 - samples/sec: 116.34 - lr: 0.000781
2022-05-13 17:55:33,852 epoch 34 - iter 70/107 - loss 0.06184322 - samples/sec: 117.00 - lr: 0.000781
2022-05-13 17:55:36,611 epoch 34 - iter 80/107 - loss 0.06115557 - samples/sec: 116.03 - lr: 0.000781
2022-05-13 17:55:39,328 epoch 34 - iter 90/107 - loss 0.06170679 - samples/sec: 117.80 - lr: 0.000781
2022-05-13 17:55:42,028 epoch 34 - iter 100/107 - loss 0.06016409 - samples/sec: 118.57 - lr: 0.000781
2022-05-13 17:55:43,777 ----------------------------------------------------------------------------------------------------
2022-05-13 17:55:43,777 EPOCH 34 done: loss 0.0619 - lr 0.000781
2022-05-13 17:55:52,644 Evaluating as a multi-label problem: False
2022-05-13 17:55:52,656 DEV : loss 0.2088516354560852 - f1-score (micro avg)  0.5055
2022-05-13 17:55:52,743 BAD EPOCHS (no improvement): 2
2022-05-13 17:55:52,745 ----------------------------------------------------------------------------------------------------
2022-05-13 17:55:55,446 epoch 35 - iter 10/107 - loss 0.05247792 - samples/sec: 118.51 - lr: 0.000781
2022-05-13 17:55:58,128 epoch 35 - iter 20/107 - loss 0.05441210 - samples/sec: 119.38 - lr: 0.000781
2022-05-13 17:56:00,849 epoch 35 - iter 30/107 - loss 0.05852455 - samples/sec: 117.64 - lr: 0.000781
2022-05-13 17:56:03,555 epoch 35 - iter 40/107 - loss 0.06066759 - samples/sec: 118.31 - lr: 0.000781
2022-05-13 17:56:06,299 epoch 35 - iter 50/107 - loss 0.05895748 - samples/sec: 116.64 - lr: 0.000781
2022-05-13 17:56:08,965 epoch 35 - iter 60/107 - loss 0.05909365 - samples/sec: 120.07 - lr: 0.000781
2022-05-13 17:56:11,656 epoch 35 - iter 70/107 - loss 0.05970975 - samples/sec: 118.96 - lr: 0.000781
2022-05-13 17:56:14,468 epoch 35 - iter 80/107 - loss 0.06055803 - samples/sec: 113.85 - lr: 0.000781
2022-05-13 17:56:17,226 epoch 35 - iter 90/107 - loss 0.06051627 - samples/sec: 116.03 - lr: 0.000781
2022-05-13 17:56:19,953 epoch 35 - iter 100/107 - loss 0.06127917 - samples/sec: 117.37 - lr: 0.000781
2022-05-13 17:56:21,578 ----------------------------------------------------------------------------------------------------
2022-05-13 17:56:21,578 EPOCH 35 done: loss 0.0605 - lr 0.000781
2022-05-13 17:56:30,427 Evaluating as a multi-label problem: False
2022-05-13 17:56:30,438 DEV : loss 0.20937417447566986 - f1-score (micro avg)  0.5055
2022-05-13 17:56:30,523 BAD EPOCHS (no improvement): 3
2022-05-13 17:56:30,524 ----------------------------------------------------------------------------------------------------
2022-05-13 17:56:33,145 epoch 36 - iter 10/107 - loss 0.06442810 - samples/sec: 122.18 - lr: 0.000781
2022-05-13 17:56:35,868 epoch 36 - iter 20/107 - loss 0.05648399 - samples/sec: 117.54 - lr: 0.000781
2022-05-13 17:56:38,604 epoch 36 - iter 30/107 - loss 0.05701351 - samples/sec: 117.00 - lr: 0.000781
2022-05-13 17:56:41,335 epoch 36 - iter 40/107 - loss 0.05627450 - samples/sec: 117.20 - lr: 0.000781
2022-05-13 17:56:44,095 epoch 36 - iter 50/107 - loss 0.05860447 - samples/sec: 115.99 - lr: 0.000781
2022-05-13 17:56:46,819 epoch 36 - iter 60/107 - loss 0.05862480 - samples/sec: 117.53 - lr: 0.000781
2022-05-13 17:56:49,502 epoch 36 - iter 70/107 - loss 0.05873171 - samples/sec: 119.31 - lr: 0.000781
2022-05-13 17:56:52,208 epoch 36 - iter 80/107 - loss 0.06067778 - samples/sec: 118.31 - lr: 0.000781
2022-05-13 17:56:54,903 epoch 36 - iter 90/107 - loss 0.05987199 - samples/sec: 118.77 - lr: 0.000781
2022-05-13 17:56:57,620 epoch 36 - iter 100/107 - loss 0.05883999 - samples/sec: 117.81 - lr: 0.000781
2022-05-13 17:56:59,292 ----------------------------------------------------------------------------------------------------
2022-05-13 17:56:59,292 EPOCH 36 done: loss 0.0599 - lr 0.000781
2022-05-13 17:57:08,230 Evaluating as a multi-label problem: False
2022-05-13 17:57:08,242 DEV : loss 0.20941780507564545 - f1-score (micro avg)  0.5051
2022-05-13 17:57:08,328 Epoch    36: reducing learning rate of group 0 to 3.9063e-04.
2022-05-13 17:57:08,328 BAD EPOCHS (no improvement): 4
2022-05-13 17:57:08,330 ----------------------------------------------------------------------------------------------------
2022-05-13 17:57:11,137 epoch 37 - iter 10/107 - loss 0.04913206 - samples/sec: 114.06 - lr: 0.000391
2022-05-13 17:57:13,826 epoch 37 - iter 20/107 - loss 0.05033517 - samples/sec: 119.06 - lr: 0.000391
2022-05-13 17:57:16,523 epoch 37 - iter 30/107 - loss 0.05638784 - samples/sec: 118.68 - lr: 0.000391
2022-05-13 17:57:19,275 epoch 37 - iter 40/107 - loss 0.05507713 - samples/sec: 116.33 - lr: 0.000391
2022-05-13 17:57:21,979 epoch 37 - iter 50/107 - loss 0.05526618 - samples/sec: 118.37 - lr: 0.000391
2022-05-13 17:57:24,734 epoch 37 - iter 60/107 - loss 0.05741069 - samples/sec: 116.18 - lr: 0.000391
2022-05-13 17:57:27,437 epoch 37 - iter 70/107 - loss 0.05807493 - samples/sec: 118.44 - lr: 0.000391
2022-05-13 17:57:29,950 epoch 37 - iter 80/107 - loss 0.05963162 - samples/sec: 127.36 - lr: 0.000391
2022-05-13 17:57:32,752 epoch 37 - iter 90/107 - loss 0.05884112 - samples/sec: 114.27 - lr: 0.000391
2022-05-13 17:57:35,360 epoch 37 - iter 100/107 - loss 0.05883939 - samples/sec: 122.76 - lr: 0.000391
2022-05-13 17:57:37,027 ----------------------------------------------------------------------------------------------------
2022-05-13 17:57:37,027 EPOCH 37 done: loss 0.0596 - lr 0.000391
2022-05-13 17:57:45,909 Evaluating as a multi-label problem: False
2022-05-13 17:57:45,920 DEV : loss 0.2101203352212906 - f1-score (micro avg)  0.5051
2022-05-13 17:57:46,006 BAD EPOCHS (no improvement): 1
2022-05-13 17:57:46,008 ----------------------------------------------------------------------------------------------------
2022-05-13 17:57:48,620 epoch 38 - iter 10/107 - loss 0.05453478 - samples/sec: 122.59 - lr: 0.000391
2022-05-13 17:57:51,439 epoch 38 - iter 20/107 - loss 0.05287148 - samples/sec: 113.55 - lr: 0.000391
2022-05-13 17:57:54,220 epoch 38 - iter 30/107 - loss 0.05630827 - samples/sec: 115.12 - lr: 0.000391
2022-05-13 17:57:56,923 epoch 38 - iter 40/107 - loss 0.05667250 - samples/sec: 118.41 - lr: 0.000391
2022-05-13 17:57:59,595 epoch 38 - iter 50/107 - loss 0.05687641 - samples/sec: 119.79 - lr: 0.000391
2022-05-13 17:58:02,414 epoch 38 - iter 60/107 - loss 0.05728463 - samples/sec: 113.57 - lr: 0.000391
2022-05-13 17:58:05,083 epoch 38 - iter 70/107 - loss 0.06015251 - samples/sec: 119.90 - lr: 0.000391
2022-05-13 17:58:07,778 epoch 38 - iter 80/107 - loss 0.06035305 - samples/sec: 118.80 - lr: 0.000391
2022-05-13 17:58:10,483 epoch 38 - iter 90/107 - loss 0.06082025 - samples/sec: 118.32 - lr: 0.000391
2022-05-13 17:58:13,289 epoch 38 - iter 100/107 - loss 0.06049623 - samples/sec: 114.09 - lr: 0.000391
2022-05-13 17:58:14,855 ----------------------------------------------------------------------------------------------------
2022-05-13 17:58:14,855 EPOCH 38 done: loss 0.0605 - lr 0.000391
2022-05-13 17:58:23,765 Evaluating as a multi-label problem: False
2022-05-13 17:58:23,777 DEV : loss 0.20978617668151855 - f1-score (micro avg)  0.5051
2022-05-13 17:58:23,860 BAD EPOCHS (no improvement): 2
2022-05-13 17:58:23,862 ----------------------------------------------------------------------------------------------------
2022-05-13 17:58:26,548 epoch 39 - iter 10/107 - loss 0.06307711 - samples/sec: 119.21 - lr: 0.000391
2022-05-13 17:58:29,303 epoch 39 - iter 20/107 - loss 0.06255922 - samples/sec: 116.22 - lr: 0.000391
2022-05-13 17:58:32,127 epoch 39 - iter 30/107 - loss 0.06547439 - samples/sec: 113.32 - lr: 0.000391
2022-05-13 17:58:34,860 epoch 39 - iter 40/107 - loss 0.06285722 - samples/sec: 117.16 - lr: 0.000391
2022-05-13 17:58:37,610 epoch 39 - iter 50/107 - loss 0.06314194 - samples/sec: 116.36 - lr: 0.000391
2022-05-13 17:58:40,226 epoch 39 - iter 60/107 - loss 0.06219616 - samples/sec: 122.41 - lr: 0.000391
2022-05-13 17:58:42,967 epoch 39 - iter 70/107 - loss 0.06025936 - samples/sec: 116.76 - lr: 0.000391
2022-05-13 17:58:45,699 epoch 39 - iter 80/107 - loss 0.05973014 - samples/sec: 117.18 - lr: 0.000391
2022-05-13 17:58:48,416 epoch 39 - iter 90/107 - loss 0.05912215 - samples/sec: 117.79 - lr: 0.000391
2022-05-13 17:58:51,048 epoch 39 - iter 100/107 - loss 0.05996554 - samples/sec: 121.64 - lr: 0.000391
2022-05-13 17:58:52,735 ----------------------------------------------------------------------------------------------------
2022-05-13 17:58:52,735 EPOCH 39 done: loss 0.0597 - lr 0.000391
2022-05-13 17:59:01,618 Evaluating as a multi-label problem: False
2022-05-13 17:59:01,629 DEV : loss 0.2095058262348175 - f1-score (micro avg)  0.5044
2022-05-13 17:59:01,718 BAD EPOCHS (no improvement): 3
2022-05-13 17:59:01,720 ----------------------------------------------------------------------------------------------------
2022-05-13 17:59:04,470 epoch 40 - iter 10/107 - loss 0.06661699 - samples/sec: 116.44 - lr: 0.000391
2022-05-13 17:59:07,231 epoch 40 - iter 20/107 - loss 0.06413111 - samples/sec: 115.93 - lr: 0.000391
2022-05-13 17:59:09,914 epoch 40 - iter 30/107 - loss 0.05927741 - samples/sec: 119.31 - lr: 0.000391
2022-05-13 17:59:12,675 epoch 40 - iter 40/107 - loss 0.05960052 - samples/sec: 115.97 - lr: 0.000391
2022-05-13 17:59:15,328 epoch 40 - iter 50/107 - loss 0.06070728 - samples/sec: 120.66 - lr: 0.000391
2022-05-13 17:59:18,038 epoch 40 - iter 60/107 - loss 0.05912662 - samples/sec: 118.09 - lr: 0.000391
2022-05-13 17:59:20,631 epoch 40 - iter 70/107 - loss 0.05957048 - samples/sec: 123.45 - lr: 0.000391
2022-05-13 17:59:23,461 epoch 40 - iter 80/107 - loss 0.06056444 - samples/sec: 113.13 - lr: 0.000391
2022-05-13 17:59:26,317 epoch 40 - iter 90/107 - loss 0.06052377 - samples/sec: 112.06 - lr: 0.000391
2022-05-13 17:59:28,861 epoch 40 - iter 100/107 - loss 0.05970966 - samples/sec: 125.86 - lr: 0.000391
2022-05-13 17:59:30,530 ----------------------------------------------------------------------------------------------------
2022-05-13 17:59:30,530 EPOCH 40 done: loss 0.0604 - lr 0.000391
2022-05-13 17:59:39,398 Evaluating as a multi-label problem: False
2022-05-13 17:59:39,409 DEV : loss 0.20965498685836792 - f1-score (micro avg)  0.504
2022-05-13 17:59:39,493 Epoch    40: reducing learning rate of group 0 to 1.9531e-04.
2022-05-13 17:59:39,494 BAD EPOCHS (no improvement): 4
2022-05-13 17:59:39,496 ----------------------------------------------------------------------------------------------------
2022-05-13 17:59:42,230 epoch 41 - iter 10/107 - loss 0.05608172 - samples/sec: 117.09 - lr: 0.000195
2022-05-13 17:59:44,862 epoch 41 - iter 20/107 - loss 0.05902663 - samples/sec: 121.61 - lr: 0.000195
2022-05-13 17:59:47,617 epoch 41 - iter 30/107 - loss 0.06027226 - samples/sec: 116.20 - lr: 0.000195
2022-05-13 17:59:50,347 epoch 41 - iter 40/107 - loss 0.06095171 - samples/sec: 117.27 - lr: 0.000195
2022-05-13 17:59:53,023 epoch 41 - iter 50/107 - loss 0.06105691 - samples/sec: 119.64 - lr: 0.000195
2022-05-13 17:59:55,746 epoch 41 - iter 60/107 - loss 0.05963008 - samples/sec: 117.54 - lr: 0.000195
2022-05-13 17:59:58,520 epoch 41 - iter 70/107 - loss 0.05930705 - samples/sec: 115.40 - lr: 0.000195
2022-05-13 18:00:01,247 epoch 41 - iter 80/107 - loss 0.06004183 - samples/sec: 117.41 - lr: 0.000195
2022-05-13 18:00:03,962 epoch 41 - iter 90/107 - loss 0.06019342 - samples/sec: 117.88 - lr: 0.000195
2022-05-13 18:00:06,580 epoch 41 - iter 100/107 - loss 0.06015658 - samples/sec: 122.31 - lr: 0.000195
2022-05-13 18:00:08,284 ----------------------------------------------------------------------------------------------------
2022-05-13 18:00:08,284 EPOCH 41 done: loss 0.0595 - lr 0.000195
2022-05-13 18:00:17,179 Evaluating as a multi-label problem: False
2022-05-13 18:00:17,191 DEV : loss 0.2100156992673874 - f1-score (micro avg)  0.5044
2022-05-13 18:00:17,277 BAD EPOCHS (no improvement): 1
2022-05-13 18:00:17,279 ----------------------------------------------------------------------------------------------------
2022-05-13 18:00:20,034 epoch 42 - iter 10/107 - loss 0.06624816 - samples/sec: 116.19 - lr: 0.000195
2022-05-13 18:00:22,733 epoch 42 - iter 20/107 - loss 0.06587611 - samples/sec: 118.62 - lr: 0.000195
2022-05-13 18:00:25,554 epoch 42 - iter 30/107 - loss 0.06484078 - samples/sec: 113.45 - lr: 0.000195
2022-05-13 18:00:28,204 epoch 42 - iter 40/107 - loss 0.06135372 - samples/sec: 120.80 - lr: 0.000195
2022-05-13 18:00:30,818 epoch 42 - iter 50/107 - loss 0.06274791 - samples/sec: 122.49 - lr: 0.000195
2022-05-13 18:00:33,558 epoch 42 - iter 60/107 - loss 0.06091202 - samples/sec: 116.82 - lr: 0.000195
2022-05-13 18:00:36,241 epoch 42 - iter 70/107 - loss 0.06239894 - samples/sec: 119.31 - lr: 0.000195
2022-05-13 18:00:38,979 epoch 42 - iter 80/107 - loss 0.06340272 - samples/sec: 116.91 - lr: 0.000195
2022-05-13 18:00:41,578 epoch 42 - iter 90/107 - loss 0.06258694 - samples/sec: 123.16 - lr: 0.000195
2022-05-13 18:00:44,119 epoch 42 - iter 100/107 - loss 0.06098579 - samples/sec: 126.02 - lr: 0.000195
2022-05-13 18:00:45,660 ----------------------------------------------------------------------------------------------------
2022-05-13 18:00:45,660 EPOCH 42 done: loss 0.0604 - lr 0.000195
2022-05-13 18:00:54,210 Evaluating as a multi-label problem: False
2022-05-13 18:00:54,221 DEV : loss 0.21014541387557983 - f1-score (micro avg)  0.504
2022-05-13 18:00:54,306 BAD EPOCHS (no improvement): 2
2022-05-13 18:00:54,310 ----------------------------------------------------------------------------------------------------
2022-05-13 18:00:57,065 epoch 43 - iter 10/107 - loss 0.05973821 - samples/sec: 116.18 - lr: 0.000195
2022-05-13 18:00:59,918 epoch 43 - iter 20/107 - loss 0.05439328 - samples/sec: 112.20 - lr: 0.000195
2022-05-13 18:01:02,620 epoch 43 - iter 30/107 - loss 0.05180572 - samples/sec: 118.46 - lr: 0.000195
2022-05-13 18:01:05,308 epoch 43 - iter 40/107 - loss 0.05882097 - samples/sec: 119.12 - lr: 0.000195
2022-05-13 18:01:07,963 epoch 43 - iter 50/107 - loss 0.05929004 - samples/sec: 120.55 - lr: 0.000195
2022-05-13 18:01:10,689 epoch 43 - iter 60/107 - loss 0.05915858 - samples/sec: 117.45 - lr: 0.000195
2022-05-13 18:01:13,362 epoch 43 - iter 70/107 - loss 0.05889765 - samples/sec: 119.74 - lr: 0.000195
2022-05-13 18:01:16,086 epoch 43 - iter 80/107 - loss 0.05860521 - samples/sec: 117.51 - lr: 0.000195
2022-05-13 18:01:18,913 epoch 43 - iter 90/107 - loss 0.05912794 - samples/sec: 113.21 - lr: 0.000195
2022-05-13 18:01:21,620 epoch 43 - iter 100/107 - loss 0.05959150 - samples/sec: 118.29 - lr: 0.000195
2022-05-13 18:01:23,326 ----------------------------------------------------------------------------------------------------
2022-05-13 18:01:23,326 EPOCH 43 done: loss 0.0605 - lr 0.000195
2022-05-13 18:01:36,228 Evaluating as a multi-label problem: False
2022-05-13 18:01:36,239 DEV : loss 0.2102155238389969 - f1-score (micro avg)  0.5055
2022-05-13 18:01:36,322 BAD EPOCHS (no improvement): 3
2022-05-13 18:01:36,328 ----------------------------------------------------------------------------------------------------
2022-05-13 18:01:39,045 epoch 44 - iter 10/107 - loss 0.06169183 - samples/sec: 117.83 - lr: 0.000195
2022-05-13 18:01:41,711 epoch 44 - iter 20/107 - loss 0.06524120 - samples/sec: 120.07 - lr: 0.000195
2022-05-13 18:01:44,397 epoch 44 - iter 30/107 - loss 0.05977317 - samples/sec: 119.17 - lr: 0.000195
2022-05-13 18:01:47,177 epoch 44 - iter 40/107 - loss 0.05686135 - samples/sec: 115.15 - lr: 0.000195
2022-05-13 18:01:49,829 epoch 44 - iter 50/107 - loss 0.06003674 - samples/sec: 120.68 - lr: 0.000195
2022-05-13 18:01:52,484 epoch 44 - iter 60/107 - loss 0.06066938 - samples/sec: 120.59 - lr: 0.000195
2022-05-13 18:01:55,188 epoch 44 - iter 70/107 - loss 0.06022206 - samples/sec: 118.39 - lr: 0.000195
2022-05-13 18:01:57,963 epoch 44 - iter 80/107 - loss 0.06074523 - samples/sec: 115.34 - lr: 0.000195
2022-05-13 18:02:00,652 epoch 44 - iter 90/107 - loss 0.06009429 - samples/sec: 119.05 - lr: 0.000195
2022-05-13 18:02:03,331 epoch 44 - iter 100/107 - loss 0.05891955 - samples/sec: 119.47 - lr: 0.000195
2022-05-13 18:02:04,964 ----------------------------------------------------------------------------------------------------
2022-05-13 18:02:04,964 EPOCH 44 done: loss 0.0605 - lr 0.000195
2022-05-13 18:02:13,855 Evaluating as a multi-label problem: False
2022-05-13 18:02:13,866 DEV : loss 0.21015730500221252 - f1-score (micro avg)  0.5051
2022-05-13 18:02:13,951 Epoch    44: reducing learning rate of group 0 to 9.7656e-05.
2022-05-13 18:02:13,951 BAD EPOCHS (no improvement): 4
2022-05-13 18:02:13,954 ----------------------------------------------------------------------------------------------------
2022-05-13 18:02:13,955 ----------------------------------------------------------------------------------------------------
2022-05-13 18:02:13,955 learning rate too small - quitting training!
2022-05-13 18:02:13,955 ----------------------------------------------------------------------------------------------------
2022-05-13 18:02:48,402 ----------------------------------------------------------------------------------------------------
2022-05-13 18:02:48,403 loading file resources/taggers/model_03_r10_run_6/best-model.pt
2022-05-13 18:03:15,528 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-05-13 18:03:37,454 Evaluating as a multi-label problem: False
2022-05-13 18:03:37,467 0.6744	0.2956	0.4111	0.2708
2022-05-13 18:03:37,467 
Results:
- F-score (micro) 0.4111
- F-score (macro) 0.2967
- Accuracy 0.2708

By class:
               precision    recall  f1-score   support

       person     0.7760    0.4522    0.5714       429
     location     0.6410    0.5000    0.5618       150
        group     0.5500    0.1333    0.2146       165
creative-work     0.6842    0.0915    0.1615       142
      product     0.3043    0.0551    0.0933       127
  corporation     0.3333    0.1212    0.1778        66

    micro avg     0.6744    0.2956    0.4111      1079
    macro avg     0.5482    0.2256    0.2967      1079
 weighted avg     0.6280    0.2956    0.3812      1079

2022-05-13 18:03:37,467 ----------------------------------------------------------------------------------------------------
