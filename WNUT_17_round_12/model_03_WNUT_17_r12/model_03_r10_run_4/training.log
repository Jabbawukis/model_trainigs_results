2022-05-13 16:20:06,280 ----------------------------------------------------------------------------------------------------
2022-05-13 16:20:06,280 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4922, out_features=4922, bias=True)
  (rnn): LSTM(4922, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-05-13 16:20:06,280 ----------------------------------------------------------------------------------------------------
2022-05-13 16:20:06,280 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-05-13 16:20:06,280 ----------------------------------------------------------------------------------------------------
2022-05-13 16:20:06,280 Parameters:
2022-05-13 16:20:06,280  - learning_rate: "0.100000"
2022-05-13 16:20:06,280  - mini_batch_size: "32"
2022-05-13 16:20:06,280  - patience: "3"
2022-05-13 16:20:06,280  - anneal_factor: "0.5"
2022-05-13 16:20:06,280  - max_epochs: "150"
2022-05-13 16:20:06,281  - shuffle: "True"
2022-05-13 16:20:06,281  - train_with_dev: "False"
2022-05-13 16:20:06,281  - batch_growth_annealing: "False"
2022-05-13 16:20:06,281 ----------------------------------------------------------------------------------------------------
2022-05-13 16:20:06,281 Model training base path: "resources/taggers/model_03_r10_run_4"
2022-05-13 16:20:06,281 ----------------------------------------------------------------------------------------------------
2022-05-13 16:20:06,281 Device: cuda:0
2022-05-13 16:20:06,281 ----------------------------------------------------------------------------------------------------
2022-05-13 16:20:06,281 Embeddings storage mode: cpu
2022-05-13 16:20:06,281 ----------------------------------------------------------------------------------------------------
2022-05-13 16:20:10,010 epoch 1 - iter 10/107 - loss 0.64277676 - samples/sec: 85.83 - lr: 0.100000
2022-05-13 16:20:13,393 epoch 1 - iter 20/107 - loss 0.46605423 - samples/sec: 94.62 - lr: 0.100000
2022-05-13 16:20:16,624 epoch 1 - iter 30/107 - loss 0.40683237 - samples/sec: 99.07 - lr: 0.100000
2022-05-13 16:20:20,006 epoch 1 - iter 40/107 - loss 0.36807482 - samples/sec: 94.65 - lr: 0.100000
2022-05-13 16:20:23,816 epoch 1 - iter 50/107 - loss 0.33852777 - samples/sec: 84.02 - lr: 0.100000
2022-05-13 16:20:27,678 epoch 1 - iter 60/107 - loss 0.32870376 - samples/sec: 82.87 - lr: 0.100000
2022-05-13 16:20:31,428 epoch 1 - iter 70/107 - loss 0.32131586 - samples/sec: 85.36 - lr: 0.100000
2022-05-13 16:20:34,892 epoch 1 - iter 80/107 - loss 0.31791412 - samples/sec: 92.41 - lr: 0.100000
2022-05-13 16:20:38,007 epoch 1 - iter 90/107 - loss 0.31487250 - samples/sec: 102.76 - lr: 0.100000
2022-05-13 16:20:41,219 epoch 1 - iter 100/107 - loss 0.31132178 - samples/sec: 99.67 - lr: 0.100000
2022-05-13 16:20:42,969 ----------------------------------------------------------------------------------------------------
2022-05-13 16:20:42,969 EPOCH 1 done: loss 0.3061 - lr 0.100000
2022-05-13 16:20:52,619 Evaluating as a multi-label problem: False
2022-05-13 16:20:52,631 DEV : loss 0.3708661198616028 - f1-score (micro avg)  0.2254
2022-05-13 16:20:52,705 BAD EPOCHS (no improvement): 0
2022-05-13 16:20:52,707 saving best model
2022-05-13 16:21:27,973 ----------------------------------------------------------------------------------------------------
2022-05-13 16:21:31,130 epoch 2 - iter 10/107 - loss 0.20061772 - samples/sec: 101.41 - lr: 0.100000
2022-05-13 16:21:34,298 epoch 2 - iter 20/107 - loss 0.18524755 - samples/sec: 101.05 - lr: 0.100000
2022-05-13 16:21:37,134 epoch 2 - iter 30/107 - loss 0.20743865 - samples/sec: 112.86 - lr: 0.100000
2022-05-13 16:21:40,159 epoch 2 - iter 40/107 - loss 0.21337429 - samples/sec: 105.84 - lr: 0.100000
2022-05-13 16:21:43,837 epoch 2 - iter 50/107 - loss 0.20322623 - samples/sec: 87.03 - lr: 0.100000
2022-05-13 16:21:47,490 epoch 2 - iter 60/107 - loss 0.19686323 - samples/sec: 87.63 - lr: 0.100000
2022-05-13 16:21:50,882 epoch 2 - iter 70/107 - loss 0.19682220 - samples/sec: 94.36 - lr: 0.100000
2022-05-13 16:21:54,425 epoch 2 - iter 80/107 - loss 0.19377337 - samples/sec: 90.33 - lr: 0.100000
2022-05-13 16:22:01,859 epoch 2 - iter 90/107 - loss 0.19043275 - samples/sec: 43.05 - lr: 0.100000
2022-05-13 16:22:05,009 epoch 2 - iter 100/107 - loss 0.18801444 - samples/sec: 101.63 - lr: 0.100000
2022-05-13 16:22:06,930 ----------------------------------------------------------------------------------------------------
2022-05-13 16:22:06,930 EPOCH 2 done: loss 0.1857 - lr 0.100000
2022-05-13 16:22:17,632 Evaluating as a multi-label problem: False
2022-05-13 16:22:17,644 DEV : loss 0.33298617601394653 - f1-score (micro avg)  0.3618
2022-05-13 16:22:17,718 BAD EPOCHS (no improvement): 0
2022-05-13 16:22:17,720 saving best model
2022-05-13 16:22:51,390 ----------------------------------------------------------------------------------------------------
2022-05-13 16:22:54,786 epoch 3 - iter 10/107 - loss 0.16052119 - samples/sec: 94.28 - lr: 0.100000
2022-05-13 16:22:58,578 epoch 3 - iter 20/107 - loss 0.14812002 - samples/sec: 84.41 - lr: 0.100000
2022-05-13 16:23:02,390 epoch 3 - iter 30/107 - loss 0.15685859 - samples/sec: 83.98 - lr: 0.100000
2022-05-13 16:23:05,949 epoch 3 - iter 40/107 - loss 0.15938113 - samples/sec: 89.93 - lr: 0.100000
2022-05-13 16:23:09,520 epoch 3 - iter 50/107 - loss 0.15781468 - samples/sec: 89.66 - lr: 0.100000
2022-05-13 16:23:13,083 epoch 3 - iter 60/107 - loss 0.15952793 - samples/sec: 89.84 - lr: 0.100000
2022-05-13 16:23:16,785 epoch 3 - iter 70/107 - loss 0.15855261 - samples/sec: 86.44 - lr: 0.100000
2022-05-13 16:23:20,192 epoch 3 - iter 80/107 - loss 0.15877001 - samples/sec: 93.97 - lr: 0.100000
2022-05-13 16:23:23,241 epoch 3 - iter 90/107 - loss 0.16005969 - samples/sec: 104.98 - lr: 0.100000
2022-05-13 16:23:26,445 epoch 3 - iter 100/107 - loss 0.15886628 - samples/sec: 99.92 - lr: 0.100000
2022-05-13 16:23:28,598 ----------------------------------------------------------------------------------------------------
2022-05-13 16:23:28,598 EPOCH 3 done: loss 0.1577 - lr 0.100000
2022-05-13 16:23:39,556 Evaluating as a multi-label problem: False
2022-05-13 16:23:39,567 DEV : loss 0.2409573793411255 - f1-score (micro avg)  0.4623
2022-05-13 16:23:39,641 BAD EPOCHS (no improvement): 0
2022-05-13 16:23:39,643 saving best model
2022-05-13 16:24:13,543 ----------------------------------------------------------------------------------------------------
2022-05-13 16:24:17,344 epoch 4 - iter 10/107 - loss 0.15890128 - samples/sec: 84.23 - lr: 0.100000
2022-05-13 16:24:20,937 epoch 4 - iter 20/107 - loss 0.14771355 - samples/sec: 89.09 - lr: 0.100000
2022-05-13 16:24:24,437 epoch 4 - iter 30/107 - loss 0.14626364 - samples/sec: 91.45 - lr: 0.100000
2022-05-13 16:24:28,142 epoch 4 - iter 40/107 - loss 0.14302701 - samples/sec: 86.39 - lr: 0.100000
2022-05-13 16:24:31,831 epoch 4 - iter 50/107 - loss 0.14568741 - samples/sec: 86.77 - lr: 0.100000
2022-05-13 16:24:35,505 epoch 4 - iter 60/107 - loss 0.14143583 - samples/sec: 87.12 - lr: 0.100000
2022-05-13 16:24:39,198 epoch 4 - iter 70/107 - loss 0.14165946 - samples/sec: 86.69 - lr: 0.100000
2022-05-13 16:24:42,290 epoch 4 - iter 80/107 - loss 0.14171240 - samples/sec: 103.52 - lr: 0.100000
2022-05-13 16:24:45,189 epoch 4 - iter 90/107 - loss 0.14033575 - samples/sec: 110.43 - lr: 0.100000
2022-05-13 16:24:48,835 epoch 4 - iter 100/107 - loss 0.14130423 - samples/sec: 87.80 - lr: 0.100000
2022-05-13 16:24:50,845 ----------------------------------------------------------------------------------------------------
2022-05-13 16:24:50,845 EPOCH 4 done: loss 0.1410 - lr 0.100000
2022-05-13 16:25:01,758 Evaluating as a multi-label problem: False
2022-05-13 16:25:01,769 DEV : loss 0.26243525743484497 - f1-score (micro avg)  0.4524
2022-05-13 16:25:01,846 BAD EPOCHS (no improvement): 1
2022-05-13 16:25:01,848 ----------------------------------------------------------------------------------------------------
2022-05-13 16:25:05,348 epoch 5 - iter 10/107 - loss 0.14411074 - samples/sec: 91.47 - lr: 0.100000
2022-05-13 16:25:08,662 epoch 5 - iter 20/107 - loss 0.13766783 - samples/sec: 96.57 - lr: 0.100000
2022-05-13 16:25:11,777 epoch 5 - iter 30/107 - loss 0.14035366 - samples/sec: 102.78 - lr: 0.100000
2022-05-13 16:25:14,921 epoch 5 - iter 40/107 - loss 0.14635193 - samples/sec: 101.79 - lr: 0.100000
2022-05-13 16:25:18,439 epoch 5 - iter 50/107 - loss 0.13759514 - samples/sec: 90.98 - lr: 0.100000
2022-05-13 16:25:22,347 epoch 5 - iter 60/107 - loss 0.13717405 - samples/sec: 81.91 - lr: 0.100000
2022-05-13 16:25:25,887 epoch 5 - iter 70/107 - loss 0.13328841 - samples/sec: 90.44 - lr: 0.100000
2022-05-13 16:25:29,390 epoch 5 - iter 80/107 - loss 0.13235662 - samples/sec: 91.37 - lr: 0.100000
2022-05-13 16:25:32,990 epoch 5 - iter 90/107 - loss 0.12849351 - samples/sec: 88.93 - lr: 0.100000
2022-05-13 16:25:36,583 epoch 5 - iter 100/107 - loss 0.12841749 - samples/sec: 89.07 - lr: 0.100000
2022-05-13 16:25:38,753 ----------------------------------------------------------------------------------------------------
2022-05-13 16:25:38,753 EPOCH 5 done: loss 0.1281 - lr 0.100000
2022-05-13 16:25:48,222 Evaluating as a multi-label problem: False
2022-05-13 16:25:48,233 DEV : loss 0.21957950294017792 - f1-score (micro avg)  0.5112
2022-05-13 16:25:48,310 BAD EPOCHS (no improvement): 0
2022-05-13 16:25:48,311 saving best model
2022-05-13 16:26:22,316 ----------------------------------------------------------------------------------------------------
2022-05-13 16:26:25,964 epoch 6 - iter 10/107 - loss 0.11638414 - samples/sec: 87.76 - lr: 0.100000
2022-05-13 16:26:29,035 epoch 6 - iter 20/107 - loss 0.11215899 - samples/sec: 104.25 - lr: 0.100000
2022-05-13 16:26:32,142 epoch 6 - iter 30/107 - loss 0.11355745 - samples/sec: 103.02 - lr: 0.100000
2022-05-13 16:26:35,826 epoch 6 - iter 40/107 - loss 0.11226019 - samples/sec: 86.89 - lr: 0.100000
2022-05-13 16:26:39,510 epoch 6 - iter 50/107 - loss 0.11556630 - samples/sec: 86.88 - lr: 0.100000
2022-05-13 16:26:43,300 epoch 6 - iter 60/107 - loss 0.11760086 - samples/sec: 84.46 - lr: 0.100000
2022-05-13 16:26:46,825 epoch 6 - iter 70/107 - loss 0.11521382 - samples/sec: 90.80 - lr: 0.100000
2022-05-13 16:26:50,161 epoch 6 - iter 80/107 - loss 0.11522627 - samples/sec: 95.95 - lr: 0.100000
2022-05-13 16:26:53,739 epoch 6 - iter 90/107 - loss 0.11604969 - samples/sec: 89.46 - lr: 0.100000
2022-05-13 16:26:57,286 epoch 6 - iter 100/107 - loss 0.11599701 - samples/sec: 90.25 - lr: 0.100000
2022-05-13 16:26:59,004 ----------------------------------------------------------------------------------------------------
2022-05-13 16:26:59,004 EPOCH 6 done: loss 0.1148 - lr 0.100000
2022-05-13 16:27:08,808 Evaluating as a multi-label problem: False
2022-05-13 16:27:08,819 DEV : loss 0.23968657851219177 - f1-score (micro avg)  0.4431
2022-05-13 16:27:08,891 BAD EPOCHS (no improvement): 1
2022-05-13 16:27:08,897 ----------------------------------------------------------------------------------------------------
2022-05-13 16:27:12,463 epoch 7 - iter 10/107 - loss 0.09599118 - samples/sec: 89.76 - lr: 0.100000
2022-05-13 16:27:16,149 epoch 7 - iter 20/107 - loss 0.09147103 - samples/sec: 86.84 - lr: 0.100000
2022-05-13 16:27:19,849 epoch 7 - iter 30/107 - loss 0.09640414 - samples/sec: 86.50 - lr: 0.100000
2022-05-13 16:27:23,319 epoch 7 - iter 40/107 - loss 0.09639258 - samples/sec: 92.24 - lr: 0.100000
2022-05-13 16:27:27,089 epoch 7 - iter 50/107 - loss 0.10016889 - samples/sec: 84.92 - lr: 0.100000
2022-05-13 16:27:30,242 epoch 7 - iter 60/107 - loss 0.10098730 - samples/sec: 101.52 - lr: 0.100000
2022-05-13 16:27:33,342 epoch 7 - iter 70/107 - loss 0.10260245 - samples/sec: 103.26 - lr: 0.100000
2022-05-13 16:27:36,738 epoch 7 - iter 80/107 - loss 0.10383645 - samples/sec: 94.24 - lr: 0.100000
2022-05-13 16:27:40,381 epoch 7 - iter 90/107 - loss 0.10658005 - samples/sec: 87.86 - lr: 0.100000
2022-05-13 16:27:43,973 epoch 7 - iter 100/107 - loss 0.10608815 - samples/sec: 89.12 - lr: 0.100000
2022-05-13 16:27:46,137 ----------------------------------------------------------------------------------------------------
2022-05-13 16:27:46,137 EPOCH 7 done: loss 0.1062 - lr 0.100000
2022-05-13 16:27:57,114 Evaluating as a multi-label problem: False
2022-05-13 16:27:57,125 DEV : loss 0.23186153173446655 - f1-score (micro avg)  0.4601
2022-05-13 16:27:57,199 BAD EPOCHS (no improvement): 2
2022-05-13 16:27:57,201 ----------------------------------------------------------------------------------------------------
2022-05-13 16:28:00,375 epoch 8 - iter 10/107 - loss 0.08422395 - samples/sec: 100.87 - lr: 0.100000
2022-05-13 16:28:03,361 epoch 8 - iter 20/107 - loss 0.09449814 - samples/sec: 107.19 - lr: 0.100000
2022-05-13 16:28:06,617 epoch 8 - iter 30/107 - loss 0.09884318 - samples/sec: 98.31 - lr: 0.100000
2022-05-13 16:28:10,559 epoch 8 - iter 40/107 - loss 0.09610404 - samples/sec: 81.19 - lr: 0.100000
2022-05-13 16:28:14,151 epoch 8 - iter 50/107 - loss 0.09957187 - samples/sec: 89.12 - lr: 0.100000
2022-05-13 16:28:17,798 epoch 8 - iter 60/107 - loss 0.10163068 - samples/sec: 87.77 - lr: 0.100000
2022-05-13 16:28:21,312 epoch 8 - iter 70/107 - loss 0.10042413 - samples/sec: 91.09 - lr: 0.100000
2022-05-13 16:28:25,011 epoch 8 - iter 80/107 - loss 0.10083163 - samples/sec: 86.53 - lr: 0.100000
2022-05-13 16:28:28,685 epoch 8 - iter 90/107 - loss 0.09911391 - samples/sec: 87.13 - lr: 0.100000
2022-05-13 16:28:31,095 epoch 8 - iter 100/107 - loss 0.10160329 - samples/sec: 132.85 - lr: 0.100000
2022-05-13 16:28:33,002 ----------------------------------------------------------------------------------------------------
2022-05-13 16:28:33,002 EPOCH 8 done: loss 0.1003 - lr 0.100000
2022-05-13 16:28:43,451 Evaluating as a multi-label problem: False
2022-05-13 16:28:43,463 DEV : loss 0.22115549445152283 - f1-score (micro avg)  0.4903
2022-05-13 16:28:43,535 BAD EPOCHS (no improvement): 3
2022-05-13 16:28:43,537 ----------------------------------------------------------------------------------------------------
2022-05-13 16:28:47,078 epoch 9 - iter 10/107 - loss 0.09001034 - samples/sec: 90.39 - lr: 0.100000
2022-05-13 16:28:50,830 epoch 9 - iter 20/107 - loss 0.09101256 - samples/sec: 85.32 - lr: 0.100000
2022-05-13 16:28:54,429 epoch 9 - iter 30/107 - loss 0.09773455 - samples/sec: 88.92 - lr: 0.100000
2022-05-13 16:28:58,268 epoch 9 - iter 40/107 - loss 0.09259394 - samples/sec: 83.39 - lr: 0.100000
2022-05-13 16:29:01,984 epoch 9 - iter 50/107 - loss 0.09056168 - samples/sec: 86.14 - lr: 0.100000
2022-05-13 16:29:04,938 epoch 9 - iter 60/107 - loss 0.09365735 - samples/sec: 108.35 - lr: 0.100000
2022-05-13 16:29:08,036 epoch 9 - iter 70/107 - loss 0.09449916 - samples/sec: 103.34 - lr: 0.100000
2022-05-13 16:29:10,382 epoch 9 - iter 80/107 - loss 0.09188909 - samples/sec: 136.43 - lr: 0.100000
2022-05-13 16:29:12,746 epoch 9 - iter 90/107 - loss 0.09372962 - samples/sec: 135.44 - lr: 0.100000
2022-05-13 16:29:15,258 epoch 9 - iter 100/107 - loss 0.09347071 - samples/sec: 127.42 - lr: 0.100000
2022-05-13 16:29:16,756 ----------------------------------------------------------------------------------------------------
2022-05-13 16:29:16,756 EPOCH 9 done: loss 0.0943 - lr 0.100000
2022-05-13 16:29:24,543 Evaluating as a multi-label problem: False
2022-05-13 16:29:24,554 DEV : loss 0.2142149657011032 - f1-score (micro avg)  0.4859
2022-05-13 16:29:24,627 Epoch     9: reducing learning rate of group 0 to 5.0000e-02.
2022-05-13 16:29:24,627 BAD EPOCHS (no improvement): 4
2022-05-13 16:29:24,629 ----------------------------------------------------------------------------------------------------
2022-05-13 16:29:27,099 epoch 10 - iter 10/107 - loss 0.07208045 - samples/sec: 129.59 - lr: 0.050000
2022-05-13 16:29:29,546 epoch 10 - iter 20/107 - loss 0.06901717 - samples/sec: 130.86 - lr: 0.050000
2022-05-13 16:29:31,914 epoch 10 - iter 30/107 - loss 0.07613745 - samples/sec: 135.15 - lr: 0.050000
2022-05-13 16:29:34,470 epoch 10 - iter 40/107 - loss 0.07998103 - samples/sec: 125.27 - lr: 0.050000
2022-05-13 16:29:36,890 epoch 10 - iter 50/107 - loss 0.08390301 - samples/sec: 132.25 - lr: 0.050000
2022-05-13 16:29:39,437 epoch 10 - iter 60/107 - loss 0.08489150 - samples/sec: 125.71 - lr: 0.050000
2022-05-13 16:29:41,879 epoch 10 - iter 70/107 - loss 0.08623666 - samples/sec: 131.08 - lr: 0.050000
2022-05-13 16:29:44,369 epoch 10 - iter 80/107 - loss 0.08787308 - samples/sec: 128.54 - lr: 0.050000
2022-05-13 16:29:49,966 epoch 10 - iter 90/107 - loss 0.08692620 - samples/sec: 57.19 - lr: 0.050000
2022-05-13 16:29:55,439 epoch 10 - iter 100/107 - loss 0.08468463 - samples/sec: 58.47 - lr: 0.050000
2022-05-13 16:29:58,414 ----------------------------------------------------------------------------------------------------
2022-05-13 16:29:58,414 EPOCH 10 done: loss 0.0829 - lr 0.050000
2022-05-13 16:30:10,670 Evaluating as a multi-label problem: False
2022-05-13 16:30:10,681 DEV : loss 0.21727333962917328 - f1-score (micro avg)  0.4968
2022-05-13 16:30:10,755 BAD EPOCHS (no improvement): 1
2022-05-13 16:30:10,757 ----------------------------------------------------------------------------------------------------
2022-05-13 16:30:14,200 epoch 11 - iter 10/107 - loss 0.07804373 - samples/sec: 92.99 - lr: 0.050000
2022-05-13 16:30:17,869 epoch 11 - iter 20/107 - loss 0.08448368 - samples/sec: 87.23 - lr: 0.050000
2022-05-13 16:30:21,501 epoch 11 - iter 30/107 - loss 0.08133224 - samples/sec: 88.12 - lr: 0.050000
2022-05-13 16:30:25,086 epoch 11 - iter 40/107 - loss 0.08361536 - samples/sec: 89.29 - lr: 0.050000
2022-05-13 16:30:28,387 epoch 11 - iter 50/107 - loss 0.07905876 - samples/sec: 96.98 - lr: 0.050000
2022-05-13 16:30:31,344 epoch 11 - iter 60/107 - loss 0.07823894 - samples/sec: 108.24 - lr: 0.050000
2022-05-13 16:30:34,194 epoch 11 - iter 70/107 - loss 0.07669386 - samples/sec: 112.32 - lr: 0.050000
2022-05-13 16:30:36,479 epoch 11 - iter 80/107 - loss 0.07665979 - samples/sec: 140.14 - lr: 0.050000
2022-05-13 16:30:38,783 epoch 11 - iter 90/107 - loss 0.07830878 - samples/sec: 138.89 - lr: 0.050000
2022-05-13 16:30:41,311 epoch 11 - iter 100/107 - loss 0.07939231 - samples/sec: 126.65 - lr: 0.050000
2022-05-13 16:30:42,886 ----------------------------------------------------------------------------------------------------
2022-05-13 16:30:42,887 EPOCH 11 done: loss 0.0800 - lr 0.050000
2022-05-13 16:30:50,580 Evaluating as a multi-label problem: False
2022-05-13 16:30:50,591 DEV : loss 0.20493842661380768 - f1-score (micro avg)  0.5044
2022-05-13 16:30:50,666 BAD EPOCHS (no improvement): 2
2022-05-13 16:30:50,669 ----------------------------------------------------------------------------------------------------
2022-05-13 16:30:53,163 epoch 12 - iter 10/107 - loss 0.07219661 - samples/sec: 128.38 - lr: 0.050000
2022-05-13 16:30:55,880 epoch 12 - iter 20/107 - loss 0.07148829 - samples/sec: 117.79 - lr: 0.050000
2022-05-13 16:30:59,318 epoch 12 - iter 30/107 - loss 0.07709993 - samples/sec: 93.13 - lr: 0.050000
2022-05-13 16:31:03,022 epoch 12 - iter 40/107 - loss 0.07472536 - samples/sec: 86.42 - lr: 0.050000
2022-05-13 16:31:06,803 epoch 12 - iter 50/107 - loss 0.07951386 - samples/sec: 84.65 - lr: 0.050000
2022-05-13 16:31:10,471 epoch 12 - iter 60/107 - loss 0.07746691 - samples/sec: 87.26 - lr: 0.050000
2022-05-13 16:31:14,269 epoch 12 - iter 70/107 - loss 0.07725248 - samples/sec: 84.27 - lr: 0.050000
2022-05-13 16:31:17,971 epoch 12 - iter 80/107 - loss 0.07846893 - samples/sec: 86.46 - lr: 0.050000
2022-05-13 16:31:21,135 epoch 12 - iter 90/107 - loss 0.07740052 - samples/sec: 101.17 - lr: 0.050000
2022-05-13 16:31:24,371 epoch 12 - iter 100/107 - loss 0.07631900 - samples/sec: 98.89 - lr: 0.050000
2022-05-13 16:31:26,227 ----------------------------------------------------------------------------------------------------
2022-05-13 16:31:26,228 EPOCH 12 done: loss 0.0766 - lr 0.050000
2022-05-13 16:31:33,807 Evaluating as a multi-label problem: False
2022-05-13 16:31:33,818 DEV : loss 0.21190020442008972 - f1-score (micro avg)  0.4848
2022-05-13 16:31:33,892 BAD EPOCHS (no improvement): 3
2022-05-13 16:31:33,893 ----------------------------------------------------------------------------------------------------
2022-05-13 16:31:36,403 epoch 13 - iter 10/107 - loss 0.08238100 - samples/sec: 127.61 - lr: 0.050000
2022-05-13 16:31:38,893 epoch 13 - iter 20/107 - loss 0.07164207 - samples/sec: 128.56 - lr: 0.050000
2022-05-13 16:31:41,406 epoch 13 - iter 30/107 - loss 0.07319851 - samples/sec: 127.37 - lr: 0.050000
2022-05-13 16:31:43,914 epoch 13 - iter 40/107 - loss 0.07464395 - samples/sec: 127.64 - lr: 0.050000
2022-05-13 16:31:46,338 epoch 13 - iter 50/107 - loss 0.07162844 - samples/sec: 132.11 - lr: 0.050000
2022-05-13 16:31:49,325 epoch 13 - iter 60/107 - loss 0.07171754 - samples/sec: 107.16 - lr: 0.050000
2022-05-13 16:31:52,911 epoch 13 - iter 70/107 - loss 0.07299795 - samples/sec: 89.25 - lr: 0.050000
2022-05-13 16:31:56,733 epoch 13 - iter 80/107 - loss 0.07227307 - samples/sec: 83.76 - lr: 0.050000
2022-05-13 16:32:00,128 epoch 13 - iter 90/107 - loss 0.07129153 - samples/sec: 94.26 - lr: 0.050000
2022-05-13 16:32:03,763 epoch 13 - iter 100/107 - loss 0.07189814 - samples/sec: 88.06 - lr: 0.050000
2022-05-13 16:32:05,956 ----------------------------------------------------------------------------------------------------
2022-05-13 16:32:05,957 EPOCH 13 done: loss 0.0717 - lr 0.050000
2022-05-13 16:32:16,423 Evaluating as a multi-label problem: False
2022-05-13 16:32:16,433 DEV : loss 0.2418949455022812 - f1-score (micro avg)  0.4611
2022-05-13 16:32:16,506 Epoch    13: reducing learning rate of group 0 to 2.5000e-02.
2022-05-13 16:32:16,506 BAD EPOCHS (no improvement): 4
2022-05-13 16:32:16,508 ----------------------------------------------------------------------------------------------------
2022-05-13 16:32:19,330 epoch 14 - iter 10/107 - loss 0.05600035 - samples/sec: 113.44 - lr: 0.025000
2022-05-13 16:32:23,006 epoch 14 - iter 20/107 - loss 0.05733881 - samples/sec: 87.07 - lr: 0.025000
2022-05-13 16:32:26,497 epoch 14 - iter 30/107 - loss 0.06196529 - samples/sec: 91.71 - lr: 0.025000
2022-05-13 16:32:30,142 epoch 14 - iter 40/107 - loss 0.06117627 - samples/sec: 87.81 - lr: 0.025000
2022-05-13 16:32:33,881 epoch 14 - iter 50/107 - loss 0.06341217 - samples/sec: 85.61 - lr: 0.025000
2022-05-13 16:32:37,432 epoch 14 - iter 60/107 - loss 0.06517824 - samples/sec: 90.13 - lr: 0.025000
2022-05-13 16:32:41,088 epoch 14 - iter 70/107 - loss 0.06548826 - samples/sec: 87.55 - lr: 0.025000
2022-05-13 16:32:44,480 epoch 14 - iter 80/107 - loss 0.06487786 - samples/sec: 94.36 - lr: 0.025000
2022-05-13 16:32:47,477 epoch 14 - iter 90/107 - loss 0.06399432 - samples/sec: 106.81 - lr: 0.025000
2022-05-13 16:32:50,445 epoch 14 - iter 100/107 - loss 0.06494155 - samples/sec: 107.87 - lr: 0.025000
2022-05-13 16:32:51,814 ----------------------------------------------------------------------------------------------------
2022-05-13 16:32:51,814 EPOCH 14 done: loss 0.0650 - lr 0.025000
2022-05-13 16:32:59,386 Evaluating as a multi-label problem: False
2022-05-13 16:32:59,397 DEV : loss 0.21156367659568787 - f1-score (micro avg)  0.4887
2022-05-13 16:32:59,470 BAD EPOCHS (no improvement): 1
2022-05-13 16:32:59,497 ----------------------------------------------------------------------------------------------------
2022-05-13 16:33:01,914 epoch 15 - iter 10/107 - loss 0.06440903 - samples/sec: 132.44 - lr: 0.025000
2022-05-13 16:33:04,374 epoch 15 - iter 20/107 - loss 0.06544804 - samples/sec: 130.11 - lr: 0.025000
2022-05-13 16:33:06,757 epoch 15 - iter 30/107 - loss 0.06199312 - samples/sec: 134.35 - lr: 0.025000
2022-05-13 16:33:09,310 epoch 15 - iter 40/107 - loss 0.05968619 - samples/sec: 125.41 - lr: 0.025000
2022-05-13 16:33:12,161 epoch 15 - iter 50/107 - loss 0.06008288 - samples/sec: 112.29 - lr: 0.025000
2022-05-13 16:33:15,692 epoch 15 - iter 60/107 - loss 0.06176223 - samples/sec: 90.66 - lr: 0.025000
2022-05-13 16:33:19,437 epoch 15 - iter 70/107 - loss 0.06074385 - samples/sec: 85.47 - lr: 0.025000
2022-05-13 16:33:23,118 epoch 15 - iter 80/107 - loss 0.06188796 - samples/sec: 86.95 - lr: 0.025000
2022-05-13 16:33:26,722 epoch 15 - iter 90/107 - loss 0.06262751 - samples/sec: 88.81 - lr: 0.025000
2022-05-13 16:33:30,306 epoch 15 - iter 100/107 - loss 0.06250799 - samples/sec: 89.31 - lr: 0.025000
2022-05-13 16:33:32,610 ----------------------------------------------------------------------------------------------------
2022-05-13 16:33:32,610 EPOCH 15 done: loss 0.0632 - lr 0.025000
2022-05-13 16:33:42,194 Evaluating as a multi-label problem: False
2022-05-13 16:33:42,204 DEV : loss 0.1968913972377777 - f1-score (micro avg)  0.5023
2022-05-13 16:33:42,279 BAD EPOCHS (no improvement): 2
2022-05-13 16:33:42,280 ----------------------------------------------------------------------------------------------------
2022-05-13 16:33:46,108 epoch 16 - iter 10/107 - loss 0.06190010 - samples/sec: 83.64 - lr: 0.025000
2022-05-13 16:33:49,878 epoch 16 - iter 20/107 - loss 0.05582638 - samples/sec: 84.90 - lr: 0.025000
2022-05-13 16:33:53,529 epoch 16 - iter 30/107 - loss 0.05687167 - samples/sec: 87.68 - lr: 0.025000
2022-05-13 16:33:57,141 epoch 16 - iter 40/107 - loss 0.05690272 - samples/sec: 88.60 - lr: 0.025000
2022-05-13 16:34:00,615 epoch 16 - iter 50/107 - loss 0.06032538 - samples/sec: 92.15 - lr: 0.025000
2022-05-13 16:34:04,059 epoch 16 - iter 60/107 - loss 0.06227812 - samples/sec: 92.95 - lr: 0.025000
2022-05-13 16:34:07,442 epoch 16 - iter 70/107 - loss 0.06091963 - samples/sec: 94.60 - lr: 0.025000
2022-05-13 16:34:10,460 epoch 16 - iter 80/107 - loss 0.06172247 - samples/sec: 106.09 - lr: 0.025000
2022-05-13 16:34:13,727 epoch 16 - iter 90/107 - loss 0.06091461 - samples/sec: 97.98 - lr: 0.025000
2022-05-13 16:34:17,347 epoch 16 - iter 100/107 - loss 0.06129236 - samples/sec: 88.41 - lr: 0.025000
2022-05-13 16:34:19,565 ----------------------------------------------------------------------------------------------------
2022-05-13 16:34:19,565 EPOCH 16 done: loss 0.0629 - lr 0.025000
2022-05-13 16:34:30,684 Evaluating as a multi-label problem: False
2022-05-13 16:34:30,695 DEV : loss 0.1996142417192459 - f1-score (micro avg)  0.5
2022-05-13 16:34:30,768 BAD EPOCHS (no improvement): 3
2022-05-13 16:34:30,770 ----------------------------------------------------------------------------------------------------
2022-05-13 16:34:34,402 epoch 17 - iter 10/107 - loss 0.06212075 - samples/sec: 88.14 - lr: 0.025000
2022-05-13 16:34:37,747 epoch 17 - iter 20/107 - loss 0.06024820 - samples/sec: 95.70 - lr: 0.025000
2022-05-13 16:34:40,861 epoch 17 - iter 30/107 - loss 0.06278749 - samples/sec: 102.78 - lr: 0.025000
2022-05-13 16:34:44,004 epoch 17 - iter 40/107 - loss 0.06622402 - samples/sec: 101.85 - lr: 0.025000
2022-05-13 16:34:47,367 epoch 17 - iter 50/107 - loss 0.06754063 - samples/sec: 95.20 - lr: 0.025000
2022-05-13 16:34:50,911 epoch 17 - iter 60/107 - loss 0.06590902 - samples/sec: 90.32 - lr: 0.025000
2022-05-13 16:34:54,652 epoch 17 - iter 70/107 - loss 0.06654358 - samples/sec: 85.55 - lr: 0.025000
2022-05-13 16:34:58,312 epoch 17 - iter 80/107 - loss 0.06473913 - samples/sec: 87.46 - lr: 0.025000
2022-05-13 16:35:02,315 epoch 17 - iter 90/107 - loss 0.06442249 - samples/sec: 79.96 - lr: 0.025000
2022-05-13 16:35:05,948 epoch 17 - iter 100/107 - loss 0.06363092 - samples/sec: 88.10 - lr: 0.025000
2022-05-13 16:35:08,263 ----------------------------------------------------------------------------------------------------
2022-05-13 16:35:08,263 EPOCH 17 done: loss 0.0622 - lr 0.025000
2022-05-13 16:35:17,910 Evaluating as a multi-label problem: False
2022-05-13 16:35:17,922 DEV : loss 0.21030570566654205 - f1-score (micro avg)  0.4908
2022-05-13 16:35:17,996 Epoch    17: reducing learning rate of group 0 to 1.2500e-02.
2022-05-13 16:35:17,996 BAD EPOCHS (no improvement): 4
2022-05-13 16:35:17,998 ----------------------------------------------------------------------------------------------------
2022-05-13 16:35:21,474 epoch 18 - iter 10/107 - loss 0.06144182 - samples/sec: 92.08 - lr: 0.012500
2022-05-13 16:35:25,214 epoch 18 - iter 20/107 - loss 0.06177905 - samples/sec: 85.60 - lr: 0.012500
2022-05-13 16:35:28,931 epoch 18 - iter 30/107 - loss 0.06271963 - samples/sec: 86.11 - lr: 0.012500
2022-05-13 16:35:32,557 epoch 18 - iter 40/107 - loss 0.06321076 - samples/sec: 88.27 - lr: 0.012500
2022-05-13 16:35:36,311 epoch 18 - iter 50/107 - loss 0.06275739 - samples/sec: 85.28 - lr: 0.012500
2022-05-13 16:35:39,675 epoch 18 - iter 60/107 - loss 0.06126167 - samples/sec: 95.13 - lr: 0.012500
2022-05-13 16:35:42,897 epoch 18 - iter 70/107 - loss 0.06068843 - samples/sec: 99.35 - lr: 0.012500
2022-05-13 16:35:45,623 epoch 18 - iter 80/107 - loss 0.06025287 - samples/sec: 117.44 - lr: 0.012500
2022-05-13 16:35:48,029 epoch 18 - iter 90/107 - loss 0.06005919 - samples/sec: 133.06 - lr: 0.012500
2022-05-13 16:35:50,489 epoch 18 - iter 100/107 - loss 0.05998368 - samples/sec: 130.11 - lr: 0.012500
2022-05-13 16:35:52,030 ----------------------------------------------------------------------------------------------------
2022-05-13 16:35:52,030 EPOCH 18 done: loss 0.0599 - lr 0.012500
2022-05-13 16:35:59,680 Evaluating as a multi-label problem: False
2022-05-13 16:35:59,691 DEV : loss 0.20844636857509613 - f1-score (micro avg)  0.5087
2022-05-13 16:35:59,765 BAD EPOCHS (no improvement): 1
2022-05-13 16:35:59,767 ----------------------------------------------------------------------------------------------------
2022-05-13 16:36:02,252 epoch 19 - iter 10/107 - loss 0.05268472 - samples/sec: 128.82 - lr: 0.012500
2022-05-13 16:36:04,756 epoch 19 - iter 20/107 - loss 0.05379210 - samples/sec: 127.86 - lr: 0.012500
2022-05-13 16:36:07,222 epoch 19 - iter 30/107 - loss 0.05734476 - samples/sec: 129.77 - lr: 0.012500
2022-05-13 16:36:10,399 epoch 19 - iter 40/107 - loss 0.05763924 - samples/sec: 100.75 - lr: 0.012500
2022-05-13 16:36:13,941 epoch 19 - iter 50/107 - loss 0.05595173 - samples/sec: 90.38 - lr: 0.012500
2022-05-13 16:36:17,640 epoch 19 - iter 60/107 - loss 0.05623624 - samples/sec: 86.55 - lr: 0.012500
2022-05-13 16:36:21,126 epoch 19 - iter 70/107 - loss 0.05784229 - samples/sec: 91.82 - lr: 0.012500
2022-05-13 16:36:24,836 epoch 19 - iter 80/107 - loss 0.05909697 - samples/sec: 86.27 - lr: 0.012500
2022-05-13 16:36:28,393 epoch 19 - iter 90/107 - loss 0.05806704 - samples/sec: 89.99 - lr: 0.012500
2022-05-13 16:36:31,838 epoch 19 - iter 100/107 - loss 0.05822864 - samples/sec: 92.92 - lr: 0.012500
2022-05-13 16:36:33,896 ----------------------------------------------------------------------------------------------------
2022-05-13 16:36:33,896 EPOCH 19 done: loss 0.0581 - lr 0.012500
2022-05-13 16:36:42,948 Evaluating as a multi-label problem: False
2022-05-13 16:36:42,959 DEV : loss 0.21606163680553436 - f1-score (micro avg)  0.4857
2022-05-13 16:36:43,033 BAD EPOCHS (no improvement): 2
2022-05-13 16:36:43,035 ----------------------------------------------------------------------------------------------------
2022-05-13 16:36:46,451 epoch 20 - iter 10/107 - loss 0.04231422 - samples/sec: 93.70 - lr: 0.012500
2022-05-13 16:36:50,006 epoch 20 - iter 20/107 - loss 0.05477881 - samples/sec: 90.04 - lr: 0.012500
2022-05-13 16:36:53,401 epoch 20 - iter 30/107 - loss 0.05869250 - samples/sec: 94.27 - lr: 0.012500
2022-05-13 16:36:56,740 epoch 20 - iter 40/107 - loss 0.05668713 - samples/sec: 95.90 - lr: 0.012500
2022-05-13 16:37:00,024 epoch 20 - iter 50/107 - loss 0.05490020 - samples/sec: 97.45 - lr: 0.012500
2022-05-13 16:37:03,525 epoch 20 - iter 60/107 - loss 0.05429472 - samples/sec: 91.44 - lr: 0.012500
2022-05-13 16:37:07,105 epoch 20 - iter 70/107 - loss 0.05492473 - samples/sec: 89.40 - lr: 0.012500
2022-05-13 16:37:10,181 epoch 20 - iter 80/107 - loss 0.05567922 - samples/sec: 104.07 - lr: 0.012500
2022-05-13 16:37:12,815 epoch 20 - iter 90/107 - loss 0.05575552 - samples/sec: 121.51 - lr: 0.012500
2022-05-13 16:37:15,662 epoch 20 - iter 100/107 - loss 0.05621886 - samples/sec: 112.45 - lr: 0.012500
2022-05-13 16:37:17,029 ----------------------------------------------------------------------------------------------------
2022-05-13 16:37:17,029 EPOCH 20 done: loss 0.0561 - lr 0.012500
2022-05-13 16:37:24,621 Evaluating as a multi-label problem: False
2022-05-13 16:37:24,631 DEV : loss 0.20875389873981476 - f1-score (micro avg)  0.5142
2022-05-13 16:37:24,704 BAD EPOCHS (no improvement): 0
2022-05-13 16:37:24,706 saving best model
2022-05-13 16:37:59,552 ----------------------------------------------------------------------------------------------------
2022-05-13 16:38:02,929 epoch 21 - iter 10/107 - loss 0.05168785 - samples/sec: 94.84 - lr: 0.012500
2022-05-13 16:38:05,421 epoch 21 - iter 20/107 - loss 0.05257080 - samples/sec: 128.46 - lr: 0.012500
2022-05-13 16:38:07,641 epoch 21 - iter 30/107 - loss 0.05340407 - samples/sec: 144.21 - lr: 0.012500
2022-05-13 16:38:10,083 epoch 21 - iter 40/107 - loss 0.05396562 - samples/sec: 131.09 - lr: 0.012500
2022-05-13 16:38:12,529 epoch 21 - iter 50/107 - loss 0.05540882 - samples/sec: 130.89 - lr: 0.012500
2022-05-13 16:38:15,022 epoch 21 - iter 60/107 - loss 0.05505124 - samples/sec: 128.40 - lr: 0.012500
2022-05-13 16:38:17,413 epoch 21 - iter 70/107 - loss 0.05596482 - samples/sec: 133.90 - lr: 0.012500
2022-05-13 16:38:19,896 epoch 21 - iter 80/107 - loss 0.05659736 - samples/sec: 128.92 - lr: 0.012500
2022-05-13 16:38:22,483 epoch 21 - iter 90/107 - loss 0.05725236 - samples/sec: 123.71 - lr: 0.012500
2022-05-13 16:38:24,912 epoch 21 - iter 100/107 - loss 0.05749911 - samples/sec: 131.82 - lr: 0.012500
2022-05-13 16:38:27,196 ----------------------------------------------------------------------------------------------------
2022-05-13 16:38:27,196 EPOCH 21 done: loss 0.0573 - lr 0.012500
2022-05-13 16:38:41,966 Evaluating as a multi-label problem: False
2022-05-13 16:38:41,977 DEV : loss 0.20233063399791718 - f1-score (micro avg)  0.5113
2022-05-13 16:38:42,050 BAD EPOCHS (no improvement): 1
2022-05-13 16:38:42,058 ----------------------------------------------------------------------------------------------------
2022-05-13 16:38:45,874 epoch 22 - iter 10/107 - loss 0.05790903 - samples/sec: 83.87 - lr: 0.012500
2022-05-13 16:38:48,909 epoch 22 - iter 20/107 - loss 0.06201106 - samples/sec: 105.48 - lr: 0.012500
2022-05-13 16:38:52,021 epoch 22 - iter 30/107 - loss 0.06114189 - samples/sec: 102.88 - lr: 0.012500
2022-05-13 16:38:55,435 epoch 22 - iter 40/107 - loss 0.05653382 - samples/sec: 93.76 - lr: 0.012500
2022-05-13 16:38:59,102 epoch 22 - iter 50/107 - loss 0.05829730 - samples/sec: 87.27 - lr: 0.012500
2022-05-13 16:39:02,770 epoch 22 - iter 60/107 - loss 0.05782366 - samples/sec: 87.26 - lr: 0.012500
2022-05-13 16:39:06,266 epoch 22 - iter 70/107 - loss 0.05802137 - samples/sec: 91.56 - lr: 0.012500
2022-05-13 16:39:09,739 epoch 22 - iter 80/107 - loss 0.05682532 - samples/sec: 92.16 - lr: 0.012500
2022-05-13 16:39:13,404 epoch 22 - iter 90/107 - loss 0.05663363 - samples/sec: 87.36 - lr: 0.012500
2022-05-13 16:39:16,913 epoch 22 - iter 100/107 - loss 0.05547800 - samples/sec: 91.23 - lr: 0.012500
2022-05-13 16:39:19,015 ----------------------------------------------------------------------------------------------------
2022-05-13 16:39:19,015 EPOCH 22 done: loss 0.0550 - lr 0.012500
2022-05-13 16:39:28,832 Evaluating as a multi-label problem: False
2022-05-13 16:39:28,843 DEV : loss 0.20959457755088806 - f1-score (micro avg)  0.5071
2022-05-13 16:39:28,916 BAD EPOCHS (no improvement): 2
2022-05-13 16:39:28,918 ----------------------------------------------------------------------------------------------------
2022-05-13 16:39:32,643 epoch 23 - iter 10/107 - loss 0.06993697 - samples/sec: 85.93 - lr: 0.012500
2022-05-13 16:39:36,214 epoch 23 - iter 20/107 - loss 0.06005166 - samples/sec: 89.63 - lr: 0.012500
2022-05-13 16:39:39,809 epoch 23 - iter 30/107 - loss 0.05695239 - samples/sec: 89.03 - lr: 0.012500
2022-05-13 16:39:43,362 epoch 23 - iter 40/107 - loss 0.05664839 - samples/sec: 90.08 - lr: 0.012500
2022-05-13 16:39:46,966 epoch 23 - iter 50/107 - loss 0.05523596 - samples/sec: 88.82 - lr: 0.012500
2022-05-13 16:39:50,321 epoch 23 - iter 60/107 - loss 0.05423720 - samples/sec: 95.40 - lr: 0.012500
2022-05-13 16:39:53,356 epoch 23 - iter 70/107 - loss 0.05392285 - samples/sec: 105.48 - lr: 0.012500
2022-05-13 16:39:56,746 epoch 23 - iter 80/107 - loss 0.05361507 - samples/sec: 94.40 - lr: 0.012500
2022-05-13 16:40:00,275 epoch 23 - iter 90/107 - loss 0.05270670 - samples/sec: 90.72 - lr: 0.012500
2022-05-13 16:40:04,043 epoch 23 - iter 100/107 - loss 0.05291802 - samples/sec: 84.94 - lr: 0.012500
2022-05-13 16:40:06,313 ----------------------------------------------------------------------------------------------------
2022-05-13 16:40:06,313 EPOCH 23 done: loss 0.0539 - lr 0.012500
2022-05-13 16:40:17,336 Evaluating as a multi-label problem: False
2022-05-13 16:40:17,349 DEV : loss 0.19871777296066284 - f1-score (micro avg)  0.5186
2022-05-13 16:40:17,423 BAD EPOCHS (no improvement): 0
2022-05-13 16:40:17,445 saving best model
2022-05-13 16:40:53,037 ----------------------------------------------------------------------------------------------------
2022-05-13 16:40:56,551 epoch 24 - iter 10/107 - loss 0.05543720 - samples/sec: 91.10 - lr: 0.012500
2022-05-13 16:41:00,211 epoch 24 - iter 20/107 - loss 0.06162482 - samples/sec: 87.47 - lr: 0.012500
2022-05-13 16:41:03,992 epoch 24 - iter 30/107 - loss 0.05883679 - samples/sec: 84.65 - lr: 0.012500
2022-05-13 16:41:07,267 epoch 24 - iter 40/107 - loss 0.05832749 - samples/sec: 97.75 - lr: 0.012500
2022-05-13 16:41:10,267 epoch 24 - iter 50/107 - loss 0.05599340 - samples/sec: 106.70 - lr: 0.012500
2022-05-13 16:41:13,287 epoch 24 - iter 60/107 - loss 0.05436164 - samples/sec: 105.98 - lr: 0.012500
2022-05-13 16:41:16,876 epoch 24 - iter 70/107 - loss 0.05541897 - samples/sec: 89.19 - lr: 0.012500
2022-05-13 16:41:20,501 epoch 24 - iter 80/107 - loss 0.05586170 - samples/sec: 88.31 - lr: 0.012500
2022-05-13 16:41:24,215 epoch 24 - iter 90/107 - loss 0.05387039 - samples/sec: 86.17 - lr: 0.012500
2022-05-13 16:41:27,856 epoch 24 - iter 100/107 - loss 0.05437065 - samples/sec: 87.91 - lr: 0.012500
2022-05-13 16:41:30,082 ----------------------------------------------------------------------------------------------------
2022-05-13 16:41:30,082 EPOCH 24 done: loss 0.0542 - lr 0.012500
2022-05-13 16:41:40,339 Evaluating as a multi-label problem: False
2022-05-13 16:41:40,352 DEV : loss 0.20759522914886475 - f1-score (micro avg)  0.5098
2022-05-13 16:41:40,425 BAD EPOCHS (no improvement): 1
2022-05-13 16:41:40,427 ----------------------------------------------------------------------------------------------------
2022-05-13 16:41:43,523 epoch 25 - iter 10/107 - loss 0.06397406 - samples/sec: 103.40 - lr: 0.012500
2022-05-13 16:41:47,335 epoch 25 - iter 20/107 - loss 0.06189506 - samples/sec: 83.97 - lr: 0.012500
2022-05-13 16:41:51,205 epoch 25 - iter 30/107 - loss 0.05808587 - samples/sec: 82.71 - lr: 0.012500
2022-05-13 16:41:54,885 epoch 25 - iter 40/107 - loss 0.05680723 - samples/sec: 86.98 - lr: 0.012500
2022-05-13 16:41:58,663 epoch 25 - iter 50/107 - loss 0.05543283 - samples/sec: 84.73 - lr: 0.012500
2022-05-13 16:42:02,278 epoch 25 - iter 60/107 - loss 0.05778986 - samples/sec: 88.53 - lr: 0.012500
2022-05-13 16:42:05,784 epoch 25 - iter 70/107 - loss 0.05587869 - samples/sec: 91.30 - lr: 0.012500
2022-05-13 16:42:09,120 epoch 25 - iter 80/107 - loss 0.05585812 - samples/sec: 95.95 - lr: 0.012500
2022-05-13 16:42:12,073 epoch 25 - iter 90/107 - loss 0.05596579 - samples/sec: 108.40 - lr: 0.012500
2022-05-13 16:42:15,229 epoch 25 - iter 100/107 - loss 0.05610010 - samples/sec: 101.43 - lr: 0.012500
2022-05-13 16:42:17,427 ----------------------------------------------------------------------------------------------------
2022-05-13 16:42:17,427 EPOCH 25 done: loss 0.0555 - lr 0.012500
2022-05-13 16:42:28,350 Evaluating as a multi-label problem: False
2022-05-13 16:42:28,361 DEV : loss 0.21034209430217743 - f1-score (micro avg)  0.5106
2022-05-13 16:42:28,433 BAD EPOCHS (no improvement): 2
2022-05-13 16:42:28,435 ----------------------------------------------------------------------------------------------------
2022-05-13 16:42:32,163 epoch 26 - iter 10/107 - loss 0.05270150 - samples/sec: 85.87 - lr: 0.012500
2022-05-13 16:42:35,903 epoch 26 - iter 20/107 - loss 0.05215986 - samples/sec: 85.59 - lr: 0.012500
2022-05-13 16:42:39,255 epoch 26 - iter 30/107 - loss 0.04982126 - samples/sec: 95.49 - lr: 0.012500
2022-05-13 16:42:42,333 epoch 26 - iter 40/107 - loss 0.04866544 - samples/sec: 104.00 - lr: 0.012500
2022-05-13 16:42:45,484 epoch 26 - iter 50/107 - loss 0.05287913 - samples/sec: 101.58 - lr: 0.012500
2022-05-13 16:42:48,901 epoch 26 - iter 60/107 - loss 0.05341367 - samples/sec: 93.68 - lr: 0.012500
2022-05-13 16:42:52,559 epoch 26 - iter 70/107 - loss 0.05101189 - samples/sec: 87.49 - lr: 0.012500
2022-05-13 16:42:56,289 epoch 26 - iter 80/107 - loss 0.05151544 - samples/sec: 85.81 - lr: 0.012500
2022-05-13 16:42:59,910 epoch 26 - iter 90/107 - loss 0.05261395 - samples/sec: 88.40 - lr: 0.012500
2022-05-13 16:43:03,373 epoch 26 - iter 100/107 - loss 0.05219192 - samples/sec: 92.44 - lr: 0.012500
2022-05-13 16:43:05,494 ----------------------------------------------------------------------------------------------------
2022-05-13 16:43:05,494 EPOCH 26 done: loss 0.0520 - lr 0.012500
2022-05-13 16:43:15,206 Evaluating as a multi-label problem: False
2022-05-13 16:43:15,217 DEV : loss 0.21092791855335236 - f1-score (micro avg)  0.4945
2022-05-13 16:43:15,292 BAD EPOCHS (no improvement): 3
2022-05-13 16:43:15,294 ----------------------------------------------------------------------------------------------------
2022-05-13 16:43:18,645 epoch 27 - iter 10/107 - loss 0.04911021 - samples/sec: 95.52 - lr: 0.012500
2022-05-13 16:43:22,304 epoch 27 - iter 20/107 - loss 0.04711785 - samples/sec: 87.48 - lr: 0.012500
2022-05-13 16:43:25,773 epoch 27 - iter 30/107 - loss 0.04804419 - samples/sec: 92.28 - lr: 0.012500
2022-05-13 16:43:29,480 epoch 27 - iter 40/107 - loss 0.05039885 - samples/sec: 86.35 - lr: 0.012500
2022-05-13 16:43:33,109 epoch 27 - iter 50/107 - loss 0.05055809 - samples/sec: 88.21 - lr: 0.012500
2022-05-13 16:43:36,622 epoch 27 - iter 60/107 - loss 0.05177660 - samples/sec: 91.11 - lr: 0.012500
2022-05-13 16:43:40,422 epoch 27 - iter 70/107 - loss 0.05046786 - samples/sec: 84.22 - lr: 0.012500
2022-05-13 16:43:43,539 epoch 27 - iter 80/107 - loss 0.05103767 - samples/sec: 102.71 - lr: 0.012500
2022-05-13 16:43:46,571 epoch 27 - iter 90/107 - loss 0.05037024 - samples/sec: 105.55 - lr: 0.012500
2022-05-13 16:43:49,683 epoch 27 - iter 100/107 - loss 0.05077203 - samples/sec: 102.89 - lr: 0.012500
2022-05-13 16:43:51,998 ----------------------------------------------------------------------------------------------------
2022-05-13 16:43:51,998 EPOCH 27 done: loss 0.0508 - lr 0.012500
2022-05-13 16:44:02,667 Evaluating as a multi-label problem: False
2022-05-13 16:44:02,678 DEV : loss 0.21086439490318298 - f1-score (micro avg)  0.4996
2022-05-13 16:44:02,751 Epoch    27: reducing learning rate of group 0 to 6.2500e-03.
2022-05-13 16:44:02,751 BAD EPOCHS (no improvement): 4
2022-05-13 16:44:02,753 ----------------------------------------------------------------------------------------------------
2022-05-13 16:44:06,360 epoch 28 - iter 10/107 - loss 0.05182034 - samples/sec: 88.73 - lr: 0.006250
2022-05-13 16:44:10,070 epoch 28 - iter 20/107 - loss 0.05369149 - samples/sec: 86.30 - lr: 0.006250
2022-05-13 16:44:13,144 epoch 28 - iter 30/107 - loss 0.05088016 - samples/sec: 104.12 - lr: 0.006250
2022-05-13 16:44:16,233 epoch 28 - iter 40/107 - loss 0.05087743 - samples/sec: 103.64 - lr: 0.006250
2022-05-13 16:44:19,562 epoch 28 - iter 50/107 - loss 0.05079946 - samples/sec: 96.13 - lr: 0.006250
2022-05-13 16:44:23,169 epoch 28 - iter 60/107 - loss 0.05138473 - samples/sec: 88.75 - lr: 0.006250
2022-05-13 16:44:26,731 epoch 28 - iter 70/107 - loss 0.05035059 - samples/sec: 89.86 - lr: 0.006250
2022-05-13 16:44:30,451 epoch 28 - iter 80/107 - loss 0.04991697 - samples/sec: 86.04 - lr: 0.006250
2022-05-13 16:44:33,975 epoch 28 - iter 90/107 - loss 0.04947442 - samples/sec: 90.83 - lr: 0.006250
2022-05-13 16:44:37,532 epoch 28 - iter 100/107 - loss 0.04914201 - samples/sec: 90.00 - lr: 0.006250
2022-05-13 16:44:39,891 ----------------------------------------------------------------------------------------------------
2022-05-13 16:44:40,029 EPOCH 28 done: loss 0.0487 - lr 0.006250
2022-05-13 16:44:49,520 Evaluating as a multi-label problem: False
2022-05-13 16:44:49,531 DEV : loss 0.21422608196735382 - f1-score (micro avg)  0.5039
2022-05-13 16:44:49,604 BAD EPOCHS (no improvement): 1
2022-05-13 16:44:49,621 ----------------------------------------------------------------------------------------------------
2022-05-13 16:44:53,098 epoch 29 - iter 10/107 - loss 0.04736104 - samples/sec: 92.05 - lr: 0.006250
2022-05-13 16:44:56,884 epoch 29 - iter 20/107 - loss 0.04845690 - samples/sec: 84.56 - lr: 0.006250
2022-05-13 16:45:00,469 epoch 29 - iter 30/107 - loss 0.04781264 - samples/sec: 89.27 - lr: 0.006250
2022-05-13 16:45:04,308 epoch 29 - iter 40/107 - loss 0.04956561 - samples/sec: 83.38 - lr: 0.006250
2022-05-13 16:45:08,084 epoch 29 - iter 50/107 - loss 0.05076706 - samples/sec: 84.76 - lr: 0.006250
2022-05-13 16:45:11,760 epoch 29 - iter 60/107 - loss 0.04992065 - samples/sec: 87.07 - lr: 0.006250
2022-05-13 16:45:14,840 epoch 29 - iter 70/107 - loss 0.05034780 - samples/sec: 103.95 - lr: 0.006250
2022-05-13 16:45:17,866 epoch 29 - iter 80/107 - loss 0.05042569 - samples/sec: 105.78 - lr: 0.006250
2022-05-13 16:45:20,843 epoch 29 - iter 90/107 - loss 0.05039878 - samples/sec: 107.50 - lr: 0.006250
2022-05-13 16:45:24,587 epoch 29 - iter 100/107 - loss 0.04943896 - samples/sec: 85.51 - lr: 0.006250
2022-05-13 16:45:26,868 ----------------------------------------------------------------------------------------------------
2022-05-13 16:45:26,868 EPOCH 29 done: loss 0.0498 - lr 0.006250
2022-05-13 16:45:37,594 Evaluating as a multi-label problem: False
2022-05-13 16:45:37,605 DEV : loss 0.21159490942955017 - f1-score (micro avg)  0.5024
2022-05-13 16:45:37,678 BAD EPOCHS (no improvement): 2
2022-05-13 16:45:37,680 ----------------------------------------------------------------------------------------------------
2022-05-13 16:45:41,275 epoch 30 - iter 10/107 - loss 0.04429420 - samples/sec: 89.05 - lr: 0.006250
2022-05-13 16:45:44,824 epoch 30 - iter 20/107 - loss 0.04552056 - samples/sec: 90.19 - lr: 0.006250
2022-05-13 16:45:47,496 epoch 30 - iter 30/107 - loss 0.04736943 - samples/sec: 119.79 - lr: 0.006250
2022-05-13 16:45:50,468 epoch 30 - iter 40/107 - loss 0.04902215 - samples/sec: 107.71 - lr: 0.006250
2022-05-13 16:45:53,486 epoch 30 - iter 50/107 - loss 0.05134886 - samples/sec: 106.04 - lr: 0.006250
2022-05-13 16:45:57,041 epoch 30 - iter 60/107 - loss 0.05287062 - samples/sec: 90.04 - lr: 0.006250
2022-05-13 16:46:00,890 epoch 30 - iter 70/107 - loss 0.05263661 - samples/sec: 83.17 - lr: 0.006250
2022-05-13 16:46:04,546 epoch 30 - iter 80/107 - loss 0.05203024 - samples/sec: 87.55 - lr: 0.006250
2022-05-13 16:46:08,093 epoch 30 - iter 90/107 - loss 0.05252349 - samples/sec: 90.22 - lr: 0.006250
2022-05-13 16:46:11,882 epoch 30 - iter 100/107 - loss 0.05112253 - samples/sec: 84.50 - lr: 0.006250
2022-05-13 16:46:13,947 ----------------------------------------------------------------------------------------------------
2022-05-13 16:46:13,947 EPOCH 30 done: loss 0.0510 - lr 0.006250
2022-05-13 16:46:23,458 Evaluating as a multi-label problem: False
2022-05-13 16:46:23,471 DEV : loss 0.2103910744190216 - f1-score (micro avg)  0.5125
2022-05-13 16:46:23,544 BAD EPOCHS (no improvement): 3
2022-05-13 16:46:23,546 ----------------------------------------------------------------------------------------------------
2022-05-13 16:46:27,078 epoch 31 - iter 10/107 - loss 0.05925090 - samples/sec: 90.64 - lr: 0.006250
2022-05-13 16:46:30,430 epoch 31 - iter 20/107 - loss 0.04905888 - samples/sec: 95.50 - lr: 0.006250
2022-05-13 16:46:34,023 epoch 31 - iter 30/107 - loss 0.04573930 - samples/sec: 89.09 - lr: 0.006250
2022-05-13 16:46:37,635 epoch 31 - iter 40/107 - loss 0.04641000 - samples/sec: 88.61 - lr: 0.006250
2022-05-13 16:46:41,380 epoch 31 - iter 50/107 - loss 0.04877928 - samples/sec: 85.46 - lr: 0.006250
2022-05-13 16:46:44,975 epoch 31 - iter 60/107 - loss 0.04855997 - samples/sec: 89.04 - lr: 0.006250
2022-05-13 16:46:48,443 epoch 31 - iter 70/107 - loss 0.04766962 - samples/sec: 92.30 - lr: 0.006250
2022-05-13 16:46:51,596 epoch 31 - iter 80/107 - loss 0.05015230 - samples/sec: 101.53 - lr: 0.006250
2022-05-13 16:46:54,518 epoch 31 - iter 90/107 - loss 0.05094363 - samples/sec: 109.54 - lr: 0.006250
2022-05-13 16:46:58,258 epoch 31 - iter 100/107 - loss 0.05098503 - samples/sec: 85.58 - lr: 0.006250
2022-05-13 16:47:00,419 ----------------------------------------------------------------------------------------------------
2022-05-13 16:47:00,419 EPOCH 31 done: loss 0.0510 - lr 0.006250
2022-05-13 16:47:11,258 Evaluating as a multi-label problem: False
2022-05-13 16:47:11,270 DEV : loss 0.20455649495124817 - f1-score (micro avg)  0.5155
2022-05-13 16:47:11,343 Epoch    31: reducing learning rate of group 0 to 3.1250e-03.
2022-05-13 16:47:11,344 BAD EPOCHS (no improvement): 4
2022-05-13 16:47:11,345 ----------------------------------------------------------------------------------------------------
2022-05-13 16:47:14,920 epoch 32 - iter 10/107 - loss 0.04555916 - samples/sec: 89.56 - lr: 0.003125
2022-05-13 16:47:18,484 epoch 32 - iter 20/107 - loss 0.04797148 - samples/sec: 89.81 - lr: 0.003125
2022-05-13 16:47:21,526 epoch 32 - iter 30/107 - loss 0.05111089 - samples/sec: 105.24 - lr: 0.003125
2022-05-13 16:47:24,283 epoch 32 - iter 40/107 - loss 0.04870894 - samples/sec: 116.10 - lr: 0.003125
2022-05-13 16:47:27,855 epoch 32 - iter 50/107 - loss 0.04878548 - samples/sec: 89.60 - lr: 0.003125
2022-05-13 16:47:31,660 epoch 32 - iter 60/107 - loss 0.04939376 - samples/sec: 84.13 - lr: 0.003125
2022-05-13 16:47:35,398 epoch 32 - iter 70/107 - loss 0.04942849 - samples/sec: 85.62 - lr: 0.003125
2022-05-13 16:47:39,107 epoch 32 - iter 80/107 - loss 0.04872366 - samples/sec: 86.31 - lr: 0.003125
2022-05-13 16:47:42,651 epoch 32 - iter 90/107 - loss 0.04812268 - samples/sec: 90.32 - lr: 0.003125
2022-05-13 16:47:46,238 epoch 32 - iter 100/107 - loss 0.05002155 - samples/sec: 89.22 - lr: 0.003125
2022-05-13 16:47:48,496 ----------------------------------------------------------------------------------------------------
2022-05-13 16:47:48,496 EPOCH 32 done: loss 0.0502 - lr 0.003125
2022-05-13 16:47:57,912 Evaluating as a multi-label problem: False
2022-05-13 16:47:57,923 DEV : loss 0.20989979803562164 - f1-score (micro avg)  0.5102
2022-05-13 16:47:57,997 BAD EPOCHS (no improvement): 1
2022-05-13 16:47:58,016 ----------------------------------------------------------------------------------------------------
2022-05-13 16:48:01,804 epoch 33 - iter 10/107 - loss 0.04041838 - samples/sec: 84.50 - lr: 0.003125
2022-05-13 16:48:05,266 epoch 33 - iter 20/107 - loss 0.04559457 - samples/sec: 92.48 - lr: 0.003125
2022-05-13 16:48:08,895 epoch 33 - iter 30/107 - loss 0.04887665 - samples/sec: 88.19 - lr: 0.003125
2022-05-13 16:48:12,569 epoch 33 - iter 40/107 - loss 0.04848912 - samples/sec: 87.11 - lr: 0.003125
2022-05-13 16:48:16,059 epoch 33 - iter 50/107 - loss 0.04942364 - samples/sec: 91.72 - lr: 0.003125
2022-05-13 16:48:19,690 epoch 33 - iter 60/107 - loss 0.04860210 - samples/sec: 88.17 - lr: 0.003125
2022-05-13 16:48:23,016 epoch 33 - iter 70/107 - loss 0.04789355 - samples/sec: 96.22 - lr: 0.003125
2022-05-13 16:48:25,991 epoch 33 - iter 80/107 - loss 0.04695086 - samples/sec: 107.60 - lr: 0.003125
2022-05-13 16:48:29,255 epoch 33 - iter 90/107 - loss 0.04909143 - samples/sec: 98.07 - lr: 0.003125
2022-05-13 16:48:33,110 epoch 33 - iter 100/107 - loss 0.04866961 - samples/sec: 83.04 - lr: 0.003125
2022-05-13 16:48:35,349 ----------------------------------------------------------------------------------------------------
2022-05-13 16:48:35,349 EPOCH 33 done: loss 0.0491 - lr 0.003125
2022-05-13 16:48:46,386 Evaluating as a multi-label problem: False
2022-05-13 16:48:46,397 DEV : loss 0.2051839530467987 - f1-score (micro avg)  0.5131
2022-05-13 16:48:46,471 BAD EPOCHS (no improvement): 2
2022-05-13 16:48:46,473 ----------------------------------------------------------------------------------------------------
2022-05-13 16:48:50,189 epoch 34 - iter 10/107 - loss 0.05467308 - samples/sec: 86.13 - lr: 0.003125
2022-05-13 16:48:53,420 epoch 34 - iter 20/107 - loss 0.05290419 - samples/sec: 99.08 - lr: 0.003125
2022-05-13 16:48:56,522 epoch 34 - iter 30/107 - loss 0.05065414 - samples/sec: 103.18 - lr: 0.003125
2022-05-13 16:48:59,513 epoch 34 - iter 40/107 - loss 0.04967737 - samples/sec: 107.04 - lr: 0.003125
2022-05-13 16:49:03,290 epoch 34 - iter 50/107 - loss 0.05041154 - samples/sec: 84.74 - lr: 0.003125
2022-05-13 16:49:06,748 epoch 34 - iter 60/107 - loss 0.05006714 - samples/sec: 92.56 - lr: 0.003125
2022-05-13 16:49:10,407 epoch 34 - iter 70/107 - loss 0.05095345 - samples/sec: 87.49 - lr: 0.003125
2022-05-13 16:49:14,025 epoch 34 - iter 80/107 - loss 0.05135713 - samples/sec: 88.47 - lr: 0.003125
2022-05-13 16:49:17,718 epoch 34 - iter 90/107 - loss 0.05091754 - samples/sec: 86.68 - lr: 0.003125
2022-05-13 16:49:21,130 epoch 34 - iter 100/107 - loss 0.05032680 - samples/sec: 93.81 - lr: 0.003125
2022-05-13 16:49:23,448 ----------------------------------------------------------------------------------------------------
2022-05-13 16:49:23,448 EPOCH 34 done: loss 0.0500 - lr 0.003125
2022-05-13 16:49:33,087 Evaluating as a multi-label problem: False
2022-05-13 16:49:33,098 DEV : loss 0.20859815180301666 - f1-score (micro avg)  0.5125
2022-05-13 16:49:33,172 BAD EPOCHS (no improvement): 3
2022-05-13 16:49:33,175 ----------------------------------------------------------------------------------------------------
2022-05-13 16:49:37,007 epoch 35 - iter 10/107 - loss 0.05054735 - samples/sec: 83.53 - lr: 0.003125
2022-05-13 16:49:40,569 epoch 35 - iter 20/107 - loss 0.04775796 - samples/sec: 89.87 - lr: 0.003125
2022-05-13 16:49:44,318 epoch 35 - iter 30/107 - loss 0.04916216 - samples/sec: 85.37 - lr: 0.003125
2022-05-13 16:49:47,999 epoch 35 - iter 40/107 - loss 0.04756732 - samples/sec: 86.95 - lr: 0.003125
2022-05-13 16:49:51,555 epoch 35 - iter 50/107 - loss 0.04690071 - samples/sec: 90.02 - lr: 0.003125
2022-05-13 16:49:55,036 epoch 35 - iter 60/107 - loss 0.04971221 - samples/sec: 91.96 - lr: 0.003125
2022-05-13 16:49:57,965 epoch 35 - iter 70/107 - loss 0.04892111 - samples/sec: 109.30 - lr: 0.003125
2022-05-13 16:50:00,830 epoch 35 - iter 80/107 - loss 0.04915875 - samples/sec: 111.71 - lr: 0.003125
2022-05-13 16:50:04,472 epoch 35 - iter 90/107 - loss 0.04973249 - samples/sec: 87.91 - lr: 0.003125
2022-05-13 16:50:08,097 epoch 35 - iter 100/107 - loss 0.04846954 - samples/sec: 88.30 - lr: 0.003125
2022-05-13 16:50:10,294 ----------------------------------------------------------------------------------------------------
2022-05-13 16:50:10,294 EPOCH 35 done: loss 0.0486 - lr 0.003125
2022-05-13 16:50:21,163 Evaluating as a multi-label problem: False
2022-05-13 16:50:21,174 DEV : loss 0.20672211050987244 - f1-score (micro avg)  0.5178
2022-05-13 16:50:21,252 Epoch    35: reducing learning rate of group 0 to 1.5625e-03.
2022-05-13 16:50:21,252 BAD EPOCHS (no improvement): 4
2022-05-13 16:50:21,255 ----------------------------------------------------------------------------------------------------
2022-05-13 16:50:25,011 epoch 36 - iter 10/107 - loss 0.04993260 - samples/sec: 85.23 - lr: 0.001563
2022-05-13 16:50:28,029 epoch 36 - iter 20/107 - loss 0.05539880 - samples/sec: 106.05 - lr: 0.001563
2022-05-13 16:50:31,250 epoch 36 - iter 30/107 - loss 0.05358662 - samples/sec: 99.38 - lr: 0.001563
2022-05-13 16:50:35,014 epoch 36 - iter 40/107 - loss 0.05023389 - samples/sec: 85.03 - lr: 0.001563
2022-05-13 16:50:38,505 epoch 36 - iter 50/107 - loss 0.04827188 - samples/sec: 91.69 - lr: 0.001563
2022-05-13 16:50:42,089 epoch 36 - iter 60/107 - loss 0.04899052 - samples/sec: 89.32 - lr: 0.001563
2022-05-13 16:50:45,736 epoch 36 - iter 70/107 - loss 0.04799826 - samples/sec: 87.76 - lr: 0.001563
2022-05-13 16:50:49,394 epoch 36 - iter 80/107 - loss 0.04852986 - samples/sec: 87.50 - lr: 0.001563
2022-05-13 16:50:53,226 epoch 36 - iter 90/107 - loss 0.04878035 - samples/sec: 83.54 - lr: 0.001563
2022-05-13 16:50:57,054 epoch 36 - iter 100/107 - loss 0.04829622 - samples/sec: 83.62 - lr: 0.001563
2022-05-13 16:50:58,925 ----------------------------------------------------------------------------------------------------
2022-05-13 16:50:58,925 EPOCH 36 done: loss 0.0488 - lr 0.001563
2022-05-13 16:51:09,285 Evaluating as a multi-label problem: False
2022-05-13 16:51:09,297 DEV : loss 0.20520488917827606 - f1-score (micro avg)  0.517
2022-05-13 16:51:09,373 BAD EPOCHS (no improvement): 1
2022-05-13 16:51:09,376 ----------------------------------------------------------------------------------------------------
2022-05-13 16:51:12,968 epoch 37 - iter 10/107 - loss 0.04895749 - samples/sec: 89.11 - lr: 0.001563
2022-05-13 16:51:16,607 epoch 37 - iter 20/107 - loss 0.04890101 - samples/sec: 87.96 - lr: 0.001563
2022-05-13 16:51:20,397 epoch 37 - iter 30/107 - loss 0.05422276 - samples/sec: 84.45 - lr: 0.001563
2022-05-13 16:51:23,877 epoch 37 - iter 40/107 - loss 0.05180045 - samples/sec: 92.00 - lr: 0.001563
2022-05-13 16:51:27,353 epoch 37 - iter 50/107 - loss 0.05250838 - samples/sec: 92.07 - lr: 0.001563
2022-05-13 16:51:30,678 epoch 37 - iter 60/107 - loss 0.05261662 - samples/sec: 96.28 - lr: 0.001563
2022-05-13 16:51:33,671 epoch 37 - iter 70/107 - loss 0.05158693 - samples/sec: 106.96 - lr: 0.001563
2022-05-13 16:51:37,088 epoch 37 - iter 80/107 - loss 0.05050531 - samples/sec: 93.67 - lr: 0.001563
2022-05-13 16:51:40,577 epoch 37 - iter 90/107 - loss 0.05021102 - samples/sec: 91.75 - lr: 0.001563
2022-05-13 16:51:44,195 epoch 37 - iter 100/107 - loss 0.04986689 - samples/sec: 88.48 - lr: 0.001563
2022-05-13 16:51:46,689 ----------------------------------------------------------------------------------------------------
2022-05-13 16:51:46,689 EPOCH 37 done: loss 0.0496 - lr 0.001563
2022-05-13 16:51:57,480 Evaluating as a multi-label problem: False
2022-05-13 16:51:57,492 DEV : loss 0.21020397543907166 - f1-score (micro avg)  0.5141
2022-05-13 16:51:57,568 BAD EPOCHS (no improvement): 2
2022-05-13 16:51:57,570 ----------------------------------------------------------------------------------------------------
2022-05-13 16:52:00,550 epoch 38 - iter 10/107 - loss 0.06145964 - samples/sec: 107.44 - lr: 0.001563
2022-05-13 16:52:03,649 epoch 38 - iter 20/107 - loss 0.05608374 - samples/sec: 103.30 - lr: 0.001563
2022-05-13 16:52:06,804 epoch 38 - iter 30/107 - loss 0.05375108 - samples/sec: 101.45 - lr: 0.001563
2022-05-13 16:52:10,469 epoch 38 - iter 40/107 - loss 0.04885056 - samples/sec: 87.32 - lr: 0.001563
2022-05-13 16:52:14,043 epoch 38 - iter 50/107 - loss 0.04635002 - samples/sec: 89.57 - lr: 0.001563
2022-05-13 16:52:17,840 epoch 38 - iter 60/107 - loss 0.04553003 - samples/sec: 84.29 - lr: 0.001563
2022-05-13 16:52:21,395 epoch 38 - iter 70/107 - loss 0.04575471 - samples/sec: 90.06 - lr: 0.001563
2022-05-13 16:52:24,936 epoch 38 - iter 80/107 - loss 0.04836694 - samples/sec: 90.40 - lr: 0.001563
2022-05-13 16:52:28,460 epoch 38 - iter 90/107 - loss 0.04858542 - samples/sec: 90.82 - lr: 0.001563
2022-05-13 16:52:31,839 epoch 38 - iter 100/107 - loss 0.04890539 - samples/sec: 94.75 - lr: 0.001563
2022-05-13 16:52:33,663 ----------------------------------------------------------------------------------------------------
2022-05-13 16:52:33,663 EPOCH 38 done: loss 0.0489 - lr 0.001563
2022-05-13 16:52:43,473 Evaluating as a multi-label problem: False
2022-05-13 16:52:43,484 DEV : loss 0.20921264588832855 - f1-score (micro avg)  0.5141
2022-05-13 16:52:43,558 BAD EPOCHS (no improvement): 3
2022-05-13 16:52:43,577 ----------------------------------------------------------------------------------------------------
2022-05-13 16:52:47,411 epoch 39 - iter 10/107 - loss 0.04936153 - samples/sec: 83.49 - lr: 0.001563
2022-05-13 16:52:50,963 epoch 39 - iter 20/107 - loss 0.04725969 - samples/sec: 90.11 - lr: 0.001563
2022-05-13 16:52:54,659 epoch 39 - iter 30/107 - loss 0.04883475 - samples/sec: 86.58 - lr: 0.001563
2022-05-13 16:52:58,214 epoch 39 - iter 40/107 - loss 0.04947937 - samples/sec: 90.04 - lr: 0.001563
2022-05-13 16:53:01,528 epoch 39 - iter 50/107 - loss 0.05002384 - samples/sec: 96.61 - lr: 0.001563
2022-05-13 16:53:04,530 epoch 39 - iter 60/107 - loss 0.05133180 - samples/sec: 106.61 - lr: 0.001563
2022-05-13 16:53:07,182 epoch 39 - iter 70/107 - loss 0.04943461 - samples/sec: 120.73 - lr: 0.001563
2022-05-13 16:53:10,108 epoch 39 - iter 80/107 - loss 0.04849868 - samples/sec: 109.41 - lr: 0.001563
2022-05-13 16:53:13,800 epoch 39 - iter 90/107 - loss 0.04928628 - samples/sec: 86.70 - lr: 0.001563
2022-05-13 16:53:17,381 epoch 39 - iter 100/107 - loss 0.04830270 - samples/sec: 89.37 - lr: 0.001563
2022-05-13 16:53:19,708 ----------------------------------------------------------------------------------------------------
2022-05-13 16:53:19,708 EPOCH 39 done: loss 0.0482 - lr 0.001563
2022-05-13 16:53:30,372 Evaluating as a multi-label problem: False
2022-05-13 16:53:30,385 DEV : loss 0.20957216620445251 - f1-score (micro avg)  0.5125
2022-05-13 16:53:30,460 Epoch    39: reducing learning rate of group 0 to 7.8125e-04.
2022-05-13 16:53:30,460 BAD EPOCHS (no improvement): 4
2022-05-13 16:53:30,462 ----------------------------------------------------------------------------------------------------
2022-05-13 16:53:34,089 epoch 40 - iter 10/107 - loss 0.03937708 - samples/sec: 88.25 - lr: 0.000781
2022-05-13 16:53:36,971 epoch 40 - iter 20/107 - loss 0.04256131 - samples/sec: 111.07 - lr: 0.000781
2022-05-13 16:53:40,129 epoch 40 - iter 30/107 - loss 0.04448953 - samples/sec: 101.37 - lr: 0.000781
2022-05-13 16:53:43,805 epoch 40 - iter 40/107 - loss 0.04548466 - samples/sec: 87.07 - lr: 0.000781
2022-05-13 16:53:47,387 epoch 40 - iter 50/107 - loss 0.04373096 - samples/sec: 89.36 - lr: 0.000781
2022-05-13 16:53:50,987 epoch 40 - iter 60/107 - loss 0.04443986 - samples/sec: 88.92 - lr: 0.000781
2022-05-13 16:53:54,757 epoch 40 - iter 70/107 - loss 0.04461060 - samples/sec: 84.89 - lr: 0.000781
2022-05-13 16:53:58,420 epoch 40 - iter 80/107 - loss 0.04465118 - samples/sec: 87.39 - lr: 0.000781
2022-05-13 16:54:02,071 epoch 40 - iter 90/107 - loss 0.04508799 - samples/sec: 87.68 - lr: 0.000781
2022-05-13 16:54:05,471 epoch 40 - iter 100/107 - loss 0.04624165 - samples/sec: 94.14 - lr: 0.000781
2022-05-13 16:54:07,543 ----------------------------------------------------------------------------------------------------
2022-05-13 16:54:07,543 EPOCH 40 done: loss 0.0465 - lr 0.000781
2022-05-13 16:54:17,584 Evaluating as a multi-label problem: False
2022-05-13 16:54:17,595 DEV : loss 0.2082778811454773 - f1-score (micro avg)  0.5132
2022-05-13 16:54:17,668 BAD EPOCHS (no improvement): 1
2022-05-13 16:54:17,670 ----------------------------------------------------------------------------------------------------
2022-05-13 16:54:21,349 epoch 41 - iter 10/107 - loss 0.03871846 - samples/sec: 87.02 - lr: 0.000781
2022-05-13 16:54:28,963 epoch 41 - iter 20/107 - loss 0.04191110 - samples/sec: 42.03 - lr: 0.000781
2022-05-13 16:54:32,631 epoch 41 - iter 30/107 - loss 0.04092904 - samples/sec: 87.25 - lr: 0.000781
2022-05-13 16:54:35,803 epoch 41 - iter 40/107 - loss 0.04615560 - samples/sec: 100.92 - lr: 0.000781
2022-05-13 16:54:38,889 epoch 41 - iter 50/107 - loss 0.04901401 - samples/sec: 103.72 - lr: 0.000781
2022-05-13 16:54:42,040 epoch 41 - iter 60/107 - loss 0.04880308 - samples/sec: 101.60 - lr: 0.000781
2022-05-13 16:54:45,664 epoch 41 - iter 70/107 - loss 0.04927990 - samples/sec: 88.31 - lr: 0.000781
2022-05-13 16:54:49,448 epoch 41 - iter 80/107 - loss 0.04869472 - samples/sec: 84.59 - lr: 0.000781
2022-05-13 16:54:53,067 epoch 41 - iter 90/107 - loss 0.04927226 - samples/sec: 88.46 - lr: 0.000781
2022-05-13 16:54:56,380 epoch 41 - iter 100/107 - loss 0.04838810 - samples/sec: 96.63 - lr: 0.000781
2022-05-13 16:54:58,713 ----------------------------------------------------------------------------------------------------
2022-05-13 16:54:58,713 EPOCH 41 done: loss 0.0481 - lr 0.000781
2022-05-13 16:55:08,756 Evaluating as a multi-label problem: False
2022-05-13 16:55:08,767 DEV : loss 0.20830954611301422 - f1-score (micro avg)  0.5159
2022-05-13 16:55:08,843 BAD EPOCHS (no improvement): 2
2022-05-13 16:55:08,907 ----------------------------------------------------------------------------------------------------
2022-05-13 16:55:12,005 epoch 42 - iter 10/107 - loss 0.04260089 - samples/sec: 103.32 - lr: 0.000781
2022-05-13 16:55:15,676 epoch 42 - iter 20/107 - loss 0.04392674 - samples/sec: 87.19 - lr: 0.000781
2022-05-13 16:55:19,522 epoch 42 - iter 30/107 - loss 0.04941038 - samples/sec: 83.22 - lr: 0.000781
2022-05-13 16:55:23,250 epoch 42 - iter 40/107 - loss 0.04792868 - samples/sec: 85.86 - lr: 0.000781
2022-05-13 16:55:26,904 epoch 42 - iter 50/107 - loss 0.04785992 - samples/sec: 87.60 - lr: 0.000781
2022-05-13 16:55:30,461 epoch 42 - iter 60/107 - loss 0.04802241 - samples/sec: 89.99 - lr: 0.000781
2022-05-13 16:55:34,196 epoch 42 - iter 70/107 - loss 0.04771932 - samples/sec: 85.70 - lr: 0.000781
2022-05-13 16:55:37,621 epoch 42 - iter 80/107 - loss 0.04661664 - samples/sec: 93.48 - lr: 0.000781
2022-05-13 16:55:40,521 epoch 42 - iter 90/107 - loss 0.04723816 - samples/sec: 110.38 - lr: 0.000781
2022-05-13 16:55:43,686 epoch 42 - iter 100/107 - loss 0.04759237 - samples/sec: 101.13 - lr: 0.000781
2022-05-13 16:55:45,793 ----------------------------------------------------------------------------------------------------
2022-05-13 16:55:45,794 EPOCH 42 done: loss 0.0474 - lr 0.000781
2022-05-13 16:55:56,890 Evaluating as a multi-label problem: False
2022-05-13 16:55:56,901 DEV : loss 0.20705541968345642 - f1-score (micro avg)  0.5128
2022-05-13 16:55:56,977 BAD EPOCHS (no improvement): 3
2022-05-13 16:55:56,979 ----------------------------------------------------------------------------------------------------
2022-05-13 16:56:00,725 epoch 43 - iter 10/107 - loss 0.04713483 - samples/sec: 85.45 - lr: 0.000781
2022-05-13 16:56:04,066 epoch 43 - iter 20/107 - loss 0.04955213 - samples/sec: 95.83 - lr: 0.000781
2022-05-13 16:56:07,442 epoch 43 - iter 30/107 - loss 0.04732863 - samples/sec: 94.80 - lr: 0.000781
2022-05-13 16:56:10,404 epoch 43 - iter 40/107 - loss 0.04723569 - samples/sec: 108.06 - lr: 0.000781
2022-05-13 16:56:13,571 epoch 43 - iter 50/107 - loss 0.04704032 - samples/sec: 101.09 - lr: 0.000781
2022-05-13 16:56:17,248 epoch 43 - iter 60/107 - loss 0.04797891 - samples/sec: 87.06 - lr: 0.000781
2022-05-13 16:56:20,905 epoch 43 - iter 70/107 - loss 0.04685624 - samples/sec: 87.52 - lr: 0.000781
2022-05-13 16:56:24,752 epoch 43 - iter 80/107 - loss 0.04615774 - samples/sec: 83.21 - lr: 0.000781
2022-05-13 16:56:28,395 epoch 43 - iter 90/107 - loss 0.04661402 - samples/sec: 87.87 - lr: 0.000781
2022-05-13 16:56:31,842 epoch 43 - iter 100/107 - loss 0.04720691 - samples/sec: 92.87 - lr: 0.000781
2022-05-13 16:56:34,206 ----------------------------------------------------------------------------------------------------
2022-05-13 16:56:34,206 EPOCH 43 done: loss 0.0473 - lr 0.000781
2022-05-13 16:56:43,920 Evaluating as a multi-label problem: False
2022-05-13 16:56:43,931 DEV : loss 0.20733125507831573 - f1-score (micro avg)  0.5144
2022-05-13 16:56:44,008 Epoch    43: reducing learning rate of group 0 to 3.9063e-04.
2022-05-13 16:56:44,008 BAD EPOCHS (no improvement): 4
2022-05-13 16:56:44,010 ----------------------------------------------------------------------------------------------------
2022-05-13 16:56:46,324 epoch 44 - iter 10/107 - loss 0.05177607 - samples/sec: 138.40 - lr: 0.000391
2022-05-13 16:56:48,963 epoch 44 - iter 20/107 - loss 0.04671204 - samples/sec: 121.30 - lr: 0.000391
2022-05-13 16:56:51,409 epoch 44 - iter 30/107 - loss 0.04782000 - samples/sec: 130.87 - lr: 0.000391
2022-05-13 16:56:53,884 epoch 44 - iter 40/107 - loss 0.04768734 - samples/sec: 129.31 - lr: 0.000391
2022-05-13 16:56:56,348 epoch 44 - iter 50/107 - loss 0.04838419 - samples/sec: 129.94 - lr: 0.000391
2022-05-13 16:56:58,751 epoch 44 - iter 60/107 - loss 0.04780045 - samples/sec: 133.19 - lr: 0.000391
2022-05-13 16:57:01,221 epoch 44 - iter 70/107 - loss 0.04789489 - samples/sec: 129.60 - lr: 0.000391
2022-05-13 16:57:03,662 epoch 44 - iter 80/107 - loss 0.04744514 - samples/sec: 131.16 - lr: 0.000391
2022-05-13 16:57:06,169 epoch 44 - iter 90/107 - loss 0.04641676 - samples/sec: 127.69 - lr: 0.000391
2022-05-13 16:57:08,660 epoch 44 - iter 100/107 - loss 0.04622431 - samples/sec: 128.54 - lr: 0.000391
2022-05-13 16:57:10,173 ----------------------------------------------------------------------------------------------------
2022-05-13 16:57:10,173 EPOCH 44 done: loss 0.0457 - lr 0.000391
2022-05-13 16:57:17,959 Evaluating as a multi-label problem: False
2022-05-13 16:57:17,970 DEV : loss 0.20791809260845184 - f1-score (micro avg)  0.5124
2022-05-13 16:57:18,043 BAD EPOCHS (no improvement): 1
2022-05-13 16:57:18,045 ----------------------------------------------------------------------------------------------------
2022-05-13 16:57:21,691 epoch 45 - iter 10/107 - loss 0.05787101 - samples/sec: 87.80 - lr: 0.000391
2022-05-13 16:57:27,599 epoch 45 - iter 20/107 - loss 0.05146707 - samples/sec: 54.17 - lr: 0.000391
2022-05-13 16:57:32,610 epoch 45 - iter 30/107 - loss 0.05118110 - samples/sec: 63.88 - lr: 0.000391
2022-05-13 16:57:38,025 epoch 45 - iter 40/107 - loss 0.04975447 - samples/sec: 59.11 - lr: 0.000391
2022-05-13 16:57:40,869 epoch 45 - iter 50/107 - loss 0.04867327 - samples/sec: 112.53 - lr: 0.000391
2022-05-13 16:57:43,209 epoch 45 - iter 60/107 - loss 0.04856210 - samples/sec: 136.83 - lr: 0.000391
2022-05-13 16:57:45,495 epoch 45 - iter 70/107 - loss 0.04861002 - samples/sec: 140.01 - lr: 0.000391
2022-05-13 16:57:47,758 epoch 45 - iter 80/107 - loss 0.04804553 - samples/sec: 141.47 - lr: 0.000391
2022-05-13 16:57:50,175 epoch 45 - iter 90/107 - loss 0.04846262 - samples/sec: 132.46 - lr: 0.000391
2022-05-13 16:57:52,688 epoch 45 - iter 100/107 - loss 0.04849754 - samples/sec: 127.36 - lr: 0.000391
2022-05-13 16:57:54,238 ----------------------------------------------------------------------------------------------------
2022-05-13 16:57:54,238 EPOCH 45 done: loss 0.0482 - lr 0.000391
2022-05-13 16:58:01,879 Evaluating as a multi-label problem: False
2022-05-13 16:58:01,890 DEV : loss 0.20842485129833221 - f1-score (micro avg)  0.514
2022-05-13 16:58:01,963 BAD EPOCHS (no improvement): 2
2022-05-13 16:58:01,965 ----------------------------------------------------------------------------------------------------
2022-05-13 16:58:04,446 epoch 46 - iter 10/107 - loss 0.04244345 - samples/sec: 129.04 - lr: 0.000391
2022-05-13 16:58:06,913 epoch 46 - iter 20/107 - loss 0.04351753 - samples/sec: 129.79 - lr: 0.000391
2022-05-13 16:58:09,391 epoch 46 - iter 30/107 - loss 0.04579036 - samples/sec: 129.18 - lr: 0.000391
2022-05-13 16:58:11,798 epoch 46 - iter 40/107 - loss 0.04537007 - samples/sec: 133.01 - lr: 0.000391
2022-05-13 16:58:14,277 epoch 46 - iter 50/107 - loss 0.04530177 - samples/sec: 129.11 - lr: 0.000391
2022-05-13 16:58:16,731 epoch 46 - iter 60/107 - loss 0.04605398 - samples/sec: 130.44 - lr: 0.000391
2022-05-13 16:58:19,234 epoch 46 - iter 70/107 - loss 0.04588518 - samples/sec: 127.89 - lr: 0.000391
2022-05-13 16:58:21,769 epoch 46 - iter 80/107 - loss 0.04738995 - samples/sec: 126.30 - lr: 0.000391
2022-05-13 16:58:24,280 epoch 46 - iter 90/107 - loss 0.04712844 - samples/sec: 127.49 - lr: 0.000391
2022-05-13 16:58:26,697 epoch 46 - iter 100/107 - loss 0.04774065 - samples/sec: 132.42 - lr: 0.000391
2022-05-13 16:58:28,147 ----------------------------------------------------------------------------------------------------
2022-05-13 16:58:28,148 EPOCH 46 done: loss 0.0480 - lr 0.000391
2022-05-13 16:58:35,829 Evaluating as a multi-label problem: False
2022-05-13 16:58:35,840 DEV : loss 0.20880767703056335 - f1-score (micro avg)  0.5121
2022-05-13 16:58:35,913 BAD EPOCHS (no improvement): 3
2022-05-13 16:58:35,915 ----------------------------------------------------------------------------------------------------
2022-05-13 16:58:38,315 epoch 47 - iter 10/107 - loss 0.05181819 - samples/sec: 133.43 - lr: 0.000391
2022-05-13 16:58:40,900 epoch 47 - iter 20/107 - loss 0.04976709 - samples/sec: 123.80 - lr: 0.000391
2022-05-13 16:58:43,337 epoch 47 - iter 30/107 - loss 0.04707426 - samples/sec: 131.39 - lr: 0.000391
2022-05-13 16:58:45,712 epoch 47 - iter 40/107 - loss 0.04630244 - samples/sec: 134.79 - lr: 0.000391
2022-05-13 16:58:48,185 epoch 47 - iter 50/107 - loss 0.04445711 - samples/sec: 129.47 - lr: 0.000391
2022-05-13 16:58:50,662 epoch 47 - iter 60/107 - loss 0.04528643 - samples/sec: 129.22 - lr: 0.000391
2022-05-13 16:58:53,055 epoch 47 - iter 70/107 - loss 0.04536382 - samples/sec: 133.78 - lr: 0.000391
2022-05-13 16:58:55,415 epoch 47 - iter 80/107 - loss 0.04550217 - samples/sec: 135.67 - lr: 0.000391
2022-05-13 16:58:57,906 epoch 47 - iter 90/107 - loss 0.04552264 - samples/sec: 128.51 - lr: 0.000391
2022-05-13 16:59:00,386 epoch 47 - iter 100/107 - loss 0.04655304 - samples/sec: 129.04 - lr: 0.000391
2022-05-13 16:59:01,932 ----------------------------------------------------------------------------------------------------
2022-05-13 16:59:01,932 EPOCH 47 done: loss 0.0468 - lr 0.000391
2022-05-13 16:59:09,678 Evaluating as a multi-label problem: False
2022-05-13 16:59:09,689 DEV : loss 0.2091674953699112 - f1-score (micro avg)  0.5113
2022-05-13 16:59:09,763 Epoch    47: reducing learning rate of group 0 to 1.9531e-04.
2022-05-13 16:59:09,763 BAD EPOCHS (no improvement): 4
2022-05-13 16:59:09,766 ----------------------------------------------------------------------------------------------------
2022-05-13 16:59:12,187 epoch 48 - iter 10/107 - loss 0.04641562 - samples/sec: 132.19 - lr: 0.000195
2022-05-13 16:59:14,728 epoch 48 - iter 20/107 - loss 0.04587032 - samples/sec: 126.00 - lr: 0.000195
2022-05-13 16:59:17,304 epoch 48 - iter 30/107 - loss 0.04505736 - samples/sec: 124.25 - lr: 0.000195
2022-05-13 16:59:19,806 epoch 48 - iter 40/107 - loss 0.04466247 - samples/sec: 127.98 - lr: 0.000195
2022-05-13 16:59:22,257 epoch 48 - iter 50/107 - loss 0.04609299 - samples/sec: 130.59 - lr: 0.000195
2022-05-13 16:59:24,726 epoch 48 - iter 60/107 - loss 0.04612032 - samples/sec: 129.68 - lr: 0.000195
2022-05-13 16:59:27,145 epoch 48 - iter 70/107 - loss 0.04732593 - samples/sec: 132.30 - lr: 0.000195
2022-05-13 16:59:29,576 epoch 48 - iter 80/107 - loss 0.04765504 - samples/sec: 131.71 - lr: 0.000195
2022-05-13 16:59:32,086 epoch 48 - iter 90/107 - loss 0.04712133 - samples/sec: 127.56 - lr: 0.000195
2022-05-13 16:59:34,485 epoch 48 - iter 100/107 - loss 0.04668398 - samples/sec: 133.43 - lr: 0.000195
2022-05-13 16:59:35,971 ----------------------------------------------------------------------------------------------------
2022-05-13 16:59:35,971 EPOCH 48 done: loss 0.0469 - lr 0.000195
2022-05-13 16:59:43,542 Evaluating as a multi-label problem: False
2022-05-13 16:59:43,553 DEV : loss 0.20887254178524017 - f1-score (micro avg)  0.5121
2022-05-13 16:59:43,626 BAD EPOCHS (no improvement): 1
2022-05-13 16:59:43,628 ----------------------------------------------------------------------------------------------------
2022-05-13 16:59:46,216 epoch 49 - iter 10/107 - loss 0.03880273 - samples/sec: 123.68 - lr: 0.000195
2022-05-13 16:59:48,728 epoch 49 - iter 20/107 - loss 0.04371153 - samples/sec: 127.46 - lr: 0.000195
2022-05-13 16:59:51,313 epoch 49 - iter 30/107 - loss 0.04615976 - samples/sec: 123.83 - lr: 0.000195
2022-05-13 16:59:53,889 epoch 49 - iter 40/107 - loss 0.04810239 - samples/sec: 124.32 - lr: 0.000195
2022-05-13 16:59:56,452 epoch 49 - iter 50/107 - loss 0.04740920 - samples/sec: 124.89 - lr: 0.000195
2022-05-13 16:59:58,903 epoch 49 - iter 60/107 - loss 0.04636458 - samples/sec: 130.64 - lr: 0.000195
2022-05-13 17:00:01,374 epoch 49 - iter 70/107 - loss 0.04795539 - samples/sec: 129.58 - lr: 0.000195
2022-05-13 17:00:03,875 epoch 49 - iter 80/107 - loss 0.04689420 - samples/sec: 127.99 - lr: 0.000195
2022-05-13 17:00:06,412 epoch 49 - iter 90/107 - loss 0.04606280 - samples/sec: 126.20 - lr: 0.000195
2022-05-13 17:00:08,944 epoch 49 - iter 100/107 - loss 0.04648027 - samples/sec: 126.42 - lr: 0.000195
2022-05-13 17:00:10,448 ----------------------------------------------------------------------------------------------------
2022-05-13 17:00:10,448 EPOCH 49 done: loss 0.0471 - lr 0.000195
2022-05-13 17:00:18,361 Evaluating as a multi-label problem: False
2022-05-13 17:00:18,373 DEV : loss 0.20900428295135498 - f1-score (micro avg)  0.5129
2022-05-13 17:00:18,452 BAD EPOCHS (no improvement): 2
2022-05-13 17:00:18,454 ----------------------------------------------------------------------------------------------------
2022-05-13 17:00:20,997 epoch 50 - iter 10/107 - loss 0.03584407 - samples/sec: 125.93 - lr: 0.000195
2022-05-13 17:00:23,544 epoch 50 - iter 20/107 - loss 0.04134421 - samples/sec: 125.69 - lr: 0.000195
2022-05-13 17:00:26,019 epoch 50 - iter 30/107 - loss 0.04363377 - samples/sec: 129.36 - lr: 0.000195
2022-05-13 17:00:28,539 epoch 50 - iter 40/107 - loss 0.04715428 - samples/sec: 127.04 - lr: 0.000195
2022-05-13 17:00:31,006 epoch 50 - iter 50/107 - loss 0.04904194 - samples/sec: 129.76 - lr: 0.000195
2022-05-13 17:00:33,483 epoch 50 - iter 60/107 - loss 0.04812976 - samples/sec: 129.26 - lr: 0.000195
2022-05-13 17:00:35,958 epoch 50 - iter 70/107 - loss 0.04704952 - samples/sec: 129.36 - lr: 0.000195
2022-05-13 17:00:38,496 epoch 50 - iter 80/107 - loss 0.04714325 - samples/sec: 126.13 - lr: 0.000195
2022-05-13 17:00:41,048 epoch 50 - iter 90/107 - loss 0.04738019 - samples/sec: 125.42 - lr: 0.000195
2022-05-13 17:00:43,593 epoch 50 - iter 100/107 - loss 0.04661368 - samples/sec: 125.82 - lr: 0.000195
2022-05-13 17:00:45,196 ----------------------------------------------------------------------------------------------------
2022-05-13 17:00:45,196 EPOCH 50 done: loss 0.0468 - lr 0.000195
2022-05-13 17:00:52,957 Evaluating as a multi-label problem: False
2022-05-13 17:00:52,969 DEV : loss 0.20970219373703003 - f1-score (micro avg)  0.5117
2022-05-13 17:00:53,045 BAD EPOCHS (no improvement): 3
2022-05-13 17:00:53,047 ----------------------------------------------------------------------------------------------------
2022-05-13 17:00:55,673 epoch 51 - iter 10/107 - loss 0.04615591 - samples/sec: 121.90 - lr: 0.000195
2022-05-13 17:00:58,203 epoch 51 - iter 20/107 - loss 0.04295058 - samples/sec: 126.59 - lr: 0.000195
2022-05-13 17:01:00,746 epoch 51 - iter 30/107 - loss 0.04580624 - samples/sec: 125.84 - lr: 0.000195
2022-05-13 17:01:03,073 epoch 51 - iter 40/107 - loss 0.04686450 - samples/sec: 137.59 - lr: 0.000195
2022-05-13 17:01:05,439 epoch 51 - iter 50/107 - loss 0.04812285 - samples/sec: 135.34 - lr: 0.000195
2022-05-13 17:01:07,762 epoch 51 - iter 60/107 - loss 0.04818882 - samples/sec: 137.77 - lr: 0.000195
2022-05-13 17:01:10,042 epoch 51 - iter 70/107 - loss 0.04775295 - samples/sec: 140.41 - lr: 0.000195
2022-05-13 17:01:12,322 epoch 51 - iter 80/107 - loss 0.04612724 - samples/sec: 140.45 - lr: 0.000195
2022-05-13 17:01:14,654 epoch 51 - iter 90/107 - loss 0.04650601 - samples/sec: 137.29 - lr: 0.000195
2022-05-13 17:01:17,106 epoch 51 - iter 100/107 - loss 0.04589748 - samples/sec: 130.56 - lr: 0.000195
2022-05-13 17:01:18,602 ----------------------------------------------------------------------------------------------------
2022-05-13 17:01:18,602 EPOCH 51 done: loss 0.0462 - lr 0.000195
2022-05-13 17:01:26,341 Evaluating as a multi-label problem: False
2022-05-13 17:01:26,352 DEV : loss 0.2094460427761078 - f1-score (micro avg)  0.5121
2022-05-13 17:01:26,426 Epoch    51: reducing learning rate of group 0 to 9.7656e-05.
2022-05-13 17:01:26,426 BAD EPOCHS (no improvement): 4
2022-05-13 17:01:26,499 ----------------------------------------------------------------------------------------------------
2022-05-13 17:01:26,499 ----------------------------------------------------------------------------------------------------
2022-05-13 17:01:26,499 learning rate too small - quitting training!
2022-05-13 17:01:26,499 ----------------------------------------------------------------------------------------------------
2022-05-13 17:02:02,215 ----------------------------------------------------------------------------------------------------
2022-05-13 17:02:02,216 loading file resources/taggers/model_03_r10_run_4/best-model.pt
2022-05-13 17:02:27,473 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-05-13 17:02:48,008 Evaluating as a multi-label problem: False
2022-05-13 17:02:48,021 0.6501	0.3031	0.4134	0.2759
2022-05-13 17:02:48,021 
Results:
- F-score (micro) 0.4134
- F-score (macro) 0.3114
- Accuracy 0.2759

By class:
               precision    recall  f1-score   support

       person     0.7659    0.4499    0.5668       429
     location     0.6404    0.4867    0.5530       150
        group     0.4627    0.1879    0.2672       165
creative-work     0.5200    0.0915    0.1557       142
      product     0.2857    0.0472    0.0811       127
  corporation     0.4583    0.1667    0.2444        66

    micro avg     0.6501    0.3031    0.4134      1079
    macro avg     0.5222    0.2383    0.3114      1079
 weighted avg     0.5944    0.3031    0.3881      1079

2022-05-13 17:02:48,021 ----------------------------------------------------------------------------------------------------
