2022-05-13 16:47:59,516 ----------------------------------------------------------------------------------------------------
2022-05-13 16:47:59,516 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_3): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4857, out_features=4857, bias=True)
  (rnn): LSTM(4857, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-05-13 16:47:59,516 ----------------------------------------------------------------------------------------------------
2022-05-13 16:47:59,516 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-05-13 16:47:59,517 ----------------------------------------------------------------------------------------------------
2022-05-13 16:47:59,517 Parameters:
2022-05-13 16:47:59,517  - learning_rate: "0.100000"
2022-05-13 16:47:59,517  - mini_batch_size: "32"
2022-05-13 16:47:59,517  - patience: "3"
2022-05-13 16:47:59,517  - anneal_factor: "0.5"
2022-05-13 16:47:59,517  - max_epochs: "150"
2022-05-13 16:47:59,517  - shuffle: "True"
2022-05-13 16:47:59,517  - train_with_dev: "False"
2022-05-13 16:47:59,517  - batch_growth_annealing: "False"
2022-05-13 16:47:59,517 ----------------------------------------------------------------------------------------------------
2022-05-13 16:47:59,517 Model training base path: "resources/taggers/model_08_r10_run_5"
2022-05-13 16:47:59,517 ----------------------------------------------------------------------------------------------------
2022-05-13 16:47:59,517 Device: cuda:2
2022-05-13 16:47:59,517 ----------------------------------------------------------------------------------------------------
2022-05-13 16:47:59,517 Embeddings storage mode: cpu
2022-05-13 16:47:59,517 ----------------------------------------------------------------------------------------------------
2022-05-13 16:48:03,333 epoch 1 - iter 10/107 - loss 1.07660140 - samples/sec: 83.88 - lr: 0.100000
2022-05-13 16:48:07,321 epoch 1 - iter 20/107 - loss 0.68224859 - samples/sec: 80.26 - lr: 0.100000
2022-05-13 16:48:10,944 epoch 1 - iter 30/107 - loss 0.55343073 - samples/sec: 88.37 - lr: 0.100000
2022-05-13 16:48:13,870 epoch 1 - iter 40/107 - loss 0.48090213 - samples/sec: 109.40 - lr: 0.100000
2022-05-13 16:48:16,548 epoch 1 - iter 50/107 - loss 0.42798780 - samples/sec: 119.52 - lr: 0.100000
2022-05-13 16:48:19,619 epoch 1 - iter 60/107 - loss 0.40588828 - samples/sec: 104.24 - lr: 0.100000
2022-05-13 16:48:23,154 epoch 1 - iter 70/107 - loss 0.39002238 - samples/sec: 90.56 - lr: 0.100000
2022-05-13 16:48:26,838 epoch 1 - iter 80/107 - loss 0.37962391 - samples/sec: 86.88 - lr: 0.100000
2022-05-13 16:48:29,897 epoch 1 - iter 90/107 - loss 0.37257024 - samples/sec: 104.65 - lr: 0.100000
2022-05-13 16:48:32,915 epoch 1 - iter 100/107 - loss 0.36492821 - samples/sec: 106.06 - lr: 0.100000
2022-05-13 16:48:34,810 ----------------------------------------------------------------------------------------------------
2022-05-13 16:48:34,811 EPOCH 1 done: loss 0.3573 - lr 0.100000
2022-05-13 16:48:45,555 Evaluating as a multi-label problem: False
2022-05-13 16:48:45,564 DEV : loss 0.5069933533668518 - f1-score (micro avg)  0.0687
2022-05-13 16:48:45,650 BAD EPOCHS (no improvement): 0
2022-05-13 16:48:45,652 saving best model
2022-05-13 16:49:00,965 ----------------------------------------------------------------------------------------------------
2022-05-13 16:49:04,401 epoch 2 - iter 10/107 - loss 0.20970335 - samples/sec: 93.19 - lr: 0.100000
2022-05-13 16:49:08,031 epoch 2 - iter 20/107 - loss 0.21207505 - samples/sec: 88.20 - lr: 0.100000
2022-05-13 16:49:11,748 epoch 2 - iter 30/107 - loss 0.21238844 - samples/sec: 86.12 - lr: 0.100000
2022-05-13 16:49:15,553 epoch 2 - iter 40/107 - loss 0.20975157 - samples/sec: 84.12 - lr: 0.100000
2022-05-13 16:49:19,269 epoch 2 - iter 50/107 - loss 0.20756158 - samples/sec: 86.15 - lr: 0.100000
2022-05-13 16:49:22,703 epoch 2 - iter 60/107 - loss 0.20574573 - samples/sec: 93.21 - lr: 0.100000
2022-05-13 16:49:26,095 epoch 2 - iter 70/107 - loss 0.20347719 - samples/sec: 94.35 - lr: 0.100000
2022-05-13 16:49:28,821 epoch 2 - iter 80/107 - loss 0.19874073 - samples/sec: 117.45 - lr: 0.100000
2022-05-13 16:49:31,575 epoch 2 - iter 90/107 - loss 0.19613274 - samples/sec: 116.23 - lr: 0.100000
2022-05-13 16:49:34,904 epoch 2 - iter 100/107 - loss 0.19338831 - samples/sec: 96.15 - lr: 0.100000
2022-05-13 16:49:37,014 ----------------------------------------------------------------------------------------------------
2022-05-13 16:49:37,014 EPOCH 2 done: loss 0.1918 - lr 0.100000
2022-05-13 16:49:47,252 Evaluating as a multi-label problem: False
2022-05-13 16:49:47,262 DEV : loss 0.3451326787471771 - f1-score (micro avg)  0.3054
2022-05-13 16:49:47,346 BAD EPOCHS (no improvement): 0
2022-05-13 16:49:47,350 saving best model
2022-05-13 16:50:02,251 ----------------------------------------------------------------------------------------------------
2022-05-13 16:50:05,667 epoch 3 - iter 10/107 - loss 0.15384907 - samples/sec: 93.71 - lr: 0.100000
2022-05-13 16:50:09,246 epoch 3 - iter 20/107 - loss 0.17058445 - samples/sec: 89.45 - lr: 0.100000
2022-05-13 16:50:12,873 epoch 3 - iter 30/107 - loss 0.16616638 - samples/sec: 88.26 - lr: 0.100000
2022-05-13 16:50:16,616 epoch 3 - iter 40/107 - loss 0.16453652 - samples/sec: 85.50 - lr: 0.100000
2022-05-13 16:50:20,315 epoch 3 - iter 50/107 - loss 0.16419385 - samples/sec: 86.55 - lr: 0.100000
2022-05-13 16:50:24,172 epoch 3 - iter 60/107 - loss 0.16770683 - samples/sec: 82.97 - lr: 0.100000
2022-05-13 16:50:27,951 epoch 3 - iter 70/107 - loss 0.16427609 - samples/sec: 84.72 - lr: 0.100000
2022-05-13 16:50:31,575 epoch 3 - iter 80/107 - loss 0.16063852 - samples/sec: 88.33 - lr: 0.100000
2022-05-13 16:50:35,466 epoch 3 - iter 90/107 - loss 0.15782096 - samples/sec: 82.27 - lr: 0.100000
2022-05-13 16:50:38,938 epoch 3 - iter 100/107 - loss 0.16078642 - samples/sec: 92.19 - lr: 0.100000
2022-05-13 16:50:40,624 ----------------------------------------------------------------------------------------------------
2022-05-13 16:50:40,624 EPOCH 3 done: loss 0.1584 - lr 0.100000
2022-05-13 16:50:49,586 Evaluating as a multi-label problem: False
2022-05-13 16:50:49,596 DEV : loss 0.30810412764549255 - f1-score (micro avg)  0.3835
2022-05-13 16:50:49,681 BAD EPOCHS (no improvement): 0
2022-05-13 16:50:49,684 saving best model
2022-05-13 16:51:04,678 ----------------------------------------------------------------------------------------------------
2022-05-13 16:51:07,873 epoch 4 - iter 10/107 - loss 0.15437998 - samples/sec: 100.21 - lr: 0.100000
2022-05-13 16:51:10,612 epoch 4 - iter 20/107 - loss 0.15099156 - samples/sec: 116.85 - lr: 0.100000
2022-05-13 16:51:13,332 epoch 4 - iter 30/107 - loss 0.15132464 - samples/sec: 117.72 - lr: 0.100000
2022-05-13 16:51:16,991 epoch 4 - iter 40/107 - loss 0.15535609 - samples/sec: 87.48 - lr: 0.100000
2022-05-13 16:51:20,603 epoch 4 - iter 50/107 - loss 0.15026389 - samples/sec: 88.62 - lr: 0.100000
2022-05-13 16:51:24,228 epoch 4 - iter 60/107 - loss 0.14760532 - samples/sec: 88.30 - lr: 0.100000
2022-05-13 16:51:27,994 epoch 4 - iter 70/107 - loss 0.14400998 - samples/sec: 85.01 - lr: 0.100000
2022-05-13 16:51:31,591 epoch 4 - iter 80/107 - loss 0.14383316 - samples/sec: 88.99 - lr: 0.100000
2022-05-13 16:51:34,977 epoch 4 - iter 90/107 - loss 0.14255868 - samples/sec: 94.55 - lr: 0.100000
2022-05-13 16:51:38,703 epoch 4 - iter 100/107 - loss 0.14228130 - samples/sec: 85.89 - lr: 0.100000
2022-05-13 16:51:40,688 ----------------------------------------------------------------------------------------------------
2022-05-13 16:51:40,689 EPOCH 4 done: loss 0.1398 - lr 0.100000
2022-05-13 16:51:50,125 Evaluating as a multi-label problem: False
2022-05-13 16:51:50,137 DEV : loss 0.2560500502586365 - f1-score (micro avg)  0.5004
2022-05-13 16:51:50,222 BAD EPOCHS (no improvement): 0
2022-05-13 16:51:50,225 saving best model
2022-05-13 16:52:05,576 ----------------------------------------------------------------------------------------------------
2022-05-13 16:52:09,235 epoch 5 - iter 10/107 - loss 0.14154828 - samples/sec: 87.47 - lr: 0.100000
2022-05-13 16:52:12,643 epoch 5 - iter 20/107 - loss 0.12872556 - samples/sec: 93.94 - lr: 0.100000
2022-05-13 16:52:16,574 epoch 5 - iter 30/107 - loss 0.12239982 - samples/sec: 81.44 - lr: 0.100000
2022-05-13 16:52:19,608 epoch 5 - iter 40/107 - loss 0.12973882 - samples/sec: 105.50 - lr: 0.100000
2022-05-13 16:52:22,252 epoch 5 - iter 50/107 - loss 0.12622779 - samples/sec: 121.10 - lr: 0.100000
2022-05-13 16:52:24,961 epoch 5 - iter 60/107 - loss 0.12651206 - samples/sec: 118.19 - lr: 0.100000
2022-05-13 16:52:28,638 epoch 5 - iter 70/107 - loss 0.12629684 - samples/sec: 87.04 - lr: 0.100000
2022-05-13 16:52:32,594 epoch 5 - iter 80/107 - loss 0.12799560 - samples/sec: 80.92 - lr: 0.100000
2022-05-13 16:52:36,068 epoch 5 - iter 90/107 - loss 0.12883107 - samples/sec: 92.15 - lr: 0.100000
2022-05-13 16:52:39,748 epoch 5 - iter 100/107 - loss 0.13005641 - samples/sec: 86.96 - lr: 0.100000
2022-05-13 16:52:41,850 ----------------------------------------------------------------------------------------------------
2022-05-13 16:52:41,850 EPOCH 5 done: loss 0.1294 - lr 0.100000
2022-05-13 16:52:52,362 Evaluating as a multi-label problem: False
2022-05-13 16:52:52,374 DEV : loss 0.23304758965969086 - f1-score (micro avg)  0.4928
2022-05-13 16:52:52,460 BAD EPOCHS (no improvement): 1
2022-05-13 16:52:52,462 ----------------------------------------------------------------------------------------------------
2022-05-13 16:52:56,231 epoch 6 - iter 10/107 - loss 0.10739580 - samples/sec: 84.95 - lr: 0.100000
2022-05-13 16:52:59,387 epoch 6 - iter 20/107 - loss 0.10949327 - samples/sec: 101.44 - lr: 0.100000
2022-05-13 16:53:02,241 epoch 6 - iter 30/107 - loss 0.11974433 - samples/sec: 112.14 - lr: 0.100000
2022-05-13 16:53:04,910 epoch 6 - iter 40/107 - loss 0.11797158 - samples/sec: 119.98 - lr: 0.100000
2022-05-13 16:53:08,064 epoch 6 - iter 50/107 - loss 0.12051707 - samples/sec: 101.47 - lr: 0.100000
2022-05-13 16:53:11,629 epoch 6 - iter 60/107 - loss 0.11942431 - samples/sec: 89.80 - lr: 0.100000
2022-05-13 16:53:15,314 epoch 6 - iter 70/107 - loss 0.11812814 - samples/sec: 86.87 - lr: 0.100000
2022-05-13 16:53:18,839 epoch 6 - iter 80/107 - loss 0.11880292 - samples/sec: 90.80 - lr: 0.100000
2022-05-13 16:53:22,606 epoch 6 - iter 90/107 - loss 0.11941708 - samples/sec: 84.97 - lr: 0.100000
2022-05-13 16:53:26,384 epoch 6 - iter 100/107 - loss 0.11831541 - samples/sec: 84.72 - lr: 0.100000
2022-05-13 16:53:28,239 ----------------------------------------------------------------------------------------------------
2022-05-13 16:53:28,239 EPOCH 6 done: loss 0.1178 - lr 0.100000
2022-05-13 16:53:39,849 Evaluating as a multi-label problem: False
2022-05-13 16:53:39,860 DEV : loss 0.21960888803005219 - f1-score (micro avg)  0.4943
2022-05-13 16:53:39,947 BAD EPOCHS (no improvement): 2
2022-05-13 16:53:39,949 ----------------------------------------------------------------------------------------------------
2022-05-13 16:53:42,241 epoch 7 - iter 10/107 - loss 0.13188037 - samples/sec: 139.71 - lr: 0.100000
2022-05-13 16:53:44,755 epoch 7 - iter 20/107 - loss 0.11717761 - samples/sec: 127.33 - lr: 0.100000
2022-05-13 16:53:47,709 epoch 7 - iter 30/107 - loss 0.11791809 - samples/sec: 108.37 - lr: 0.100000
2022-05-13 16:53:51,103 epoch 7 - iter 40/107 - loss 0.11103350 - samples/sec: 94.33 - lr: 0.100000
2022-05-13 16:53:55,212 epoch 7 - iter 50/107 - loss 0.10811255 - samples/sec: 77.90 - lr: 0.100000
2022-05-13 16:53:59,184 epoch 7 - iter 60/107 - loss 0.10789930 - samples/sec: 80.58 - lr: 0.100000
2022-05-13 16:54:02,705 epoch 7 - iter 70/107 - loss 0.10967676 - samples/sec: 90.92 - lr: 0.100000
2022-05-13 16:54:06,323 epoch 7 - iter 80/107 - loss 0.10933441 - samples/sec: 88.48 - lr: 0.100000
2022-05-13 16:54:10,089 epoch 7 - iter 90/107 - loss 0.10947510 - samples/sec: 85.00 - lr: 0.100000
2022-05-13 16:54:13,715 epoch 7 - iter 100/107 - loss 0.10951196 - samples/sec: 88.26 - lr: 0.100000
2022-05-13 16:54:15,907 ----------------------------------------------------------------------------------------------------
2022-05-13 16:54:15,907 EPOCH 7 done: loss 0.1084 - lr 0.100000
2022-05-13 16:54:25,689 Evaluating as a multi-label problem: False
2022-05-13 16:54:25,700 DEV : loss 0.25048932433128357 - f1-score (micro avg)  0.4713
2022-05-13 16:54:25,786 BAD EPOCHS (no improvement): 3
2022-05-13 16:54:25,788 ----------------------------------------------------------------------------------------------------
2022-05-13 16:54:28,572 epoch 8 - iter 10/107 - loss 0.12085905 - samples/sec: 114.98 - lr: 0.100000
2022-05-13 16:54:32,089 epoch 8 - iter 20/107 - loss 0.10052070 - samples/sec: 91.02 - lr: 0.100000
2022-05-13 16:54:35,750 epoch 8 - iter 30/107 - loss 0.10081238 - samples/sec: 87.44 - lr: 0.100000
2022-05-13 16:54:39,274 epoch 8 - iter 40/107 - loss 0.09706232 - samples/sec: 90.85 - lr: 0.100000
2022-05-13 16:54:42,829 epoch 8 - iter 50/107 - loss 0.09745570 - samples/sec: 90.02 - lr: 0.100000
2022-05-13 16:54:46,284 epoch 8 - iter 60/107 - loss 0.09447847 - samples/sec: 92.67 - lr: 0.100000
2022-05-13 16:54:49,533 epoch 8 - iter 70/107 - loss 0.09746166 - samples/sec: 98.51 - lr: 0.100000
2022-05-13 16:54:53,090 epoch 8 - iter 80/107 - loss 0.10237764 - samples/sec: 89.99 - lr: 0.100000
2022-05-13 16:54:56,665 epoch 8 - iter 90/107 - loss 0.10364449 - samples/sec: 89.54 - lr: 0.100000
2022-05-13 16:55:00,422 epoch 8 - iter 100/107 - loss 0.10409421 - samples/sec: 85.21 - lr: 0.100000
2022-05-13 16:55:02,812 ----------------------------------------------------------------------------------------------------
2022-05-13 16:55:02,812 EPOCH 8 done: loss 0.1039 - lr 0.100000
2022-05-13 16:55:10,455 Evaluating as a multi-label problem: False
2022-05-13 16:55:10,466 DEV : loss 0.27039963006973267 - f1-score (micro avg)  0.4437
2022-05-13 16:55:10,552 Epoch     8: reducing learning rate of group 0 to 5.0000e-02.
2022-05-13 16:55:10,552 BAD EPOCHS (no improvement): 4
2022-05-13 16:55:10,553 ----------------------------------------------------------------------------------------------------
2022-05-13 16:55:14,474 epoch 9 - iter 10/107 - loss 0.09717223 - samples/sec: 81.65 - lr: 0.050000
2022-05-13 16:55:18,157 epoch 9 - iter 20/107 - loss 0.09731377 - samples/sec: 86.89 - lr: 0.050000
2022-05-13 16:55:21,761 epoch 9 - iter 30/107 - loss 0.09051124 - samples/sec: 88.82 - lr: 0.050000
2022-05-13 16:55:25,250 epoch 9 - iter 40/107 - loss 0.09118239 - samples/sec: 91.77 - lr: 0.050000
2022-05-13 16:55:28,594 epoch 9 - iter 50/107 - loss 0.09022573 - samples/sec: 95.71 - lr: 0.050000
2022-05-13 16:55:32,375 epoch 9 - iter 60/107 - loss 0.09091657 - samples/sec: 84.67 - lr: 0.050000
2022-05-13 16:55:35,981 epoch 9 - iter 70/107 - loss 0.09125897 - samples/sec: 88.75 - lr: 0.050000
2022-05-13 16:55:39,463 epoch 9 - iter 80/107 - loss 0.09170527 - samples/sec: 91.94 - lr: 0.050000
2022-05-13 16:55:43,288 epoch 9 - iter 90/107 - loss 0.09130824 - samples/sec: 83.69 - lr: 0.050000
2022-05-13 16:55:46,507 epoch 9 - iter 100/107 - loss 0.09082380 - samples/sec: 99.42 - lr: 0.050000
2022-05-13 16:55:48,233 ----------------------------------------------------------------------------------------------------
2022-05-13 16:55:48,233 EPOCH 9 done: loss 0.0901 - lr 0.050000
2022-05-13 16:55:57,239 Evaluating as a multi-label problem: False
2022-05-13 16:55:57,250 DEV : loss 0.23670640587806702 - f1-score (micro avg)  0.4522
2022-05-13 16:55:57,336 BAD EPOCHS (no improvement): 1
2022-05-13 16:55:57,339 ----------------------------------------------------------------------------------------------------
2022-05-13 16:56:00,778 epoch 10 - iter 10/107 - loss 0.06308239 - samples/sec: 93.09 - lr: 0.050000
2022-05-13 16:56:04,453 epoch 10 - iter 20/107 - loss 0.07456501 - samples/sec: 87.09 - lr: 0.050000
2022-05-13 16:56:07,979 epoch 10 - iter 30/107 - loss 0.07779899 - samples/sec: 90.76 - lr: 0.050000
2022-05-13 16:56:11,595 epoch 10 - iter 40/107 - loss 0.07954366 - samples/sec: 88.54 - lr: 0.050000
2022-05-13 16:56:15,229 epoch 10 - iter 50/107 - loss 0.08023769 - samples/sec: 88.09 - lr: 0.050000
2022-05-13 16:56:18,949 epoch 10 - iter 60/107 - loss 0.08298479 - samples/sec: 86.04 - lr: 0.050000
2022-05-13 16:56:22,439 epoch 10 - iter 70/107 - loss 0.08252802 - samples/sec: 91.72 - lr: 0.050000
2022-05-13 16:56:25,558 epoch 10 - iter 80/107 - loss 0.08654674 - samples/sec: 102.64 - lr: 0.050000
2022-05-13 16:56:28,595 epoch 10 - iter 90/107 - loss 0.08660499 - samples/sec: 105.38 - lr: 0.050000
2022-05-13 16:56:31,305 epoch 10 - iter 100/107 - loss 0.08740996 - samples/sec: 118.16 - lr: 0.050000
2022-05-13 16:56:33,071 ----------------------------------------------------------------------------------------------------
2022-05-13 16:56:33,072 EPOCH 10 done: loss 0.0872 - lr 0.050000
2022-05-13 16:56:43,547 Evaluating as a multi-label problem: False
2022-05-13 16:56:43,558 DEV : loss 0.2079469859600067 - f1-score (micro avg)  0.5429
2022-05-13 16:56:43,642 BAD EPOCHS (no improvement): 0
2022-05-13 16:56:43,658 saving best model
2022-05-13 16:56:59,071 ----------------------------------------------------------------------------------------------------
2022-05-13 16:57:01,795 epoch 11 - iter 10/107 - loss 0.09360572 - samples/sec: 117.56 - lr: 0.050000
2022-05-13 16:57:05,034 epoch 11 - iter 20/107 - loss 0.07778062 - samples/sec: 98.85 - lr: 0.050000
2022-05-13 16:57:08,756 epoch 11 - iter 30/107 - loss 0.08481337 - samples/sec: 85.98 - lr: 0.050000
2022-05-13 16:57:12,186 epoch 11 - iter 40/107 - loss 0.08583937 - samples/sec: 93.32 - lr: 0.050000
2022-05-13 16:57:15,320 epoch 11 - iter 50/107 - loss 0.08242011 - samples/sec: 102.15 - lr: 0.050000
2022-05-13 16:57:19,328 epoch 11 - iter 60/107 - loss 0.08356647 - samples/sec: 79.87 - lr: 0.050000
2022-05-13 16:57:22,927 epoch 11 - iter 70/107 - loss 0.08310606 - samples/sec: 88.94 - lr: 0.050000
2022-05-13 16:57:26,690 epoch 11 - iter 80/107 - loss 0.08308705 - samples/sec: 85.05 - lr: 0.050000
2022-05-13 16:57:30,053 epoch 11 - iter 90/107 - loss 0.08279692 - samples/sec: 95.20 - lr: 0.050000
2022-05-13 16:57:33,789 epoch 11 - iter 100/107 - loss 0.08253509 - samples/sec: 85.66 - lr: 0.050000
2022-05-13 16:57:35,997 ----------------------------------------------------------------------------------------------------
2022-05-13 16:57:35,997 EPOCH 11 done: loss 0.0826 - lr 0.050000
2022-05-13 16:57:43,402 Evaluating as a multi-label problem: False
2022-05-13 16:57:43,412 DEV : loss 0.20585843920707703 - f1-score (micro avg)  0.5125
2022-05-13 16:57:43,501 BAD EPOCHS (no improvement): 1
2022-05-13 16:57:43,502 ----------------------------------------------------------------------------------------------------
2022-05-13 16:57:46,915 epoch 12 - iter 10/107 - loss 0.06525409 - samples/sec: 93.81 - lr: 0.050000
2022-05-13 16:57:50,489 epoch 12 - iter 20/107 - loss 0.06551815 - samples/sec: 89.58 - lr: 0.050000
2022-05-13 16:57:54,418 epoch 12 - iter 30/107 - loss 0.06834634 - samples/sec: 81.46 - lr: 0.050000
2022-05-13 16:57:58,218 epoch 12 - iter 40/107 - loss 0.07156960 - samples/sec: 84.24 - lr: 0.050000
2022-05-13 16:58:01,718 epoch 12 - iter 50/107 - loss 0.07837758 - samples/sec: 91.45 - lr: 0.050000
2022-05-13 16:58:05,575 epoch 12 - iter 60/107 - loss 0.07598669 - samples/sec: 82.98 - lr: 0.050000
2022-05-13 16:58:09,334 epoch 12 - iter 70/107 - loss 0.07568566 - samples/sec: 85.16 - lr: 0.050000
2022-05-13 16:58:12,985 epoch 12 - iter 80/107 - loss 0.07671947 - samples/sec: 87.68 - lr: 0.050000
2022-05-13 16:58:16,305 epoch 12 - iter 90/107 - loss 0.07833276 - samples/sec: 96.41 - lr: 0.050000
2022-05-13 16:58:19,852 epoch 12 - iter 100/107 - loss 0.07827195 - samples/sec: 90.25 - lr: 0.050000
2022-05-13 16:58:21,469 ----------------------------------------------------------------------------------------------------
2022-05-13 16:58:21,469 EPOCH 12 done: loss 0.0778 - lr 0.050000
2022-05-13 16:58:32,660 Evaluating as a multi-label problem: False
2022-05-13 16:58:32,671 DEV : loss 0.21257755160331726 - f1-score (micro avg)  0.51
2022-05-13 16:58:32,756 BAD EPOCHS (no improvement): 2
2022-05-13 16:58:32,758 ----------------------------------------------------------------------------------------------------
2022-05-13 16:58:36,528 epoch 13 - iter 10/107 - loss 0.07863131 - samples/sec: 84.92 - lr: 0.050000
2022-05-13 16:58:39,968 epoch 13 - iter 20/107 - loss 0.07721440 - samples/sec: 93.06 - lr: 0.050000
2022-05-13 16:58:43,248 epoch 13 - iter 30/107 - loss 0.07786360 - samples/sec: 97.60 - lr: 0.050000
2022-05-13 16:58:46,646 epoch 13 - iter 40/107 - loss 0.07871277 - samples/sec: 94.21 - lr: 0.050000
2022-05-13 16:58:50,080 epoch 13 - iter 50/107 - loss 0.07657991 - samples/sec: 93.22 - lr: 0.050000
2022-05-13 16:58:53,852 epoch 13 - iter 60/107 - loss 0.07556887 - samples/sec: 84.85 - lr: 0.050000
2022-05-13 16:58:57,719 epoch 13 - iter 70/107 - loss 0.07445052 - samples/sec: 82.77 - lr: 0.050000
2022-05-13 16:59:00,723 epoch 13 - iter 80/107 - loss 0.07609307 - samples/sec: 106.58 - lr: 0.050000
2022-05-13 16:59:03,400 epoch 13 - iter 90/107 - loss 0.07531209 - samples/sec: 119.56 - lr: 0.050000
2022-05-13 16:59:06,330 epoch 13 - iter 100/107 - loss 0.07542685 - samples/sec: 109.26 - lr: 0.050000
2022-05-13 16:59:08,700 ----------------------------------------------------------------------------------------------------
2022-05-13 16:59:08,700 EPOCH 13 done: loss 0.0749 - lr 0.050000
2022-05-13 16:59:19,864 Evaluating as a multi-label problem: False
2022-05-13 16:59:19,875 DEV : loss 0.19966302812099457 - f1-score (micro avg)  0.5055
2022-05-13 16:59:19,961 BAD EPOCHS (no improvement): 3
2022-05-13 16:59:19,963 ----------------------------------------------------------------------------------------------------
2022-05-13 16:59:23,920 epoch 14 - iter 10/107 - loss 0.07186048 - samples/sec: 80.90 - lr: 0.050000
2022-05-13 16:59:27,351 epoch 14 - iter 20/107 - loss 0.07931072 - samples/sec: 93.31 - lr: 0.050000
2022-05-13 16:59:31,361 epoch 14 - iter 30/107 - loss 0.07595408 - samples/sec: 79.83 - lr: 0.050000
2022-05-13 16:59:34,822 epoch 14 - iter 40/107 - loss 0.07521210 - samples/sec: 92.47 - lr: 0.050000
2022-05-13 16:59:38,164 epoch 14 - iter 50/107 - loss 0.07383755 - samples/sec: 95.80 - lr: 0.050000
2022-05-13 16:59:41,249 epoch 14 - iter 60/107 - loss 0.07420534 - samples/sec: 103.76 - lr: 0.050000
2022-05-13 16:59:43,984 epoch 14 - iter 70/107 - loss 0.07490422 - samples/sec: 117.04 - lr: 0.050000
2022-05-13 16:59:46,671 epoch 14 - iter 80/107 - loss 0.07329648 - samples/sec: 119.15 - lr: 0.050000
2022-05-13 16:59:49,880 epoch 14 - iter 90/107 - loss 0.07234866 - samples/sec: 99.74 - lr: 0.050000
2022-05-13 16:59:53,576 epoch 14 - iter 100/107 - loss 0.07372652 - samples/sec: 86.60 - lr: 0.050000
2022-05-13 16:59:55,873 ----------------------------------------------------------------------------------------------------
2022-05-13 16:59:55,873 EPOCH 14 done: loss 0.0740 - lr 0.050000
2022-05-13 17:00:06,225 Evaluating as a multi-label problem: False
2022-05-13 17:00:06,236 DEV : loss 0.1939743608236313 - f1-score (micro avg)  0.5266
2022-05-13 17:00:06,320 Epoch    14: reducing learning rate of group 0 to 2.5000e-02.
2022-05-13 17:00:06,321 BAD EPOCHS (no improvement): 4
2022-05-13 17:00:06,323 ----------------------------------------------------------------------------------------------------
2022-05-13 17:00:09,739 epoch 15 - iter 10/107 - loss 0.06465488 - samples/sec: 93.69 - lr: 0.025000
2022-05-13 17:00:13,321 epoch 15 - iter 20/107 - loss 0.06218847 - samples/sec: 89.39 - lr: 0.025000
2022-05-13 17:00:17,028 epoch 15 - iter 30/107 - loss 0.06413834 - samples/sec: 86.34 - lr: 0.025000
2022-05-13 17:00:20,659 epoch 15 - iter 40/107 - loss 0.06435202 - samples/sec: 88.15 - lr: 0.025000
2022-05-13 17:00:23,264 epoch 15 - iter 50/107 - loss 0.06670465 - samples/sec: 122.91 - lr: 0.025000
2022-05-13 17:00:25,975 epoch 15 - iter 60/107 - loss 0.06688384 - samples/sec: 118.10 - lr: 0.025000
2022-05-13 17:00:28,854 epoch 15 - iter 70/107 - loss 0.06766429 - samples/sec: 111.19 - lr: 0.025000
2022-05-13 17:00:32,906 epoch 15 - iter 80/107 - loss 0.06675350 - samples/sec: 78.98 - lr: 0.025000
2022-05-13 17:00:36,489 epoch 15 - iter 90/107 - loss 0.06595987 - samples/sec: 89.34 - lr: 0.025000
2022-05-13 17:00:40,363 epoch 15 - iter 100/107 - loss 0.06651201 - samples/sec: 82.63 - lr: 0.025000
2022-05-13 17:00:42,353 ----------------------------------------------------------------------------------------------------
2022-05-13 17:00:42,353 EPOCH 15 done: loss 0.0655 - lr 0.025000
2022-05-13 17:00:52,970 Evaluating as a multi-label problem: False
2022-05-13 17:00:52,981 DEV : loss 0.2120388150215149 - f1-score (micro avg)  0.5149
2022-05-13 17:00:53,067 BAD EPOCHS (no improvement): 1
2022-05-13 17:00:53,070 ----------------------------------------------------------------------------------------------------
2022-05-13 17:00:56,532 epoch 16 - iter 10/107 - loss 0.07606483 - samples/sec: 92.47 - lr: 0.025000
2022-05-13 17:01:00,360 epoch 16 - iter 20/107 - loss 0.07277436 - samples/sec: 83.64 - lr: 0.025000
2022-05-13 17:01:03,280 epoch 16 - iter 30/107 - loss 0.07448140 - samples/sec: 109.62 - lr: 0.025000
2022-05-13 17:01:05,993 epoch 16 - iter 40/107 - loss 0.06942252 - samples/sec: 117.98 - lr: 0.025000
2022-05-13 17:01:08,854 epoch 16 - iter 50/107 - loss 0.06834420 - samples/sec: 111.90 - lr: 0.025000
2022-05-13 17:01:12,205 epoch 16 - iter 60/107 - loss 0.06708949 - samples/sec: 95.55 - lr: 0.025000
2022-05-13 17:01:15,957 epoch 16 - iter 70/107 - loss 0.06854419 - samples/sec: 85.29 - lr: 0.025000
2022-05-13 17:01:19,811 epoch 16 - iter 80/107 - loss 0.06665441 - samples/sec: 83.07 - lr: 0.025000
2022-05-13 17:01:23,546 epoch 16 - iter 90/107 - loss 0.06568988 - samples/sec: 85.68 - lr: 0.025000
2022-05-13 17:01:27,228 epoch 16 - iter 100/107 - loss 0.06675158 - samples/sec: 86.94 - lr: 0.025000
2022-05-13 17:01:29,691 ----------------------------------------------------------------------------------------------------
2022-05-13 17:01:29,691 EPOCH 16 done: loss 0.0666 - lr 0.025000
2022-05-13 17:01:40,302 Evaluating as a multi-label problem: False
2022-05-13 17:01:40,313 DEV : loss 0.19431757926940918 - f1-score (micro avg)  0.5382
2022-05-13 17:01:40,397 BAD EPOCHS (no improvement): 2
2022-05-13 17:01:40,401 ----------------------------------------------------------------------------------------------------
2022-05-13 17:01:43,376 epoch 17 - iter 10/107 - loss 0.05789818 - samples/sec: 107.61 - lr: 0.025000
2022-05-13 17:01:46,065 epoch 17 - iter 20/107 - loss 0.06351034 - samples/sec: 119.05 - lr: 0.025000
2022-05-13 17:01:48,705 epoch 17 - iter 30/107 - loss 0.06275030 - samples/sec: 121.27 - lr: 0.025000
2022-05-13 17:01:52,175 epoch 17 - iter 40/107 - loss 0.06105051 - samples/sec: 92.27 - lr: 0.025000
2022-05-13 17:01:55,930 epoch 17 - iter 50/107 - loss 0.06499942 - samples/sec: 85.24 - lr: 0.025000
2022-05-13 17:01:59,544 epoch 17 - iter 60/107 - loss 0.06653637 - samples/sec: 88.57 - lr: 0.025000
2022-05-13 17:02:03,194 epoch 17 - iter 70/107 - loss 0.06736529 - samples/sec: 87.71 - lr: 0.025000
2022-05-13 17:02:06,977 epoch 17 - iter 80/107 - loss 0.06628868 - samples/sec: 84.59 - lr: 0.025000
2022-05-13 17:02:10,779 epoch 17 - iter 90/107 - loss 0.06732774 - samples/sec: 84.19 - lr: 0.025000
2022-05-13 17:02:14,460 epoch 17 - iter 100/107 - loss 0.06588374 - samples/sec: 86.97 - lr: 0.025000
2022-05-13 17:02:16,884 ----------------------------------------------------------------------------------------------------
2022-05-13 17:02:16,884 EPOCH 17 done: loss 0.0656 - lr 0.025000
2022-05-13 17:02:26,417 Evaluating as a multi-label problem: False
2022-05-13 17:02:26,429 DEV : loss 0.1980966478586197 - f1-score (micro avg)  0.5266
2022-05-13 17:02:26,515 BAD EPOCHS (no improvement): 3
2022-05-13 17:02:26,554 ----------------------------------------------------------------------------------------------------
2022-05-13 17:02:28,851 epoch 18 - iter 10/107 - loss 0.05841004 - samples/sec: 139.42 - lr: 0.025000
2022-05-13 17:02:31,937 epoch 18 - iter 20/107 - loss 0.06550250 - samples/sec: 103.75 - lr: 0.025000
2022-05-13 17:02:35,579 epoch 18 - iter 30/107 - loss 0.06906622 - samples/sec: 87.88 - lr: 0.025000
2022-05-13 17:02:39,080 epoch 18 - iter 40/107 - loss 0.06659066 - samples/sec: 91.44 - lr: 0.025000
2022-05-13 17:02:42,865 epoch 18 - iter 50/107 - loss 0.06305181 - samples/sec: 84.57 - lr: 0.025000
2022-05-13 17:02:46,599 epoch 18 - iter 60/107 - loss 0.06277852 - samples/sec: 85.72 - lr: 0.025000
2022-05-13 17:02:50,344 epoch 18 - iter 70/107 - loss 0.06103785 - samples/sec: 85.47 - lr: 0.025000
2022-05-13 17:02:53,683 epoch 18 - iter 80/107 - loss 0.06082137 - samples/sec: 95.85 - lr: 0.025000
2022-05-13 17:02:57,400 epoch 18 - iter 90/107 - loss 0.06115724 - samples/sec: 86.12 - lr: 0.025000
2022-05-13 17:03:02,497 epoch 18 - iter 100/107 - loss 0.06236447 - samples/sec: 62.79 - lr: 0.025000
2022-05-13 17:03:04,337 ----------------------------------------------------------------------------------------------------
2022-05-13 17:03:04,338 EPOCH 18 done: loss 0.0631 - lr 0.025000
2022-05-13 17:03:11,812 Evaluating as a multi-label problem: False
2022-05-13 17:03:11,823 DEV : loss 0.19256240129470825 - f1-score (micro avg)  0.541
2022-05-13 17:03:11,908 Epoch    18: reducing learning rate of group 0 to 1.2500e-02.
2022-05-13 17:03:11,908 BAD EPOCHS (no improvement): 4
2022-05-13 17:03:11,909 ----------------------------------------------------------------------------------------------------
2022-05-13 17:03:13,923 epoch 19 - iter 10/107 - loss 0.06137138 - samples/sec: 159.07 - lr: 0.012500
2022-05-13 17:03:15,996 epoch 19 - iter 20/107 - loss 0.06365401 - samples/sec: 154.38 - lr: 0.012500
2022-05-13 17:03:18,150 epoch 19 - iter 30/107 - loss 0.06108137 - samples/sec: 148.65 - lr: 0.012500
2022-05-13 17:03:20,430 epoch 19 - iter 40/107 - loss 0.05849657 - samples/sec: 140.43 - lr: 0.012500
2022-05-13 17:03:22,623 epoch 19 - iter 50/107 - loss 0.05819340 - samples/sec: 145.98 - lr: 0.012500
2022-05-13 17:03:24,848 epoch 19 - iter 60/107 - loss 0.05840058 - samples/sec: 143.90 - lr: 0.012500
2022-05-13 17:03:27,032 epoch 19 - iter 70/107 - loss 0.05677607 - samples/sec: 146.58 - lr: 0.012500
2022-05-13 17:03:29,264 epoch 19 - iter 80/107 - loss 0.05702792 - samples/sec: 143.46 - lr: 0.012500
2022-05-13 17:03:31,516 epoch 19 - iter 90/107 - loss 0.05644064 - samples/sec: 142.14 - lr: 0.012500
2022-05-13 17:03:33,757 epoch 19 - iter 100/107 - loss 0.05815866 - samples/sec: 142.90 - lr: 0.012500
2022-05-13 17:03:35,063 ----------------------------------------------------------------------------------------------------
2022-05-13 17:03:35,064 EPOCH 19 done: loss 0.0581 - lr 0.012500
2022-05-13 17:03:41,795 Evaluating as a multi-label problem: False
2022-05-13 17:03:41,806 DEV : loss 0.20727849006652832 - f1-score (micro avg)  0.5162
2022-05-13 17:03:41,890 BAD EPOCHS (no improvement): 1
2022-05-13 17:03:41,892 ----------------------------------------------------------------------------------------------------
2022-05-13 17:03:44,148 epoch 20 - iter 10/107 - loss 0.05454790 - samples/sec: 141.92 - lr: 0.012500
2022-05-13 17:03:46,392 epoch 20 - iter 20/107 - loss 0.05506729 - samples/sec: 142.67 - lr: 0.012500
2022-05-13 17:03:51,241 epoch 20 - iter 30/107 - loss 0.05764701 - samples/sec: 66.02 - lr: 0.012500
2022-05-13 17:03:56,527 epoch 20 - iter 40/107 - loss 0.05573278 - samples/sec: 60.54 - lr: 0.012500
2022-05-13 17:04:01,139 epoch 20 - iter 50/107 - loss 0.05520719 - samples/sec: 69.41 - lr: 0.012500
2022-05-13 17:04:03,816 epoch 20 - iter 60/107 - loss 0.05610474 - samples/sec: 119.58 - lr: 0.012500
2022-05-13 17:04:08,301 epoch 20 - iter 70/107 - loss 0.05513308 - samples/sec: 71.35 - lr: 0.012500
2022-05-13 17:04:11,957 epoch 20 - iter 80/107 - loss 0.05487177 - samples/sec: 87.57 - lr: 0.012500
2022-05-13 17:04:15,715 epoch 20 - iter 90/107 - loss 0.05685909 - samples/sec: 85.19 - lr: 0.012500
2022-05-13 17:04:19,243 epoch 20 - iter 100/107 - loss 0.05880712 - samples/sec: 90.73 - lr: 0.012500
2022-05-13 17:04:21,622 ----------------------------------------------------------------------------------------------------
2022-05-13 17:04:21,622 EPOCH 20 done: loss 0.0587 - lr 0.012500
2022-05-13 17:04:31,906 Evaluating as a multi-label problem: False
2022-05-13 17:04:31,917 DEV : loss 0.20637109875679016 - f1-score (micro avg)  0.5269
2022-05-13 17:04:32,003 BAD EPOCHS (no improvement): 2
2022-05-13 17:04:32,005 ----------------------------------------------------------------------------------------------------
2022-05-13 17:04:35,875 epoch 21 - iter 10/107 - loss 0.05628864 - samples/sec: 82.70 - lr: 0.012500
2022-05-13 17:04:39,737 epoch 21 - iter 20/107 - loss 0.05890738 - samples/sec: 82.88 - lr: 0.012500
2022-05-13 17:04:42,914 epoch 21 - iter 30/107 - loss 0.06404852 - samples/sec: 100.78 - lr: 0.012500
2022-05-13 17:04:45,610 epoch 21 - iter 40/107 - loss 0.06087393 - samples/sec: 118.73 - lr: 0.012500
2022-05-13 17:04:48,274 epoch 21 - iter 50/107 - loss 0.05840220 - samples/sec: 120.16 - lr: 0.012500
2022-05-13 17:04:50,478 epoch 21 - iter 60/107 - loss 0.05779521 - samples/sec: 145.28 - lr: 0.012500
2022-05-13 17:04:52,494 epoch 21 - iter 70/107 - loss 0.05736499 - samples/sec: 158.75 - lr: 0.012500
2022-05-13 17:04:54,604 epoch 21 - iter 80/107 - loss 0.05640452 - samples/sec: 151.79 - lr: 0.012500
2022-05-13 17:04:56,779 epoch 21 - iter 90/107 - loss 0.05750716 - samples/sec: 147.21 - lr: 0.012500
2022-05-13 17:04:58,979 epoch 21 - iter 100/107 - loss 0.05721305 - samples/sec: 145.49 - lr: 0.012500
2022-05-13 17:05:00,370 ----------------------------------------------------------------------------------------------------
2022-05-13 17:05:00,370 EPOCH 21 done: loss 0.0572 - lr 0.012500
2022-05-13 17:05:07,240 Evaluating as a multi-label problem: False
2022-05-13 17:05:07,251 DEV : loss 0.21240070462226868 - f1-score (micro avg)  0.5165
2022-05-13 17:05:07,336 BAD EPOCHS (no improvement): 3
2022-05-13 17:05:07,339 ----------------------------------------------------------------------------------------------------
2022-05-13 17:05:09,557 epoch 22 - iter 10/107 - loss 0.05760342 - samples/sec: 144.41 - lr: 0.012500
2022-05-13 17:05:11,869 epoch 22 - iter 20/107 - loss 0.05712449 - samples/sec: 138.47 - lr: 0.012500
2022-05-13 17:05:15,641 epoch 22 - iter 30/107 - loss 0.05457898 - samples/sec: 84.86 - lr: 0.012500
2022-05-13 17:05:19,495 epoch 22 - iter 40/107 - loss 0.05338907 - samples/sec: 83.06 - lr: 0.012500
2022-05-13 17:05:22,825 epoch 22 - iter 50/107 - loss 0.05625709 - samples/sec: 96.12 - lr: 0.012500
2022-05-13 17:05:26,732 epoch 22 - iter 60/107 - loss 0.05618851 - samples/sec: 81.95 - lr: 0.012500
2022-05-13 17:05:30,340 epoch 22 - iter 70/107 - loss 0.05654228 - samples/sec: 88.71 - lr: 0.012500
2022-05-13 17:05:33,969 epoch 22 - iter 80/107 - loss 0.05772692 - samples/sec: 88.21 - lr: 0.012500
2022-05-13 17:05:37,671 epoch 22 - iter 90/107 - loss 0.05810545 - samples/sec: 86.46 - lr: 0.012500
2022-05-13 17:05:41,283 epoch 22 - iter 100/107 - loss 0.05785296 - samples/sec: 88.63 - lr: 0.012500
2022-05-13 17:05:43,663 ----------------------------------------------------------------------------------------------------
2022-05-13 17:05:43,663 EPOCH 22 done: loss 0.0574 - lr 0.012500
2022-05-13 17:05:51,632 Evaluating as a multi-label problem: False
2022-05-13 17:05:51,643 DEV : loss 0.21088507771492004 - f1-score (micro avg)  0.5204
2022-05-13 17:05:51,729 Epoch    22: reducing learning rate of group 0 to 6.2500e-03.
2022-05-13 17:05:51,729 BAD EPOCHS (no improvement): 4
2022-05-13 17:05:51,731 ----------------------------------------------------------------------------------------------------
2022-05-13 17:05:53,804 epoch 23 - iter 10/107 - loss 0.05462278 - samples/sec: 154.46 - lr: 0.006250
2022-05-13 17:05:55,916 epoch 23 - iter 20/107 - loss 0.05450716 - samples/sec: 151.59 - lr: 0.006250
2022-05-13 17:05:58,102 epoch 23 - iter 30/107 - loss 0.05853735 - samples/sec: 146.49 - lr: 0.006250
2022-05-13 17:06:00,279 epoch 23 - iter 40/107 - loss 0.05775006 - samples/sec: 147.07 - lr: 0.006250
2022-05-13 17:06:02,517 epoch 23 - iter 50/107 - loss 0.05484148 - samples/sec: 143.02 - lr: 0.006250
2022-05-13 17:06:04,687 epoch 23 - iter 60/107 - loss 0.05628069 - samples/sec: 147.56 - lr: 0.006250
2022-05-13 17:06:06,847 epoch 23 - iter 70/107 - loss 0.05615648 - samples/sec: 148.21 - lr: 0.006250
2022-05-13 17:06:09,041 epoch 23 - iter 80/107 - loss 0.05524173 - samples/sec: 145.93 - lr: 0.006250
2022-05-13 17:06:11,236 epoch 23 - iter 90/107 - loss 0.05432603 - samples/sec: 145.87 - lr: 0.006250
2022-05-13 17:06:13,455 epoch 23 - iter 100/107 - loss 0.05464353 - samples/sec: 144.25 - lr: 0.006250
2022-05-13 17:06:14,826 ----------------------------------------------------------------------------------------------------
2022-05-13 17:06:14,826 EPOCH 23 done: loss 0.0547 - lr 0.006250
2022-05-13 17:06:23,225 Evaluating as a multi-label problem: False
2022-05-13 17:06:23,235 DEV : loss 0.20897136628627777 - f1-score (micro avg)  0.5253
2022-05-13 17:06:23,320 BAD EPOCHS (no improvement): 1
2022-05-13 17:06:23,323 ----------------------------------------------------------------------------------------------------
2022-05-13 17:06:26,989 epoch 24 - iter 10/107 - loss 0.05626881 - samples/sec: 87.32 - lr: 0.006250
2022-05-13 17:06:30,350 epoch 24 - iter 20/107 - loss 0.06152972 - samples/sec: 95.25 - lr: 0.006250
2022-05-13 17:06:33,889 epoch 24 - iter 30/107 - loss 0.06274273 - samples/sec: 90.44 - lr: 0.006250
2022-05-13 17:06:37,464 epoch 24 - iter 40/107 - loss 0.06015756 - samples/sec: 89.53 - lr: 0.006250
2022-05-13 17:06:41,199 epoch 24 - iter 50/107 - loss 0.05973622 - samples/sec: 85.71 - lr: 0.006250
2022-05-13 17:06:46,383 epoch 24 - iter 60/107 - loss 0.05852002 - samples/sec: 61.74 - lr: 0.006250
2022-05-13 17:06:49,670 epoch 24 - iter 70/107 - loss 0.05830683 - samples/sec: 97.39 - lr: 0.006250
2022-05-13 17:06:52,243 epoch 24 - iter 80/107 - loss 0.05991232 - samples/sec: 124.39 - lr: 0.006250
2022-05-13 17:06:54,891 epoch 24 - iter 90/107 - loss 0.05913556 - samples/sec: 120.92 - lr: 0.006250
2022-05-13 17:06:57,938 epoch 24 - iter 100/107 - loss 0.05797458 - samples/sec: 105.04 - lr: 0.006250
2022-05-13 17:07:00,294 ----------------------------------------------------------------------------------------------------
2022-05-13 17:07:00,295 EPOCH 24 done: loss 0.0572 - lr 0.006250
2022-05-13 17:07:10,919 Evaluating as a multi-label problem: False
2022-05-13 17:07:10,929 DEV : loss 0.20679281651973724 - f1-score (micro avg)  0.5311
2022-05-13 17:07:11,015 BAD EPOCHS (no improvement): 2
2022-05-13 17:07:11,019 ----------------------------------------------------------------------------------------------------
2022-05-13 17:07:14,726 epoch 25 - iter 10/107 - loss 0.03305249 - samples/sec: 86.36 - lr: 0.006250
2022-05-13 17:07:18,525 epoch 25 - iter 20/107 - loss 0.04729429 - samples/sec: 84.25 - lr: 0.006250
2022-05-13 17:07:22,232 epoch 25 - iter 30/107 - loss 0.05361163 - samples/sec: 86.34 - lr: 0.006250
2022-05-13 17:07:25,939 epoch 25 - iter 40/107 - loss 0.05246247 - samples/sec: 86.34 - lr: 0.006250
2022-05-13 17:07:29,631 epoch 25 - iter 50/107 - loss 0.05257184 - samples/sec: 86.71 - lr: 0.006250
2022-05-13 17:07:32,559 epoch 25 - iter 60/107 - loss 0.05162909 - samples/sec: 109.31 - lr: 0.006250
2022-05-13 17:07:35,146 epoch 25 - iter 70/107 - loss 0.05102434 - samples/sec: 123.79 - lr: 0.006250
2022-05-13 17:07:38,288 epoch 25 - iter 80/107 - loss 0.05313915 - samples/sec: 101.86 - lr: 0.006250
2022-05-13 17:07:42,062 epoch 25 - iter 90/107 - loss 0.05439438 - samples/sec: 84.83 - lr: 0.006250
2022-05-13 17:07:45,693 epoch 25 - iter 100/107 - loss 0.05369484 - samples/sec: 88.14 - lr: 0.006250
2022-05-13 17:07:47,937 ----------------------------------------------------------------------------------------------------
2022-05-13 17:07:47,937 EPOCH 25 done: loss 0.0541 - lr 0.006250
2022-05-13 17:07:58,422 Evaluating as a multi-label problem: False
2022-05-13 17:07:58,433 DEV : loss 0.2068021297454834 - f1-score (micro avg)  0.5302
2022-05-13 17:07:58,519 BAD EPOCHS (no improvement): 3
2022-05-13 17:07:58,530 ----------------------------------------------------------------------------------------------------
2022-05-13 17:08:02,237 epoch 26 - iter 10/107 - loss 0.04805575 - samples/sec: 86.35 - lr: 0.006250
2022-05-13 17:08:05,840 epoch 26 - iter 20/107 - loss 0.05232532 - samples/sec: 88.84 - lr: 0.006250
2022-05-13 17:08:09,537 epoch 26 - iter 30/107 - loss 0.05217665 - samples/sec: 86.58 - lr: 0.006250
2022-05-13 17:08:12,477 epoch 26 - iter 40/107 - loss 0.05269157 - samples/sec: 108.86 - lr: 0.006250
2022-05-13 17:08:15,145 epoch 26 - iter 50/107 - loss 0.05177211 - samples/sec: 119.98 - lr: 0.006250
2022-05-13 17:08:17,906 epoch 26 - iter 60/107 - loss 0.05170328 - samples/sec: 115.96 - lr: 0.006250
2022-05-13 17:08:19,863 epoch 26 - iter 70/107 - loss 0.05320475 - samples/sec: 163.60 - lr: 0.006250
2022-05-13 17:08:21,975 epoch 26 - iter 80/107 - loss 0.05277710 - samples/sec: 151.64 - lr: 0.006250
2022-05-13 17:08:24,133 epoch 26 - iter 90/107 - loss 0.05287677 - samples/sec: 148.37 - lr: 0.006250
2022-05-13 17:08:26,345 epoch 26 - iter 100/107 - loss 0.05341374 - samples/sec: 144.68 - lr: 0.006250
2022-05-13 17:08:27,667 ----------------------------------------------------------------------------------------------------
2022-05-13 17:08:27,667 EPOCH 26 done: loss 0.0538 - lr 0.006250
2022-05-13 17:08:34,395 Evaluating as a multi-label problem: False
2022-05-13 17:08:34,405 DEV : loss 0.1998053640127182 - f1-score (micro avg)  0.5334
2022-05-13 17:08:34,490 Epoch    26: reducing learning rate of group 0 to 3.1250e-03.
2022-05-13 17:08:34,490 BAD EPOCHS (no improvement): 4
2022-05-13 17:08:34,492 ----------------------------------------------------------------------------------------------------
2022-05-13 17:08:36,704 epoch 27 - iter 10/107 - loss 0.05793296 - samples/sec: 144.77 - lr: 0.003125
2022-05-13 17:08:38,862 epoch 27 - iter 20/107 - loss 0.05549689 - samples/sec: 148.32 - lr: 0.003125
2022-05-13 17:08:41,229 epoch 27 - iter 30/107 - loss 0.05325168 - samples/sec: 135.26 - lr: 0.003125
2022-05-13 17:08:44,835 epoch 27 - iter 40/107 - loss 0.05690634 - samples/sec: 88.76 - lr: 0.003125
2022-05-13 17:08:48,439 epoch 27 - iter 50/107 - loss 0.05401391 - samples/sec: 88.83 - lr: 0.003125
2022-05-13 17:08:51,978 epoch 27 - iter 60/107 - loss 0.05597275 - samples/sec: 90.43 - lr: 0.003125
2022-05-13 17:08:55,543 epoch 27 - iter 70/107 - loss 0.05792882 - samples/sec: 89.80 - lr: 0.003125
2022-05-13 17:08:59,224 epoch 27 - iter 80/107 - loss 0.05607779 - samples/sec: 86.96 - lr: 0.003125
2022-05-13 17:09:02,993 epoch 27 - iter 90/107 - loss 0.05549332 - samples/sec: 84.91 - lr: 0.003125
2022-05-13 17:09:06,740 epoch 27 - iter 100/107 - loss 0.05594477 - samples/sec: 85.44 - lr: 0.003125
2022-05-13 17:09:09,020 ----------------------------------------------------------------------------------------------------
2022-05-13 17:09:09,020 EPOCH 27 done: loss 0.0558 - lr 0.003125
2022-05-13 17:09:17,926 Evaluating as a multi-label problem: False
2022-05-13 17:09:17,937 DEV : loss 0.20273548364639282 - f1-score (micro avg)  0.5396
2022-05-13 17:09:18,021 BAD EPOCHS (no improvement): 1
2022-05-13 17:09:18,023 ----------------------------------------------------------------------------------------------------
2022-05-13 17:09:20,613 epoch 28 - iter 10/107 - loss 0.05467905 - samples/sec: 123.61 - lr: 0.003125
2022-05-13 17:09:24,240 epoch 28 - iter 20/107 - loss 0.05365625 - samples/sec: 88.24 - lr: 0.003125
2022-05-13 17:09:27,855 epoch 28 - iter 30/107 - loss 0.05759273 - samples/sec: 88.55 - lr: 0.003125
2022-05-13 17:09:31,651 epoch 28 - iter 40/107 - loss 0.05785287 - samples/sec: 84.33 - lr: 0.003125
2022-05-13 17:09:35,061 epoch 28 - iter 50/107 - loss 0.05638560 - samples/sec: 93.86 - lr: 0.003125
2022-05-13 17:09:38,656 epoch 28 - iter 60/107 - loss 0.05666811 - samples/sec: 89.05 - lr: 0.003125
2022-05-13 17:09:42,250 epoch 28 - iter 70/107 - loss 0.05576265 - samples/sec: 89.07 - lr: 0.003125
2022-05-13 17:09:45,972 epoch 28 - iter 80/107 - loss 0.05477356 - samples/sec: 86.00 - lr: 0.003125
2022-05-13 17:09:49,655 epoch 28 - iter 90/107 - loss 0.05540239 - samples/sec: 86.89 - lr: 0.003125
2022-05-13 17:09:53,277 epoch 28 - iter 100/107 - loss 0.05471649 - samples/sec: 88.38 - lr: 0.003125
2022-05-13 17:09:55,357 ----------------------------------------------------------------------------------------------------
2022-05-13 17:09:55,357 EPOCH 28 done: loss 0.0540 - lr 0.003125
2022-05-13 17:10:02,935 Evaluating as a multi-label problem: False
2022-05-13 17:10:02,946 DEV : loss 0.20752106606960297 - f1-score (micro avg)  0.5192
2022-05-13 17:10:03,031 BAD EPOCHS (no improvement): 2
2022-05-13 17:10:03,078 ----------------------------------------------------------------------------------------------------
2022-05-13 17:10:05,040 epoch 29 - iter 10/107 - loss 0.06508609 - samples/sec: 163.21 - lr: 0.003125
2022-05-13 17:10:07,172 epoch 29 - iter 20/107 - loss 0.05172379 - samples/sec: 150.18 - lr: 0.003125
2022-05-13 17:10:09,342 epoch 29 - iter 30/107 - loss 0.05215227 - samples/sec: 147.50 - lr: 0.003125
2022-05-13 17:10:11,580 epoch 29 - iter 40/107 - loss 0.05727502 - samples/sec: 143.07 - lr: 0.003125
2022-05-13 17:10:13,809 epoch 29 - iter 50/107 - loss 0.05557070 - samples/sec: 143.60 - lr: 0.003125
2022-05-13 17:10:16,022 epoch 29 - iter 60/107 - loss 0.05502323 - samples/sec: 144.63 - lr: 0.003125
2022-05-13 17:10:18,168 epoch 29 - iter 70/107 - loss 0.05393677 - samples/sec: 149.23 - lr: 0.003125
2022-05-13 17:10:20,316 epoch 29 - iter 80/107 - loss 0.05398039 - samples/sec: 149.05 - lr: 0.003125
2022-05-13 17:10:22,458 epoch 29 - iter 90/107 - loss 0.05351075 - samples/sec: 149.44 - lr: 0.003125
2022-05-13 17:10:24,677 epoch 29 - iter 100/107 - loss 0.05316347 - samples/sec: 144.29 - lr: 0.003125
2022-05-13 17:10:26,527 ----------------------------------------------------------------------------------------------------
2022-05-13 17:10:26,528 EPOCH 29 done: loss 0.0534 - lr 0.003125
2022-05-13 17:10:35,908 Evaluating as a multi-label problem: False
2022-05-13 17:10:35,918 DEV : loss 0.20713265240192413 - f1-score (micro avg)  0.5284
2022-05-13 17:10:36,005 BAD EPOCHS (no improvement): 3
2022-05-13 17:10:36,024 ----------------------------------------------------------------------------------------------------
2022-05-13 17:10:39,295 epoch 30 - iter 10/107 - loss 0.05218628 - samples/sec: 97.88 - lr: 0.003125
2022-05-13 17:10:42,481 epoch 30 - iter 20/107 - loss 0.04899109 - samples/sec: 100.47 - lr: 0.003125
2022-05-13 17:10:47,140 epoch 30 - iter 30/107 - loss 0.04975465 - samples/sec: 68.70 - lr: 0.003125
2022-05-13 17:10:50,247 epoch 30 - iter 40/107 - loss 0.04667841 - samples/sec: 103.03 - lr: 0.003125
2022-05-13 17:10:53,859 epoch 30 - iter 50/107 - loss 0.04951170 - samples/sec: 88.62 - lr: 0.003125
2022-05-13 17:10:57,382 epoch 30 - iter 60/107 - loss 0.05031535 - samples/sec: 90.85 - lr: 0.003125
2022-05-13 17:11:00,365 epoch 30 - iter 70/107 - loss 0.05079982 - samples/sec: 107.32 - lr: 0.003125
2022-05-13 17:11:03,055 epoch 30 - iter 80/107 - loss 0.05104537 - samples/sec: 119.00 - lr: 0.003125
2022-05-13 17:11:05,807 epoch 30 - iter 90/107 - loss 0.05235532 - samples/sec: 116.29 - lr: 0.003125
2022-05-13 17:11:07,949 epoch 30 - iter 100/107 - loss 0.05244521 - samples/sec: 149.49 - lr: 0.003125
2022-05-13 17:11:09,209 ----------------------------------------------------------------------------------------------------
2022-05-13 17:11:09,209 EPOCH 30 done: loss 0.0528 - lr 0.003125
2022-05-13 17:11:15,881 Evaluating as a multi-label problem: False
2022-05-13 17:11:15,891 DEV : loss 0.20565612614154816 - f1-score (micro avg)  0.5248
2022-05-13 17:11:15,976 Epoch    30: reducing learning rate of group 0 to 1.5625e-03.
2022-05-13 17:11:15,976 BAD EPOCHS (no improvement): 4
2022-05-13 17:11:16,022 ----------------------------------------------------------------------------------------------------
2022-05-13 17:11:18,287 epoch 31 - iter 10/107 - loss 0.05333800 - samples/sec: 141.32 - lr: 0.001563
2022-05-13 17:11:20,500 epoch 31 - iter 20/107 - loss 0.05393223 - samples/sec: 144.66 - lr: 0.001563
2022-05-13 17:11:22,821 epoch 31 - iter 30/107 - loss 0.05406094 - samples/sec: 137.95 - lr: 0.001563
2022-05-13 17:11:24,973 epoch 31 - iter 40/107 - loss 0.05234789 - samples/sec: 148.76 - lr: 0.001563
2022-05-13 17:11:27,197 epoch 31 - iter 50/107 - loss 0.05123453 - samples/sec: 143.96 - lr: 0.001563
2022-05-13 17:11:29,356 epoch 31 - iter 60/107 - loss 0.05105619 - samples/sec: 148.32 - lr: 0.001563
2022-05-13 17:11:32,255 epoch 31 - iter 70/107 - loss 0.04954556 - samples/sec: 110.44 - lr: 0.001563
2022-05-13 17:11:35,677 epoch 31 - iter 80/107 - loss 0.05065619 - samples/sec: 93.53 - lr: 0.001563
2022-05-13 17:11:39,500 epoch 31 - iter 90/107 - loss 0.05136753 - samples/sec: 83.72 - lr: 0.001563
2022-05-13 17:11:42,975 epoch 31 - iter 100/107 - loss 0.05078904 - samples/sec: 92.13 - lr: 0.001563
2022-05-13 17:11:45,078 ----------------------------------------------------------------------------------------------------
2022-05-13 17:11:45,078 EPOCH 31 done: loss 0.0509 - lr 0.001563
2022-05-13 17:11:55,482 Evaluating as a multi-label problem: False
2022-05-13 17:11:55,493 DEV : loss 0.20578865706920624 - f1-score (micro avg)  0.528
2022-05-13 17:11:55,577 BAD EPOCHS (no improvement): 1
2022-05-13 17:11:55,580 ----------------------------------------------------------------------------------------------------
2022-05-13 17:11:59,214 epoch 32 - iter 10/107 - loss 0.04868963 - samples/sec: 88.09 - lr: 0.001563
2022-05-13 17:12:02,566 epoch 32 - iter 20/107 - loss 0.05590439 - samples/sec: 95.48 - lr: 0.001563
2022-05-13 17:12:05,749 epoch 32 - iter 30/107 - loss 0.05427449 - samples/sec: 100.57 - lr: 0.001563
2022-05-13 17:12:08,382 epoch 32 - iter 40/107 - loss 0.05128592 - samples/sec: 121.59 - lr: 0.001563
2022-05-13 17:12:11,130 epoch 32 - iter 50/107 - loss 0.05038545 - samples/sec: 116.52 - lr: 0.001563
2022-05-13 17:12:13,071 epoch 32 - iter 60/107 - loss 0.05131477 - samples/sec: 164.95 - lr: 0.001563
2022-05-13 17:12:15,190 epoch 32 - iter 70/107 - loss 0.05010707 - samples/sec: 151.08 - lr: 0.001563
2022-05-13 17:12:17,338 epoch 32 - iter 80/107 - loss 0.05024266 - samples/sec: 149.08 - lr: 0.001563
2022-05-13 17:12:19,529 epoch 32 - iter 90/107 - loss 0.05112459 - samples/sec: 146.09 - lr: 0.001563
2022-05-13 17:12:21,664 epoch 32 - iter 100/107 - loss 0.05166190 - samples/sec: 149.98 - lr: 0.001563
2022-05-13 17:12:23,048 ----------------------------------------------------------------------------------------------------
2022-05-13 17:12:23,048 EPOCH 32 done: loss 0.0537 - lr 0.001563
2022-05-13 17:12:29,740 Evaluating as a multi-label problem: False
2022-05-13 17:12:29,751 DEV : loss 0.20535500347614288 - f1-score (micro avg)  0.531
2022-05-13 17:12:29,836 BAD EPOCHS (no improvement): 2
2022-05-13 17:12:29,847 ----------------------------------------------------------------------------------------------------
2022-05-13 17:12:32,009 epoch 33 - iter 10/107 - loss 0.05010928 - samples/sec: 148.10 - lr: 0.001563
2022-05-13 17:12:34,137 epoch 33 - iter 20/107 - loss 0.04338757 - samples/sec: 150.45 - lr: 0.001563
2022-05-13 17:12:37,868 epoch 33 - iter 30/107 - loss 0.04891440 - samples/sec: 85.77 - lr: 0.001563
2022-05-13 17:12:41,456 epoch 33 - iter 40/107 - loss 0.05289170 - samples/sec: 89.23 - lr: 0.001563
2022-05-13 17:12:45,013 epoch 33 - iter 50/107 - loss 0.05229210 - samples/sec: 89.99 - lr: 0.001563
2022-05-13 17:12:48,883 epoch 33 - iter 60/107 - loss 0.05131639 - samples/sec: 82.70 - lr: 0.001563
2022-05-13 17:12:52,508 epoch 33 - iter 70/107 - loss 0.05156463 - samples/sec: 88.29 - lr: 0.001563
2022-05-13 17:12:55,845 epoch 33 - iter 80/107 - loss 0.05183914 - samples/sec: 95.94 - lr: 0.001563
2022-05-13 17:12:59,387 epoch 33 - iter 90/107 - loss 0.05165610 - samples/sec: 90.36 - lr: 0.001563
2022-05-13 17:13:03,053 epoch 33 - iter 100/107 - loss 0.05151808 - samples/sec: 87.31 - lr: 0.001563
2022-05-13 17:13:05,163 ----------------------------------------------------------------------------------------------------
2022-05-13 17:13:05,163 EPOCH 33 done: loss 0.0517 - lr 0.001563
2022-05-13 17:13:13,807 Evaluating as a multi-label problem: False
2022-05-13 17:13:13,818 DEV : loss 0.20618745684623718 - f1-score (micro avg)  0.5294
2022-05-13 17:13:13,903 BAD EPOCHS (no improvement): 3
2022-05-13 17:13:13,905 ----------------------------------------------------------------------------------------------------
2022-05-13 17:13:17,110 epoch 34 - iter 10/107 - loss 0.04466308 - samples/sec: 99.88 - lr: 0.001563
2022-05-13 17:13:20,757 epoch 34 - iter 20/107 - loss 0.04947066 - samples/sec: 87.78 - lr: 0.001563
2022-05-13 17:13:24,518 epoch 34 - iter 30/107 - loss 0.05034858 - samples/sec: 85.11 - lr: 0.001563
2022-05-13 17:13:28,249 epoch 34 - iter 40/107 - loss 0.05173565 - samples/sec: 85.78 - lr: 0.001563
2022-05-13 17:13:32,035 epoch 34 - iter 50/107 - loss 0.05248352 - samples/sec: 84.55 - lr: 0.001563
2022-05-13 17:13:35,482 epoch 34 - iter 60/107 - loss 0.05631390 - samples/sec: 92.84 - lr: 0.001563
2022-05-13 17:13:38,965 epoch 34 - iter 70/107 - loss 0.05580270 - samples/sec: 91.92 - lr: 0.001563
2022-05-13 17:13:42,821 epoch 34 - iter 80/107 - loss 0.05370039 - samples/sec: 83.01 - lr: 0.001563
2022-05-13 17:13:46,786 epoch 34 - iter 90/107 - loss 0.05423229 - samples/sec: 80.73 - lr: 0.001563
2022-05-13 17:13:49,994 epoch 34 - iter 100/107 - loss 0.05399731 - samples/sec: 99.77 - lr: 0.001563
2022-05-13 17:13:51,885 ----------------------------------------------------------------------------------------------------
2022-05-13 17:13:51,886 EPOCH 34 done: loss 0.0540 - lr 0.001563
2022-05-13 17:13:59,204 Evaluating as a multi-label problem: False
2022-05-13 17:13:59,215 DEV : loss 0.2066955715417862 - f1-score (micro avg)  0.5241
2022-05-13 17:13:59,299 Epoch    34: reducing learning rate of group 0 to 7.8125e-04.
2022-05-13 17:13:59,299 BAD EPOCHS (no improvement): 4
2022-05-13 17:13:59,301 ----------------------------------------------------------------------------------------------------
2022-05-13 17:14:01,456 epoch 35 - iter 10/107 - loss 0.05214159 - samples/sec: 148.61 - lr: 0.000781
2022-05-13 17:14:03,639 epoch 35 - iter 20/107 - loss 0.05279814 - samples/sec: 146.62 - lr: 0.000781
2022-05-13 17:14:05,965 epoch 35 - iter 30/107 - loss 0.05033949 - samples/sec: 137.65 - lr: 0.000781
2022-05-13 17:14:08,077 epoch 35 - iter 40/107 - loss 0.05143922 - samples/sec: 151.59 - lr: 0.000781
2022-05-13 17:14:10,230 epoch 35 - iter 50/107 - loss 0.05252905 - samples/sec: 148.69 - lr: 0.000781
2022-05-13 17:14:12,415 epoch 35 - iter 60/107 - loss 0.05181107 - samples/sec: 146.53 - lr: 0.000781
2022-05-13 17:14:14,612 epoch 35 - iter 70/107 - loss 0.04988175 - samples/sec: 145.69 - lr: 0.000781
2022-05-13 17:14:16,861 epoch 35 - iter 80/107 - loss 0.04975418 - samples/sec: 142.35 - lr: 0.000781
2022-05-13 17:14:19,009 epoch 35 - iter 90/107 - loss 0.05069467 - samples/sec: 149.08 - lr: 0.000781
2022-05-13 17:14:22,065 epoch 35 - iter 100/107 - loss 0.05304217 - samples/sec: 104.75 - lr: 0.000781
2022-05-13 17:14:24,186 ----------------------------------------------------------------------------------------------------
2022-05-13 17:14:24,186 EPOCH 35 done: loss 0.0526 - lr 0.000781
2022-05-13 17:14:34,833 Evaluating as a multi-label problem: False
2022-05-13 17:14:34,843 DEV : loss 0.20505845546722412 - f1-score (micro avg)  0.5275
2022-05-13 17:14:34,928 BAD EPOCHS (no improvement): 1
2022-05-13 17:14:34,930 ----------------------------------------------------------------------------------------------------
2022-05-13 17:14:39,982 epoch 36 - iter 10/107 - loss 0.05964544 - samples/sec: 63.37 - lr: 0.000781
2022-05-13 17:14:43,384 epoch 36 - iter 20/107 - loss 0.05368473 - samples/sec: 94.09 - lr: 0.000781
2022-05-13 17:14:46,990 epoch 36 - iter 30/107 - loss 0.05175944 - samples/sec: 88.76 - lr: 0.000781
2022-05-13 17:14:50,571 epoch 36 - iter 40/107 - loss 0.05270482 - samples/sec: 89.38 - lr: 0.000781
2022-05-13 17:14:53,128 epoch 36 - iter 50/107 - loss 0.05304073 - samples/sec: 125.22 - lr: 0.000781
2022-05-13 17:14:55,960 epoch 36 - iter 60/107 - loss 0.05193409 - samples/sec: 113.04 - lr: 0.000781
2022-05-13 17:14:58,612 epoch 36 - iter 70/107 - loss 0.05414024 - samples/sec: 120.67 - lr: 0.000781
2022-05-13 17:15:00,841 epoch 36 - iter 80/107 - loss 0.05388594 - samples/sec: 143.67 - lr: 0.000781
2022-05-13 17:15:02,921 epoch 36 - iter 90/107 - loss 0.05442279 - samples/sec: 153.88 - lr: 0.000781
2022-05-13 17:15:05,047 epoch 36 - iter 100/107 - loss 0.05474159 - samples/sec: 150.61 - lr: 0.000781
2022-05-13 17:15:06,419 ----------------------------------------------------------------------------------------------------
2022-05-13 17:15:06,419 EPOCH 36 done: loss 0.0548 - lr 0.000781
2022-05-13 17:15:13,092 Evaluating as a multi-label problem: False
2022-05-13 17:15:13,103 DEV : loss 0.20437923073768616 - f1-score (micro avg)  0.5283
2022-05-13 17:15:13,187 BAD EPOCHS (no improvement): 2
2022-05-13 17:15:13,189 ----------------------------------------------------------------------------------------------------
2022-05-13 17:15:15,402 epoch 37 - iter 10/107 - loss 0.06446014 - samples/sec: 144.67 - lr: 0.000781
2022-05-13 17:15:17,497 epoch 37 - iter 20/107 - loss 0.05377595 - samples/sec: 152.83 - lr: 0.000781
2022-05-13 17:15:19,718 epoch 37 - iter 30/107 - loss 0.05331974 - samples/sec: 144.14 - lr: 0.000781
2022-05-13 17:15:22,005 epoch 37 - iter 40/107 - loss 0.05298977 - samples/sec: 139.96 - lr: 0.000781
2022-05-13 17:15:25,286 epoch 37 - iter 50/107 - loss 0.05149398 - samples/sec: 97.55 - lr: 0.000781
2022-05-13 17:15:28,966 epoch 37 - iter 60/107 - loss 0.05125445 - samples/sec: 87.01 - lr: 0.000781
2022-05-13 17:15:32,472 epoch 37 - iter 70/107 - loss 0.05173779 - samples/sec: 91.30 - lr: 0.000781
2022-05-13 17:15:36,093 epoch 37 - iter 80/107 - loss 0.05355911 - samples/sec: 88.39 - lr: 0.000781
2022-05-13 17:15:39,780 epoch 37 - iter 90/107 - loss 0.05279767 - samples/sec: 86.81 - lr: 0.000781
2022-05-13 17:15:43,299 epoch 37 - iter 100/107 - loss 0.05233872 - samples/sec: 90.96 - lr: 0.000781
2022-05-13 17:15:45,478 ----------------------------------------------------------------------------------------------------
2022-05-13 17:15:45,478 EPOCH 37 done: loss 0.0520 - lr 0.000781
2022-05-13 17:15:56,001 Evaluating as a multi-label problem: False
2022-05-13 17:15:56,012 DEV : loss 0.2050456553697586 - f1-score (micro avg)  0.5283
2022-05-13 17:15:56,097 BAD EPOCHS (no improvement): 3
2022-05-13 17:15:56,099 ----------------------------------------------------------------------------------------------------
2022-05-13 17:15:58,993 epoch 38 - iter 10/107 - loss 0.05155911 - samples/sec: 110.60 - lr: 0.000781
2022-05-13 17:16:01,653 epoch 38 - iter 20/107 - loss 0.04557073 - samples/sec: 120.34 - lr: 0.000781
2022-05-13 17:16:03,879 epoch 38 - iter 30/107 - loss 0.04721003 - samples/sec: 143.83 - lr: 0.000781
2022-05-13 17:16:06,325 epoch 38 - iter 40/107 - loss 0.04810086 - samples/sec: 130.89 - lr: 0.000781
2022-05-13 17:16:09,991 epoch 38 - iter 50/107 - loss 0.04817962 - samples/sec: 87.31 - lr: 0.000781
2022-05-13 17:16:13,728 epoch 38 - iter 60/107 - loss 0.04920482 - samples/sec: 85.67 - lr: 0.000781
2022-05-13 17:16:17,200 epoch 38 - iter 70/107 - loss 0.04909665 - samples/sec: 92.20 - lr: 0.000781
2022-05-13 17:16:20,902 epoch 38 - iter 80/107 - loss 0.04840039 - samples/sec: 86.46 - lr: 0.000781
2022-05-13 17:16:24,363 epoch 38 - iter 90/107 - loss 0.04966597 - samples/sec: 92.50 - lr: 0.000781
2022-05-13 17:16:27,918 epoch 38 - iter 100/107 - loss 0.05044937 - samples/sec: 90.03 - lr: 0.000781
2022-05-13 17:16:30,217 ----------------------------------------------------------------------------------------------------
2022-05-13 17:16:30,218 EPOCH 38 done: loss 0.0507 - lr 0.000781
2022-05-13 17:16:40,382 Evaluating as a multi-label problem: False
2022-05-13 17:16:40,393 DEV : loss 0.20538820326328278 - f1-score (micro avg)  0.5279
2022-05-13 17:16:40,479 Epoch    38: reducing learning rate of group 0 to 3.9063e-04.
2022-05-13 17:16:40,479 BAD EPOCHS (no improvement): 4
2022-05-13 17:16:40,481 ----------------------------------------------------------------------------------------------------
2022-05-13 17:16:43,165 epoch 39 - iter 10/107 - loss 0.05064918 - samples/sec: 119.27 - lr: 0.000391
2022-05-13 17:16:45,915 epoch 39 - iter 20/107 - loss 0.05778646 - samples/sec: 116.43 - lr: 0.000391
2022-05-13 17:16:49,544 epoch 39 - iter 30/107 - loss 0.05601267 - samples/sec: 88.21 - lr: 0.000391
2022-05-13 17:16:52,789 epoch 39 - iter 40/107 - loss 0.05654198 - samples/sec: 98.63 - lr: 0.000391
2022-05-13 17:16:56,140 epoch 39 - iter 50/107 - loss 0.05499523 - samples/sec: 95.53 - lr: 0.000391
2022-05-13 17:16:59,885 epoch 39 - iter 60/107 - loss 0.05296069 - samples/sec: 85.46 - lr: 0.000391
2022-05-13 17:17:03,511 epoch 39 - iter 70/107 - loss 0.05212199 - samples/sec: 88.29 - lr: 0.000391
2022-05-13 17:17:07,034 epoch 39 - iter 80/107 - loss 0.05267718 - samples/sec: 90.87 - lr: 0.000391
2022-05-13 17:17:10,139 epoch 39 - iter 90/107 - loss 0.05339615 - samples/sec: 103.10 - lr: 0.000391
2022-05-13 17:17:13,868 epoch 39 - iter 100/107 - loss 0.05359590 - samples/sec: 85.84 - lr: 0.000391
2022-05-13 17:17:16,146 ----------------------------------------------------------------------------------------------------
2022-05-13 17:17:16,146 EPOCH 39 done: loss 0.0529 - lr 0.000391
2022-05-13 17:17:24,771 Evaluating as a multi-label problem: False
2022-05-13 17:17:24,782 DEV : loss 0.20547831058502197 - f1-score (micro avg)  0.5301
2022-05-13 17:17:24,867 BAD EPOCHS (no improvement): 1
2022-05-13 17:17:24,870 ----------------------------------------------------------------------------------------------------
2022-05-13 17:17:27,467 epoch 40 - iter 10/107 - loss 0.05028131 - samples/sec: 123.28 - lr: 0.000391
2022-05-13 17:17:31,036 epoch 40 - iter 20/107 - loss 0.04585173 - samples/sec: 89.70 - lr: 0.000391
2022-05-13 17:17:34,723 epoch 40 - iter 30/107 - loss 0.04752328 - samples/sec: 86.80 - lr: 0.000391
2022-05-13 17:17:38,139 epoch 40 - iter 40/107 - loss 0.04776786 - samples/sec: 93.70 - lr: 0.000391
2022-05-13 17:17:41,753 epoch 40 - iter 50/107 - loss 0.04871649 - samples/sec: 88.57 - lr: 0.000391
2022-05-13 17:17:45,374 epoch 40 - iter 60/107 - loss 0.05016211 - samples/sec: 88.40 - lr: 0.000391
2022-05-13 17:17:48,808 epoch 40 - iter 70/107 - loss 0.04927282 - samples/sec: 93.22 - lr: 0.000391
2022-05-13 17:17:52,427 epoch 40 - iter 80/107 - loss 0.05091194 - samples/sec: 88.45 - lr: 0.000391
2022-05-13 17:17:56,248 epoch 40 - iter 90/107 - loss 0.05096190 - samples/sec: 83.78 - lr: 0.000391
2022-05-13 17:17:59,561 epoch 40 - iter 100/107 - loss 0.05063688 - samples/sec: 96.62 - lr: 0.000391
2022-05-13 17:18:01,474 ----------------------------------------------------------------------------------------------------
2022-05-13 17:18:01,474 EPOCH 40 done: loss 0.0510 - lr 0.000391
2022-05-13 17:18:09,566 Evaluating as a multi-label problem: False
2022-05-13 17:18:09,577 DEV : loss 0.205564484000206 - f1-score (micro avg)  0.5301
2022-05-13 17:18:09,662 BAD EPOCHS (no improvement): 2
2022-05-13 17:18:09,669 ----------------------------------------------------------------------------------------------------
2022-05-13 17:18:13,257 epoch 41 - iter 10/107 - loss 0.05450674 - samples/sec: 89.21 - lr: 0.000391
2022-05-13 17:18:16,875 epoch 41 - iter 20/107 - loss 0.05508656 - samples/sec: 88.47 - lr: 0.000391
2022-05-13 17:18:20,411 epoch 41 - iter 30/107 - loss 0.05041086 - samples/sec: 90.53 - lr: 0.000391
2022-05-13 17:18:24,078 epoch 41 - iter 40/107 - loss 0.04968575 - samples/sec: 87.28 - lr: 0.000391
2022-05-13 17:18:27,739 epoch 41 - iter 50/107 - loss 0.04907522 - samples/sec: 87.44 - lr: 0.000391
2022-05-13 17:18:31,381 epoch 41 - iter 60/107 - loss 0.04903993 - samples/sec: 87.88 - lr: 0.000391
2022-05-13 17:18:34,995 epoch 41 - iter 70/107 - loss 0.04997160 - samples/sec: 88.57 - lr: 0.000391
2022-05-13 17:18:38,548 epoch 41 - iter 80/107 - loss 0.05054410 - samples/sec: 90.10 - lr: 0.000391
2022-05-13 17:18:41,709 epoch 41 - iter 90/107 - loss 0.05061641 - samples/sec: 101.27 - lr: 0.000391
2022-05-13 17:18:44,379 epoch 41 - iter 100/107 - loss 0.05048547 - samples/sec: 119.92 - lr: 0.000391
2022-05-13 17:18:46,053 ----------------------------------------------------------------------------------------------------
2022-05-13 17:18:46,053 EPOCH 41 done: loss 0.0509 - lr 0.000391
2022-05-13 17:18:57,109 Evaluating as a multi-label problem: False
2022-05-13 17:18:57,120 DEV : loss 0.2060360461473465 - f1-score (micro avg)  0.5279
2022-05-13 17:18:57,204 BAD EPOCHS (no improvement): 3
2022-05-13 17:18:57,206 ----------------------------------------------------------------------------------------------------
2022-05-13 17:19:00,907 epoch 42 - iter 10/107 - loss 0.04361903 - samples/sec: 86.49 - lr: 0.000391
2022-05-13 17:19:04,537 epoch 42 - iter 20/107 - loss 0.04972926 - samples/sec: 88.18 - lr: 0.000391
2022-05-13 17:19:08,136 epoch 42 - iter 30/107 - loss 0.04771864 - samples/sec: 88.92 - lr: 0.000391
2022-05-13 17:19:11,967 epoch 42 - iter 40/107 - loss 0.04934815 - samples/sec: 83.57 - lr: 0.000391
2022-05-13 17:19:15,457 epoch 42 - iter 50/107 - loss 0.05425678 - samples/sec: 91.70 - lr: 0.000391
2022-05-13 17:19:19,191 epoch 42 - iter 60/107 - loss 0.05331859 - samples/sec: 85.73 - lr: 0.000391
2022-05-13 17:19:21,997 epoch 42 - iter 70/107 - loss 0.05498324 - samples/sec: 114.12 - lr: 0.000391
2022-05-13 17:19:24,656 epoch 42 - iter 80/107 - loss 0.05488560 - samples/sec: 120.39 - lr: 0.000391
2022-05-13 17:19:27,526 epoch 42 - iter 90/107 - loss 0.05394317 - samples/sec: 111.53 - lr: 0.000391
2022-05-13 17:19:31,454 epoch 42 - iter 100/107 - loss 0.05349332 - samples/sec: 81.50 - lr: 0.000391
2022-05-13 17:19:33,687 ----------------------------------------------------------------------------------------------------
2022-05-13 17:19:33,687 EPOCH 42 done: loss 0.0540 - lr 0.000391
2022-05-13 17:19:44,105 Evaluating as a multi-label problem: False
2022-05-13 17:19:44,116 DEV : loss 0.2049109786748886 - f1-score (micro avg)  0.5286
2022-05-13 17:19:44,201 Epoch    42: reducing learning rate of group 0 to 1.9531e-04.
2022-05-13 17:19:44,201 BAD EPOCHS (no improvement): 4
2022-05-13 17:19:44,203 ----------------------------------------------------------------------------------------------------
2022-05-13 17:19:47,796 epoch 43 - iter 10/107 - loss 0.05142845 - samples/sec: 89.10 - lr: 0.000195
2022-05-13 17:19:51,274 epoch 43 - iter 20/107 - loss 0.05496292 - samples/sec: 92.05 - lr: 0.000195
2022-05-13 17:19:54,945 epoch 43 - iter 30/107 - loss 0.05303670 - samples/sec: 87.19 - lr: 0.000195
2022-05-13 17:19:58,729 epoch 43 - iter 40/107 - loss 0.05496089 - samples/sec: 84.59 - lr: 0.000195
2022-05-13 17:20:01,868 epoch 43 - iter 50/107 - loss 0.05299944 - samples/sec: 101.98 - lr: 0.000195
2022-05-13 17:20:04,494 epoch 43 - iter 60/107 - loss 0.05335240 - samples/sec: 121.93 - lr: 0.000195
2022-05-13 17:20:07,198 epoch 43 - iter 70/107 - loss 0.05394345 - samples/sec: 118.39 - lr: 0.000195
2022-05-13 17:20:10,845 epoch 43 - iter 80/107 - loss 0.05434789 - samples/sec: 87.76 - lr: 0.000195
2022-05-13 17:20:14,235 epoch 43 - iter 90/107 - loss 0.05311089 - samples/sec: 94.43 - lr: 0.000195
2022-05-13 17:20:17,966 epoch 43 - iter 100/107 - loss 0.05365964 - samples/sec: 85.80 - lr: 0.000195
2022-05-13 17:20:20,318 ----------------------------------------------------------------------------------------------------
2022-05-13 17:20:20,319 EPOCH 43 done: loss 0.0538 - lr 0.000195
2022-05-13 17:20:30,645 Evaluating as a multi-label problem: False
2022-05-13 17:20:30,656 DEV : loss 0.2051522433757782 - f1-score (micro avg)  0.529
2022-05-13 17:20:30,743 BAD EPOCHS (no improvement): 1
2022-05-13 17:20:30,747 ----------------------------------------------------------------------------------------------------
2022-05-13 17:20:34,538 epoch 44 - iter 10/107 - loss 0.04529224 - samples/sec: 84.45 - lr: 0.000195
2022-05-13 17:20:38,206 epoch 44 - iter 20/107 - loss 0.04731968 - samples/sec: 87.26 - lr: 0.000195
2022-05-13 17:20:41,296 epoch 44 - iter 30/107 - loss 0.04734259 - samples/sec: 103.58 - lr: 0.000195
2022-05-13 17:20:44,181 epoch 44 - iter 40/107 - loss 0.04704972 - samples/sec: 110.95 - lr: 0.000195
2022-05-13 17:20:46,813 epoch 44 - iter 50/107 - loss 0.04983364 - samples/sec: 121.64 - lr: 0.000195
2022-05-13 17:20:50,149 epoch 44 - iter 60/107 - loss 0.05009755 - samples/sec: 95.95 - lr: 0.000195
2022-05-13 17:20:53,844 epoch 44 - iter 70/107 - loss 0.05027221 - samples/sec: 86.64 - lr: 0.000195
2022-05-13 17:20:57,285 epoch 44 - iter 80/107 - loss 0.04991880 - samples/sec: 93.02 - lr: 0.000195
2022-05-13 17:21:01,307 epoch 44 - iter 90/107 - loss 0.04986409 - samples/sec: 79.58 - lr: 0.000195
2022-05-13 17:21:04,873 epoch 44 - iter 100/107 - loss 0.05221261 - samples/sec: 89.78 - lr: 0.000195
2022-05-13 17:21:07,091 ----------------------------------------------------------------------------------------------------
2022-05-13 17:21:07,092 EPOCH 44 done: loss 0.0519 - lr 0.000195
2022-05-13 17:21:17,237 Evaluating as a multi-label problem: False
2022-05-13 17:21:17,248 DEV : loss 0.20516236126422882 - f1-score (micro avg)  0.529
2022-05-13 17:21:17,334 BAD EPOCHS (no improvement): 2
2022-05-13 17:21:17,341 ----------------------------------------------------------------------------------------------------
2022-05-13 17:21:20,884 epoch 45 - iter 10/107 - loss 0.06134198 - samples/sec: 90.36 - lr: 0.000195
2022-05-13 17:21:23,723 epoch 45 - iter 20/107 - loss 0.05443395 - samples/sec: 112.78 - lr: 0.000195
2022-05-13 17:21:26,397 epoch 45 - iter 30/107 - loss 0.05519169 - samples/sec: 119.72 - lr: 0.000195
2022-05-13 17:21:29,306 epoch 45 - iter 40/107 - loss 0.05227451 - samples/sec: 110.04 - lr: 0.000195
2022-05-13 17:21:32,914 epoch 45 - iter 50/107 - loss 0.05293558 - samples/sec: 88.72 - lr: 0.000195
2022-05-13 17:21:36,557 epoch 45 - iter 60/107 - loss 0.05212599 - samples/sec: 87.85 - lr: 0.000195
2022-05-13 17:21:39,930 epoch 45 - iter 70/107 - loss 0.05164970 - samples/sec: 94.90 - lr: 0.000195
2022-05-13 17:21:43,485 epoch 45 - iter 80/107 - loss 0.05124599 - samples/sec: 90.06 - lr: 0.000195
2022-05-13 17:21:47,431 epoch 45 - iter 90/107 - loss 0.05141838 - samples/sec: 81.12 - lr: 0.000195
2022-05-13 17:21:51,087 epoch 45 - iter 100/107 - loss 0.05072963 - samples/sec: 87.55 - lr: 0.000195
2022-05-13 17:21:53,267 ----------------------------------------------------------------------------------------------------
2022-05-13 17:21:53,268 EPOCH 45 done: loss 0.0506 - lr 0.000195
2022-05-13 17:22:03,277 Evaluating as a multi-label problem: False
2022-05-13 17:22:03,288 DEV : loss 0.20555371046066284 - f1-score (micro avg)  0.5305
2022-05-13 17:22:03,379 BAD EPOCHS (no improvement): 3
2022-05-13 17:22:03,381 ----------------------------------------------------------------------------------------------------
2022-05-13 17:22:06,044 epoch 46 - iter 10/107 - loss 0.05165254 - samples/sec: 120.22 - lr: 0.000195
2022-05-13 17:22:08,716 epoch 46 - iter 20/107 - loss 0.05435364 - samples/sec: 119.81 - lr: 0.000195
2022-05-13 17:22:12,086 epoch 46 - iter 30/107 - loss 0.05427879 - samples/sec: 94.98 - lr: 0.000195
2022-05-13 17:22:15,513 epoch 46 - iter 40/107 - loss 0.05320779 - samples/sec: 93.41 - lr: 0.000195
2022-05-13 17:22:19,143 epoch 46 - iter 50/107 - loss 0.05498985 - samples/sec: 88.16 - lr: 0.000195
2022-05-13 17:22:23,055 epoch 46 - iter 60/107 - loss 0.05281753 - samples/sec: 81.83 - lr: 0.000195
2022-05-13 17:22:26,815 epoch 46 - iter 70/107 - loss 0.05132856 - samples/sec: 85.13 - lr: 0.000195
2022-05-13 17:22:30,446 epoch 46 - iter 80/107 - loss 0.05198527 - samples/sec: 88.16 - lr: 0.000195
2022-05-13 17:22:34,063 epoch 46 - iter 90/107 - loss 0.05220843 - samples/sec: 88.51 - lr: 0.000195
2022-05-13 17:22:37,807 epoch 46 - iter 100/107 - loss 0.05193120 - samples/sec: 85.48 - lr: 0.000195
2022-05-13 17:22:39,974 ----------------------------------------------------------------------------------------------------
2022-05-13 17:22:39,974 EPOCH 46 done: loss 0.0515 - lr 0.000195
2022-05-13 17:22:49,401 Evaluating as a multi-label problem: False
2022-05-13 17:22:49,412 DEV : loss 0.20533807575702667 - f1-score (micro avg)  0.5301
2022-05-13 17:22:49,497 Epoch    46: reducing learning rate of group 0 to 9.7656e-05.
2022-05-13 17:22:49,497 BAD EPOCHS (no improvement): 4
2022-05-13 17:22:49,499 ----------------------------------------------------------------------------------------------------
2022-05-13 17:22:49,499 ----------------------------------------------------------------------------------------------------
2022-05-13 17:22:49,499 learning rate too small - quitting training!
2022-05-13 17:22:49,499 ----------------------------------------------------------------------------------------------------
2022-05-13 17:23:04,583 ----------------------------------------------------------------------------------------------------
2022-05-13 17:23:04,584 loading file resources/taggers/model_08_r10_run_5/best-model.pt
2022-05-13 17:23:14,227 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-05-13 17:23:35,539 Evaluating as a multi-label problem: False
2022-05-13 17:23:35,552 0.689	0.3244	0.4411	0.2966
2022-05-13 17:23:35,552 
Results:
- F-score (micro) 0.4411
- F-score (macro) 0.3129
- Accuracy 0.2966

By class:
               precision    recall  f1-score   support

       person     0.7551    0.5175    0.6141       429
     location     0.6909    0.5067    0.5846       150
        group     0.5091    0.1697    0.2545       165
creative-work     0.8333    0.0352    0.0676       142
      product     0.5000    0.0315    0.0593       127
  corporation     0.4286    0.2273    0.2970        66

    micro avg     0.6890    0.3244    0.4411      1079
    macro avg     0.6195    0.2480    0.3129      1079
 weighted avg     0.6689    0.3244    0.3984      1079

2022-05-13 17:23:35,552 ----------------------------------------------------------------------------------------------------
