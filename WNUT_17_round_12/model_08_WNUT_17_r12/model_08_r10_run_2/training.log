2022-05-13 14:52:48,908 ----------------------------------------------------------------------------------------------------
2022-05-13 14:52:48,908 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_3): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4857, out_features=4857, bias=True)
  (rnn): LSTM(4857, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-05-13 14:52:48,908 ----------------------------------------------------------------------------------------------------
2022-05-13 14:52:48,908 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-05-13 14:52:48,909 ----------------------------------------------------------------------------------------------------
2022-05-13 14:52:48,909 Parameters:
2022-05-13 14:52:48,909  - learning_rate: "0.100000"
2022-05-13 14:52:48,909  - mini_batch_size: "32"
2022-05-13 14:52:48,909  - patience: "3"
2022-05-13 14:52:48,909  - anneal_factor: "0.5"
2022-05-13 14:52:48,909  - max_epochs: "150"
2022-05-13 14:52:48,909  - shuffle: "True"
2022-05-13 14:52:48,909  - train_with_dev: "False"
2022-05-13 14:52:48,909  - batch_growth_annealing: "False"
2022-05-13 14:52:48,909 ----------------------------------------------------------------------------------------------------
2022-05-13 14:52:48,909 Model training base path: "resources/taggers/model_08_r10_run_2"
2022-05-13 14:52:48,909 ----------------------------------------------------------------------------------------------------
2022-05-13 14:52:48,909 Device: cuda:2
2022-05-13 14:52:48,909 ----------------------------------------------------------------------------------------------------
2022-05-13 14:52:48,909 Embeddings storage mode: cpu
2022-05-13 14:52:48,909 ----------------------------------------------------------------------------------------------------
2022-05-13 14:52:52,746 epoch 1 - iter 10/107 - loss 1.10214723 - samples/sec: 83.41 - lr: 0.100000
2022-05-13 14:52:56,465 epoch 1 - iter 20/107 - loss 0.68499063 - samples/sec: 86.07 - lr: 0.100000
2022-05-13 14:52:59,392 epoch 1 - iter 30/107 - loss 0.54707224 - samples/sec: 109.36 - lr: 0.100000
2022-05-13 14:53:02,081 epoch 1 - iter 40/107 - loss 0.47251345 - samples/sec: 119.05 - lr: 0.100000
2022-05-13 14:53:05,005 epoch 1 - iter 50/107 - loss 0.41869093 - samples/sec: 109.50 - lr: 0.100000
2022-05-13 14:53:08,794 epoch 1 - iter 60/107 - loss 0.39761932 - samples/sec: 84.48 - lr: 0.100000
2022-05-13 14:53:12,411 epoch 1 - iter 70/107 - loss 0.38100047 - samples/sec: 88.48 - lr: 0.100000
2022-05-13 14:53:15,829 epoch 1 - iter 80/107 - loss 0.37292977 - samples/sec: 93.66 - lr: 0.100000
2022-05-13 14:53:18,952 epoch 1 - iter 90/107 - loss 0.36664084 - samples/sec: 102.52 - lr: 0.100000
2022-05-13 14:53:21,903 epoch 1 - iter 100/107 - loss 0.35777996 - samples/sec: 108.48 - lr: 0.100000
2022-05-13 14:53:23,990 ----------------------------------------------------------------------------------------------------
2022-05-13 14:53:23,990 EPOCH 1 done: loss 0.3504 - lr 0.100000
2022-05-13 14:53:34,485 Evaluating as a multi-label problem: False
2022-05-13 14:53:34,495 DEV : loss 0.43391478061676025 - f1-score (micro avg)  0.212
2022-05-13 14:53:34,578 BAD EPOCHS (no improvement): 0
2022-05-13 14:53:34,580 saving best model
2022-05-13 14:53:49,344 ----------------------------------------------------------------------------------------------------
2022-05-13 14:53:53,237 epoch 2 - iter 10/107 - loss 0.20080809 - samples/sec: 82.22 - lr: 0.100000
2022-05-13 14:53:56,729 epoch 2 - iter 20/107 - loss 0.19473055 - samples/sec: 91.69 - lr: 0.100000
2022-05-13 14:54:00,549 epoch 2 - iter 30/107 - loss 0.19892444 - samples/sec: 83.78 - lr: 0.100000
2022-05-13 14:54:04,397 epoch 2 - iter 40/107 - loss 0.20110727 - samples/sec: 83.18 - lr: 0.100000
2022-05-13 14:54:07,879 epoch 2 - iter 50/107 - loss 0.19712550 - samples/sec: 91.95 - lr: 0.100000
2022-05-13 14:54:11,331 epoch 2 - iter 60/107 - loss 0.20139196 - samples/sec: 92.73 - lr: 0.100000
2022-05-13 14:54:14,183 epoch 2 - iter 70/107 - loss 0.19509355 - samples/sec: 112.24 - lr: 0.100000
2022-05-13 14:54:16,837 epoch 2 - iter 80/107 - loss 0.19200483 - samples/sec: 120.62 - lr: 0.100000
2022-05-13 14:54:19,706 epoch 2 - iter 90/107 - loss 0.18873839 - samples/sec: 111.57 - lr: 0.100000
2022-05-13 14:54:23,427 epoch 2 - iter 100/107 - loss 0.18676845 - samples/sec: 86.03 - lr: 0.100000
2022-05-13 14:54:25,804 ----------------------------------------------------------------------------------------------------
2022-05-13 14:54:25,804 EPOCH 2 done: loss 0.1846 - lr 0.100000
2022-05-13 14:54:36,198 Evaluating as a multi-label problem: False
2022-05-13 14:54:36,208 DEV : loss 0.2976748049259186 - f1-score (micro avg)  0.4654
2022-05-13 14:54:36,291 BAD EPOCHS (no improvement): 0
2022-05-13 14:54:36,358 saving best model
2022-05-13 14:54:51,109 ----------------------------------------------------------------------------------------------------
2022-05-13 14:54:54,787 epoch 3 - iter 10/107 - loss 0.16113188 - samples/sec: 87.06 - lr: 0.100000
2022-05-13 14:54:58,449 epoch 3 - iter 20/107 - loss 0.16234938 - samples/sec: 87.41 - lr: 0.100000
2022-05-13 14:55:02,095 epoch 3 - iter 30/107 - loss 0.16473545 - samples/sec: 87.79 - lr: 0.100000
2022-05-13 14:55:05,493 epoch 3 - iter 40/107 - loss 0.16321908 - samples/sec: 94.22 - lr: 0.100000
2022-05-13 14:55:09,068 epoch 3 - iter 50/107 - loss 0.15675424 - samples/sec: 89.51 - lr: 0.100000
2022-05-13 14:55:12,763 epoch 3 - iter 60/107 - loss 0.15732423 - samples/sec: 86.64 - lr: 0.100000
2022-05-13 14:55:16,708 epoch 3 - iter 70/107 - loss 0.15845535 - samples/sec: 81.13 - lr: 0.100000
2022-05-13 14:55:20,039 epoch 3 - iter 80/107 - loss 0.16055053 - samples/sec: 96.12 - lr: 0.100000
2022-05-13 14:55:23,720 epoch 3 - iter 90/107 - loss 0.15793201 - samples/sec: 86.94 - lr: 0.100000
2022-05-13 14:55:26,710 epoch 3 - iter 100/107 - loss 0.15624529 - samples/sec: 107.07 - lr: 0.100000
2022-05-13 14:55:28,310 ----------------------------------------------------------------------------------------------------
2022-05-13 14:55:28,310 EPOCH 3 done: loss 0.1570 - lr 0.100000
2022-05-13 14:55:37,541 Evaluating as a multi-label problem: False
2022-05-13 14:55:37,552 DEV : loss 0.22897347807884216 - f1-score (micro avg)  0.4977
2022-05-13 14:55:37,636 BAD EPOCHS (no improvement): 0
2022-05-13 14:55:37,638 saving best model
2022-05-13 14:55:52,728 ----------------------------------------------------------------------------------------------------
2022-05-13 14:55:55,768 epoch 4 - iter 10/107 - loss 0.14986499 - samples/sec: 105.32 - lr: 0.100000
2022-05-13 14:55:58,500 epoch 4 - iter 20/107 - loss 0.14250633 - samples/sec: 117.19 - lr: 0.100000
2022-05-13 14:56:01,360 epoch 4 - iter 30/107 - loss 0.14109595 - samples/sec: 111.90 - lr: 0.100000
2022-05-13 14:56:05,054 epoch 4 - iter 40/107 - loss 0.14587629 - samples/sec: 86.67 - lr: 0.100000
2022-05-13 14:56:08,503 epoch 4 - iter 50/107 - loss 0.14220366 - samples/sec: 92.81 - lr: 0.100000
2022-05-13 14:56:12,218 epoch 4 - iter 60/107 - loss 0.14558438 - samples/sec: 86.15 - lr: 0.100000
2022-05-13 14:56:15,884 epoch 4 - iter 70/107 - loss 0.14314038 - samples/sec: 87.32 - lr: 0.100000
2022-05-13 14:56:19,509 epoch 4 - iter 80/107 - loss 0.13823051 - samples/sec: 88.29 - lr: 0.100000
2022-05-13 14:56:22,881 epoch 4 - iter 90/107 - loss 0.13604753 - samples/sec: 94.94 - lr: 0.100000
2022-05-13 14:56:26,386 epoch 4 - iter 100/107 - loss 0.13679704 - samples/sec: 91.32 - lr: 0.100000
2022-05-13 14:56:28,517 ----------------------------------------------------------------------------------------------------
2022-05-13 14:56:28,517 EPOCH 4 done: loss 0.1350 - lr 0.100000
2022-05-13 14:56:37,838 Evaluating as a multi-label problem: False
2022-05-13 14:56:37,848 DEV : loss 0.24801209568977356 - f1-score (micro avg)  0.4677
2022-05-13 14:56:37,931 BAD EPOCHS (no improvement): 1
2022-05-13 14:56:37,933 ----------------------------------------------------------------------------------------------------
2022-05-13 14:56:40,601 epoch 5 - iter 10/107 - loss 0.12342583 - samples/sec: 119.97 - lr: 0.100000
2022-05-13 14:56:43,885 epoch 5 - iter 20/107 - loss 0.11956880 - samples/sec: 97.49 - lr: 0.100000
2022-05-13 14:56:47,393 epoch 5 - iter 30/107 - loss 0.13205072 - samples/sec: 91.23 - lr: 0.100000
2022-05-13 14:56:50,998 epoch 5 - iter 40/107 - loss 0.12886810 - samples/sec: 88.81 - lr: 0.100000
2022-05-13 14:56:54,612 epoch 5 - iter 50/107 - loss 0.12989658 - samples/sec: 88.56 - lr: 0.100000
2022-05-13 14:56:57,855 epoch 5 - iter 60/107 - loss 0.13006877 - samples/sec: 98.72 - lr: 0.100000
2022-05-13 14:57:01,465 epoch 5 - iter 70/107 - loss 0.12699362 - samples/sec: 88.65 - lr: 0.100000
2022-05-13 14:57:05,254 epoch 5 - iter 80/107 - loss 0.12579911 - samples/sec: 84.48 - lr: 0.100000
2022-05-13 14:57:08,654 epoch 5 - iter 90/107 - loss 0.12665831 - samples/sec: 94.17 - lr: 0.100000
2022-05-13 14:57:12,215 epoch 5 - iter 100/107 - loss 0.12560255 - samples/sec: 89.88 - lr: 0.100000
2022-05-13 14:57:14,474 ----------------------------------------------------------------------------------------------------
2022-05-13 14:57:14,474 EPOCH 5 done: loss 0.1255 - lr 0.100000
2022-05-13 14:57:22,663 Evaluating as a multi-label problem: False
2022-05-13 14:57:22,674 DEV : loss 0.21970677375793457 - f1-score (micro avg)  0.51
2022-05-13 14:57:22,759 BAD EPOCHS (no improvement): 0
2022-05-13 14:57:22,761 saving best model
2022-05-13 14:57:37,606 ----------------------------------------------------------------------------------------------------
2022-05-13 14:57:41,420 epoch 6 - iter 10/107 - loss 0.14494750 - samples/sec: 83.94 - lr: 0.100000
2022-05-13 14:57:44,936 epoch 6 - iter 20/107 - loss 0.12677032 - samples/sec: 91.03 - lr: 0.100000
2022-05-13 14:57:47,759 epoch 6 - iter 30/107 - loss 0.12340007 - samples/sec: 113.42 - lr: 0.100000
2022-05-13 14:57:50,536 epoch 6 - iter 40/107 - loss 0.12457227 - samples/sec: 115.26 - lr: 0.100000
2022-05-13 14:57:53,212 epoch 6 - iter 50/107 - loss 0.12261246 - samples/sec: 119.60 - lr: 0.100000
2022-05-13 14:57:56,623 epoch 6 - iter 60/107 - loss 0.12099446 - samples/sec: 93.86 - lr: 0.100000
2022-05-13 14:57:59,980 epoch 6 - iter 70/107 - loss 0.12062607 - samples/sec: 95.35 - lr: 0.100000
2022-05-13 14:58:03,375 epoch 6 - iter 80/107 - loss 0.11692611 - samples/sec: 94.29 - lr: 0.100000
2022-05-13 14:58:07,130 epoch 6 - iter 90/107 - loss 0.11647161 - samples/sec: 85.25 - lr: 0.100000
2022-05-13 14:58:10,789 epoch 6 - iter 100/107 - loss 0.11572856 - samples/sec: 87.48 - lr: 0.100000
2022-05-13 14:58:12,986 ----------------------------------------------------------------------------------------------------
2022-05-13 14:58:12,986 EPOCH 6 done: loss 0.1137 - lr 0.100000
2022-05-13 14:58:23,580 Evaluating as a multi-label problem: False
2022-05-13 14:58:23,591 DEV : loss 0.2378268539905548 - f1-score (micro avg)  0.4736
2022-05-13 14:58:23,675 BAD EPOCHS (no improvement): 1
2022-05-13 14:58:23,677 ----------------------------------------------------------------------------------------------------
2022-05-13 14:58:27,097 epoch 7 - iter 10/107 - loss 0.11813629 - samples/sec: 93.61 - lr: 0.100000
2022-05-13 14:58:29,911 epoch 7 - iter 20/107 - loss 0.11794352 - samples/sec: 113.76 - lr: 0.100000
2022-05-13 14:58:32,640 epoch 7 - iter 30/107 - loss 0.12032529 - samples/sec: 117.31 - lr: 0.100000
2022-05-13 14:58:35,386 epoch 7 - iter 40/107 - loss 0.11239850 - samples/sec: 116.57 - lr: 0.100000
2022-05-13 14:58:39,010 epoch 7 - iter 50/107 - loss 0.10764909 - samples/sec: 88.33 - lr: 0.100000
2022-05-13 14:58:42,452 epoch 7 - iter 60/107 - loss 0.10559559 - samples/sec: 93.01 - lr: 0.100000
2022-05-13 14:58:46,153 epoch 7 - iter 70/107 - loss 0.10639078 - samples/sec: 86.49 - lr: 0.100000
2022-05-13 14:58:49,507 epoch 7 - iter 80/107 - loss 0.10290141 - samples/sec: 95.46 - lr: 0.100000
2022-05-13 14:58:53,327 epoch 7 - iter 90/107 - loss 0.10270811 - samples/sec: 83.78 - lr: 0.100000
2022-05-13 14:58:56,795 epoch 7 - iter 100/107 - loss 0.10449452 - samples/sec: 92.30 - lr: 0.100000
2022-05-13 14:58:58,923 ----------------------------------------------------------------------------------------------------
2022-05-13 14:58:58,923 EPOCH 7 done: loss 0.1063 - lr 0.100000
2022-05-13 14:59:08,728 Evaluating as a multi-label problem: False
2022-05-13 14:59:08,739 DEV : loss 0.2252945899963379 - f1-score (micro avg)  0.4669
2022-05-13 14:59:08,822 BAD EPOCHS (no improvement): 2
2022-05-13 14:59:08,824 ----------------------------------------------------------------------------------------------------
2022-05-13 14:59:11,683 epoch 8 - iter 10/107 - loss 0.10314718 - samples/sec: 111.97 - lr: 0.100000
2022-05-13 14:59:14,415 epoch 8 - iter 20/107 - loss 0.10132718 - samples/sec: 117.18 - lr: 0.100000
2022-05-13 14:59:17,753 epoch 8 - iter 30/107 - loss 0.09969032 - samples/sec: 95.89 - lr: 0.100000
2022-05-13 14:59:21,369 epoch 8 - iter 40/107 - loss 0.10138086 - samples/sec: 88.53 - lr: 0.100000
2022-05-13 14:59:24,897 epoch 8 - iter 50/107 - loss 0.10048611 - samples/sec: 90.74 - lr: 0.100000
2022-05-13 14:59:28,335 epoch 8 - iter 60/107 - loss 0.10136472 - samples/sec: 93.12 - lr: 0.100000
2022-05-13 14:59:31,643 epoch 8 - iter 70/107 - loss 0.10143795 - samples/sec: 96.77 - lr: 0.100000
2022-05-13 14:59:35,248 epoch 8 - iter 80/107 - loss 0.09987842 - samples/sec: 88.79 - lr: 0.100000
2022-05-13 14:59:39,077 epoch 8 - iter 90/107 - loss 0.10002688 - samples/sec: 83.58 - lr: 0.100000
2022-05-13 14:59:41,325 epoch 8 - iter 100/107 - loss 0.09883663 - samples/sec: 142.41 - lr: 0.100000
2022-05-13 14:59:43,202 ----------------------------------------------------------------------------------------------------
2022-05-13 14:59:43,202 EPOCH 8 done: loss 0.0993 - lr 0.100000
2022-05-13 14:59:52,703 Evaluating as a multi-label problem: False
2022-05-13 14:59:52,714 DEV : loss 0.1888570636510849 - f1-score (micro avg)  0.5127
2022-05-13 14:59:52,801 BAD EPOCHS (no improvement): 0
2022-05-13 14:59:52,802 saving best model
2022-05-13 15:00:08,083 ----------------------------------------------------------------------------------------------------
2022-05-13 15:00:11,884 epoch 9 - iter 10/107 - loss 0.08383519 - samples/sec: 84.21 - lr: 0.100000
2022-05-13 15:00:15,404 epoch 9 - iter 20/107 - loss 0.09135509 - samples/sec: 90.96 - lr: 0.100000
2022-05-13 15:00:19,055 epoch 9 - iter 30/107 - loss 0.09025833 - samples/sec: 87.67 - lr: 0.100000
2022-05-13 15:00:22,039 epoch 9 - iter 40/107 - loss 0.09467091 - samples/sec: 107.29 - lr: 0.100000
2022-05-13 15:00:24,713 epoch 9 - iter 50/107 - loss 0.09653526 - samples/sec: 119.71 - lr: 0.100000
2022-05-13 15:00:27,385 epoch 9 - iter 60/107 - loss 0.09398243 - samples/sec: 119.78 - lr: 0.100000
2022-05-13 15:00:30,497 epoch 9 - iter 70/107 - loss 0.09115396 - samples/sec: 102.89 - lr: 0.100000
2022-05-13 15:00:34,311 epoch 9 - iter 80/107 - loss 0.09229338 - samples/sec: 83.92 - lr: 0.100000
2022-05-13 15:00:37,950 epoch 9 - iter 90/107 - loss 0.09150418 - samples/sec: 87.95 - lr: 0.100000
2022-05-13 15:00:41,708 epoch 9 - iter 100/107 - loss 0.09085922 - samples/sec: 85.17 - lr: 0.100000
2022-05-13 15:00:44,077 ----------------------------------------------------------------------------------------------------
2022-05-13 15:00:44,077 EPOCH 9 done: loss 0.0910 - lr 0.100000
2022-05-13 15:00:56,333 Evaluating as a multi-label problem: False
2022-05-13 15:00:56,344 DEV : loss 0.1914677917957306 - f1-score (micro avg)  0.5351
2022-05-13 15:00:56,431 BAD EPOCHS (no improvement): 0
2022-05-13 15:00:56,448 saving best model
2022-05-13 15:01:11,849 ----------------------------------------------------------------------------------------------------
2022-05-13 15:01:15,510 epoch 10 - iter 10/107 - loss 0.08307746 - samples/sec: 87.44 - lr: 0.100000
2022-05-13 15:01:19,252 epoch 10 - iter 20/107 - loss 0.08515752 - samples/sec: 85.55 - lr: 0.100000
2022-05-13 15:01:22,808 epoch 10 - iter 30/107 - loss 0.08791625 - samples/sec: 90.01 - lr: 0.100000
2022-05-13 15:01:26,608 epoch 10 - iter 40/107 - loss 0.09127389 - samples/sec: 84.24 - lr: 0.100000
2022-05-13 15:01:30,206 epoch 10 - iter 50/107 - loss 0.08717460 - samples/sec: 88.95 - lr: 0.100000
2022-05-13 15:01:33,207 epoch 10 - iter 60/107 - loss 0.08741406 - samples/sec: 106.67 - lr: 0.100000
2022-05-13 15:01:35,782 epoch 10 - iter 70/107 - loss 0.08870198 - samples/sec: 124.34 - lr: 0.100000
2022-05-13 15:01:38,437 epoch 10 - iter 80/107 - loss 0.08814800 - samples/sec: 120.55 - lr: 0.100000
2022-05-13 15:01:41,337 epoch 10 - iter 90/107 - loss 0.08703351 - samples/sec: 110.39 - lr: 0.100000
2022-05-13 15:01:45,348 epoch 10 - iter 100/107 - loss 0.08750063 - samples/sec: 79.79 - lr: 0.100000
2022-05-13 15:01:47,555 ----------------------------------------------------------------------------------------------------
2022-05-13 15:01:47,555 EPOCH 10 done: loss 0.0867 - lr 0.100000
2022-05-13 15:01:58,246 Evaluating as a multi-label problem: False
2022-05-13 15:01:58,257 DEV : loss 0.22673816978931427 - f1-score (micro avg)  0.5024
2022-05-13 15:01:58,340 BAD EPOCHS (no improvement): 1
2022-05-13 15:01:58,343 ----------------------------------------------------------------------------------------------------
2022-05-13 15:02:02,019 epoch 11 - iter 10/107 - loss 0.08832787 - samples/sec: 87.09 - lr: 0.100000
2022-05-13 15:02:05,425 epoch 11 - iter 20/107 - loss 0.08389090 - samples/sec: 93.98 - lr: 0.100000
2022-05-13 15:02:09,226 epoch 11 - iter 30/107 - loss 0.07891778 - samples/sec: 84.20 - lr: 0.100000
2022-05-13 15:02:12,925 epoch 11 - iter 40/107 - loss 0.07672651 - samples/sec: 86.54 - lr: 0.100000
2022-05-13 15:02:15,517 epoch 11 - iter 50/107 - loss 0.08077492 - samples/sec: 123.49 - lr: 0.100000
2022-05-13 15:02:18,219 epoch 11 - iter 60/107 - loss 0.08051612 - samples/sec: 118.49 - lr: 0.100000
2022-05-13 15:02:21,175 epoch 11 - iter 70/107 - loss 0.07962641 - samples/sec: 108.30 - lr: 0.100000
2022-05-13 15:02:25,019 epoch 11 - iter 80/107 - loss 0.07924208 - samples/sec: 83.26 - lr: 0.100000
2022-05-13 15:02:28,575 epoch 11 - iter 90/107 - loss 0.08145478 - samples/sec: 90.00 - lr: 0.100000
2022-05-13 15:02:32,400 epoch 11 - iter 100/107 - loss 0.08250346 - samples/sec: 83.70 - lr: 0.100000
2022-05-13 15:02:34,507 ----------------------------------------------------------------------------------------------------
2022-05-13 15:02:34,507 EPOCH 11 done: loss 0.0828 - lr 0.100000
2022-05-13 15:02:44,976 Evaluating as a multi-label problem: False
2022-05-13 15:02:44,987 DEV : loss 0.21119360625743866 - f1-score (micro avg)  0.4892
2022-05-13 15:02:45,071 BAD EPOCHS (no improvement): 2
2022-05-13 15:02:45,073 ----------------------------------------------------------------------------------------------------
2022-05-13 15:02:48,637 epoch 12 - iter 10/107 - loss 0.08597232 - samples/sec: 89.84 - lr: 0.100000
2022-05-13 15:02:52,470 epoch 12 - iter 20/107 - loss 0.08332066 - samples/sec: 83.51 - lr: 0.100000
2022-05-13 15:02:55,379 epoch 12 - iter 30/107 - loss 0.08222133 - samples/sec: 110.03 - lr: 0.100000
2022-05-13 15:02:58,046 epoch 12 - iter 40/107 - loss 0.07935450 - samples/sec: 120.03 - lr: 0.100000
2022-05-13 15:03:00,770 epoch 12 - iter 50/107 - loss 0.08008254 - samples/sec: 117.52 - lr: 0.100000
2022-05-13 15:03:03,924 epoch 12 - iter 60/107 - loss 0.07950583 - samples/sec: 101.50 - lr: 0.100000
2022-05-13 15:03:07,580 epoch 12 - iter 70/107 - loss 0.08158120 - samples/sec: 87.55 - lr: 0.100000
2022-05-13 15:03:11,312 epoch 12 - iter 80/107 - loss 0.07947794 - samples/sec: 85.77 - lr: 0.100000
2022-05-13 15:03:14,519 epoch 12 - iter 90/107 - loss 0.07740899 - samples/sec: 99.81 - lr: 0.100000
2022-05-13 15:03:18,231 epoch 12 - iter 100/107 - loss 0.07829545 - samples/sec: 86.24 - lr: 0.100000
2022-05-13 15:03:20,553 ----------------------------------------------------------------------------------------------------
2022-05-13 15:03:20,553 EPOCH 12 done: loss 0.0782 - lr 0.100000
2022-05-13 15:03:31,252 Evaluating as a multi-label problem: False
2022-05-13 15:03:31,263 DEV : loss 0.22978921234607697 - f1-score (micro avg)  0.4827
2022-05-13 15:03:31,347 BAD EPOCHS (no improvement): 3
2022-05-13 15:03:31,349 ----------------------------------------------------------------------------------------------------
2022-05-13 15:03:34,629 epoch 13 - iter 10/107 - loss 0.06245341 - samples/sec: 97.60 - lr: 0.100000
2022-05-13 15:03:37,492 epoch 13 - iter 20/107 - loss 0.06246757 - samples/sec: 111.83 - lr: 0.100000
2022-05-13 15:03:40,225 epoch 13 - iter 30/107 - loss 0.06837411 - samples/sec: 117.13 - lr: 0.100000
2022-05-13 15:03:43,044 epoch 13 - iter 40/107 - loss 0.06959239 - samples/sec: 113.54 - lr: 0.100000
2022-05-13 15:03:46,621 epoch 13 - iter 50/107 - loss 0.06919899 - samples/sec: 89.50 - lr: 0.100000
2022-05-13 15:03:49,804 epoch 13 - iter 60/107 - loss 0.07054677 - samples/sec: 100.55 - lr: 0.100000
2022-05-13 15:03:53,307 epoch 13 - iter 70/107 - loss 0.07103281 - samples/sec: 91.39 - lr: 0.100000
2022-05-13 15:03:56,860 epoch 13 - iter 80/107 - loss 0.07229864 - samples/sec: 90.07 - lr: 0.100000
2022-05-13 15:04:00,542 epoch 13 - iter 90/107 - loss 0.07319465 - samples/sec: 86.95 - lr: 0.100000
2022-05-13 15:04:04,192 epoch 13 - iter 100/107 - loss 0.07326011 - samples/sec: 87.70 - lr: 0.100000
2022-05-13 15:04:06,335 ----------------------------------------------------------------------------------------------------
2022-05-13 15:04:06,335 EPOCH 13 done: loss 0.0737 - lr 0.100000
2022-05-13 15:04:16,416 Evaluating as a multi-label problem: False
2022-05-13 15:04:16,427 DEV : loss 0.1895700842142105 - f1-score (micro avg)  0.516
2022-05-13 15:04:16,511 Epoch    13: reducing learning rate of group 0 to 5.0000e-02.
2022-05-13 15:04:16,511 BAD EPOCHS (no improvement): 4
2022-05-13 15:04:16,514 ----------------------------------------------------------------------------------------------------
2022-05-13 15:04:19,193 epoch 14 - iter 10/107 - loss 0.07061744 - samples/sec: 119.51 - lr: 0.050000
2022-05-13 15:04:22,096 epoch 14 - iter 20/107 - loss 0.06972926 - samples/sec: 110.29 - lr: 0.050000
2022-05-13 15:04:25,655 epoch 14 - iter 30/107 - loss 0.06714300 - samples/sec: 89.93 - lr: 0.050000
2022-05-13 15:04:29,548 epoch 14 - iter 40/107 - loss 0.06268004 - samples/sec: 82.23 - lr: 0.050000
2022-05-13 15:04:33,392 epoch 14 - iter 50/107 - loss 0.06351193 - samples/sec: 83.26 - lr: 0.050000
2022-05-13 15:04:37,291 epoch 14 - iter 60/107 - loss 0.06275202 - samples/sec: 82.11 - lr: 0.050000
2022-05-13 15:04:40,974 epoch 14 - iter 70/107 - loss 0.06352179 - samples/sec: 86.91 - lr: 0.050000
2022-05-13 15:04:44,778 epoch 14 - iter 80/107 - loss 0.06395027 - samples/sec: 84.16 - lr: 0.050000
2022-05-13 15:04:48,555 epoch 14 - iter 90/107 - loss 0.06479598 - samples/sec: 84.75 - lr: 0.050000
2022-05-13 15:04:52,464 epoch 14 - iter 100/107 - loss 0.06455307 - samples/sec: 81.87 - lr: 0.050000
2022-05-13 15:04:54,464 ----------------------------------------------------------------------------------------------------
2022-05-13 15:04:54,464 EPOCH 14 done: loss 0.0646 - lr 0.050000
2022-05-13 15:05:02,891 Evaluating as a multi-label problem: False
2022-05-13 15:05:02,902 DEV : loss 0.1874294877052307 - f1-score (micro avg)  0.536
2022-05-13 15:05:02,988 BAD EPOCHS (no improvement): 0
2022-05-13 15:05:02,989 saving best model
2022-05-13 15:05:18,221 ----------------------------------------------------------------------------------------------------
2022-05-13 15:05:22,003 epoch 15 - iter 10/107 - loss 0.07750625 - samples/sec: 84.66 - lr: 0.050000
2022-05-13 15:05:25,611 epoch 15 - iter 20/107 - loss 0.06367539 - samples/sec: 88.72 - lr: 0.050000
2022-05-13 15:05:28,410 epoch 15 - iter 30/107 - loss 0.06269249 - samples/sec: 114.40 - lr: 0.050000
2022-05-13 15:05:31,100 epoch 15 - iter 40/107 - loss 0.06587637 - samples/sec: 118.99 - lr: 0.050000
2022-05-13 15:05:33,750 epoch 15 - iter 50/107 - loss 0.06535388 - samples/sec: 120.80 - lr: 0.050000
2022-05-13 15:05:37,523 epoch 15 - iter 60/107 - loss 0.06340076 - samples/sec: 84.84 - lr: 0.050000
2022-05-13 15:05:41,340 epoch 15 - iter 70/107 - loss 0.06254013 - samples/sec: 83.85 - lr: 0.050000
2022-05-13 15:05:45,015 epoch 15 - iter 80/107 - loss 0.06247122 - samples/sec: 87.10 - lr: 0.050000
2022-05-13 15:05:48,834 epoch 15 - iter 90/107 - loss 0.06149569 - samples/sec: 83.82 - lr: 0.050000
2022-05-13 15:05:52,468 epoch 15 - iter 100/107 - loss 0.06101996 - samples/sec: 88.08 - lr: 0.050000
2022-05-13 15:05:54,664 ----------------------------------------------------------------------------------------------------
2022-05-13 15:05:54,664 EPOCH 15 done: loss 0.0611 - lr 0.050000
2022-05-13 15:06:06,422 Evaluating as a multi-label problem: False
2022-05-13 15:06:06,433 DEV : loss 0.19308090209960938 - f1-score (micro avg)  0.5247
2022-05-13 15:06:06,517 BAD EPOCHS (no improvement): 1
2022-05-13 15:06:06,519 ----------------------------------------------------------------------------------------------------
2022-05-13 15:06:09,187 epoch 16 - iter 10/107 - loss 0.04314712 - samples/sec: 119.99 - lr: 0.050000
2022-05-13 15:06:11,870 epoch 16 - iter 20/107 - loss 0.05102387 - samples/sec: 119.33 - lr: 0.050000
2022-05-13 15:06:14,373 epoch 16 - iter 30/107 - loss 0.05667475 - samples/sec: 127.88 - lr: 0.050000
2022-05-13 15:06:18,163 epoch 16 - iter 40/107 - loss 0.05597540 - samples/sec: 84.45 - lr: 0.050000
2022-05-13 15:06:22,174 epoch 16 - iter 50/107 - loss 0.05678519 - samples/sec: 79.82 - lr: 0.050000
2022-05-13 15:06:25,896 epoch 16 - iter 60/107 - loss 0.05908333 - samples/sec: 85.99 - lr: 0.050000
2022-05-13 15:06:29,591 epoch 16 - iter 70/107 - loss 0.05928344 - samples/sec: 86.62 - lr: 0.050000
2022-05-13 15:06:33,189 epoch 16 - iter 80/107 - loss 0.05932221 - samples/sec: 88.97 - lr: 0.050000
2022-05-13 15:06:36,808 epoch 16 - iter 90/107 - loss 0.05889297 - samples/sec: 88.44 - lr: 0.050000
2022-05-13 15:06:40,416 epoch 16 - iter 100/107 - loss 0.05857104 - samples/sec: 88.73 - lr: 0.050000
2022-05-13 15:06:42,782 ----------------------------------------------------------------------------------------------------
2022-05-13 15:06:42,782 EPOCH 16 done: loss 0.0587 - lr 0.050000
2022-05-13 15:06:51,974 Evaluating as a multi-label problem: False
2022-05-13 15:06:51,986 DEV : loss 0.18686527013778687 - f1-score (micro avg)  0.5309
2022-05-13 15:06:52,069 BAD EPOCHS (no improvement): 2
2022-05-13 15:06:52,072 ----------------------------------------------------------------------------------------------------
2022-05-13 15:06:54,757 epoch 17 - iter 10/107 - loss 0.05135697 - samples/sec: 119.24 - lr: 0.050000
2022-05-13 15:06:57,807 epoch 17 - iter 20/107 - loss 0.06583549 - samples/sec: 104.95 - lr: 0.050000
2022-05-13 15:07:01,309 epoch 17 - iter 30/107 - loss 0.06104967 - samples/sec: 91.40 - lr: 0.050000
2022-05-13 15:07:05,145 epoch 17 - iter 40/107 - loss 0.05907182 - samples/sec: 83.45 - lr: 0.050000
2022-05-13 15:07:08,673 epoch 17 - iter 50/107 - loss 0.05654430 - samples/sec: 90.73 - lr: 0.050000
2022-05-13 15:07:12,165 epoch 17 - iter 60/107 - loss 0.05771926 - samples/sec: 91.68 - lr: 0.050000
2022-05-13 15:07:15,860 epoch 17 - iter 70/107 - loss 0.05712098 - samples/sec: 86.62 - lr: 0.050000
2022-05-13 15:07:19,625 epoch 17 - iter 80/107 - loss 0.05634361 - samples/sec: 85.01 - lr: 0.050000
2022-05-13 15:07:23,233 epoch 17 - iter 90/107 - loss 0.05758528 - samples/sec: 88.73 - lr: 0.050000
2022-05-13 15:07:26,776 epoch 17 - iter 100/107 - loss 0.05900773 - samples/sec: 90.35 - lr: 0.050000
2022-05-13 15:07:29,193 ----------------------------------------------------------------------------------------------------
2022-05-13 15:07:29,193 EPOCH 17 done: loss 0.0588 - lr 0.050000
2022-05-13 15:07:36,675 Evaluating as a multi-label problem: False
2022-05-13 15:07:36,686 DEV : loss 0.20098650455474854 - f1-score (micro avg)  0.5133
2022-05-13 15:07:36,770 BAD EPOCHS (no improvement): 3
2022-05-13 15:07:36,815 ----------------------------------------------------------------------------------------------------
2022-05-13 15:07:40,379 epoch 18 - iter 10/107 - loss 0.04862234 - samples/sec: 89.85 - lr: 0.050000
2022-05-13 15:07:44,265 epoch 18 - iter 20/107 - loss 0.05060025 - samples/sec: 82.35 - lr: 0.050000
2022-05-13 15:07:47,919 epoch 18 - iter 30/107 - loss 0.05494089 - samples/sec: 87.60 - lr: 0.050000
2022-05-13 15:07:51,376 epoch 18 - iter 40/107 - loss 0.05840925 - samples/sec: 92.59 - lr: 0.050000
2022-05-13 15:07:54,876 epoch 18 - iter 50/107 - loss 0.05627184 - samples/sec: 91.48 - lr: 0.050000
2022-05-13 15:07:58,530 epoch 18 - iter 60/107 - loss 0.05606663 - samples/sec: 87.60 - lr: 0.050000
2022-05-13 15:08:01,933 epoch 18 - iter 70/107 - loss 0.05521424 - samples/sec: 94.06 - lr: 0.050000
2022-05-13 15:08:05,977 epoch 18 - iter 80/107 - loss 0.05442123 - samples/sec: 79.14 - lr: 0.050000
2022-05-13 15:08:09,712 epoch 18 - iter 90/107 - loss 0.05427542 - samples/sec: 85.70 - lr: 0.050000
2022-05-13 15:08:12,895 epoch 18 - iter 100/107 - loss 0.05419717 - samples/sec: 100.58 - lr: 0.050000
2022-05-13 15:08:14,116 ----------------------------------------------------------------------------------------------------
2022-05-13 15:08:14,116 EPOCH 18 done: loss 0.0543 - lr 0.050000
2022-05-13 15:08:22,097 Evaluating as a multi-label problem: False
2022-05-13 15:08:22,108 DEV : loss 0.19789834320545197 - f1-score (micro avg)  0.5181
2022-05-13 15:08:22,192 Epoch    18: reducing learning rate of group 0 to 2.5000e-02.
2022-05-13 15:08:22,192 BAD EPOCHS (no improvement): 4
2022-05-13 15:08:22,196 ----------------------------------------------------------------------------------------------------
2022-05-13 15:08:25,721 epoch 19 - iter 10/107 - loss 0.04267346 - samples/sec: 90.81 - lr: 0.025000
2022-05-13 15:08:29,294 epoch 19 - iter 20/107 - loss 0.04663329 - samples/sec: 89.58 - lr: 0.025000
2022-05-13 15:08:32,969 epoch 19 - iter 30/107 - loss 0.04856969 - samples/sec: 87.12 - lr: 0.025000
2022-05-13 15:08:36,497 epoch 19 - iter 40/107 - loss 0.05029581 - samples/sec: 90.72 - lr: 0.025000
2022-05-13 15:08:40,226 epoch 19 - iter 50/107 - loss 0.05020848 - samples/sec: 85.83 - lr: 0.025000
2022-05-13 15:08:43,909 epoch 19 - iter 60/107 - loss 0.05072292 - samples/sec: 86.91 - lr: 0.025000
2022-05-13 15:08:47,666 epoch 19 - iter 70/107 - loss 0.05008686 - samples/sec: 85.20 - lr: 0.025000
2022-05-13 15:08:51,120 epoch 19 - iter 80/107 - loss 0.05064388 - samples/sec: 92.67 - lr: 0.025000
2022-05-13 15:08:54,453 epoch 19 - iter 90/107 - loss 0.05067585 - samples/sec: 96.04 - lr: 0.025000
2022-05-13 15:08:57,263 epoch 19 - iter 100/107 - loss 0.05109332 - samples/sec: 113.92 - lr: 0.025000
2022-05-13 15:08:58,906 ----------------------------------------------------------------------------------------------------
2022-05-13 15:08:58,906 EPOCH 19 done: loss 0.0508 - lr 0.025000
2022-05-13 15:09:08,496 Evaluating as a multi-label problem: False
2022-05-13 15:09:08,507 DEV : loss 0.19923874735832214 - f1-score (micro avg)  0.5199
2022-05-13 15:09:08,590 BAD EPOCHS (no improvement): 1
2022-05-13 15:09:08,592 ----------------------------------------------------------------------------------------------------
2022-05-13 15:09:12,125 epoch 20 - iter 10/107 - loss 0.04991807 - samples/sec: 90.61 - lr: 0.025000
2022-05-13 15:09:15,778 epoch 20 - iter 20/107 - loss 0.04837633 - samples/sec: 87.62 - lr: 0.025000
2022-05-13 15:09:19,549 epoch 20 - iter 30/107 - loss 0.04792125 - samples/sec: 84.88 - lr: 0.025000
2022-05-13 15:09:23,379 epoch 20 - iter 40/107 - loss 0.04958211 - samples/sec: 83.57 - lr: 0.025000
2022-05-13 15:09:26,812 epoch 20 - iter 50/107 - loss 0.04770096 - samples/sec: 93.25 - lr: 0.025000
2022-05-13 15:09:30,138 epoch 20 - iter 60/107 - loss 0.04956078 - samples/sec: 96.24 - lr: 0.025000
2022-05-13 15:09:33,587 epoch 20 - iter 70/107 - loss 0.05060606 - samples/sec: 92.80 - lr: 0.025000
2022-05-13 15:09:36,614 epoch 20 - iter 80/107 - loss 0.05026170 - samples/sec: 105.76 - lr: 0.025000
2022-05-13 15:09:39,315 epoch 20 - iter 90/107 - loss 0.04981069 - samples/sec: 118.52 - lr: 0.025000
2022-05-13 15:09:42,054 epoch 20 - iter 100/107 - loss 0.04946820 - samples/sec: 116.87 - lr: 0.025000
2022-05-13 15:09:44,176 ----------------------------------------------------------------------------------------------------
2022-05-13 15:09:44,176 EPOCH 20 done: loss 0.0496 - lr 0.025000
2022-05-13 15:09:54,576 Evaluating as a multi-label problem: False
2022-05-13 15:09:54,587 DEV : loss 0.19890356063842773 - f1-score (micro avg)  0.5231
2022-05-13 15:09:54,671 BAD EPOCHS (no improvement): 2
2022-05-13 15:09:54,673 ----------------------------------------------------------------------------------------------------
2022-05-13 15:09:58,288 epoch 21 - iter 10/107 - loss 0.05186100 - samples/sec: 88.57 - lr: 0.025000
2022-05-13 15:10:01,835 epoch 21 - iter 20/107 - loss 0.04811987 - samples/sec: 90.24 - lr: 0.025000
2022-05-13 15:10:05,447 epoch 21 - iter 30/107 - loss 0.04689565 - samples/sec: 88.61 - lr: 0.025000
2022-05-13 15:10:08,868 epoch 21 - iter 40/107 - loss 0.04694691 - samples/sec: 93.58 - lr: 0.025000
2022-05-13 15:10:12,666 epoch 21 - iter 50/107 - loss 0.04732094 - samples/sec: 84.28 - lr: 0.025000
2022-05-13 15:10:16,106 epoch 21 - iter 60/107 - loss 0.04528990 - samples/sec: 93.05 - lr: 0.025000
2022-05-13 15:10:18,870 epoch 21 - iter 70/107 - loss 0.04565866 - samples/sec: 115.84 - lr: 0.025000
2022-05-13 15:10:21,609 epoch 21 - iter 80/107 - loss 0.04530417 - samples/sec: 116.87 - lr: 0.025000
2022-05-13 15:10:24,997 epoch 21 - iter 90/107 - loss 0.04584579 - samples/sec: 94.46 - lr: 0.025000
2022-05-13 15:10:28,599 epoch 21 - iter 100/107 - loss 0.04609620 - samples/sec: 88.88 - lr: 0.025000
2022-05-13 15:10:30,758 ----------------------------------------------------------------------------------------------------
2022-05-13 15:10:30,758 EPOCH 21 done: loss 0.0473 - lr 0.025000
2022-05-13 15:10:42,666 Evaluating as a multi-label problem: False
2022-05-13 15:10:42,677 DEV : loss 0.19905655086040497 - f1-score (micro avg)  0.5217
2022-05-13 15:10:42,760 BAD EPOCHS (no improvement): 3
2022-05-13 15:10:42,763 ----------------------------------------------------------------------------------------------------
2022-05-13 15:10:46,035 epoch 22 - iter 10/107 - loss 0.04170570 - samples/sec: 97.83 - lr: 0.025000
2022-05-13 15:10:49,652 epoch 22 - iter 20/107 - loss 0.04786162 - samples/sec: 88.51 - lr: 0.025000
2022-05-13 15:10:53,326 epoch 22 - iter 30/107 - loss 0.04584757 - samples/sec: 87.11 - lr: 0.025000
2022-05-13 15:10:56,231 epoch 22 - iter 40/107 - loss 0.04804616 - samples/sec: 112.48 - lr: 0.025000
2022-05-13 15:10:58,918 epoch 22 - iter 50/107 - loss 0.04897837 - samples/sec: 119.15 - lr: 0.025000
2022-05-13 15:11:01,666 epoch 22 - iter 60/107 - loss 0.04843142 - samples/sec: 116.48 - lr: 0.025000
2022-05-13 15:11:04,818 epoch 22 - iter 70/107 - loss 0.04741643 - samples/sec: 101.57 - lr: 0.025000
2022-05-13 15:11:08,229 epoch 22 - iter 80/107 - loss 0.04693098 - samples/sec: 93.83 - lr: 0.025000
2022-05-13 15:11:11,677 epoch 22 - iter 90/107 - loss 0.04638423 - samples/sec: 92.84 - lr: 0.025000
2022-05-13 15:11:15,513 epoch 22 - iter 100/107 - loss 0.04682558 - samples/sec: 83.44 - lr: 0.025000
2022-05-13 15:11:17,826 ----------------------------------------------------------------------------------------------------
2022-05-13 15:11:17,826 EPOCH 22 done: loss 0.0469 - lr 0.025000
2022-05-13 15:11:28,961 Evaluating as a multi-label problem: False
2022-05-13 15:11:28,972 DEV : loss 0.20160961151123047 - f1-score (micro avg)  0.513
2022-05-13 15:11:29,056 Epoch    22: reducing learning rate of group 0 to 1.2500e-02.
2022-05-13 15:11:29,057 BAD EPOCHS (no improvement): 4
2022-05-13 15:11:29,059 ----------------------------------------------------------------------------------------------------
2022-05-13 15:11:32,697 epoch 23 - iter 10/107 - loss 0.04366671 - samples/sec: 88.00 - lr: 0.012500
2022-05-13 15:11:36,304 epoch 23 - iter 20/107 - loss 0.03994373 - samples/sec: 88.74 - lr: 0.012500
2022-05-13 15:11:39,037 epoch 23 - iter 30/107 - loss 0.04333965 - samples/sec: 117.13 - lr: 0.012500
2022-05-13 15:11:41,693 epoch 23 - iter 40/107 - loss 0.04138075 - samples/sec: 120.52 - lr: 0.012500
2022-05-13 15:11:44,324 epoch 23 - iter 50/107 - loss 0.04273287 - samples/sec: 121.67 - lr: 0.012500
2022-05-13 15:11:47,908 epoch 23 - iter 60/107 - loss 0.04444051 - samples/sec: 89.32 - lr: 0.012500
2022-05-13 15:11:51,782 epoch 23 - iter 70/107 - loss 0.04626826 - samples/sec: 82.62 - lr: 0.012500
2022-05-13 15:11:55,513 epoch 23 - iter 80/107 - loss 0.04524928 - samples/sec: 85.80 - lr: 0.012500
2022-05-13 15:11:58,984 epoch 23 - iter 90/107 - loss 0.04460832 - samples/sec: 92.21 - lr: 0.012500
2022-05-13 15:12:02,388 epoch 23 - iter 100/107 - loss 0.04393641 - samples/sec: 94.05 - lr: 0.012500
2022-05-13 15:12:04,706 ----------------------------------------------------------------------------------------------------
2022-05-13 15:12:04,706 EPOCH 23 done: loss 0.0439 - lr 0.012500
2022-05-13 15:12:15,156 Evaluating as a multi-label problem: False
2022-05-13 15:12:15,168 DEV : loss 0.20467521250247955 - f1-score (micro avg)  0.5093
2022-05-13 15:12:15,252 BAD EPOCHS (no improvement): 1
2022-05-13 15:12:15,254 ----------------------------------------------------------------------------------------------------
2022-05-13 15:12:18,228 epoch 24 - iter 10/107 - loss 0.03562390 - samples/sec: 107.66 - lr: 0.012500
2022-05-13 15:12:21,097 epoch 24 - iter 20/107 - loss 0.04415155 - samples/sec: 111.60 - lr: 0.012500
2022-05-13 15:12:23,745 epoch 24 - iter 30/107 - loss 0.04336476 - samples/sec: 120.87 - lr: 0.012500
2022-05-13 15:12:26,521 epoch 24 - iter 40/107 - loss 0.04252161 - samples/sec: 115.35 - lr: 0.012500
2022-05-13 15:12:30,278 epoch 24 - iter 50/107 - loss 0.04287046 - samples/sec: 85.18 - lr: 0.012500
2022-05-13 15:12:34,088 epoch 24 - iter 60/107 - loss 0.04316759 - samples/sec: 84.01 - lr: 0.012500
2022-05-13 15:12:37,940 epoch 24 - iter 70/107 - loss 0.04329284 - samples/sec: 83.10 - lr: 0.012500
2022-05-13 15:12:41,704 epoch 24 - iter 80/107 - loss 0.04353082 - samples/sec: 85.03 - lr: 0.012500
2022-05-13 15:12:45,340 epoch 24 - iter 90/107 - loss 0.04463772 - samples/sec: 88.05 - lr: 0.012500
2022-05-13 15:12:48,909 epoch 24 - iter 100/107 - loss 0.04423345 - samples/sec: 89.68 - lr: 0.012500
2022-05-13 15:12:51,188 ----------------------------------------------------------------------------------------------------
2022-05-13 15:12:51,188 EPOCH 24 done: loss 0.0440 - lr 0.012500
2022-05-13 15:13:01,109 Evaluating as a multi-label problem: False
2022-05-13 15:13:01,120 DEV : loss 0.1998954713344574 - f1-score (micro avg)  0.5253
2022-05-13 15:13:01,206 BAD EPOCHS (no improvement): 2
2022-05-13 15:13:01,207 ----------------------------------------------------------------------------------------------------
2022-05-13 15:13:03,827 epoch 25 - iter 10/107 - loss 0.04102294 - samples/sec: 122.22 - lr: 0.012500
2022-05-13 15:13:06,527 epoch 25 - iter 20/107 - loss 0.04707531 - samples/sec: 118.57 - lr: 0.012500
2022-05-13 15:13:08,449 epoch 25 - iter 30/107 - loss 0.04583375 - samples/sec: 166.60 - lr: 0.012500
2022-05-13 15:13:10,489 epoch 25 - iter 40/107 - loss 0.04629875 - samples/sec: 156.91 - lr: 0.012500
2022-05-13 15:13:12,552 epoch 25 - iter 50/107 - loss 0.04631461 - samples/sec: 155.20 - lr: 0.012500
2022-05-13 15:13:14,741 epoch 25 - iter 60/107 - loss 0.04602641 - samples/sec: 146.29 - lr: 0.012500
2022-05-13 15:13:16,968 epoch 25 - iter 70/107 - loss 0.04539360 - samples/sec: 143.74 - lr: 0.012500
2022-05-13 15:13:19,210 epoch 25 - iter 80/107 - loss 0.04673800 - samples/sec: 142.82 - lr: 0.012500
2022-05-13 15:13:21,418 epoch 25 - iter 90/107 - loss 0.04635250 - samples/sec: 144.94 - lr: 0.012500
2022-05-13 15:13:23,677 epoch 25 - iter 100/107 - loss 0.04526689 - samples/sec: 141.74 - lr: 0.012500
2022-05-13 15:13:24,984 ----------------------------------------------------------------------------------------------------
2022-05-13 15:13:24,984 EPOCH 25 done: loss 0.0452 - lr 0.012500
2022-05-13 15:13:31,721 Evaluating as a multi-label problem: False
2022-05-13 15:13:31,731 DEV : loss 0.20447981357574463 - f1-score (micro avg)  0.5152
2022-05-13 15:13:31,815 BAD EPOCHS (no improvement): 3
2022-05-13 15:13:31,817 ----------------------------------------------------------------------------------------------------
2022-05-13 15:13:34,041 epoch 26 - iter 10/107 - loss 0.04105612 - samples/sec: 144.00 - lr: 0.012500
2022-05-13 15:13:36,229 epoch 26 - iter 20/107 - loss 0.03966425 - samples/sec: 146.31 - lr: 0.012500
2022-05-13 15:13:38,333 epoch 26 - iter 30/107 - loss 0.04181326 - samples/sec: 152.15 - lr: 0.012500
2022-05-13 15:13:40,464 epoch 26 - iter 40/107 - loss 0.04370266 - samples/sec: 150.24 - lr: 0.012500
2022-05-13 15:13:42,686 epoch 26 - iter 50/107 - loss 0.04289658 - samples/sec: 144.07 - lr: 0.012500
2022-05-13 15:13:44,783 epoch 26 - iter 60/107 - loss 0.04135137 - samples/sec: 152.69 - lr: 0.012500
2022-05-13 15:13:50,540 epoch 26 - iter 70/107 - loss 0.04127996 - samples/sec: 55.59 - lr: 0.012500
2022-05-13 15:13:55,615 epoch 26 - iter 80/107 - loss 0.04072260 - samples/sec: 63.07 - lr: 0.012500
2022-05-13 15:14:00,393 epoch 26 - iter 90/107 - loss 0.04217473 - samples/sec: 66.99 - lr: 0.012500
2022-05-13 15:14:05,612 epoch 26 - iter 100/107 - loss 0.04251543 - samples/sec: 61.34 - lr: 0.012500
2022-05-13 15:14:07,452 ----------------------------------------------------------------------------------------------------
2022-05-13 15:14:07,452 EPOCH 26 done: loss 0.0425 - lr 0.012500
2022-05-13 15:14:17,709 Evaluating as a multi-label problem: False
2022-05-13 15:14:17,720 DEV : loss 0.20219652354717255 - f1-score (micro avg)  0.521
2022-05-13 15:14:17,804 Epoch    26: reducing learning rate of group 0 to 6.2500e-03.
2022-05-13 15:14:17,804 BAD EPOCHS (no improvement): 4
2022-05-13 15:14:17,807 ----------------------------------------------------------------------------------------------------
2022-05-13 15:14:21,291 epoch 27 - iter 10/107 - loss 0.04769688 - samples/sec: 91.87 - lr: 0.006250
2022-05-13 15:14:25,133 epoch 27 - iter 20/107 - loss 0.04177815 - samples/sec: 83.32 - lr: 0.006250
2022-05-13 15:14:28,279 epoch 27 - iter 30/107 - loss 0.04162725 - samples/sec: 101.75 - lr: 0.006250
2022-05-13 15:14:32,140 epoch 27 - iter 40/107 - loss 0.04091628 - samples/sec: 82.89 - lr: 0.006250
2022-05-13 15:14:35,808 epoch 27 - iter 50/107 - loss 0.03970043 - samples/sec: 87.27 - lr: 0.006250
2022-05-13 15:14:39,441 epoch 27 - iter 60/107 - loss 0.03757354 - samples/sec: 88.12 - lr: 0.006250
2022-05-13 15:14:42,179 epoch 27 - iter 70/107 - loss 0.03956314 - samples/sec: 116.93 - lr: 0.006250
2022-05-13 15:14:44,864 epoch 27 - iter 80/107 - loss 0.03980338 - samples/sec: 119.22 - lr: 0.006250
2022-05-13 15:14:47,042 epoch 27 - iter 90/107 - loss 0.03973233 - samples/sec: 146.96 - lr: 0.006250
2022-05-13 15:14:49,087 epoch 27 - iter 100/107 - loss 0.04064899 - samples/sec: 156.55 - lr: 0.006250
2022-05-13 15:14:50,364 ----------------------------------------------------------------------------------------------------
2022-05-13 15:14:50,364 EPOCH 27 done: loss 0.0411 - lr 0.006250
2022-05-13 15:14:58,664 Evaluating as a multi-label problem: False
2022-05-13 15:14:58,675 DEV : loss 0.20336563885211945 - f1-score (micro avg)  0.5194
2022-05-13 15:14:58,760 BAD EPOCHS (no improvement): 1
2022-05-13 15:14:58,761 ----------------------------------------------------------------------------------------------------
2022-05-13 15:15:01,020 epoch 28 - iter 10/107 - loss 0.04128471 - samples/sec: 141.74 - lr: 0.006250
2022-05-13 15:15:03,215 epoch 28 - iter 20/107 - loss 0.03959162 - samples/sec: 145.85 - lr: 0.006250
2022-05-13 15:15:05,449 epoch 28 - iter 30/107 - loss 0.04209744 - samples/sec: 143.31 - lr: 0.006250
2022-05-13 15:15:07,654 epoch 28 - iter 40/107 - loss 0.04441957 - samples/sec: 145.20 - lr: 0.006250
2022-05-13 15:15:10,296 epoch 28 - iter 50/107 - loss 0.04245318 - samples/sec: 121.17 - lr: 0.006250
2022-05-13 15:15:13,855 epoch 28 - iter 60/107 - loss 0.04375646 - samples/sec: 89.94 - lr: 0.006250
2022-05-13 15:15:17,407 epoch 28 - iter 70/107 - loss 0.04252676 - samples/sec: 90.10 - lr: 0.006250
2022-05-13 15:15:21,271 epoch 28 - iter 80/107 - loss 0.04268097 - samples/sec: 82.84 - lr: 0.006250
2022-05-13 15:15:24,795 epoch 28 - iter 90/107 - loss 0.04289455 - samples/sec: 90.85 - lr: 0.006250
2022-05-13 15:15:28,343 epoch 28 - iter 100/107 - loss 0.04259699 - samples/sec: 90.21 - lr: 0.006250
2022-05-13 15:15:30,543 ----------------------------------------------------------------------------------------------------
2022-05-13 15:15:30,544 EPOCH 28 done: loss 0.0428 - lr 0.006250
2022-05-13 15:15:41,172 Evaluating as a multi-label problem: False
2022-05-13 15:15:41,183 DEV : loss 0.2051897644996643 - f1-score (micro avg)  0.5219
2022-05-13 15:15:41,272 BAD EPOCHS (no improvement): 2
2022-05-13 15:15:41,274 ----------------------------------------------------------------------------------------------------
2022-05-13 15:15:44,333 epoch 29 - iter 10/107 - loss 0.03483348 - samples/sec: 104.66 - lr: 0.006250
2022-05-13 15:15:47,005 epoch 29 - iter 20/107 - loss 0.03553215 - samples/sec: 119.81 - lr: 0.006250
2022-05-13 15:15:49,763 epoch 29 - iter 30/107 - loss 0.03691763 - samples/sec: 116.09 - lr: 0.006250
2022-05-13 15:15:51,742 epoch 29 - iter 40/107 - loss 0.03723735 - samples/sec: 161.77 - lr: 0.006250
2022-05-13 15:15:53,852 epoch 29 - iter 50/107 - loss 0.03889008 - samples/sec: 151.74 - lr: 0.006250
2022-05-13 15:15:56,031 epoch 29 - iter 60/107 - loss 0.03915359 - samples/sec: 146.88 - lr: 0.006250
2022-05-13 15:15:58,160 epoch 29 - iter 70/107 - loss 0.03915857 - samples/sec: 150.38 - lr: 0.006250
2022-05-13 15:16:00,363 epoch 29 - iter 80/107 - loss 0.03828542 - samples/sec: 145.31 - lr: 0.006250
2022-05-13 15:16:02,542 epoch 29 - iter 90/107 - loss 0.03843538 - samples/sec: 146.94 - lr: 0.006250
2022-05-13 15:16:04,693 epoch 29 - iter 100/107 - loss 0.03998558 - samples/sec: 148.84 - lr: 0.006250
2022-05-13 15:16:06,001 ----------------------------------------------------------------------------------------------------
2022-05-13 15:16:06,002 EPOCH 29 done: loss 0.0407 - lr 0.006250
2022-05-13 15:16:13,055 Evaluating as a multi-label problem: False
2022-05-13 15:16:13,066 DEV : loss 0.20091550052165985 - f1-score (micro avg)  0.5267
2022-05-13 15:16:13,151 BAD EPOCHS (no improvement): 3
2022-05-13 15:16:13,152 ----------------------------------------------------------------------------------------------------
2022-05-13 15:16:16,533 epoch 30 - iter 10/107 - loss 0.04714510 - samples/sec: 94.70 - lr: 0.006250
2022-05-13 15:16:19,832 epoch 30 - iter 20/107 - loss 0.04437352 - samples/sec: 97.02 - lr: 0.006250
2022-05-13 15:16:23,072 epoch 30 - iter 30/107 - loss 0.03921632 - samples/sec: 98.80 - lr: 0.006250
2022-05-13 15:16:26,313 epoch 30 - iter 40/107 - loss 0.03945116 - samples/sec: 98.76 - lr: 0.006250
2022-05-13 15:16:29,458 epoch 30 - iter 50/107 - loss 0.04143095 - samples/sec: 101.79 - lr: 0.006250
2022-05-13 15:16:32,630 epoch 30 - iter 60/107 - loss 0.04066592 - samples/sec: 100.91 - lr: 0.006250
2022-05-13 15:16:35,824 epoch 30 - iter 70/107 - loss 0.04075328 - samples/sec: 100.21 - lr: 0.006250
2022-05-13 15:16:38,941 epoch 30 - iter 80/107 - loss 0.04040195 - samples/sec: 102.72 - lr: 0.006250
2022-05-13 15:16:42,087 epoch 30 - iter 90/107 - loss 0.04187362 - samples/sec: 101.74 - lr: 0.006250
2022-05-13 15:16:45,231 epoch 30 - iter 100/107 - loss 0.04123799 - samples/sec: 101.82 - lr: 0.006250
2022-05-13 15:16:47,201 ----------------------------------------------------------------------------------------------------
2022-05-13 15:16:47,201 EPOCH 30 done: loss 0.0414 - lr 0.006250
2022-05-13 15:16:56,087 Evaluating as a multi-label problem: False
2022-05-13 15:16:56,098 DEV : loss 0.20805662870407104 - f1-score (micro avg)  0.5136
2022-05-13 15:16:56,185 Epoch    30: reducing learning rate of group 0 to 3.1250e-03.
2022-05-13 15:16:56,185 BAD EPOCHS (no improvement): 4
2022-05-13 15:16:56,187 ----------------------------------------------------------------------------------------------------
2022-05-13 15:16:58,148 epoch 31 - iter 10/107 - loss 0.03832311 - samples/sec: 163.35 - lr: 0.003125
2022-05-13 15:17:00,231 epoch 31 - iter 20/107 - loss 0.04086368 - samples/sec: 153.70 - lr: 0.003125
2022-05-13 15:17:02,375 epoch 31 - iter 30/107 - loss 0.03837015 - samples/sec: 149.33 - lr: 0.003125
2022-05-13 15:17:04,614 epoch 31 - iter 40/107 - loss 0.04191777 - samples/sec: 142.98 - lr: 0.003125
2022-05-13 15:17:06,760 epoch 31 - iter 50/107 - loss 0.04148469 - samples/sec: 149.22 - lr: 0.003125
2022-05-13 15:17:08,973 epoch 31 - iter 60/107 - loss 0.04088742 - samples/sec: 144.66 - lr: 0.003125
2022-05-13 15:17:11,148 epoch 31 - iter 70/107 - loss 0.03997535 - samples/sec: 147.18 - lr: 0.003125
2022-05-13 15:17:13,393 epoch 31 - iter 80/107 - loss 0.04030733 - samples/sec: 142.57 - lr: 0.003125
2022-05-13 15:17:15,582 epoch 31 - iter 90/107 - loss 0.04006713 - samples/sec: 146.28 - lr: 0.003125
2022-05-13 15:17:17,790 epoch 31 - iter 100/107 - loss 0.04041203 - samples/sec: 145.02 - lr: 0.003125
2022-05-13 15:17:19,153 ----------------------------------------------------------------------------------------------------
2022-05-13 15:17:19,153 EPOCH 31 done: loss 0.0395 - lr 0.003125
2022-05-13 15:17:27,955 Evaluating as a multi-label problem: False
2022-05-13 15:17:27,966 DEV : loss 0.21001370251178741 - f1-score (micro avg)  0.5145
2022-05-13 15:17:28,051 BAD EPOCHS (no improvement): 1
2022-05-13 15:17:28,053 ----------------------------------------------------------------------------------------------------
2022-05-13 15:17:31,877 epoch 32 - iter 10/107 - loss 0.03476209 - samples/sec: 83.71 - lr: 0.003125
2022-05-13 15:17:35,235 epoch 32 - iter 20/107 - loss 0.03896715 - samples/sec: 95.33 - lr: 0.003125
2022-05-13 15:17:38,369 epoch 32 - iter 30/107 - loss 0.03773609 - samples/sec: 102.16 - lr: 0.003125
2022-05-13 15:17:41,606 epoch 32 - iter 40/107 - loss 0.03798225 - samples/sec: 98.87 - lr: 0.003125
2022-05-13 15:17:44,742 epoch 32 - iter 50/107 - loss 0.03962238 - samples/sec: 102.11 - lr: 0.003125
2022-05-13 15:17:47,914 epoch 32 - iter 60/107 - loss 0.03979675 - samples/sec: 100.91 - lr: 0.003125
2022-05-13 15:17:50,992 epoch 32 - iter 70/107 - loss 0.04029300 - samples/sec: 104.01 - lr: 0.003125
2022-05-13 15:17:54,172 epoch 32 - iter 80/107 - loss 0.04127100 - samples/sec: 100.66 - lr: 0.003125
2022-05-13 15:17:56,968 epoch 32 - iter 90/107 - loss 0.04172868 - samples/sec: 114.48 - lr: 0.003125
2022-05-13 15:17:59,974 epoch 32 - iter 100/107 - loss 0.04172047 - samples/sec: 106.53 - lr: 0.003125
2022-05-13 15:18:01,941 ----------------------------------------------------------------------------------------------------
2022-05-13 15:18:01,941 EPOCH 32 done: loss 0.0416 - lr 0.003125
2022-05-13 15:18:11,110 Evaluating as a multi-label problem: False
2022-05-13 15:18:11,121 DEV : loss 0.204838365316391 - f1-score (micro avg)  0.52
2022-05-13 15:18:11,205 BAD EPOCHS (no improvement): 2
2022-05-13 15:18:11,207 ----------------------------------------------------------------------------------------------------
2022-05-13 15:18:14,381 epoch 33 - iter 10/107 - loss 0.04325675 - samples/sec: 100.88 - lr: 0.003125
2022-05-13 15:18:17,550 epoch 33 - iter 20/107 - loss 0.04239117 - samples/sec: 100.99 - lr: 0.003125
2022-05-13 15:18:21,168 epoch 33 - iter 30/107 - loss 0.04129357 - samples/sec: 88.47 - lr: 0.003125
2022-05-13 15:18:24,263 epoch 33 - iter 40/107 - loss 0.04138704 - samples/sec: 103.44 - lr: 0.003125
2022-05-13 15:18:27,347 epoch 33 - iter 50/107 - loss 0.04175042 - samples/sec: 103.82 - lr: 0.003125
2022-05-13 15:18:30,540 epoch 33 - iter 60/107 - loss 0.04142387 - samples/sec: 100.25 - lr: 0.003125
2022-05-13 15:18:33,803 epoch 33 - iter 70/107 - loss 0.04090283 - samples/sec: 98.09 - lr: 0.003125
2022-05-13 15:18:38,413 epoch 33 - iter 80/107 - loss 0.04135152 - samples/sec: 69.42 - lr: 0.003125
2022-05-13 15:18:41,398 epoch 33 - iter 90/107 - loss 0.04143614 - samples/sec: 107.25 - lr: 0.003125
2022-05-13 15:18:44,501 epoch 33 - iter 100/107 - loss 0.04112228 - samples/sec: 103.17 - lr: 0.003125
2022-05-13 15:18:46,382 ----------------------------------------------------------------------------------------------------
2022-05-13 15:18:46,382 EPOCH 33 done: loss 0.0421 - lr 0.003125
2022-05-13 15:18:55,555 Evaluating as a multi-label problem: False
2022-05-13 15:18:55,566 DEV : loss 0.20311585068702698 - f1-score (micro avg)  0.5211
2022-05-13 15:18:55,652 BAD EPOCHS (no improvement): 3
2022-05-13 15:18:55,654 ----------------------------------------------------------------------------------------------------
2022-05-13 15:18:58,852 epoch 34 - iter 10/107 - loss 0.04365079 - samples/sec: 100.11 - lr: 0.003125
2022-05-13 15:19:01,985 epoch 34 - iter 20/107 - loss 0.04076161 - samples/sec: 102.16 - lr: 0.003125
2022-05-13 15:19:05,156 epoch 34 - iter 30/107 - loss 0.03895163 - samples/sec: 100.96 - lr: 0.003125
2022-05-13 15:19:08,272 epoch 34 - iter 40/107 - loss 0.04085685 - samples/sec: 102.72 - lr: 0.003125
2022-05-13 15:19:11,369 epoch 34 - iter 50/107 - loss 0.04113038 - samples/sec: 103.37 - lr: 0.003125
2022-05-13 15:19:14,487 epoch 34 - iter 60/107 - loss 0.03980609 - samples/sec: 102.68 - lr: 0.003125
2022-05-13 15:19:17,703 epoch 34 - iter 70/107 - loss 0.03840431 - samples/sec: 99.52 - lr: 0.003125
2022-05-13 15:19:20,844 epoch 34 - iter 80/107 - loss 0.03833830 - samples/sec: 101.91 - lr: 0.003125
2022-05-13 15:19:23,792 epoch 34 - iter 90/107 - loss 0.03875942 - samples/sec: 108.59 - lr: 0.003125
2022-05-13 15:19:26,701 epoch 34 - iter 100/107 - loss 0.03906234 - samples/sec: 110.04 - lr: 0.003125
2022-05-13 15:19:28,897 ----------------------------------------------------------------------------------------------------
2022-05-13 15:19:28,898 EPOCH 34 done: loss 0.0396 - lr 0.003125
2022-05-13 15:19:35,725 Evaluating as a multi-label problem: False
2022-05-13 15:19:35,736 DEV : loss 0.2058272808790207 - f1-score (micro avg)  0.5216
2022-05-13 15:19:35,820 Epoch    34: reducing learning rate of group 0 to 1.5625e-03.
2022-05-13 15:19:35,820 BAD EPOCHS (no improvement): 4
2022-05-13 15:19:35,821 ----------------------------------------------------------------------------------------------------
2022-05-13 15:19:38,083 epoch 35 - iter 10/107 - loss 0.03919675 - samples/sec: 141.58 - lr: 0.001563
2022-05-13 15:19:40,266 epoch 35 - iter 20/107 - loss 0.04221329 - samples/sec: 146.65 - lr: 0.001563
2022-05-13 15:19:42,391 epoch 35 - iter 30/107 - loss 0.04027675 - samples/sec: 150.66 - lr: 0.001563
2022-05-13 15:19:44,599 epoch 35 - iter 40/107 - loss 0.03977218 - samples/sec: 145.01 - lr: 0.001563
2022-05-13 15:19:46,825 epoch 35 - iter 50/107 - loss 0.03840133 - samples/sec: 143.82 - lr: 0.001563
2022-05-13 15:19:49,021 epoch 35 - iter 60/107 - loss 0.03923806 - samples/sec: 145.78 - lr: 0.001563
2022-05-13 15:19:51,235 epoch 35 - iter 70/107 - loss 0.03854554 - samples/sec: 144.57 - lr: 0.001563
2022-05-13 15:19:53,504 epoch 35 - iter 80/107 - loss 0.03835148 - samples/sec: 141.12 - lr: 0.001563
2022-05-13 15:19:57,019 epoch 35 - iter 90/107 - loss 0.03884516 - samples/sec: 91.07 - lr: 0.001563
2022-05-13 15:20:00,153 epoch 35 - iter 100/107 - loss 0.03933641 - samples/sec: 102.14 - lr: 0.001563
2022-05-13 15:20:02,180 ----------------------------------------------------------------------------------------------------
2022-05-13 15:20:02,180 EPOCH 35 done: loss 0.0387 - lr 0.001563
2022-05-13 15:20:11,806 Evaluating as a multi-label problem: False
2022-05-13 15:20:11,817 DEV : loss 0.2066657543182373 - f1-score (micro avg)  0.5208
2022-05-13 15:20:11,903 BAD EPOCHS (no improvement): 1
2022-05-13 15:20:11,906 ----------------------------------------------------------------------------------------------------
2022-05-13 15:20:15,072 epoch 36 - iter 10/107 - loss 0.05002195 - samples/sec: 101.11 - lr: 0.001563
2022-05-13 15:20:18,151 epoch 36 - iter 20/107 - loss 0.04499117 - samples/sec: 103.96 - lr: 0.001563
2022-05-13 15:20:21,232 epoch 36 - iter 30/107 - loss 0.04173135 - samples/sec: 103.90 - lr: 0.001563
2022-05-13 15:20:24,392 epoch 36 - iter 40/107 - loss 0.04292613 - samples/sec: 101.30 - lr: 0.001563
2022-05-13 15:20:27,339 epoch 36 - iter 50/107 - loss 0.04322341 - samples/sec: 108.61 - lr: 0.001563
2022-05-13 15:20:30,287 epoch 36 - iter 60/107 - loss 0.04294628 - samples/sec: 108.60 - lr: 0.001563
2022-05-13 15:20:32,922 epoch 36 - iter 70/107 - loss 0.04106377 - samples/sec: 121.48 - lr: 0.001563
2022-05-13 15:20:35,685 epoch 36 - iter 80/107 - loss 0.04195277 - samples/sec: 115.87 - lr: 0.001563
2022-05-13 15:20:37,673 epoch 36 - iter 90/107 - loss 0.04129210 - samples/sec: 161.04 - lr: 0.001563
2022-05-13 15:20:39,848 epoch 36 - iter 100/107 - loss 0.04039329 - samples/sec: 147.20 - lr: 0.001563
2022-05-13 15:20:41,241 ----------------------------------------------------------------------------------------------------
2022-05-13 15:20:41,241 EPOCH 36 done: loss 0.0405 - lr 0.001563
2022-05-13 15:20:47,942 Evaluating as a multi-label problem: False
2022-05-13 15:20:47,953 DEV : loss 0.2077169120311737 - f1-score (micro avg)  0.5194
2022-05-13 15:20:48,037 BAD EPOCHS (no improvement): 2
2022-05-13 15:20:48,038 ----------------------------------------------------------------------------------------------------
2022-05-13 15:20:50,288 epoch 37 - iter 10/107 - loss 0.04213096 - samples/sec: 142.31 - lr: 0.001563
2022-05-13 15:20:52,519 epoch 37 - iter 20/107 - loss 0.03806942 - samples/sec: 143.52 - lr: 0.001563
2022-05-13 15:20:54,647 epoch 37 - iter 30/107 - loss 0.03920411 - samples/sec: 150.48 - lr: 0.001563
2022-05-13 15:20:56,751 epoch 37 - iter 40/107 - loss 0.04026240 - samples/sec: 152.14 - lr: 0.001563
2022-05-13 15:20:59,019 epoch 37 - iter 50/107 - loss 0.03994125 - samples/sec: 141.19 - lr: 0.001563
2022-05-13 15:21:02,511 epoch 37 - iter 60/107 - loss 0.04017741 - samples/sec: 91.64 - lr: 0.001563
2022-05-13 15:21:06,184 epoch 37 - iter 70/107 - loss 0.04047831 - samples/sec: 87.16 - lr: 0.001563
2022-05-13 15:21:09,958 epoch 37 - iter 80/107 - loss 0.04213310 - samples/sec: 84.81 - lr: 0.001563
2022-05-13 15:21:13,488 epoch 37 - iter 90/107 - loss 0.04222830 - samples/sec: 90.69 - lr: 0.001563
2022-05-13 15:21:17,133 epoch 37 - iter 100/107 - loss 0.04107554 - samples/sec: 87.82 - lr: 0.001563
2022-05-13 15:21:19,096 ----------------------------------------------------------------------------------------------------
2022-05-13 15:21:19,096 EPOCH 37 done: loss 0.0407 - lr 0.001563
2022-05-13 15:21:29,645 Evaluating as a multi-label problem: False
2022-05-13 15:21:29,656 DEV : loss 0.20525376498699188 - f1-score (micro avg)  0.5209
2022-05-13 15:21:29,741 BAD EPOCHS (no improvement): 3
2022-05-13 15:21:29,743 ----------------------------------------------------------------------------------------------------
2022-05-13 15:21:32,904 epoch 38 - iter 10/107 - loss 0.03951934 - samples/sec: 101.29 - lr: 0.001563
2022-05-13 15:21:35,776 epoch 38 - iter 20/107 - loss 0.04026951 - samples/sec: 111.47 - lr: 0.001563
2022-05-13 15:21:38,456 epoch 38 - iter 30/107 - loss 0.03837159 - samples/sec: 119.45 - lr: 0.001563
2022-05-13 15:21:41,257 epoch 38 - iter 40/107 - loss 0.04133945 - samples/sec: 114.27 - lr: 0.001563
2022-05-13 15:21:44,907 epoch 38 - iter 50/107 - loss 0.04068928 - samples/sec: 87.71 - lr: 0.001563
2022-05-13 15:21:48,755 epoch 38 - iter 60/107 - loss 0.04086810 - samples/sec: 83.17 - lr: 0.001563
2022-05-13 15:21:52,524 epoch 38 - iter 70/107 - loss 0.04034836 - samples/sec: 84.93 - lr: 0.001563
2022-05-13 15:21:56,179 epoch 38 - iter 80/107 - loss 0.04006465 - samples/sec: 87.58 - lr: 0.001563
2022-05-13 15:21:59,594 epoch 38 - iter 90/107 - loss 0.03898405 - samples/sec: 93.74 - lr: 0.001563
2022-05-13 15:22:03,431 epoch 38 - iter 100/107 - loss 0.04022761 - samples/sec: 83.41 - lr: 0.001563
2022-05-13 15:22:05,608 ----------------------------------------------------------------------------------------------------
2022-05-13 15:22:05,608 EPOCH 38 done: loss 0.0405 - lr 0.001563
2022-05-13 15:22:15,689 Evaluating as a multi-label problem: False
2022-05-13 15:22:15,700 DEV : loss 0.20473703742027283 - f1-score (micro avg)  0.5208
2022-05-13 15:22:15,784 Epoch    38: reducing learning rate of group 0 to 7.8125e-04.
2022-05-13 15:22:15,784 BAD EPOCHS (no improvement): 4
2022-05-13 15:22:15,786 ----------------------------------------------------------------------------------------------------
2022-05-13 15:22:18,403 epoch 39 - iter 10/107 - loss 0.03628017 - samples/sec: 122.36 - lr: 0.000781
2022-05-13 15:22:21,100 epoch 39 - iter 20/107 - loss 0.03420228 - samples/sec: 118.71 - lr: 0.000781
2022-05-13 15:22:23,024 epoch 39 - iter 30/107 - loss 0.03593540 - samples/sec: 166.40 - lr: 0.000781
2022-05-13 15:22:25,058 epoch 39 - iter 40/107 - loss 0.03591668 - samples/sec: 157.34 - lr: 0.000781
2022-05-13 15:22:28,615 epoch 39 - iter 50/107 - loss 0.03587204 - samples/sec: 90.00 - lr: 0.000781
2022-05-13 15:22:30,759 epoch 39 - iter 60/107 - loss 0.03644069 - samples/sec: 149.35 - lr: 0.000781
2022-05-13 15:22:33,008 epoch 39 - iter 70/107 - loss 0.03723763 - samples/sec: 142.29 - lr: 0.000781
2022-05-13 15:22:35,229 epoch 39 - iter 80/107 - loss 0.03717528 - samples/sec: 144.17 - lr: 0.000781
2022-05-13 15:22:37,403 epoch 39 - iter 90/107 - loss 0.03868231 - samples/sec: 147.27 - lr: 0.000781
2022-05-13 15:22:39,706 epoch 39 - iter 100/107 - loss 0.03819387 - samples/sec: 139.00 - lr: 0.000781
2022-05-13 15:22:41,071 ----------------------------------------------------------------------------------------------------
2022-05-13 15:22:41,072 EPOCH 39 done: loss 0.0393 - lr 0.000781
2022-05-13 15:22:49,411 Evaluating as a multi-label problem: False
2022-05-13 15:22:49,421 DEV : loss 0.2049778252840042 - f1-score (micro avg)  0.5212
2022-05-13 15:22:49,506 BAD EPOCHS (no improvement): 1
2022-05-13 15:22:49,527 ----------------------------------------------------------------------------------------------------
2022-05-13 15:22:53,141 epoch 40 - iter 10/107 - loss 0.04538269 - samples/sec: 88.59 - lr: 0.000781
2022-05-13 15:22:57,165 epoch 40 - iter 20/107 - loss 0.04378623 - samples/sec: 79.55 - lr: 0.000781
2022-05-13 15:23:00,560 epoch 40 - iter 30/107 - loss 0.04204750 - samples/sec: 94.30 - lr: 0.000781
2022-05-13 15:23:04,472 epoch 40 - iter 40/107 - loss 0.04139701 - samples/sec: 81.83 - lr: 0.000781
2022-05-13 15:23:07,927 epoch 40 - iter 50/107 - loss 0.04029323 - samples/sec: 92.64 - lr: 0.000781
2022-05-13 15:23:11,668 epoch 40 - iter 60/107 - loss 0.03987543 - samples/sec: 85.57 - lr: 0.000781
2022-05-13 15:23:15,224 epoch 40 - iter 70/107 - loss 0.03973969 - samples/sec: 90.00 - lr: 0.000781
2022-05-13 15:23:18,635 epoch 40 - iter 80/107 - loss 0.03933830 - samples/sec: 93.86 - lr: 0.000781
2022-05-13 15:23:21,550 epoch 40 - iter 90/107 - loss 0.03913454 - samples/sec: 109.80 - lr: 0.000781
2022-05-13 15:23:24,271 epoch 40 - iter 100/107 - loss 0.03894381 - samples/sec: 117.65 - lr: 0.000781
2022-05-13 15:23:26,002 ----------------------------------------------------------------------------------------------------
2022-05-13 15:23:26,002 EPOCH 40 done: loss 0.0389 - lr 0.000781
2022-05-13 15:23:36,406 Evaluating as a multi-label problem: False
2022-05-13 15:23:36,417 DEV : loss 0.2066730111837387 - f1-score (micro avg)  0.5213
2022-05-13 15:23:36,501 BAD EPOCHS (no improvement): 2
2022-05-13 15:23:36,503 ----------------------------------------------------------------------------------------------------
2022-05-13 15:23:40,121 epoch 41 - iter 10/107 - loss 0.04289470 - samples/sec: 88.47 - lr: 0.000781
2022-05-13 15:23:43,845 epoch 41 - iter 20/107 - loss 0.03813686 - samples/sec: 85.96 - lr: 0.000781
2022-05-13 15:23:47,223 epoch 41 - iter 30/107 - loss 0.03694322 - samples/sec: 94.79 - lr: 0.000781
2022-05-13 15:23:51,063 epoch 41 - iter 40/107 - loss 0.03789880 - samples/sec: 83.34 - lr: 0.000781
2022-05-13 15:23:54,689 epoch 41 - iter 50/107 - loss 0.03787934 - samples/sec: 88.30 - lr: 0.000781
2022-05-13 15:23:57,979 epoch 41 - iter 60/107 - loss 0.03897409 - samples/sec: 97.30 - lr: 0.000781
2022-05-13 15:24:00,940 epoch 41 - iter 70/107 - loss 0.03782435 - samples/sec: 108.09 - lr: 0.000781
2022-05-13 15:24:03,650 epoch 41 - iter 80/107 - loss 0.03824403 - samples/sec: 118.11 - lr: 0.000781
2022-05-13 15:24:06,363 epoch 41 - iter 90/107 - loss 0.03880947 - samples/sec: 118.00 - lr: 0.000781
2022-05-13 15:24:09,608 epoch 41 - iter 100/107 - loss 0.03837138 - samples/sec: 98.65 - lr: 0.000781
2022-05-13 15:24:12,185 ----------------------------------------------------------------------------------------------------
2022-05-13 15:24:12,185 EPOCH 41 done: loss 0.0382 - lr 0.000781
2022-05-13 15:24:22,461 Evaluating as a multi-label problem: False
2022-05-13 15:24:22,473 DEV : loss 0.20592936873435974 - f1-score (micro avg)  0.5205
2022-05-13 15:24:22,557 BAD EPOCHS (no improvement): 3
2022-05-13 15:24:22,560 ----------------------------------------------------------------------------------------------------
2022-05-13 15:24:26,264 epoch 42 - iter 10/107 - loss 0.03589022 - samples/sec: 86.42 - lr: 0.000781
2022-05-13 15:24:29,938 epoch 42 - iter 20/107 - loss 0.03516041 - samples/sec: 87.13 - lr: 0.000781
2022-05-13 15:24:33,608 epoch 42 - iter 30/107 - loss 0.03941062 - samples/sec: 87.22 - lr: 0.000781
2022-05-13 15:24:37,323 epoch 42 - iter 40/107 - loss 0.03823917 - samples/sec: 86.18 - lr: 0.000781
2022-05-13 15:24:40,624 epoch 42 - iter 50/107 - loss 0.03814909 - samples/sec: 96.95 - lr: 0.000781
2022-05-13 15:24:43,883 epoch 42 - iter 60/107 - loss 0.03794613 - samples/sec: 98.21 - lr: 0.000781
2022-05-13 15:24:46,564 epoch 42 - iter 70/107 - loss 0.03870725 - samples/sec: 119.41 - lr: 0.000781
2022-05-13 15:24:49,428 epoch 42 - iter 80/107 - loss 0.03839474 - samples/sec: 111.77 - lr: 0.000781
2022-05-13 15:24:53,099 epoch 42 - iter 90/107 - loss 0.03842914 - samples/sec: 87.21 - lr: 0.000781
2022-05-13 15:24:56,492 epoch 42 - iter 100/107 - loss 0.03916396 - samples/sec: 94.34 - lr: 0.000781
2022-05-13 15:24:58,764 ----------------------------------------------------------------------------------------------------
2022-05-13 15:24:58,764 EPOCH 42 done: loss 0.0391 - lr 0.000781
2022-05-13 15:25:09,120 Evaluating as a multi-label problem: False
2022-05-13 15:25:09,131 DEV : loss 0.20467105507850647 - f1-score (micro avg)  0.5223
2022-05-13 15:25:09,216 Epoch    42: reducing learning rate of group 0 to 3.9063e-04.
2022-05-13 15:25:09,216 BAD EPOCHS (no improvement): 4
2022-05-13 15:25:09,219 ----------------------------------------------------------------------------------------------------
2022-05-13 15:25:12,514 epoch 43 - iter 10/107 - loss 0.03968895 - samples/sec: 97.17 - lr: 0.000391
2022-05-13 15:25:16,270 epoch 43 - iter 20/107 - loss 0.03852910 - samples/sec: 85.21 - lr: 0.000391
2022-05-13 15:25:20,006 epoch 43 - iter 30/107 - loss 0.03878558 - samples/sec: 85.69 - lr: 0.000391
2022-05-13 15:25:23,230 epoch 43 - iter 40/107 - loss 0.03877801 - samples/sec: 99.28 - lr: 0.000391
2022-05-13 15:25:25,866 epoch 43 - iter 50/107 - loss 0.03790243 - samples/sec: 121.46 - lr: 0.000391
2022-05-13 15:25:28,573 epoch 43 - iter 60/107 - loss 0.03745712 - samples/sec: 118.23 - lr: 0.000391
2022-05-13 15:25:30,666 epoch 43 - iter 70/107 - loss 0.03811697 - samples/sec: 153.01 - lr: 0.000391
2022-05-13 15:25:33,986 epoch 43 - iter 80/107 - loss 0.03829090 - samples/sec: 96.41 - lr: 0.000391
2022-05-13 15:25:37,606 epoch 43 - iter 90/107 - loss 0.03884133 - samples/sec: 88.42 - lr: 0.000391
2022-05-13 15:25:41,160 epoch 43 - iter 100/107 - loss 0.03954722 - samples/sec: 90.06 - lr: 0.000391
2022-05-13 15:25:43,172 ----------------------------------------------------------------------------------------------------
2022-05-13 15:25:43,173 EPOCH 43 done: loss 0.0391 - lr 0.000391
2022-05-13 15:25:53,625 Evaluating as a multi-label problem: False
2022-05-13 15:25:53,636 DEV : loss 0.20506572723388672 - f1-score (micro avg)  0.5205
2022-05-13 15:25:53,720 BAD EPOCHS (no improvement): 1
2022-05-13 15:25:53,723 ----------------------------------------------------------------------------------------------------
2022-05-13 15:25:57,550 epoch 44 - iter 10/107 - loss 0.02977570 - samples/sec: 83.66 - lr: 0.000391
2022-05-13 15:26:01,239 epoch 44 - iter 20/107 - loss 0.03125932 - samples/sec: 86.78 - lr: 0.000391
2022-05-13 15:26:04,533 epoch 44 - iter 30/107 - loss 0.03353183 - samples/sec: 97.16 - lr: 0.000391
2022-05-13 15:26:07,394 epoch 44 - iter 40/107 - loss 0.03528610 - samples/sec: 111.91 - lr: 0.000391
2022-05-13 15:26:10,008 epoch 44 - iter 50/107 - loss 0.03589017 - samples/sec: 122.46 - lr: 0.000391
2022-05-13 15:26:13,587 epoch 44 - iter 60/107 - loss 0.03608382 - samples/sec: 89.43 - lr: 0.000391
2022-05-13 15:26:16,910 epoch 44 - iter 70/107 - loss 0.03720731 - samples/sec: 96.33 - lr: 0.000391
2022-05-13 15:26:20,377 epoch 44 - iter 80/107 - loss 0.03615252 - samples/sec: 92.33 - lr: 0.000391
2022-05-13 15:26:24,076 epoch 44 - iter 90/107 - loss 0.03697872 - samples/sec: 86.53 - lr: 0.000391
2022-05-13 15:26:27,676 epoch 44 - iter 100/107 - loss 0.03734041 - samples/sec: 88.91 - lr: 0.000391
2022-05-13 15:26:30,012 ----------------------------------------------------------------------------------------------------
2022-05-13 15:26:30,012 EPOCH 44 done: loss 0.0374 - lr 0.000391
2022-05-13 15:26:40,387 Evaluating as a multi-label problem: False
2022-05-13 15:26:40,398 DEV : loss 0.20495641231536865 - f1-score (micro avg)  0.5205
2022-05-13 15:26:40,483 BAD EPOCHS (no improvement): 2
2022-05-13 15:26:40,485 ----------------------------------------------------------------------------------------------------
2022-05-13 15:26:43,948 epoch 45 - iter 10/107 - loss 0.03580233 - samples/sec: 92.44 - lr: 0.000391
2022-05-13 15:26:48,123 epoch 45 - iter 20/107 - loss 0.03614374 - samples/sec: 76.68 - lr: 0.000391
2022-05-13 15:26:50,829 epoch 45 - iter 30/107 - loss 0.03598750 - samples/sec: 118.27 - lr: 0.000391
2022-05-13 15:26:54,246 epoch 45 - iter 40/107 - loss 0.03699695 - samples/sec: 93.69 - lr: 0.000391
2022-05-13 15:26:57,865 epoch 45 - iter 50/107 - loss 0.03846213 - samples/sec: 88.45 - lr: 0.000391
2022-05-13 15:27:01,587 epoch 45 - iter 60/107 - loss 0.03812899 - samples/sec: 85.98 - lr: 0.000391
2022-05-13 15:27:05,191 epoch 45 - iter 70/107 - loss 0.03769905 - samples/sec: 88.83 - lr: 0.000391
2022-05-13 15:27:08,670 epoch 45 - iter 80/107 - loss 0.03847436 - samples/sec: 92.00 - lr: 0.000391
2022-05-13 15:27:12,759 epoch 45 - iter 90/107 - loss 0.03853131 - samples/sec: 78.28 - lr: 0.000391
2022-05-13 15:27:16,517 epoch 45 - iter 100/107 - loss 0.03872071 - samples/sec: 85.16 - lr: 0.000391
2022-05-13 15:27:18,713 ----------------------------------------------------------------------------------------------------
2022-05-13 15:27:18,713 EPOCH 45 done: loss 0.0381 - lr 0.000391
2022-05-13 15:27:28,320 Evaluating as a multi-label problem: False
2022-05-13 15:27:28,331 DEV : loss 0.20537777245044708 - f1-score (micro avg)  0.5212
2022-05-13 15:27:28,416 BAD EPOCHS (no improvement): 3
2022-05-13 15:27:28,418 ----------------------------------------------------------------------------------------------------
2022-05-13 15:27:31,075 epoch 46 - iter 10/107 - loss 0.04172178 - samples/sec: 120.52 - lr: 0.000391
2022-05-13 15:27:34,323 epoch 46 - iter 20/107 - loss 0.03904988 - samples/sec: 98.57 - lr: 0.000391
2022-05-13 15:27:37,618 epoch 46 - iter 30/107 - loss 0.04086497 - samples/sec: 97.13 - lr: 0.000391
2022-05-13 15:27:41,219 epoch 46 - iter 40/107 - loss 0.04099341 - samples/sec: 88.91 - lr: 0.000391
2022-05-13 15:27:45,063 epoch 46 - iter 50/107 - loss 0.04013784 - samples/sec: 83.27 - lr: 0.000391
2022-05-13 15:27:48,561 epoch 46 - iter 60/107 - loss 0.03967825 - samples/sec: 91.50 - lr: 0.000391
2022-05-13 15:27:52,219 epoch 46 - iter 70/107 - loss 0.03871022 - samples/sec: 87.51 - lr: 0.000391
2022-05-13 15:27:55,573 epoch 46 - iter 80/107 - loss 0.03854184 - samples/sec: 95.43 - lr: 0.000391
2022-05-13 15:27:59,573 epoch 46 - iter 90/107 - loss 0.03841353 - samples/sec: 80.02 - lr: 0.000391
2022-05-13 15:28:03,103 epoch 46 - iter 100/107 - loss 0.03910193 - samples/sec: 90.69 - lr: 0.000391
2022-05-13 15:28:05,353 ----------------------------------------------------------------------------------------------------
2022-05-13 15:28:05,353 EPOCH 46 done: loss 0.0386 - lr 0.000391
2022-05-13 15:28:13,176 Evaluating as a multi-label problem: False
2022-05-13 15:28:13,187 DEV : loss 0.2052602469921112 - f1-score (micro avg)  0.5223
2022-05-13 15:28:13,273 Epoch    46: reducing learning rate of group 0 to 1.9531e-04.
2022-05-13 15:28:13,273 BAD EPOCHS (no improvement): 4
2022-05-13 15:28:13,275 ----------------------------------------------------------------------------------------------------
2022-05-13 15:28:15,349 epoch 47 - iter 10/107 - loss 0.03640123 - samples/sec: 154.35 - lr: 0.000195
2022-05-13 15:28:17,434 epoch 47 - iter 20/107 - loss 0.03855887 - samples/sec: 153.55 - lr: 0.000195
2022-05-13 15:28:19,627 epoch 47 - iter 30/107 - loss 0.03656194 - samples/sec: 146.05 - lr: 0.000195
2022-05-13 15:28:21,830 epoch 47 - iter 40/107 - loss 0.03746589 - samples/sec: 145.35 - lr: 0.000195
2022-05-13 15:28:24,055 epoch 47 - iter 50/107 - loss 0.03721433 - samples/sec: 143.84 - lr: 0.000195
2022-05-13 15:28:26,286 epoch 47 - iter 60/107 - loss 0.03660213 - samples/sec: 143.51 - lr: 0.000195
2022-05-13 15:28:28,484 epoch 47 - iter 70/107 - loss 0.03767196 - samples/sec: 145.66 - lr: 0.000195
2022-05-13 15:28:30,667 epoch 47 - iter 80/107 - loss 0.03646305 - samples/sec: 146.68 - lr: 0.000195
2022-05-13 15:28:32,860 epoch 47 - iter 90/107 - loss 0.03867869 - samples/sec: 145.94 - lr: 0.000195
2022-05-13 15:28:35,076 epoch 47 - iter 100/107 - loss 0.03824205 - samples/sec: 145.58 - lr: 0.000195
2022-05-13 15:28:36,916 ----------------------------------------------------------------------------------------------------
2022-05-13 15:28:36,916 EPOCH 47 done: loss 0.0379 - lr 0.000195
2022-05-13 15:28:47,512 Evaluating as a multi-label problem: False
2022-05-13 15:28:47,523 DEV : loss 0.20567002892494202 - f1-score (micro avg)  0.5236
2022-05-13 15:28:47,608 BAD EPOCHS (no improvement): 1
2022-05-13 15:28:47,610 ----------------------------------------------------------------------------------------------------
2022-05-13 15:28:51,526 epoch 48 - iter 10/107 - loss 0.03960902 - samples/sec: 81.74 - lr: 0.000195
2022-05-13 15:28:55,117 epoch 48 - iter 20/107 - loss 0.04275089 - samples/sec: 89.15 - lr: 0.000195
2022-05-13 15:28:58,796 epoch 48 - iter 30/107 - loss 0.03937293 - samples/sec: 86.99 - lr: 0.000195
2022-05-13 15:29:02,553 epoch 48 - iter 40/107 - loss 0.03948577 - samples/sec: 85.20 - lr: 0.000195
2022-05-13 15:29:06,191 epoch 48 - iter 50/107 - loss 0.04044274 - samples/sec: 87.99 - lr: 0.000195
2022-05-13 15:29:09,516 epoch 48 - iter 60/107 - loss 0.03948408 - samples/sec: 96.28 - lr: 0.000195
2022-05-13 15:29:12,222 epoch 48 - iter 70/107 - loss 0.03929221 - samples/sec: 118.29 - lr: 0.000195
2022-05-13 15:29:14,884 epoch 48 - iter 80/107 - loss 0.03898444 - samples/sec: 120.29 - lr: 0.000195
2022-05-13 15:29:18,010 epoch 48 - iter 90/107 - loss 0.03909530 - samples/sec: 102.39 - lr: 0.000195
2022-05-13 15:29:21,724 epoch 48 - iter 100/107 - loss 0.03906845 - samples/sec: 86.17 - lr: 0.000195
2022-05-13 15:29:23,903 ----------------------------------------------------------------------------------------------------
2022-05-13 15:29:23,903 EPOCH 48 done: loss 0.0390 - lr 0.000195
2022-05-13 15:29:34,189 Evaluating as a multi-label problem: False
2022-05-13 15:29:34,200 DEV : loss 0.20562219619750977 - f1-score (micro avg)  0.5227
2022-05-13 15:29:34,285 BAD EPOCHS (no improvement): 2
2022-05-13 15:29:34,335 ----------------------------------------------------------------------------------------------------
2022-05-13 15:29:38,199 epoch 49 - iter 10/107 - loss 0.03405006 - samples/sec: 82.87 - lr: 0.000195
2022-05-13 15:29:41,736 epoch 49 - iter 20/107 - loss 0.03237167 - samples/sec: 90.50 - lr: 0.000195
2022-05-13 15:29:45,234 epoch 49 - iter 30/107 - loss 0.03746645 - samples/sec: 91.51 - lr: 0.000195
2022-05-13 15:29:48,770 epoch 49 - iter 40/107 - loss 0.03980861 - samples/sec: 90.53 - lr: 0.000195
2022-05-13 15:29:52,258 epoch 49 - iter 50/107 - loss 0.04077136 - samples/sec: 91.78 - lr: 0.000195
2022-05-13 15:29:54,962 epoch 49 - iter 60/107 - loss 0.03908104 - samples/sec: 118.40 - lr: 0.000195
2022-05-13 15:29:57,742 epoch 49 - iter 70/107 - loss 0.03927898 - samples/sec: 115.13 - lr: 0.000195
2022-05-13 15:30:01,593 epoch 49 - iter 80/107 - loss 0.03947430 - samples/sec: 83.11 - lr: 0.000195
2022-05-13 15:30:05,236 epoch 49 - iter 90/107 - loss 0.03863340 - samples/sec: 87.87 - lr: 0.000195
2022-05-13 15:30:09,040 epoch 49 - iter 100/107 - loss 0.03864638 - samples/sec: 84.16 - lr: 0.000195
2022-05-13 15:30:11,256 ----------------------------------------------------------------------------------------------------
2022-05-13 15:30:11,257 EPOCH 49 done: loss 0.0381 - lr 0.000195
2022-05-13 15:30:21,925 Evaluating as a multi-label problem: False
2022-05-13 15:30:21,936 DEV : loss 0.20578616857528687 - f1-score (micro avg)  0.5223
2022-05-13 15:30:22,020 BAD EPOCHS (no improvement): 3
2022-05-13 15:30:22,023 ----------------------------------------------------------------------------------------------------
2022-05-13 15:30:25,496 epoch 50 - iter 10/107 - loss 0.04287300 - samples/sec: 92.18 - lr: 0.000195
2022-05-13 15:30:29,335 epoch 50 - iter 20/107 - loss 0.04270490 - samples/sec: 83.41 - lr: 0.000195
2022-05-13 15:30:31,856 epoch 50 - iter 30/107 - loss 0.03908567 - samples/sec: 126.99 - lr: 0.000195
2022-05-13 15:30:34,610 epoch 50 - iter 40/107 - loss 0.03971214 - samples/sec: 116.24 - lr: 0.000195
2022-05-13 15:30:37,312 epoch 50 - iter 50/107 - loss 0.03804830 - samples/sec: 118.49 - lr: 0.000195
2022-05-13 15:30:40,687 epoch 50 - iter 60/107 - loss 0.03945087 - samples/sec: 94.84 - lr: 0.000195
2022-05-13 15:30:44,067 epoch 50 - iter 70/107 - loss 0.03951311 - samples/sec: 94.71 - lr: 0.000195
2022-05-13 15:30:47,858 epoch 50 - iter 80/107 - loss 0.03927279 - samples/sec: 84.44 - lr: 0.000195
2022-05-13 15:30:51,416 epoch 50 - iter 90/107 - loss 0.04045333 - samples/sec: 89.96 - lr: 0.000195
2022-05-13 15:30:55,167 epoch 50 - iter 100/107 - loss 0.04006160 - samples/sec: 85.34 - lr: 0.000195
2022-05-13 15:30:57,562 ----------------------------------------------------------------------------------------------------
2022-05-13 15:30:57,563 EPOCH 50 done: loss 0.0401 - lr 0.000195
2022-05-13 15:31:09,382 Evaluating as a multi-label problem: False
2022-05-13 15:31:09,392 DEV : loss 0.2056196630001068 - f1-score (micro avg)  0.5223
2022-05-13 15:31:09,477 Epoch    50: reducing learning rate of group 0 to 9.7656e-05.
2022-05-13 15:31:09,477 BAD EPOCHS (no improvement): 4
2022-05-13 15:31:09,479 ----------------------------------------------------------------------------------------------------
2022-05-13 15:31:09,479 ----------------------------------------------------------------------------------------------------
2022-05-13 15:31:09,480 learning rate too small - quitting training!
2022-05-13 15:31:09,480 ----------------------------------------------------------------------------------------------------
2022-05-13 15:31:23,784 ----------------------------------------------------------------------------------------------------
2022-05-13 15:31:23,785 loading file resources/taggers/model_08_r10_run_2/best-model.pt
2022-05-13 15:31:31,896 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-05-13 15:31:52,281 Evaluating as a multi-label problem: False
2022-05-13 15:31:52,293 0.6599	0.3309	0.4407	0.2995
2022-05-13 15:31:52,293 
Results:
- F-score (micro) 0.4407
- F-score (macro) 0.3262
- Accuracy 0.2995

By class:
               precision    recall  f1-score   support

       person     0.7734    0.5012    0.6082       429
     location     0.6613    0.5467    0.5985       150
        group     0.4833    0.1758    0.2578       165
creative-work     0.6429    0.0634    0.1154       142
      product     0.2692    0.0551    0.0915       127
  corporation     0.3846    0.2273    0.2857        66

    micro avg     0.6599    0.3309    0.4407      1079
    macro avg     0.5358    0.2616    0.3262      1079
 weighted avg     0.6131    0.3309    0.4079      1079

2022-05-13 15:31:52,293 ----------------------------------------------------------------------------------------------------
