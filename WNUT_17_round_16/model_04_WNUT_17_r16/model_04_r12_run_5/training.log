2022-05-20 19:54:54,839 ----------------------------------------------------------------------------------------------------
2022-05-20 19:54:54,839 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4103, out_features=4103, bias=True)
  (rnn): LSTM(4103, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-05-20 19:54:54,839 ----------------------------------------------------------------------------------------------------
2022-05-20 19:54:54,839 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-05-20 19:54:54,839 ----------------------------------------------------------------------------------------------------
2022-05-20 19:54:54,839 Parameters:
2022-05-20 19:54:54,839  - learning_rate: "0.100000"
2022-05-20 19:54:54,839  - mini_batch_size: "32"
2022-05-20 19:54:54,839  - patience: "3"
2022-05-20 19:54:54,839  - anneal_factor: "0.5"
2022-05-20 19:54:54,839  - max_epochs: "150"
2022-05-20 19:54:54,839  - shuffle: "True"
2022-05-20 19:54:54,839  - train_with_dev: "False"
2022-05-20 19:54:54,839  - batch_growth_annealing: "False"
2022-05-20 19:54:54,839 ----------------------------------------------------------------------------------------------------
2022-05-20 19:54:54,839 Model training base path: "resources/taggers/model_04_r12_run_2"
2022-05-20 19:54:54,840 ----------------------------------------------------------------------------------------------------
2022-05-20 19:54:54,840 Device: cuda:0
2022-05-20 19:54:54,840 ----------------------------------------------------------------------------------------------------
2022-05-20 19:54:54,840 Embeddings storage mode: cpu
2022-05-20 19:54:54,840 ----------------------------------------------------------------------------------------------------
2022-05-20 19:54:57,453 epoch 1 - iter 10/107 - loss 0.59724122 - samples/sec: 122.48 - lr: 0.100000
2022-05-20 19:55:00,004 epoch 1 - iter 20/107 - loss 0.44142946 - samples/sec: 125.50 - lr: 0.100000
2022-05-20 19:55:02,555 epoch 1 - iter 30/107 - loss 0.38345450 - samples/sec: 125.49 - lr: 0.100000
2022-05-20 19:55:05,035 epoch 1 - iter 40/107 - loss 0.34599670 - samples/sec: 129.09 - lr: 0.100000
2022-05-20 19:55:07,562 epoch 1 - iter 50/107 - loss 0.31522424 - samples/sec: 126.68 - lr: 0.100000
2022-05-20 19:55:10,042 epoch 1 - iter 60/107 - loss 0.30754951 - samples/sec: 129.08 - lr: 0.100000
2022-05-20 19:55:12,527 epoch 1 - iter 70/107 - loss 0.29998665 - samples/sec: 128.86 - lr: 0.100000
2022-05-20 19:55:14,891 epoch 1 - iter 80/107 - loss 0.29789536 - samples/sec: 135.41 - lr: 0.100000
2022-05-20 19:55:17,150 epoch 1 - iter 90/107 - loss 0.29614117 - samples/sec: 141.73 - lr: 0.100000
2022-05-20 19:55:19,430 epoch 1 - iter 100/107 - loss 0.29286513 - samples/sec: 140.39 - lr: 0.100000
2022-05-20 19:55:20,784 ----------------------------------------------------------------------------------------------------
2022-05-20 19:55:20,784 EPOCH 1 done: loss 0.2885 - lr 0.100000
2022-05-20 19:55:26,603 Evaluating as a multi-label problem: False
2022-05-20 19:55:26,613 DEV : loss 0.3558850884437561 - f1-score (micro avg)  0.2555
2022-05-20 19:55:26,686 BAD EPOCHS (no improvement): 0
2022-05-20 19:55:26,688 saving best model
2022-05-20 19:55:33,559 ----------------------------------------------------------------------------------------------------
2022-05-20 19:55:36,045 epoch 2 - iter 10/107 - loss 0.22931812 - samples/sec: 128.81 - lr: 0.100000
2022-05-20 19:55:38,550 epoch 2 - iter 20/107 - loss 0.20108040 - samples/sec: 127.80 - lr: 0.100000
2022-05-20 19:55:41,026 epoch 2 - iter 30/107 - loss 0.20112480 - samples/sec: 129.31 - lr: 0.100000
2022-05-20 19:55:43,602 epoch 2 - iter 40/107 - loss 0.19963109 - samples/sec: 124.25 - lr: 0.100000
2022-05-20 19:55:46,075 epoch 2 - iter 50/107 - loss 0.19141290 - samples/sec: 129.48 - lr: 0.100000
2022-05-20 19:55:48,663 epoch 2 - iter 60/107 - loss 0.19127544 - samples/sec: 123.67 - lr: 0.100000
2022-05-20 19:55:50,812 epoch 2 - iter 70/107 - loss 0.18999651 - samples/sec: 148.96 - lr: 0.100000
2022-05-20 19:55:52,258 epoch 2 - iter 80/107 - loss 0.18868210 - samples/sec: 221.53 - lr: 0.100000
2022-05-20 19:55:54,497 epoch 2 - iter 90/107 - loss 0.19067043 - samples/sec: 143.00 - lr: 0.100000
2022-05-20 19:55:56,647 epoch 2 - iter 100/107 - loss 0.18838898 - samples/sec: 148.88 - lr: 0.100000
2022-05-20 19:55:58,003 ----------------------------------------------------------------------------------------------------
2022-05-20 19:55:58,003 EPOCH 2 done: loss 0.1868 - lr 0.100000
2022-05-20 19:56:05,512 Evaluating as a multi-label problem: False
2022-05-20 19:56:05,523 DEV : loss 0.28526395559310913 - f1-score (micro avg)  0.3986
2022-05-20 19:56:05,595 BAD EPOCHS (no improvement): 0
2022-05-20 19:56:05,597 saving best model
2022-05-20 19:56:12,482 ----------------------------------------------------------------------------------------------------
2022-05-20 19:56:15,112 epoch 3 - iter 10/107 - loss 0.17696065 - samples/sec: 121.79 - lr: 0.100000
2022-05-20 19:56:17,839 epoch 3 - iter 20/107 - loss 0.17557808 - samples/sec: 117.38 - lr: 0.100000
2022-05-20 19:56:20,278 epoch 3 - iter 30/107 - loss 0.18040624 - samples/sec: 131.26 - lr: 0.100000
2022-05-20 19:56:22,550 epoch 3 - iter 40/107 - loss 0.17015204 - samples/sec: 140.92 - lr: 0.100000
2022-05-20 19:56:24,802 epoch 3 - iter 50/107 - loss 0.16965963 - samples/sec: 142.12 - lr: 0.100000
2022-05-20 19:56:26,912 epoch 3 - iter 60/107 - loss 0.16464433 - samples/sec: 151.76 - lr: 0.100000
2022-05-20 19:56:29,170 epoch 3 - iter 70/107 - loss 0.16308391 - samples/sec: 141.78 - lr: 0.100000
2022-05-20 19:56:31,649 epoch 3 - iter 80/107 - loss 0.16249341 - samples/sec: 129.14 - lr: 0.100000
2022-05-20 19:56:34,141 epoch 3 - iter 90/107 - loss 0.15700953 - samples/sec: 128.45 - lr: 0.100000
2022-05-20 19:56:36,514 epoch 3 - iter 100/107 - loss 0.15804501 - samples/sec: 134.86 - lr: 0.100000
2022-05-20 19:56:37,954 ----------------------------------------------------------------------------------------------------
2022-05-20 19:56:37,954 EPOCH 3 done: loss 0.1580 - lr 0.100000
2022-05-20 19:56:45,277 Evaluating as a multi-label problem: False
2022-05-20 19:56:45,287 DEV : loss 0.24809186160564423 - f1-score (micro avg)  0.4531
2022-05-20 19:56:45,360 BAD EPOCHS (no improvement): 0
2022-05-20 19:56:45,362 saving best model
2022-05-20 19:56:52,255 ----------------------------------------------------------------------------------------------------
2022-05-20 19:56:54,554 epoch 4 - iter 10/107 - loss 0.13068025 - samples/sec: 139.30 - lr: 0.100000
2022-05-20 19:56:56,687 epoch 4 - iter 20/107 - loss 0.14093722 - samples/sec: 150.08 - lr: 0.100000
2022-05-20 19:56:58,840 epoch 4 - iter 30/107 - loss 0.13759220 - samples/sec: 148.72 - lr: 0.100000
2022-05-20 19:57:01,430 epoch 4 - iter 40/107 - loss 0.13711467 - samples/sec: 123.58 - lr: 0.100000
2022-05-20 19:57:03,792 epoch 4 - iter 50/107 - loss 0.14143745 - samples/sec: 135.54 - lr: 0.100000
2022-05-20 19:57:06,202 epoch 4 - iter 60/107 - loss 0.14193215 - samples/sec: 132.87 - lr: 0.100000
2022-05-20 19:57:08,869 epoch 4 - iter 70/107 - loss 0.14285962 - samples/sec: 120.03 - lr: 0.100000
2022-05-20 19:57:11,318 epoch 4 - iter 80/107 - loss 0.13876520 - samples/sec: 130.69 - lr: 0.100000
2022-05-20 19:57:13,936 epoch 4 - iter 90/107 - loss 0.13828164 - samples/sec: 122.29 - lr: 0.100000
2022-05-20 19:57:16,407 epoch 4 - iter 100/107 - loss 0.13702312 - samples/sec: 129.52 - lr: 0.100000
2022-05-20 19:57:17,951 ----------------------------------------------------------------------------------------------------
2022-05-20 19:57:17,951 EPOCH 4 done: loss 0.1361 - lr 0.100000
2022-05-20 19:57:25,513 Evaluating as a multi-label problem: False
2022-05-20 19:57:25,524 DEV : loss 0.27946025133132935 - f1-score (micro avg)  0.3375
2022-05-20 19:57:25,598 BAD EPOCHS (no improvement): 1
2022-05-20 19:57:25,600 ----------------------------------------------------------------------------------------------------
2022-05-20 19:57:27,820 epoch 5 - iter 10/107 - loss 0.15177792 - samples/sec: 144.19 - lr: 0.100000
2022-05-20 19:57:30,052 epoch 5 - iter 20/107 - loss 0.13584917 - samples/sec: 143.42 - lr: 0.100000
2022-05-20 19:57:32,343 epoch 5 - iter 30/107 - loss 0.13180887 - samples/sec: 139.73 - lr: 0.100000
2022-05-20 19:57:34,640 epoch 5 - iter 40/107 - loss 0.12656943 - samples/sec: 139.41 - lr: 0.100000
2022-05-20 19:57:37,039 epoch 5 - iter 50/107 - loss 0.12963303 - samples/sec: 133.42 - lr: 0.100000
2022-05-20 19:57:39,507 epoch 5 - iter 60/107 - loss 0.12735631 - samples/sec: 129.74 - lr: 0.100000
2022-05-20 19:57:41,926 epoch 5 - iter 70/107 - loss 0.12746862 - samples/sec: 132.33 - lr: 0.100000
2022-05-20 19:57:44,313 epoch 5 - iter 80/107 - loss 0.12675244 - samples/sec: 134.12 - lr: 0.100000
2022-05-20 19:57:46,712 epoch 5 - iter 90/107 - loss 0.12576508 - samples/sec: 133.44 - lr: 0.100000
2022-05-20 19:57:49,155 epoch 5 - iter 100/107 - loss 0.12445359 - samples/sec: 131.04 - lr: 0.100000
2022-05-20 19:57:50,742 ----------------------------------------------------------------------------------------------------
2022-05-20 19:57:50,742 EPOCH 5 done: loss 0.1252 - lr 0.100000
2022-05-20 19:57:58,572 Evaluating as a multi-label problem: False
2022-05-20 19:57:58,582 DEV : loss 0.2112579643726349 - f1-score (micro avg)  0.5048
2022-05-20 19:57:58,653 BAD EPOCHS (no improvement): 0
2022-05-20 19:57:58,654 saving best model
2022-05-20 19:58:05,456 ----------------------------------------------------------------------------------------------------
2022-05-20 19:58:07,957 epoch 6 - iter 10/107 - loss 0.11723917 - samples/sec: 128.05 - lr: 0.100000
2022-05-20 19:58:10,344 epoch 6 - iter 20/107 - loss 0.11250507 - samples/sec: 134.12 - lr: 0.100000
2022-05-20 19:58:12,777 epoch 6 - iter 30/107 - loss 0.10557201 - samples/sec: 131.54 - lr: 0.100000
2022-05-20 19:58:15,262 epoch 6 - iter 40/107 - loss 0.11130333 - samples/sec: 128.82 - lr: 0.100000
2022-05-20 19:58:17,731 epoch 6 - iter 50/107 - loss 0.11371515 - samples/sec: 129.66 - lr: 0.100000
2022-05-20 19:58:20,195 epoch 6 - iter 60/107 - loss 0.11562483 - samples/sec: 129.98 - lr: 0.100000
2022-05-20 19:58:22,654 epoch 6 - iter 70/107 - loss 0.11419413 - samples/sec: 130.19 - lr: 0.100000
2022-05-20 19:58:25,183 epoch 6 - iter 80/107 - loss 0.11798949 - samples/sec: 126.58 - lr: 0.100000
2022-05-20 19:58:27,609 epoch 6 - iter 90/107 - loss 0.11727431 - samples/sec: 131.98 - lr: 0.100000
2022-05-20 19:58:29,905 epoch 6 - iter 100/107 - loss 0.11749921 - samples/sec: 139.41 - lr: 0.100000
2022-05-20 19:58:31,144 ----------------------------------------------------------------------------------------------------
2022-05-20 19:58:31,144 EPOCH 6 done: loss 0.1179 - lr 0.100000
2022-05-20 19:58:38,083 Evaluating as a multi-label problem: False
2022-05-20 19:58:38,093 DEV : loss 0.2499241977930069 - f1-score (micro avg)  0.3631
2022-05-20 19:58:38,164 BAD EPOCHS (no improvement): 1
2022-05-20 19:58:38,165 ----------------------------------------------------------------------------------------------------
2022-05-20 19:58:40,590 epoch 7 - iter 10/107 - loss 0.07405454 - samples/sec: 132.05 - lr: 0.100000
2022-05-20 19:58:43,009 epoch 7 - iter 20/107 - loss 0.08685256 - samples/sec: 132.33 - lr: 0.100000
2022-05-20 19:58:45,462 epoch 7 - iter 30/107 - loss 0.09934716 - samples/sec: 130.51 - lr: 0.100000
2022-05-20 19:58:47,969 epoch 7 - iter 40/107 - loss 0.10593222 - samples/sec: 127.68 - lr: 0.100000
2022-05-20 19:58:50,425 epoch 7 - iter 50/107 - loss 0.10487106 - samples/sec: 130.34 - lr: 0.100000
2022-05-20 19:58:52,841 epoch 7 - iter 60/107 - loss 0.10468880 - samples/sec: 132.52 - lr: 0.100000
2022-05-20 19:58:55,342 epoch 7 - iter 70/107 - loss 0.10551726 - samples/sec: 127.99 - lr: 0.100000
2022-05-20 19:58:57,721 epoch 7 - iter 80/107 - loss 0.10451161 - samples/sec: 134.57 - lr: 0.100000
2022-05-20 19:59:00,195 epoch 7 - iter 90/107 - loss 0.10531367 - samples/sec: 129.41 - lr: 0.100000
2022-05-20 19:59:02,559 epoch 7 - iter 100/107 - loss 0.10745350 - samples/sec: 135.41 - lr: 0.100000
2022-05-20 19:59:03,839 ----------------------------------------------------------------------------------------------------
2022-05-20 19:59:03,839 EPOCH 7 done: loss 0.1079 - lr 0.100000
2022-05-20 19:59:10,782 Evaluating as a multi-label problem: False
2022-05-20 19:59:10,793 DEV : loss 0.19340261816978455 - f1-score (micro avg)  0.5324
2022-05-20 19:59:10,864 BAD EPOCHS (no improvement): 0
2022-05-20 19:59:10,867 saving best model
2022-05-20 19:59:17,683 ----------------------------------------------------------------------------------------------------
2022-05-20 19:59:20,126 epoch 8 - iter 10/107 - loss 0.10587895 - samples/sec: 131.06 - lr: 0.100000
2022-05-20 19:59:22,548 epoch 8 - iter 20/107 - loss 0.11518501 - samples/sec: 132.17 - lr: 0.100000
2022-05-20 19:59:25,014 epoch 8 - iter 30/107 - loss 0.11243495 - samples/sec: 129.81 - lr: 0.100000
2022-05-20 19:59:27,547 epoch 8 - iter 40/107 - loss 0.10691881 - samples/sec: 126.40 - lr: 0.100000
2022-05-20 19:59:29,925 epoch 8 - iter 50/107 - loss 0.10224538 - samples/sec: 134.64 - lr: 0.100000
2022-05-20 19:59:32,092 epoch 8 - iter 60/107 - loss 0.10505757 - samples/sec: 147.70 - lr: 0.100000
2022-05-20 19:59:33,774 epoch 8 - iter 70/107 - loss 0.10286097 - samples/sec: 190.34 - lr: 0.100000
2022-05-20 19:59:36,069 epoch 8 - iter 80/107 - loss 0.10173525 - samples/sec: 139.54 - lr: 0.100000
2022-05-20 19:59:38,384 epoch 8 - iter 90/107 - loss 0.10297794 - samples/sec: 138.27 - lr: 0.100000
2022-05-20 19:59:40,762 epoch 8 - iter 100/107 - loss 0.10126419 - samples/sec: 134.60 - lr: 0.100000
2022-05-20 19:59:42,210 ----------------------------------------------------------------------------------------------------
2022-05-20 19:59:42,210 EPOCH 8 done: loss 0.1016 - lr 0.100000
2022-05-20 19:59:49,721 Evaluating as a multi-label problem: False
2022-05-20 19:59:49,731 DEV : loss 0.24029959738254547 - f1-score (micro avg)  0.414
2022-05-20 19:59:49,803 BAD EPOCHS (no improvement): 1
2022-05-20 19:59:49,812 ----------------------------------------------------------------------------------------------------
2022-05-20 19:59:52,425 epoch 9 - iter 10/107 - loss 0.11104971 - samples/sec: 122.50 - lr: 0.100000
2022-05-20 19:59:54,865 epoch 9 - iter 20/107 - loss 0.09418561 - samples/sec: 131.21 - lr: 0.100000
2022-05-20 19:59:57,318 epoch 9 - iter 30/107 - loss 0.09223196 - samples/sec: 130.51 - lr: 0.100000
2022-05-20 19:59:59,914 epoch 9 - iter 40/107 - loss 0.09784406 - samples/sec: 123.33 - lr: 0.100000
2022-05-20 20:00:02,376 epoch 9 - iter 50/107 - loss 0.09656215 - samples/sec: 130.00 - lr: 0.100000
2022-05-20 20:00:04,828 epoch 9 - iter 60/107 - loss 0.09513800 - samples/sec: 130.59 - lr: 0.100000
2022-05-20 20:00:07,110 epoch 9 - iter 70/107 - loss 0.09521073 - samples/sec: 140.27 - lr: 0.100000
2022-05-20 20:00:09,239 epoch 9 - iter 80/107 - loss 0.09495338 - samples/sec: 150.38 - lr: 0.100000
2022-05-20 20:00:11,399 epoch 9 - iter 90/107 - loss 0.09608523 - samples/sec: 148.20 - lr: 0.100000
2022-05-20 20:00:13,732 epoch 9 - iter 100/107 - loss 0.09672561 - samples/sec: 137.24 - lr: 0.100000
2022-05-20 20:00:15,246 ----------------------------------------------------------------------------------------------------
2022-05-20 20:00:15,247 EPOCH 9 done: loss 0.0963 - lr 0.100000
2022-05-20 20:00:22,695 Evaluating as a multi-label problem: False
2022-05-20 20:00:22,706 DEV : loss 0.19949474930763245 - f1-score (micro avg)  0.5042
2022-05-20 20:00:22,777 BAD EPOCHS (no improvement): 2
2022-05-20 20:00:22,779 ----------------------------------------------------------------------------------------------------
2022-05-20 20:00:25,289 epoch 10 - iter 10/107 - loss 0.09759221 - samples/sec: 127.55 - lr: 0.100000
2022-05-20 20:00:27,741 epoch 10 - iter 20/107 - loss 0.09748449 - samples/sec: 130.57 - lr: 0.100000
2022-05-20 20:00:30,193 epoch 10 - iter 30/107 - loss 0.09684545 - samples/sec: 130.55 - lr: 0.100000
2022-05-20 20:00:32,702 epoch 10 - iter 40/107 - loss 0.09624462 - samples/sec: 127.59 - lr: 0.100000
2022-05-20 20:00:35,153 epoch 10 - iter 50/107 - loss 0.09451613 - samples/sec: 130.60 - lr: 0.100000
2022-05-20 20:00:37,600 epoch 10 - iter 60/107 - loss 0.09450146 - samples/sec: 130.83 - lr: 0.100000
2022-05-20 20:00:39,946 epoch 10 - iter 70/107 - loss 0.09150759 - samples/sec: 136.50 - lr: 0.100000
2022-05-20 20:00:42,238 epoch 10 - iter 80/107 - loss 0.09124297 - samples/sec: 139.65 - lr: 0.100000
2022-05-20 20:00:44,366 epoch 10 - iter 90/107 - loss 0.09155894 - samples/sec: 150.46 - lr: 0.100000
2022-05-20 20:00:46,488 epoch 10 - iter 100/107 - loss 0.09133855 - samples/sec: 150.84 - lr: 0.100000
2022-05-20 20:00:47,836 ----------------------------------------------------------------------------------------------------
2022-05-20 20:00:47,836 EPOCH 10 done: loss 0.0910 - lr 0.100000
2022-05-20 20:00:56,220 Evaluating as a multi-label problem: False
2022-05-20 20:00:56,231 DEV : loss 0.1824190467596054 - f1-score (micro avg)  0.5276
2022-05-20 20:00:56,307 BAD EPOCHS (no improvement): 3
2022-05-20 20:00:56,308 ----------------------------------------------------------------------------------------------------
2022-05-20 20:00:58,774 epoch 11 - iter 10/107 - loss 0.09122852 - samples/sec: 129.85 - lr: 0.100000
2022-05-20 20:01:01,267 epoch 11 - iter 20/107 - loss 0.07952243 - samples/sec: 128.40 - lr: 0.100000
2022-05-20 20:01:03,705 epoch 11 - iter 30/107 - loss 0.07906819 - samples/sec: 131.33 - lr: 0.100000
2022-05-20 20:01:06,188 epoch 11 - iter 40/107 - loss 0.07863277 - samples/sec: 128.90 - lr: 0.100000
2022-05-20 20:01:08,577 epoch 11 - iter 50/107 - loss 0.07973817 - samples/sec: 134.06 - lr: 0.100000
2022-05-20 20:01:11,086 epoch 11 - iter 60/107 - loss 0.08135336 - samples/sec: 127.59 - lr: 0.100000
2022-05-20 20:01:13,371 epoch 11 - iter 70/107 - loss 0.08526066 - samples/sec: 140.07 - lr: 0.100000
2022-05-20 20:01:15,440 epoch 11 - iter 80/107 - loss 0.08692923 - samples/sec: 154.72 - lr: 0.100000
2022-05-20 20:01:17,597 epoch 11 - iter 90/107 - loss 0.08675106 - samples/sec: 148.46 - lr: 0.100000
2022-05-20 20:01:19,925 epoch 11 - iter 100/107 - loss 0.08492020 - samples/sec: 137.51 - lr: 0.100000
2022-05-20 20:01:20,829 ----------------------------------------------------------------------------------------------------
2022-05-20 20:01:20,829 EPOCH 11 done: loss 0.0856 - lr 0.100000
2022-05-20 20:01:26,243 Evaluating as a multi-label problem: False
2022-05-20 20:01:26,254 DEV : loss 0.20556321740150452 - f1-score (micro avg)  0.5162
2022-05-20 20:01:26,325 Epoch    11: reducing learning rate of group 0 to 5.0000e-02.
2022-05-20 20:01:26,325 BAD EPOCHS (no improvement): 4
2022-05-20 20:01:26,327 ----------------------------------------------------------------------------------------------------
2022-05-20 20:01:27,919 epoch 12 - iter 10/107 - loss 0.08285261 - samples/sec: 201.20 - lr: 0.050000
2022-05-20 20:01:29,444 epoch 12 - iter 20/107 - loss 0.08291030 - samples/sec: 210.00 - lr: 0.050000
2022-05-20 20:01:31,043 epoch 12 - iter 30/107 - loss 0.07941184 - samples/sec: 200.25 - lr: 0.050000
2022-05-20 20:01:32,575 epoch 12 - iter 40/107 - loss 0.07790957 - samples/sec: 209.03 - lr: 0.050000
2022-05-20 20:01:34,167 epoch 12 - iter 50/107 - loss 0.07728224 - samples/sec: 201.14 - lr: 0.050000
2022-05-20 20:01:35,862 epoch 12 - iter 60/107 - loss 0.07742807 - samples/sec: 188.87 - lr: 0.050000
2022-05-20 20:01:37,558 epoch 12 - iter 70/107 - loss 0.07753781 - samples/sec: 188.84 - lr: 0.050000
2022-05-20 20:01:39,215 epoch 12 - iter 80/107 - loss 0.07624147 - samples/sec: 193.16 - lr: 0.050000
2022-05-20 20:01:42,707 epoch 12 - iter 90/107 - loss 0.07491921 - samples/sec: 91.68 - lr: 0.050000
2022-05-20 20:01:46,128 epoch 12 - iter 100/107 - loss 0.07615259 - samples/sec: 93.56 - lr: 0.050000
2022-05-20 20:01:48,917 ----------------------------------------------------------------------------------------------------
2022-05-20 20:01:48,917 EPOCH 12 done: loss 0.0782 - lr 0.050000
2022-05-20 20:01:59,115 Evaluating as a multi-label problem: False
2022-05-20 20:01:59,126 DEV : loss 0.18930412828922272 - f1-score (micro avg)  0.4992
2022-05-20 20:01:59,197 BAD EPOCHS (no improvement): 1
2022-05-20 20:01:59,200 ----------------------------------------------------------------------------------------------------
2022-05-20 20:02:01,757 epoch 13 - iter 10/107 - loss 0.07739332 - samples/sec: 125.23 - lr: 0.050000
2022-05-20 20:02:04,412 epoch 13 - iter 20/107 - loss 0.07990532 - samples/sec: 120.54 - lr: 0.050000
2022-05-20 20:02:07,136 epoch 13 - iter 30/107 - loss 0.07808370 - samples/sec: 117.54 - lr: 0.050000
2022-05-20 20:02:09,555 epoch 13 - iter 40/107 - loss 0.07599173 - samples/sec: 132.33 - lr: 0.050000
2022-05-20 20:02:12,050 epoch 13 - iter 50/107 - loss 0.07296751 - samples/sec: 128.33 - lr: 0.050000
2022-05-20 20:02:14,737 epoch 13 - iter 60/107 - loss 0.07439177 - samples/sec: 119.13 - lr: 0.050000
2022-05-20 20:02:17,162 epoch 13 - iter 70/107 - loss 0.07446166 - samples/sec: 131.97 - lr: 0.050000
2022-05-20 20:02:19,720 epoch 13 - iter 80/107 - loss 0.07333904 - samples/sec: 125.16 - lr: 0.050000
2022-05-20 20:02:22,347 epoch 13 - iter 90/107 - loss 0.07425453 - samples/sec: 121.86 - lr: 0.050000
2022-05-20 20:02:24,960 epoch 13 - iter 100/107 - loss 0.07511542 - samples/sec: 122.56 - lr: 0.050000
2022-05-20 20:02:26,374 ----------------------------------------------------------------------------------------------------
2022-05-20 20:02:26,374 EPOCH 13 done: loss 0.0746 - lr 0.050000
2022-05-20 20:02:32,258 Evaluating as a multi-label problem: False
2022-05-20 20:02:32,270 DEV : loss 0.19008952379226685 - f1-score (micro avg)  0.5117
2022-05-20 20:02:32,341 BAD EPOCHS (no improvement): 2
2022-05-20 20:02:32,342 ----------------------------------------------------------------------------------------------------
2022-05-20 20:02:33,766 epoch 14 - iter 10/107 - loss 0.06621681 - samples/sec: 225.03 - lr: 0.050000
2022-05-20 20:02:35,286 epoch 14 - iter 20/107 - loss 0.06706106 - samples/sec: 210.65 - lr: 0.050000
2022-05-20 20:02:36,852 epoch 14 - iter 30/107 - loss 0.06980800 - samples/sec: 204.48 - lr: 0.050000
2022-05-20 20:02:38,374 epoch 14 - iter 40/107 - loss 0.06996910 - samples/sec: 210.43 - lr: 0.050000
2022-05-20 20:02:39,863 epoch 14 - iter 50/107 - loss 0.06947184 - samples/sec: 214.94 - lr: 0.050000
2022-05-20 20:02:41,438 epoch 14 - iter 60/107 - loss 0.06849517 - samples/sec: 203.37 - lr: 0.050000
2022-05-20 20:02:43,052 epoch 14 - iter 70/107 - loss 0.07121028 - samples/sec: 198.35 - lr: 0.050000
2022-05-20 20:02:45,545 epoch 14 - iter 80/107 - loss 0.07019195 - samples/sec: 128.38 - lr: 0.050000
2022-05-20 20:02:48,064 epoch 14 - iter 90/107 - loss 0.06875199 - samples/sec: 127.08 - lr: 0.050000
2022-05-20 20:02:50,295 epoch 14 - iter 100/107 - loss 0.07075250 - samples/sec: 143.51 - lr: 0.050000
2022-05-20 20:02:51,953 ----------------------------------------------------------------------------------------------------
2022-05-20 20:02:51,953 EPOCH 14 done: loss 0.0708 - lr 0.050000
2022-05-20 20:02:59,178 Evaluating as a multi-label problem: False
2022-05-20 20:02:59,188 DEV : loss 0.205886110663414 - f1-score (micro avg)  0.4846
2022-05-20 20:02:59,258 BAD EPOCHS (no improvement): 3
2022-05-20 20:02:59,260 ----------------------------------------------------------------------------------------------------
2022-05-20 20:03:01,955 epoch 15 - iter 10/107 - loss 0.07094082 - samples/sec: 118.80 - lr: 0.050000
2022-05-20 20:03:04,302 epoch 15 - iter 20/107 - loss 0.07649641 - samples/sec: 136.40 - lr: 0.050000
2022-05-20 20:03:06,727 epoch 15 - iter 30/107 - loss 0.07090329 - samples/sec: 132.06 - lr: 0.050000
2022-05-20 20:03:09,288 epoch 15 - iter 40/107 - loss 0.06962152 - samples/sec: 125.01 - lr: 0.050000
2022-05-20 20:03:11,760 epoch 15 - iter 50/107 - loss 0.06706463 - samples/sec: 129.48 - lr: 0.050000
2022-05-20 20:03:14,183 epoch 15 - iter 60/107 - loss 0.06801277 - samples/sec: 132.11 - lr: 0.050000
2022-05-20 20:03:16,512 epoch 15 - iter 70/107 - loss 0.06937625 - samples/sec: 137.44 - lr: 0.050000
2022-05-20 20:03:18,568 epoch 15 - iter 80/107 - loss 0.06942799 - samples/sec: 155.76 - lr: 0.050000
2022-05-20 20:03:20,758 epoch 15 - iter 90/107 - loss 0.06997242 - samples/sec: 146.14 - lr: 0.050000
2022-05-20 20:03:22,985 epoch 15 - iter 100/107 - loss 0.07024872 - samples/sec: 143.79 - lr: 0.050000
2022-05-20 20:03:23,869 ----------------------------------------------------------------------------------------------------
2022-05-20 20:03:23,869 EPOCH 15 done: loss 0.0712 - lr 0.050000
2022-05-20 20:03:29,290 Evaluating as a multi-label problem: False
2022-05-20 20:03:29,301 DEV : loss 0.17733144760131836 - f1-score (micro avg)  0.5282
2022-05-20 20:03:29,372 Epoch    15: reducing learning rate of group 0 to 2.5000e-02.
2022-05-20 20:03:29,372 BAD EPOCHS (no improvement): 4
2022-05-20 20:03:29,374 ----------------------------------------------------------------------------------------------------
2022-05-20 20:03:31,062 epoch 16 - iter 10/107 - loss 0.07708688 - samples/sec: 189.77 - lr: 0.025000
2022-05-20 20:03:32,698 epoch 16 - iter 20/107 - loss 0.06716707 - samples/sec: 195.63 - lr: 0.025000
2022-05-20 20:03:34,456 epoch 16 - iter 30/107 - loss 0.06565881 - samples/sec: 182.12 - lr: 0.025000
2022-05-20 20:03:36,934 epoch 16 - iter 40/107 - loss 0.06566664 - samples/sec: 129.21 - lr: 0.025000
2022-05-20 20:03:39,524 epoch 16 - iter 50/107 - loss 0.06693880 - samples/sec: 123.62 - lr: 0.025000
2022-05-20 20:03:41,939 epoch 16 - iter 60/107 - loss 0.06561594 - samples/sec: 132.57 - lr: 0.025000
2022-05-20 20:03:44,403 epoch 16 - iter 70/107 - loss 0.06457505 - samples/sec: 129.89 - lr: 0.025000
2022-05-20 20:03:46,857 epoch 16 - iter 80/107 - loss 0.06354432 - samples/sec: 130.47 - lr: 0.025000
2022-05-20 20:03:49,500 epoch 16 - iter 90/107 - loss 0.06484142 - samples/sec: 121.12 - lr: 0.025000
2022-05-20 20:03:52,836 epoch 16 - iter 100/107 - loss 0.06422207 - samples/sec: 95.95 - lr: 0.025000
2022-05-20 20:03:54,445 ----------------------------------------------------------------------------------------------------
2022-05-20 20:03:54,445 EPOCH 16 done: loss 0.0637 - lr 0.025000
2022-05-20 20:04:01,795 Evaluating as a multi-label problem: False
2022-05-20 20:04:01,805 DEV : loss 0.20086324214935303 - f1-score (micro avg)  0.4928
2022-05-20 20:04:01,876 BAD EPOCHS (no improvement): 1
2022-05-20 20:04:01,879 ----------------------------------------------------------------------------------------------------
2022-05-20 20:04:04,168 epoch 17 - iter 10/107 - loss 0.06597650 - samples/sec: 139.89 - lr: 0.025000
2022-05-20 20:04:06,383 epoch 17 - iter 20/107 - loss 0.06065498 - samples/sec: 144.48 - lr: 0.025000
2022-05-20 20:04:08,760 epoch 17 - iter 30/107 - loss 0.05925616 - samples/sec: 134.68 - lr: 0.025000
2022-05-20 20:04:11,136 epoch 17 - iter 40/107 - loss 0.06245341 - samples/sec: 134.76 - lr: 0.025000
2022-05-20 20:04:13,618 epoch 17 - iter 50/107 - loss 0.06228071 - samples/sec: 128.99 - lr: 0.025000
2022-05-20 20:04:16,073 epoch 17 - iter 60/107 - loss 0.06164973 - samples/sec: 130.38 - lr: 0.025000
2022-05-20 20:04:18,708 epoch 17 - iter 70/107 - loss 0.06300972 - samples/sec: 121.48 - lr: 0.025000
2022-05-20 20:04:21,124 epoch 17 - iter 80/107 - loss 0.06260078 - samples/sec: 132.52 - lr: 0.025000
2022-05-20 20:04:23,512 epoch 17 - iter 90/107 - loss 0.06079274 - samples/sec: 134.05 - lr: 0.025000
2022-05-20 20:04:25,904 epoch 17 - iter 100/107 - loss 0.06157196 - samples/sec: 133.82 - lr: 0.025000
2022-05-20 20:04:27,453 ----------------------------------------------------------------------------------------------------
2022-05-20 20:04:27,454 EPOCH 17 done: loss 0.0625 - lr 0.025000
2022-05-20 20:04:34,876 Evaluating as a multi-label problem: False
2022-05-20 20:04:34,887 DEV : loss 0.1900586634874344 - f1-score (micro avg)  0.5039
2022-05-20 20:04:34,960 BAD EPOCHS (no improvement): 2
2022-05-20 20:04:34,962 ----------------------------------------------------------------------------------------------------
2022-05-20 20:04:37,160 epoch 18 - iter 10/107 - loss 0.05823515 - samples/sec: 145.69 - lr: 0.025000
2022-05-20 20:04:39,671 epoch 18 - iter 20/107 - loss 0.06099633 - samples/sec: 127.52 - lr: 0.025000
2022-05-20 20:04:41,405 epoch 18 - iter 30/107 - loss 0.06136695 - samples/sec: 184.66 - lr: 0.025000
2022-05-20 20:04:42,921 epoch 18 - iter 40/107 - loss 0.05902278 - samples/sec: 211.14 - lr: 0.025000
2022-05-20 20:04:44,363 epoch 18 - iter 50/107 - loss 0.06040478 - samples/sec: 222.04 - lr: 0.025000
2022-05-20 20:04:45,894 epoch 18 - iter 60/107 - loss 0.06070966 - samples/sec: 209.22 - lr: 0.025000
2022-05-20 20:04:47,355 epoch 18 - iter 70/107 - loss 0.06219058 - samples/sec: 219.09 - lr: 0.025000
2022-05-20 20:04:48,922 epoch 18 - iter 80/107 - loss 0.06053051 - samples/sec: 204.31 - lr: 0.025000
2022-05-20 20:04:50,454 epoch 18 - iter 90/107 - loss 0.06102884 - samples/sec: 209.10 - lr: 0.025000
2022-05-20 20:04:52,505 epoch 18 - iter 100/107 - loss 0.06077073 - samples/sec: 156.04 - lr: 0.025000
2022-05-20 20:04:54,020 ----------------------------------------------------------------------------------------------------
2022-05-20 20:04:54,020 EPOCH 18 done: loss 0.0608 - lr 0.025000
2022-05-20 20:05:01,710 Evaluating as a multi-label problem: False
2022-05-20 20:05:01,720 DEV : loss 0.20875711739063263 - f1-score (micro avg)  0.488
2022-05-20 20:05:01,794 BAD EPOCHS (no improvement): 3
2022-05-20 20:05:01,797 ----------------------------------------------------------------------------------------------------
2022-05-20 20:05:04,207 epoch 19 - iter 10/107 - loss 0.06148417 - samples/sec: 132.89 - lr: 0.025000
2022-05-20 20:05:06,679 epoch 19 - iter 20/107 - loss 0.06181169 - samples/sec: 129.46 - lr: 0.025000
2022-05-20 20:05:09,077 epoch 19 - iter 30/107 - loss 0.05947634 - samples/sec: 133.54 - lr: 0.025000
2022-05-20 20:05:11,611 epoch 19 - iter 40/107 - loss 0.05815966 - samples/sec: 126.35 - lr: 0.025000
2022-05-20 20:05:14,056 epoch 19 - iter 50/107 - loss 0.06067371 - samples/sec: 130.94 - lr: 0.025000
2022-05-20 20:05:16,482 epoch 19 - iter 60/107 - loss 0.05975994 - samples/sec: 131.96 - lr: 0.025000
2022-05-20 20:05:18,650 epoch 19 - iter 70/107 - loss 0.05932855 - samples/sec: 147.63 - lr: 0.025000
2022-05-20 20:05:20,855 epoch 19 - iter 80/107 - loss 0.06072712 - samples/sec: 145.20 - lr: 0.025000
2022-05-20 20:05:22,927 epoch 19 - iter 90/107 - loss 0.06158305 - samples/sec: 154.48 - lr: 0.025000
2022-05-20 20:05:25,139 epoch 19 - iter 100/107 - loss 0.06062749 - samples/sec: 144.75 - lr: 0.025000
2022-05-20 20:05:26,599 ----------------------------------------------------------------------------------------------------
2022-05-20 20:05:26,599 EPOCH 19 done: loss 0.0615 - lr 0.025000
2022-05-20 20:05:34,149 Evaluating as a multi-label problem: False
2022-05-20 20:05:34,160 DEV : loss 0.1891259104013443 - f1-score (micro avg)  0.5135
2022-05-20 20:05:34,231 Epoch    19: reducing learning rate of group 0 to 1.2500e-02.
2022-05-20 20:05:34,231 BAD EPOCHS (no improvement): 4
2022-05-20 20:05:34,233 ----------------------------------------------------------------------------------------------------
2022-05-20 20:05:36,559 epoch 20 - iter 10/107 - loss 0.05284416 - samples/sec: 137.67 - lr: 0.012500
2022-05-20 20:05:38,989 epoch 20 - iter 20/107 - loss 0.05067376 - samples/sec: 131.73 - lr: 0.012500
2022-05-20 20:05:41,544 epoch 20 - iter 30/107 - loss 0.05209376 - samples/sec: 125.28 - lr: 0.012500
2022-05-20 20:05:44,295 epoch 20 - iter 40/107 - loss 0.05165573 - samples/sec: 116.36 - lr: 0.012500
2022-05-20 20:05:46,774 epoch 20 - iter 50/107 - loss 0.05706998 - samples/sec: 129.15 - lr: 0.012500
2022-05-20 20:05:49,163 epoch 20 - iter 60/107 - loss 0.05848934 - samples/sec: 133.98 - lr: 0.012500
2022-05-20 20:05:51,345 epoch 20 - iter 70/107 - loss 0.05777156 - samples/sec: 146.76 - lr: 0.012500
2022-05-20 20:05:53,566 epoch 20 - iter 80/107 - loss 0.05817245 - samples/sec: 144.11 - lr: 0.012500
2022-05-20 20:05:55,892 epoch 20 - iter 90/107 - loss 0.05749914 - samples/sec: 137.65 - lr: 0.012500
2022-05-20 20:05:57,811 epoch 20 - iter 100/107 - loss 0.05838921 - samples/sec: 166.87 - lr: 0.012500
2022-05-20 20:05:58,725 ----------------------------------------------------------------------------------------------------
2022-05-20 20:05:58,725 EPOCH 20 done: loss 0.0580 - lr 0.012500
2022-05-20 20:06:04,148 Evaluating as a multi-label problem: False
2022-05-20 20:06:04,159 DEV : loss 0.1936921626329422 - f1-score (micro avg)  0.5121
2022-05-20 20:06:04,230 BAD EPOCHS (no improvement): 1
2022-05-20 20:06:04,232 ----------------------------------------------------------------------------------------------------
2022-05-20 20:06:05,808 epoch 21 - iter 10/107 - loss 0.05438424 - samples/sec: 203.19 - lr: 0.012500
2022-05-20 20:06:07,392 epoch 21 - iter 20/107 - loss 0.05959087 - samples/sec: 202.14 - lr: 0.012500
2022-05-20 20:06:09,420 epoch 21 - iter 30/107 - loss 0.05813318 - samples/sec: 157.84 - lr: 0.012500
2022-05-20 20:06:11,808 epoch 21 - iter 40/107 - loss 0.06183078 - samples/sec: 134.06 - lr: 0.012500
2022-05-20 20:06:14,249 epoch 21 - iter 50/107 - loss 0.05948816 - samples/sec: 131.15 - lr: 0.012500
2022-05-20 20:06:16,644 epoch 21 - iter 60/107 - loss 0.05778930 - samples/sec: 133.66 - lr: 0.012500
2022-05-20 20:06:19,123 epoch 21 - iter 70/107 - loss 0.05725757 - samples/sec: 129.13 - lr: 0.012500
2022-05-20 20:06:21,561 epoch 21 - iter 80/107 - loss 0.05827386 - samples/sec: 131.32 - lr: 0.012500
2022-05-20 20:06:23,976 epoch 21 - iter 90/107 - loss 0.05743587 - samples/sec: 132.55 - lr: 0.012500
2022-05-20 20:06:26,452 epoch 21 - iter 100/107 - loss 0.05746240 - samples/sec: 129.32 - lr: 0.012500
2022-05-20 20:06:27,906 ----------------------------------------------------------------------------------------------------
2022-05-20 20:06:27,906 EPOCH 21 done: loss 0.0573 - lr 0.012500
2022-05-20 20:06:36,338 Evaluating as a multi-label problem: False
2022-05-20 20:06:36,349 DEV : loss 0.20474602282047272 - f1-score (micro avg)  0.4953
2022-05-20 20:06:36,421 BAD EPOCHS (no improvement): 2
2022-05-20 20:06:36,423 ----------------------------------------------------------------------------------------------------
2022-05-20 20:06:38,530 epoch 22 - iter 10/107 - loss 0.05584188 - samples/sec: 152.02 - lr: 0.012500
2022-05-20 20:06:40,684 epoch 22 - iter 20/107 - loss 0.05054391 - samples/sec: 148.62 - lr: 0.012500
2022-05-20 20:06:42,119 epoch 22 - iter 30/107 - loss 0.05309668 - samples/sec: 223.10 - lr: 0.012500
2022-05-20 20:06:43,586 epoch 22 - iter 40/107 - loss 0.05427715 - samples/sec: 218.26 - lr: 0.012500
2022-05-20 20:06:45,138 epoch 22 - iter 50/107 - loss 0.05466752 - samples/sec: 206.35 - lr: 0.012500
2022-05-20 20:06:46,695 epoch 22 - iter 60/107 - loss 0.05502003 - samples/sec: 205.61 - lr: 0.012500
2022-05-20 20:06:48,265 epoch 22 - iter 70/107 - loss 0.05579354 - samples/sec: 203.92 - lr: 0.012500
2022-05-20 20:06:49,797 epoch 22 - iter 80/107 - loss 0.05553351 - samples/sec: 209.07 - lr: 0.012500
2022-05-20 20:06:51,424 epoch 22 - iter 90/107 - loss 0.05521817 - samples/sec: 196.74 - lr: 0.012500
2022-05-20 20:06:53,810 epoch 22 - iter 100/107 - loss 0.05456207 - samples/sec: 134.15 - lr: 0.012500
2022-05-20 20:06:55,285 ----------------------------------------------------------------------------------------------------
2022-05-20 20:06:55,285 EPOCH 22 done: loss 0.0556 - lr 0.012500
2022-05-20 20:07:02,825 Evaluating as a multi-label problem: False
2022-05-20 20:07:02,835 DEV : loss 0.19363567233085632 - f1-score (micro avg)  0.5115
2022-05-20 20:07:02,908 BAD EPOCHS (no improvement): 3
2022-05-20 20:07:02,911 ----------------------------------------------------------------------------------------------------
2022-05-20 20:07:05,347 epoch 23 - iter 10/107 - loss 0.05760811 - samples/sec: 131.39 - lr: 0.012500
2022-05-20 20:07:07,773 epoch 23 - iter 20/107 - loss 0.05509739 - samples/sec: 131.97 - lr: 0.012500
2022-05-20 20:07:10,164 epoch 23 - iter 30/107 - loss 0.05659727 - samples/sec: 133.87 - lr: 0.012500
2022-05-20 20:07:12,683 epoch 23 - iter 40/107 - loss 0.05722015 - samples/sec: 127.13 - lr: 0.012500
2022-05-20 20:07:15,122 epoch 23 - iter 50/107 - loss 0.05489722 - samples/sec: 131.24 - lr: 0.012500
2022-05-20 20:07:17,357 epoch 23 - iter 60/107 - loss 0.05640035 - samples/sec: 143.23 - lr: 0.012500
2022-05-20 20:07:19,577 epoch 23 - iter 70/107 - loss 0.05577957 - samples/sec: 144.26 - lr: 0.012500
2022-05-20 20:07:21,754 epoch 23 - iter 80/107 - loss 0.05480030 - samples/sec: 147.04 - lr: 0.012500
2022-05-20 20:07:23,982 epoch 23 - iter 90/107 - loss 0.05421555 - samples/sec: 143.67 - lr: 0.012500
2022-05-20 20:07:26,642 epoch 23 - iter 100/107 - loss 0.05459130 - samples/sec: 120.35 - lr: 0.012500
2022-05-20 20:07:28,237 ----------------------------------------------------------------------------------------------------
2022-05-20 20:07:28,237 EPOCH 23 done: loss 0.0552 - lr 0.012500
2022-05-20 20:07:36,030 Evaluating as a multi-label problem: False
2022-05-20 20:07:36,041 DEV : loss 0.20084401965141296 - f1-score (micro avg)  0.5035
2022-05-20 20:07:36,112 Epoch    23: reducing learning rate of group 0 to 6.2500e-03.
2022-05-20 20:07:36,112 BAD EPOCHS (no improvement): 4
2022-05-20 20:07:36,113 ----------------------------------------------------------------------------------------------------
2022-05-20 20:07:38,624 epoch 24 - iter 10/107 - loss 0.05146667 - samples/sec: 127.50 - lr: 0.006250
2022-05-20 20:07:41,160 epoch 24 - iter 20/107 - loss 0.05455060 - samples/sec: 126.25 - lr: 0.006250
2022-05-20 20:07:43,720 epoch 24 - iter 30/107 - loss 0.05437096 - samples/sec: 125.05 - lr: 0.006250
2022-05-20 20:07:46,190 epoch 24 - iter 40/107 - loss 0.05861911 - samples/sec: 129.58 - lr: 0.006250
2022-05-20 20:07:48,645 epoch 24 - iter 50/107 - loss 0.05742078 - samples/sec: 130.40 - lr: 0.006250
2022-05-20 20:07:50,605 epoch 24 - iter 60/107 - loss 0.05871103 - samples/sec: 163.33 - lr: 0.006250
2022-05-20 20:07:52,322 epoch 24 - iter 70/107 - loss 0.05625361 - samples/sec: 186.48 - lr: 0.006250
2022-05-20 20:07:54,469 epoch 24 - iter 80/107 - loss 0.05544910 - samples/sec: 149.14 - lr: 0.006250
2022-05-20 20:07:56,673 epoch 24 - iter 90/107 - loss 0.05472100 - samples/sec: 145.27 - lr: 0.006250
2022-05-20 20:07:58,884 epoch 24 - iter 100/107 - loss 0.05416229 - samples/sec: 144.77 - lr: 0.006250
2022-05-20 20:08:00,376 ----------------------------------------------------------------------------------------------------
2022-05-20 20:08:00,376 EPOCH 24 done: loss 0.0538 - lr 0.006250
2022-05-20 20:08:08,022 Evaluating as a multi-label problem: False
2022-05-20 20:08:08,034 DEV : loss 0.20484785735607147 - f1-score (micro avg)  0.4992
2022-05-20 20:08:08,105 BAD EPOCHS (no improvement): 1
2022-05-20 20:08:08,107 ----------------------------------------------------------------------------------------------------
2022-05-20 20:08:10,444 epoch 25 - iter 10/107 - loss 0.05293114 - samples/sec: 137.04 - lr: 0.006250
2022-05-20 20:08:12,856 epoch 25 - iter 20/107 - loss 0.05274082 - samples/sec: 132.71 - lr: 0.006250
2022-05-20 20:08:15,329 epoch 25 - iter 30/107 - loss 0.04899172 - samples/sec: 129.44 - lr: 0.006250
2022-05-20 20:08:17,816 epoch 25 - iter 40/107 - loss 0.05022358 - samples/sec: 128.74 - lr: 0.006250
2022-05-20 20:08:20,354 epoch 25 - iter 50/107 - loss 0.05042185 - samples/sec: 126.15 - lr: 0.006250
2022-05-20 20:08:22,829 epoch 25 - iter 60/107 - loss 0.05087495 - samples/sec: 129.31 - lr: 0.006250
2022-05-20 20:08:25,194 epoch 25 - iter 70/107 - loss 0.05265494 - samples/sec: 135.36 - lr: 0.006250
2022-05-20 20:08:27,378 epoch 25 - iter 80/107 - loss 0.05259715 - samples/sec: 146.58 - lr: 0.006250
2022-05-20 20:08:29,661 epoch 25 - iter 90/107 - loss 0.05372382 - samples/sec: 140.21 - lr: 0.006250
2022-05-20 20:08:31,856 epoch 25 - iter 100/107 - loss 0.05388463 - samples/sec: 145.85 - lr: 0.006250
2022-05-20 20:08:33,405 ----------------------------------------------------------------------------------------------------
2022-05-20 20:08:33,405 EPOCH 25 done: loss 0.0546 - lr 0.006250
2022-05-20 20:08:41,073 Evaluating as a multi-label problem: False
2022-05-20 20:08:41,084 DEV : loss 0.19250653684139252 - f1-score (micro avg)  0.5184
2022-05-20 20:08:41,156 BAD EPOCHS (no improvement): 2
2022-05-20 20:08:41,158 ----------------------------------------------------------------------------------------------------
2022-05-20 20:08:43,558 epoch 26 - iter 10/107 - loss 0.04860684 - samples/sec: 133.40 - lr: 0.006250
2022-05-20 20:08:45,997 epoch 26 - iter 20/107 - loss 0.05051276 - samples/sec: 131.29 - lr: 0.006250
2022-05-20 20:08:48,494 epoch 26 - iter 30/107 - loss 0.05567075 - samples/sec: 128.18 - lr: 0.006250
2022-05-20 20:08:50,904 epoch 26 - iter 40/107 - loss 0.05727646 - samples/sec: 132.88 - lr: 0.006250
2022-05-20 20:08:53,284 epoch 26 - iter 50/107 - loss 0.05626677 - samples/sec: 134.52 - lr: 0.006250
2022-05-20 20:08:55,828 epoch 26 - iter 60/107 - loss 0.05501190 - samples/sec: 125.83 - lr: 0.006250
2022-05-20 20:08:58,203 epoch 26 - iter 70/107 - loss 0.05543130 - samples/sec: 134.77 - lr: 0.006250
2022-05-20 20:09:00,354 epoch 26 - iter 80/107 - loss 0.05454698 - samples/sec: 148.86 - lr: 0.006250
2022-05-20 20:09:02,471 epoch 26 - iter 90/107 - loss 0.05411151 - samples/sec: 151.23 - lr: 0.006250
2022-05-20 20:09:04,720 epoch 26 - iter 100/107 - loss 0.05361297 - samples/sec: 142.29 - lr: 0.006250
2022-05-20 20:09:06,192 ----------------------------------------------------------------------------------------------------
2022-05-20 20:09:06,192 EPOCH 26 done: loss 0.0545 - lr 0.006250
2022-05-20 20:09:14,171 Evaluating as a multi-label problem: False
2022-05-20 20:09:14,182 DEV : loss 0.1990092545747757 - f1-score (micro avg)  0.5085
2022-05-20 20:09:14,254 BAD EPOCHS (no improvement): 3
2022-05-20 20:09:14,257 ----------------------------------------------------------------------------------------------------
2022-05-20 20:09:17,081 epoch 27 - iter 10/107 - loss 0.06534832 - samples/sec: 113.38 - lr: 0.006250
2022-05-20 20:09:19,522 epoch 27 - iter 20/107 - loss 0.06263882 - samples/sec: 131.13 - lr: 0.006250
2022-05-20 20:09:21,926 epoch 27 - iter 30/107 - loss 0.05829005 - samples/sec: 133.20 - lr: 0.006250
2022-05-20 20:09:24,317 epoch 27 - iter 40/107 - loss 0.05835166 - samples/sec: 133.87 - lr: 0.006250
2022-05-20 20:09:26,780 epoch 27 - iter 50/107 - loss 0.05620219 - samples/sec: 129.97 - lr: 0.006250
2022-05-20 20:09:29,240 epoch 27 - iter 60/107 - loss 0.05567012 - samples/sec: 130.13 - lr: 0.006250
2022-05-20 20:09:32,296 epoch 27 - iter 70/107 - loss 0.05599656 - samples/sec: 104.74 - lr: 0.006250
2022-05-20 20:09:34,618 epoch 27 - iter 80/107 - loss 0.05470275 - samples/sec: 137.92 - lr: 0.006250
2022-05-20 20:09:36,760 epoch 27 - iter 90/107 - loss 0.05410081 - samples/sec: 149.40 - lr: 0.006250
2022-05-20 20:09:38,885 epoch 27 - iter 100/107 - loss 0.05412744 - samples/sec: 150.69 - lr: 0.006250
2022-05-20 20:09:40,668 ----------------------------------------------------------------------------------------------------
2022-05-20 20:09:40,668 EPOCH 27 done: loss 0.0535 - lr 0.006250
2022-05-20 20:09:48,470 Evaluating as a multi-label problem: False
2022-05-20 20:09:48,480 DEV : loss 0.1998746693134308 - f1-score (micro avg)  0.5089
2022-05-20 20:09:48,553 Epoch    27: reducing learning rate of group 0 to 3.1250e-03.
2022-05-20 20:09:48,553 BAD EPOCHS (no improvement): 4
2022-05-20 20:09:48,555 ----------------------------------------------------------------------------------------------------
2022-05-20 20:09:50,917 epoch 28 - iter 10/107 - loss 0.06345041 - samples/sec: 135.56 - lr: 0.003125
2022-05-20 20:09:53,483 epoch 28 - iter 20/107 - loss 0.06087692 - samples/sec: 124.76 - lr: 0.003125
2022-05-20 20:09:56,216 epoch 28 - iter 30/107 - loss 0.05584002 - samples/sec: 117.12 - lr: 0.003125
2022-05-20 20:09:58,699 epoch 28 - iter 40/107 - loss 0.05603220 - samples/sec: 128.93 - lr: 0.003125
2022-05-20 20:10:01,150 epoch 28 - iter 50/107 - loss 0.05361802 - samples/sec: 130.61 - lr: 0.003125
2022-05-20 20:10:03,569 epoch 28 - iter 60/107 - loss 0.05176540 - samples/sec: 132.35 - lr: 0.003125
2022-05-20 20:10:05,687 epoch 28 - iter 70/107 - loss 0.05484678 - samples/sec: 151.20 - lr: 0.003125
2022-05-20 20:10:07,845 epoch 28 - iter 80/107 - loss 0.05314455 - samples/sec: 148.32 - lr: 0.003125
2022-05-20 20:10:10,278 epoch 28 - iter 90/107 - loss 0.05254264 - samples/sec: 131.61 - lr: 0.003125
2022-05-20 20:10:12,446 epoch 28 - iter 100/107 - loss 0.05250008 - samples/sec: 147.63 - lr: 0.003125
2022-05-20 20:10:13,330 ----------------------------------------------------------------------------------------------------
2022-05-20 20:10:13,330 EPOCH 28 done: loss 0.0532 - lr 0.003125
2022-05-20 20:10:18,623 Evaluating as a multi-label problem: False
2022-05-20 20:10:18,634 DEV : loss 0.19881372153759003 - f1-score (micro avg)  0.5147
2022-05-20 20:10:18,706 BAD EPOCHS (no improvement): 1
2022-05-20 20:10:18,708 ----------------------------------------------------------------------------------------------------
2022-05-20 20:10:20,361 epoch 29 - iter 10/107 - loss 0.05665870 - samples/sec: 193.78 - lr: 0.003125
2022-05-20 20:10:21,949 epoch 29 - iter 20/107 - loss 0.05141467 - samples/sec: 201.66 - lr: 0.003125
2022-05-20 20:10:24,038 epoch 29 - iter 30/107 - loss 0.05176301 - samples/sec: 153.24 - lr: 0.003125
2022-05-20 20:10:26,468 epoch 29 - iter 40/107 - loss 0.04784468 - samples/sec: 131.77 - lr: 0.003125
2022-05-20 20:10:28,917 epoch 29 - iter 50/107 - loss 0.05170877 - samples/sec: 130.74 - lr: 0.003125
2022-05-20 20:10:31,383 epoch 29 - iter 60/107 - loss 0.05290285 - samples/sec: 129.79 - lr: 0.003125
2022-05-20 20:10:33,826 epoch 29 - iter 70/107 - loss 0.05278817 - samples/sec: 131.07 - lr: 0.003125
2022-05-20 20:10:36,313 epoch 29 - iter 80/107 - loss 0.05336849 - samples/sec: 128.70 - lr: 0.003125
2022-05-20 20:10:38,791 epoch 29 - iter 90/107 - loss 0.05268797 - samples/sec: 129.16 - lr: 0.003125
2022-05-20 20:10:41,217 epoch 29 - iter 100/107 - loss 0.05200478 - samples/sec: 132.00 - lr: 0.003125
2022-05-20 20:10:42,788 ----------------------------------------------------------------------------------------------------
2022-05-20 20:10:42,789 EPOCH 29 done: loss 0.0520 - lr 0.003125
2022-05-20 20:10:50,202 Evaluating as a multi-label problem: False
2022-05-20 20:10:50,213 DEV : loss 0.20084942877292633 - f1-score (micro avg)  0.5039
2022-05-20 20:10:50,287 BAD EPOCHS (no improvement): 2
2022-05-20 20:10:50,289 ----------------------------------------------------------------------------------------------------
2022-05-20 20:10:52,349 epoch 30 - iter 10/107 - loss 0.06242251 - samples/sec: 155.42 - lr: 0.003125
2022-05-20 20:10:54,555 epoch 30 - iter 20/107 - loss 0.05681349 - samples/sec: 145.16 - lr: 0.003125
2022-05-20 20:10:56,641 epoch 30 - iter 30/107 - loss 0.05166188 - samples/sec: 153.43 - lr: 0.003125
2022-05-20 20:10:59,121 epoch 30 - iter 40/107 - loss 0.05215448 - samples/sec: 129.08 - lr: 0.003125
2022-05-20 20:11:01,502 epoch 30 - iter 50/107 - loss 0.05196912 - samples/sec: 134.46 - lr: 0.003125
2022-05-20 20:11:03,926 epoch 30 - iter 60/107 - loss 0.05302886 - samples/sec: 132.06 - lr: 0.003125
2022-05-20 20:11:06,324 epoch 30 - iter 70/107 - loss 0.05324376 - samples/sec: 133.55 - lr: 0.003125
2022-05-20 20:11:08,713 epoch 30 - iter 80/107 - loss 0.05194227 - samples/sec: 133.97 - lr: 0.003125
2022-05-20 20:11:11,236 epoch 30 - iter 90/107 - loss 0.05138043 - samples/sec: 126.92 - lr: 0.003125
2022-05-20 20:11:13,703 epoch 30 - iter 100/107 - loss 0.05117511 - samples/sec: 129.76 - lr: 0.003125
2022-05-20 20:11:15,185 ----------------------------------------------------------------------------------------------------
2022-05-20 20:11:15,185 EPOCH 30 done: loss 0.0513 - lr 0.003125
2022-05-20 20:11:22,630 Evaluating as a multi-label problem: False
2022-05-20 20:11:22,641 DEV : loss 0.20011171698570251 - f1-score (micro avg)  0.5125
2022-05-20 20:11:22,714 BAD EPOCHS (no improvement): 3
2022-05-20 20:11:22,757 ----------------------------------------------------------------------------------------------------
2022-05-20 20:11:25,030 epoch 31 - iter 10/107 - loss 0.05698798 - samples/sec: 140.86 - lr: 0.003125
2022-05-20 20:11:27,246 epoch 31 - iter 20/107 - loss 0.05400009 - samples/sec: 144.44 - lr: 0.003125
2022-05-20 20:11:29,312 epoch 31 - iter 30/107 - loss 0.05235969 - samples/sec: 154.97 - lr: 0.003125
2022-05-20 20:11:31,664 epoch 31 - iter 40/107 - loss 0.05360827 - samples/sec: 136.12 - lr: 0.003125
2022-05-20 20:11:34,132 epoch 31 - iter 50/107 - loss 0.05262525 - samples/sec: 129.73 - lr: 0.003125
2022-05-20 20:11:36,707 epoch 31 - iter 60/107 - loss 0.05314511 - samples/sec: 124.31 - lr: 0.003125
2022-05-20 20:11:39,095 epoch 31 - iter 70/107 - loss 0.05271897 - samples/sec: 134.04 - lr: 0.003125
2022-05-20 20:11:41,546 epoch 31 - iter 80/107 - loss 0.05212133 - samples/sec: 130.65 - lr: 0.003125
2022-05-20 20:11:43,897 epoch 31 - iter 90/107 - loss 0.05262512 - samples/sec: 136.16 - lr: 0.003125
2022-05-20 20:11:46,393 epoch 31 - iter 100/107 - loss 0.05282556 - samples/sec: 128.23 - lr: 0.003125
2022-05-20 20:11:47,827 ----------------------------------------------------------------------------------------------------
2022-05-20 20:11:47,827 EPOCH 31 done: loss 0.0527 - lr 0.003125
2022-05-20 20:11:55,042 Evaluating as a multi-label problem: False
2022-05-20 20:11:55,053 DEV : loss 0.2010021209716797 - f1-score (micro avg)  0.5117
2022-05-20 20:11:55,124 Epoch    31: reducing learning rate of group 0 to 1.5625e-03.
2022-05-20 20:11:55,124 BAD EPOCHS (no improvement): 4
2022-05-20 20:11:55,126 ----------------------------------------------------------------------------------------------------
2022-05-20 20:11:57,358 epoch 32 - iter 10/107 - loss 0.05395488 - samples/sec: 143.44 - lr: 0.001563
2022-05-20 20:11:59,018 epoch 32 - iter 20/107 - loss 0.04710625 - samples/sec: 192.96 - lr: 0.001563
2022-05-20 20:12:01,438 epoch 32 - iter 30/107 - loss 0.04697225 - samples/sec: 132.30 - lr: 0.001563
2022-05-20 20:12:03,751 epoch 32 - iter 40/107 - loss 0.04868030 - samples/sec: 138.35 - lr: 0.001563
2022-05-20 20:12:05,251 epoch 32 - iter 50/107 - loss 0.04965694 - samples/sec: 213.49 - lr: 0.001563
2022-05-20 20:12:06,734 epoch 32 - iter 60/107 - loss 0.04847781 - samples/sec: 215.91 - lr: 0.001563
2022-05-20 20:12:08,227 epoch 32 - iter 70/107 - loss 0.04886085 - samples/sec: 214.53 - lr: 0.001563
2022-05-20 20:12:09,709 epoch 32 - iter 80/107 - loss 0.04931217 - samples/sec: 216.05 - lr: 0.001563
2022-05-20 20:12:11,292 epoch 32 - iter 90/107 - loss 0.05025859 - samples/sec: 202.27 - lr: 0.001563
2022-05-20 20:12:12,809 epoch 32 - iter 100/107 - loss 0.05009468 - samples/sec: 211.16 - lr: 0.001563
2022-05-20 20:12:13,751 ----------------------------------------------------------------------------------------------------
2022-05-20 20:12:13,752 EPOCH 32 done: loss 0.0498 - lr 0.001563
2022-05-20 20:12:21,957 Evaluating as a multi-label problem: False
2022-05-20 20:12:21,968 DEV : loss 0.19917145371437073 - f1-score (micro avg)  0.5155
2022-05-20 20:12:22,039 BAD EPOCHS (no improvement): 1
2022-05-20 20:12:22,042 ----------------------------------------------------------------------------------------------------
2022-05-20 20:12:24,494 epoch 33 - iter 10/107 - loss 0.05475449 - samples/sec: 130.54 - lr: 0.001563
2022-05-20 20:12:26,905 epoch 33 - iter 20/107 - loss 0.05163531 - samples/sec: 132.78 - lr: 0.001563
2022-05-20 20:12:29,340 epoch 33 - iter 30/107 - loss 0.05088425 - samples/sec: 131.49 - lr: 0.001563
2022-05-20 20:12:31,872 epoch 33 - iter 40/107 - loss 0.05030456 - samples/sec: 126.43 - lr: 0.001563
2022-05-20 20:12:34,259 epoch 33 - iter 50/107 - loss 0.05193480 - samples/sec: 134.14 - lr: 0.001563
2022-05-20 20:12:36,755 epoch 33 - iter 60/107 - loss 0.05086263 - samples/sec: 128.21 - lr: 0.001563
2022-05-20 20:12:39,203 epoch 33 - iter 70/107 - loss 0.05013308 - samples/sec: 130.79 - lr: 0.001563
2022-05-20 20:12:41,320 epoch 33 - iter 80/107 - loss 0.05014719 - samples/sec: 151.25 - lr: 0.001563
2022-05-20 20:12:43,694 epoch 33 - iter 90/107 - loss 0.04962640 - samples/sec: 134.81 - lr: 0.001563
2022-05-20 20:12:46,145 epoch 33 - iter 100/107 - loss 0.05028663 - samples/sec: 130.61 - lr: 0.001563
2022-05-20 20:12:47,579 ----------------------------------------------------------------------------------------------------
2022-05-20 20:12:47,579 EPOCH 33 done: loss 0.0504 - lr 0.001563
2022-05-20 20:12:55,293 Evaluating as a multi-label problem: False
2022-05-20 20:12:55,305 DEV : loss 0.19939441978931427 - f1-score (micro avg)  0.5112
2022-05-20 20:12:55,375 BAD EPOCHS (no improvement): 2
2022-05-20 20:12:55,377 ----------------------------------------------------------------------------------------------------
2022-05-20 20:12:57,694 epoch 34 - iter 10/107 - loss 0.04757078 - samples/sec: 138.18 - lr: 0.001563
2022-05-20 20:13:00,125 epoch 34 - iter 20/107 - loss 0.04618017 - samples/sec: 131.70 - lr: 0.001563
2022-05-20 20:13:02,575 epoch 34 - iter 30/107 - loss 0.04879346 - samples/sec: 130.70 - lr: 0.001563
2022-05-20 20:13:05,046 epoch 34 - iter 40/107 - loss 0.05300854 - samples/sec: 129.55 - lr: 0.001563
2022-05-20 20:13:07,494 epoch 34 - iter 50/107 - loss 0.05175362 - samples/sec: 130.75 - lr: 0.001563
2022-05-20 20:13:09,857 epoch 34 - iter 60/107 - loss 0.05173779 - samples/sec: 135.47 - lr: 0.001563
2022-05-20 20:13:12,285 epoch 34 - iter 70/107 - loss 0.05245489 - samples/sec: 131.89 - lr: 0.001563
2022-05-20 20:13:14,427 epoch 34 - iter 80/107 - loss 0.05159490 - samples/sec: 149.45 - lr: 0.001563
2022-05-20 20:13:16,630 epoch 34 - iter 90/107 - loss 0.05225609 - samples/sec: 145.27 - lr: 0.001563
2022-05-20 20:13:18,980 epoch 34 - iter 100/107 - loss 0.05079340 - samples/sec: 136.24 - lr: 0.001563
2022-05-20 20:13:20,271 ----------------------------------------------------------------------------------------------------
2022-05-20 20:13:20,272 EPOCH 34 done: loss 0.0507 - lr 0.001563
2022-05-20 20:13:27,869 Evaluating as a multi-label problem: False
2022-05-20 20:13:27,880 DEV : loss 0.20042350888252258 - f1-score (micro avg)  0.5148
2022-05-20 20:13:27,953 BAD EPOCHS (no improvement): 3
2022-05-20 20:13:27,955 ----------------------------------------------------------------------------------------------------
2022-05-20 20:13:30,780 epoch 35 - iter 10/107 - loss 0.05415712 - samples/sec: 113.35 - lr: 0.001563
2022-05-20 20:13:33,246 epoch 35 - iter 20/107 - loss 0.05081646 - samples/sec: 129.82 - lr: 0.001563
2022-05-20 20:13:35,741 epoch 35 - iter 30/107 - loss 0.04967973 - samples/sec: 128.34 - lr: 0.001563
2022-05-20 20:13:38,257 epoch 35 - iter 40/107 - loss 0.05008124 - samples/sec: 127.22 - lr: 0.001563
2022-05-20 20:13:40,678 epoch 35 - iter 50/107 - loss 0.05248563 - samples/sec: 132.20 - lr: 0.001563
2022-05-20 20:13:43,077 epoch 35 - iter 60/107 - loss 0.05045798 - samples/sec: 133.45 - lr: 0.001563
2022-05-20 20:13:45,502 epoch 35 - iter 70/107 - loss 0.05155734 - samples/sec: 132.01 - lr: 0.001563
2022-05-20 20:13:47,600 epoch 35 - iter 80/107 - loss 0.05074914 - samples/sec: 152.61 - lr: 0.001563
2022-05-20 20:13:50,008 epoch 35 - iter 90/107 - loss 0.04993011 - samples/sec: 132.96 - lr: 0.001563
2022-05-20 20:13:52,216 epoch 35 - iter 100/107 - loss 0.04987406 - samples/sec: 145.01 - lr: 0.001563
2022-05-20 20:13:53,595 ----------------------------------------------------------------------------------------------------
2022-05-20 20:13:53,595 EPOCH 35 done: loss 0.0497 - lr 0.001563
2022-05-20 20:14:01,190 Evaluating as a multi-label problem: False
2022-05-20 20:14:01,201 DEV : loss 0.20188088715076447 - f1-score (micro avg)  0.5155
2022-05-20 20:14:01,273 Epoch    35: reducing learning rate of group 0 to 7.8125e-04.
2022-05-20 20:14:01,273 BAD EPOCHS (no improvement): 4
2022-05-20 20:14:01,275 ----------------------------------------------------------------------------------------------------
2022-05-20 20:14:03,832 epoch 36 - iter 10/107 - loss 0.04935029 - samples/sec: 125.20 - lr: 0.000781
2022-05-20 20:14:06,258 epoch 36 - iter 20/107 - loss 0.04981080 - samples/sec: 131.98 - lr: 0.000781
2022-05-20 20:14:08,742 epoch 36 - iter 30/107 - loss 0.05228296 - samples/sec: 128.85 - lr: 0.000781
2022-05-20 20:14:11,246 epoch 36 - iter 40/107 - loss 0.05313854 - samples/sec: 127.87 - lr: 0.000781
2022-05-20 20:14:13,616 epoch 36 - iter 50/107 - loss 0.05326879 - samples/sec: 135.11 - lr: 0.000781
2022-05-20 20:14:16,020 epoch 36 - iter 60/107 - loss 0.05329921 - samples/sec: 133.14 - lr: 0.000781
2022-05-20 20:14:18,408 epoch 36 - iter 70/107 - loss 0.05204387 - samples/sec: 134.09 - lr: 0.000781
2022-05-20 20:14:20,521 epoch 36 - iter 80/107 - loss 0.05183471 - samples/sec: 151.51 - lr: 0.000781
2022-05-20 20:14:22,685 epoch 36 - iter 90/107 - loss 0.05273072 - samples/sec: 147.91 - lr: 0.000781
2022-05-20 20:14:24,851 epoch 36 - iter 100/107 - loss 0.05232044 - samples/sec: 147.80 - lr: 0.000781
2022-05-20 20:14:26,285 ----------------------------------------------------------------------------------------------------
2022-05-20 20:14:26,285 EPOCH 36 done: loss 0.0521 - lr 0.000781
2022-05-20 20:14:34,251 Evaluating as a multi-label problem: False
2022-05-20 20:14:34,262 DEV : loss 0.19961172342300415 - f1-score (micro avg)  0.5116
2022-05-20 20:14:34,336 BAD EPOCHS (no improvement): 1
2022-05-20 20:14:34,338 ----------------------------------------------------------------------------------------------------
2022-05-20 20:14:36,910 epoch 37 - iter 10/107 - loss 0.05028195 - samples/sec: 124.49 - lr: 0.000781
2022-05-20 20:14:39,349 epoch 37 - iter 20/107 - loss 0.04841312 - samples/sec: 131.25 - lr: 0.000781
2022-05-20 20:14:41,781 epoch 37 - iter 30/107 - loss 0.04953587 - samples/sec: 131.62 - lr: 0.000781
2022-05-20 20:14:44,241 epoch 37 - iter 40/107 - loss 0.05041720 - samples/sec: 130.16 - lr: 0.000781
2022-05-20 20:14:46,902 epoch 37 - iter 50/107 - loss 0.05060077 - samples/sec: 120.32 - lr: 0.000781
2022-05-20 20:14:49,406 epoch 37 - iter 60/107 - loss 0.05195360 - samples/sec: 127.86 - lr: 0.000781
2022-05-20 20:14:51,805 epoch 37 - iter 70/107 - loss 0.05123236 - samples/sec: 133.41 - lr: 0.000781
2022-05-20 20:14:53,899 epoch 37 - iter 80/107 - loss 0.05214903 - samples/sec: 152.95 - lr: 0.000781
2022-05-20 20:14:56,166 epoch 37 - iter 90/107 - loss 0.05233639 - samples/sec: 141.21 - lr: 0.000781
2022-05-20 20:14:58,374 epoch 37 - iter 100/107 - loss 0.05147987 - samples/sec: 144.99 - lr: 0.000781
2022-05-20 20:14:59,624 ----------------------------------------------------------------------------------------------------
2022-05-20 20:14:59,625 EPOCH 37 done: loss 0.0521 - lr 0.000781
2022-05-20 20:15:07,331 Evaluating as a multi-label problem: False
2022-05-20 20:15:07,342 DEV : loss 0.20028473436832428 - f1-score (micro avg)  0.512
2022-05-20 20:15:07,414 BAD EPOCHS (no improvement): 2
2022-05-20 20:15:07,416 ----------------------------------------------------------------------------------------------------
2022-05-20 20:15:09,976 epoch 38 - iter 10/107 - loss 0.04976708 - samples/sec: 125.07 - lr: 0.000781
2022-05-20 20:15:12,450 epoch 38 - iter 20/107 - loss 0.05048647 - samples/sec: 129.43 - lr: 0.000781
2022-05-20 20:15:15,631 epoch 38 - iter 30/107 - loss 0.05109337 - samples/sec: 100.61 - lr: 0.000781
2022-05-20 20:15:18,115 epoch 38 - iter 40/107 - loss 0.04936028 - samples/sec: 128.88 - lr: 0.000781
2022-05-20 20:15:20,564 epoch 38 - iter 50/107 - loss 0.05309002 - samples/sec: 130.74 - lr: 0.000781
2022-05-20 20:15:22,980 epoch 38 - iter 60/107 - loss 0.05294919 - samples/sec: 132.49 - lr: 0.000781
2022-05-20 20:15:25,223 epoch 38 - iter 70/107 - loss 0.05234505 - samples/sec: 142.70 - lr: 0.000781
2022-05-20 20:15:27,341 epoch 38 - iter 80/107 - loss 0.05268722 - samples/sec: 151.19 - lr: 0.000781
2022-05-20 20:15:29,529 epoch 38 - iter 90/107 - loss 0.05188657 - samples/sec: 146.32 - lr: 0.000781
2022-05-20 20:15:31,728 epoch 38 - iter 100/107 - loss 0.05098057 - samples/sec: 145.62 - lr: 0.000781
2022-05-20 20:15:33,352 ----------------------------------------------------------------------------------------------------
2022-05-20 20:15:33,352 EPOCH 38 done: loss 0.0509 - lr 0.000781
2022-05-20 20:15:41,317 Evaluating as a multi-label problem: False
2022-05-20 20:15:41,328 DEV : loss 0.20025372505187988 - f1-score (micro avg)  0.5113
2022-05-20 20:15:41,400 BAD EPOCHS (no improvement): 3
2022-05-20 20:15:41,402 ----------------------------------------------------------------------------------------------------
2022-05-20 20:15:43,800 epoch 39 - iter 10/107 - loss 0.04396977 - samples/sec: 133.48 - lr: 0.000781
2022-05-20 20:15:46,259 epoch 39 - iter 20/107 - loss 0.04615621 - samples/sec: 130.22 - lr: 0.000781
2022-05-20 20:15:48,722 epoch 39 - iter 30/107 - loss 0.04992216 - samples/sec: 129.97 - lr: 0.000781
2022-05-20 20:15:51,185 epoch 39 - iter 40/107 - loss 0.05205182 - samples/sec: 129.98 - lr: 0.000781
2022-05-20 20:15:53,660 epoch 39 - iter 50/107 - loss 0.05237164 - samples/sec: 129.31 - lr: 0.000781
2022-05-20 20:15:56,092 epoch 39 - iter 60/107 - loss 0.05235386 - samples/sec: 131.64 - lr: 0.000781
2022-05-20 20:15:58,343 epoch 39 - iter 70/107 - loss 0.05156617 - samples/sec: 142.19 - lr: 0.000781
2022-05-20 20:16:00,605 epoch 39 - iter 80/107 - loss 0.05138307 - samples/sec: 141.53 - lr: 0.000781
2022-05-20 20:16:02,312 epoch 39 - iter 90/107 - loss 0.05136397 - samples/sec: 187.60 - lr: 0.000781
2022-05-20 20:16:04,594 epoch 39 - iter 100/107 - loss 0.05094293 - samples/sec: 140.26 - lr: 0.000781
2022-05-20 20:16:05,972 ----------------------------------------------------------------------------------------------------
2022-05-20 20:16:05,972 EPOCH 39 done: loss 0.0510 - lr 0.000781
2022-05-20 20:16:11,480 Evaluating as a multi-label problem: False
2022-05-20 20:16:11,491 DEV : loss 0.20045463740825653 - f1-score (micro avg)  0.5105
2022-05-20 20:16:11,563 Epoch    39: reducing learning rate of group 0 to 3.9063e-04.
2022-05-20 20:16:11,563 BAD EPOCHS (no improvement): 4
2022-05-20 20:16:11,566 ----------------------------------------------------------------------------------------------------
2022-05-20 20:16:13,175 epoch 40 - iter 10/107 - loss 0.05516486 - samples/sec: 199.13 - lr: 0.000391
2022-05-20 20:16:14,809 epoch 40 - iter 20/107 - loss 0.05507697 - samples/sec: 195.90 - lr: 0.000391
2022-05-20 20:16:16,363 epoch 40 - iter 30/107 - loss 0.05314009 - samples/sec: 206.03 - lr: 0.000391
2022-05-20 20:16:18,614 epoch 40 - iter 40/107 - loss 0.05284265 - samples/sec: 142.23 - lr: 0.000391
2022-05-20 20:16:21,023 epoch 40 - iter 50/107 - loss 0.05282507 - samples/sec: 132.89 - lr: 0.000391
2022-05-20 20:16:23,471 epoch 40 - iter 60/107 - loss 0.05264888 - samples/sec: 130.81 - lr: 0.000391
2022-05-20 20:16:25,898 epoch 40 - iter 70/107 - loss 0.05116498 - samples/sec: 131.86 - lr: 0.000391
2022-05-20 20:16:28,384 epoch 40 - iter 80/107 - loss 0.05156156 - samples/sec: 128.80 - lr: 0.000391
2022-05-20 20:16:30,812 epoch 40 - iter 90/107 - loss 0.05119502 - samples/sec: 131.85 - lr: 0.000391
2022-05-20 20:16:33,262 epoch 40 - iter 100/107 - loss 0.05162595 - samples/sec: 130.63 - lr: 0.000391
2022-05-20 20:16:34,723 ----------------------------------------------------------------------------------------------------
2022-05-20 20:16:34,723 EPOCH 40 done: loss 0.0509 - lr 0.000391
2022-05-20 20:16:42,518 Evaluating as a multi-label problem: False
2022-05-20 20:16:42,529 DEV : loss 0.20075075328350067 - f1-score (micro avg)  0.5097
2022-05-20 20:16:42,604 BAD EPOCHS (no improvement): 1
2022-05-20 20:16:42,607 ----------------------------------------------------------------------------------------------------
2022-05-20 20:16:44,877 epoch 41 - iter 10/107 - loss 0.04080787 - samples/sec: 141.08 - lr: 0.000391
2022-05-20 20:16:47,330 epoch 41 - iter 20/107 - loss 0.03924193 - samples/sec: 130.49 - lr: 0.000391
2022-05-20 20:16:49,603 epoch 41 - iter 30/107 - loss 0.04782801 - samples/sec: 140.83 - lr: 0.000391
2022-05-20 20:16:52,234 epoch 41 - iter 40/107 - loss 0.04918201 - samples/sec: 121.70 - lr: 0.000391
2022-05-20 20:16:54,598 epoch 41 - iter 50/107 - loss 0.04908405 - samples/sec: 135.41 - lr: 0.000391
2022-05-20 20:16:57,074 epoch 41 - iter 60/107 - loss 0.04887021 - samples/sec: 129.29 - lr: 0.000391
2022-05-20 20:16:59,522 epoch 41 - iter 70/107 - loss 0.04826228 - samples/sec: 130.78 - lr: 0.000391
2022-05-20 20:17:01,898 epoch 41 - iter 80/107 - loss 0.04980835 - samples/sec: 134.71 - lr: 0.000391
2022-05-20 20:17:04,389 epoch 41 - iter 90/107 - loss 0.04942899 - samples/sec: 128.53 - lr: 0.000391
2022-05-20 20:17:06,863 epoch 41 - iter 100/107 - loss 0.04944664 - samples/sec: 129.38 - lr: 0.000391
2022-05-20 20:17:08,492 ----------------------------------------------------------------------------------------------------
2022-05-20 20:17:08,492 EPOCH 41 done: loss 0.0498 - lr 0.000391
2022-05-20 20:17:16,028 Evaluating as a multi-label problem: False
2022-05-20 20:17:16,039 DEV : loss 0.2001938372850418 - f1-score (micro avg)  0.5109
2022-05-20 20:17:16,114 BAD EPOCHS (no improvement): 2
2022-05-20 20:17:16,116 ----------------------------------------------------------------------------------------------------
2022-05-20 20:17:18,524 epoch 42 - iter 10/107 - loss 0.04697559 - samples/sec: 132.94 - lr: 0.000391
2022-05-20 20:17:20,737 epoch 42 - iter 20/107 - loss 0.05037634 - samples/sec: 144.70 - lr: 0.000391
2022-05-20 20:17:23,004 epoch 42 - iter 30/107 - loss 0.04824378 - samples/sec: 141.25 - lr: 0.000391
2022-05-20 20:17:25,640 epoch 42 - iter 40/107 - loss 0.04602693 - samples/sec: 121.43 - lr: 0.000391
2022-05-20 20:17:28,027 epoch 42 - iter 50/107 - loss 0.04797763 - samples/sec: 134.15 - lr: 0.000391
2022-05-20 20:17:30,468 epoch 42 - iter 60/107 - loss 0.04963189 - samples/sec: 131.11 - lr: 0.000391
2022-05-20 20:17:32,908 epoch 42 - iter 70/107 - loss 0.04960567 - samples/sec: 131.19 - lr: 0.000391
2022-05-20 20:17:35,254 epoch 42 - iter 80/107 - loss 0.04947289 - samples/sec: 136.46 - lr: 0.000391
2022-05-20 20:17:37,615 epoch 42 - iter 90/107 - loss 0.05031857 - samples/sec: 135.60 - lr: 0.000391
2022-05-20 20:17:40,140 epoch 42 - iter 100/107 - loss 0.05017369 - samples/sec: 126.79 - lr: 0.000391
2022-05-20 20:17:41,622 ----------------------------------------------------------------------------------------------------
2022-05-20 20:17:41,622 EPOCH 42 done: loss 0.0506 - lr 0.000391
2022-05-20 20:17:49,013 Evaluating as a multi-label problem: False
2022-05-20 20:17:49,024 DEV : loss 0.20010901987552643 - f1-score (micro avg)  0.5097
2022-05-20 20:17:49,095 BAD EPOCHS (no improvement): 3
2022-05-20 20:17:49,107 ----------------------------------------------------------------------------------------------------
2022-05-20 20:17:51,295 epoch 43 - iter 10/107 - loss 0.05009577 - samples/sec: 146.30 - lr: 0.000391
2022-05-20 20:17:53,714 epoch 43 - iter 20/107 - loss 0.04644673 - samples/sec: 132.35 - lr: 0.000391
2022-05-20 20:17:55,776 epoch 43 - iter 30/107 - loss 0.04748254 - samples/sec: 155.27 - lr: 0.000391
2022-05-20 20:17:58,381 epoch 43 - iter 40/107 - loss 0.05013964 - samples/sec: 122.89 - lr: 0.000391
2022-05-20 20:18:00,824 epoch 43 - iter 50/107 - loss 0.04973010 - samples/sec: 131.03 - lr: 0.000391
2022-05-20 20:18:03,367 epoch 43 - iter 60/107 - loss 0.05040084 - samples/sec: 125.89 - lr: 0.000391
2022-05-20 20:18:05,853 epoch 43 - iter 70/107 - loss 0.05079836 - samples/sec: 128.79 - lr: 0.000391
2022-05-20 20:18:08,313 epoch 43 - iter 80/107 - loss 0.05051165 - samples/sec: 130.17 - lr: 0.000391
2022-05-20 20:18:10,774 epoch 43 - iter 90/107 - loss 0.04986752 - samples/sec: 130.05 - lr: 0.000391
2022-05-20 20:18:13,141 epoch 43 - iter 100/107 - loss 0.05026781 - samples/sec: 135.27 - lr: 0.000391
2022-05-20 20:18:14,601 ----------------------------------------------------------------------------------------------------
2022-05-20 20:18:14,601 EPOCH 43 done: loss 0.0502 - lr 0.000391
2022-05-20 20:18:22,608 Evaluating as a multi-label problem: False
2022-05-20 20:18:22,618 DEV : loss 0.20076322555541992 - f1-score (micro avg)  0.5105
2022-05-20 20:18:22,689 Epoch    43: reducing learning rate of group 0 to 1.9531e-04.
2022-05-20 20:18:22,689 BAD EPOCHS (no improvement): 4
2022-05-20 20:18:22,692 ----------------------------------------------------------------------------------------------------
2022-05-20 20:18:24,816 epoch 44 - iter 10/107 - loss 0.04878348 - samples/sec: 150.74 - lr: 0.000195
2022-05-20 20:18:27,034 epoch 44 - iter 20/107 - loss 0.04732180 - samples/sec: 144.32 - lr: 0.000195
2022-05-20 20:18:29,284 epoch 44 - iter 30/107 - loss 0.04871773 - samples/sec: 142.26 - lr: 0.000195
2022-05-20 20:18:31,690 epoch 44 - iter 40/107 - loss 0.04918211 - samples/sec: 133.07 - lr: 0.000195
2022-05-20 20:18:34,057 epoch 44 - iter 50/107 - loss 0.05087128 - samples/sec: 135.25 - lr: 0.000195
2022-05-20 20:18:36,460 epoch 44 - iter 60/107 - loss 0.05308753 - samples/sec: 133.23 - lr: 0.000195
2022-05-20 20:18:38,912 epoch 44 - iter 70/107 - loss 0.05227743 - samples/sec: 130.52 - lr: 0.000195
2022-05-20 20:18:41,371 epoch 44 - iter 80/107 - loss 0.05243090 - samples/sec: 130.21 - lr: 0.000195
2022-05-20 20:18:43,793 epoch 44 - iter 90/107 - loss 0.05206253 - samples/sec: 132.21 - lr: 0.000195
2022-05-20 20:18:46,358 epoch 44 - iter 100/107 - loss 0.05064466 - samples/sec: 124.82 - lr: 0.000195
2022-05-20 20:18:47,875 ----------------------------------------------------------------------------------------------------
2022-05-20 20:18:47,875 EPOCH 44 done: loss 0.0518 - lr 0.000195
2022-05-20 20:18:55,265 Evaluating as a multi-label problem: False
2022-05-20 20:18:55,276 DEV : loss 0.2005266547203064 - f1-score (micro avg)  0.5089
2022-05-20 20:18:55,349 BAD EPOCHS (no improvement): 1
2022-05-20 20:18:55,351 ----------------------------------------------------------------------------------------------------
2022-05-20 20:18:57,519 epoch 45 - iter 10/107 - loss 0.04906585 - samples/sec: 147.70 - lr: 0.000195
2022-05-20 20:18:59,892 epoch 45 - iter 20/107 - loss 0.04982914 - samples/sec: 134.89 - lr: 0.000195
2022-05-20 20:19:02,182 epoch 45 - iter 30/107 - loss 0.04878257 - samples/sec: 139.80 - lr: 0.000195
2022-05-20 20:19:04,627 epoch 45 - iter 40/107 - loss 0.05171043 - samples/sec: 130.92 - lr: 0.000195
2022-05-20 20:19:07,131 epoch 45 - iter 50/107 - loss 0.05049464 - samples/sec: 127.86 - lr: 0.000195
2022-05-20 20:19:09,576 epoch 45 - iter 60/107 - loss 0.05052832 - samples/sec: 130.97 - lr: 0.000195
2022-05-20 20:19:12,000 epoch 45 - iter 70/107 - loss 0.04930033 - samples/sec: 132.08 - lr: 0.000195
2022-05-20 20:19:14,504 epoch 45 - iter 80/107 - loss 0.04910037 - samples/sec: 127.81 - lr: 0.000195
2022-05-20 20:19:16,843 epoch 45 - iter 90/107 - loss 0.04844380 - samples/sec: 136.92 - lr: 0.000195
2022-05-20 20:19:19,460 epoch 45 - iter 100/107 - loss 0.04801180 - samples/sec: 122.30 - lr: 0.000195
2022-05-20 20:19:20,886 ----------------------------------------------------------------------------------------------------
2022-05-20 20:19:20,886 EPOCH 45 done: loss 0.0486 - lr 0.000195
2022-05-20 20:19:28,100 Evaluating as a multi-label problem: False
2022-05-20 20:19:28,111 DEV : loss 0.2004798948764801 - f1-score (micro avg)  0.5101
2022-05-20 20:19:28,182 BAD EPOCHS (no improvement): 2
2022-05-20 20:19:28,185 ----------------------------------------------------------------------------------------------------
2022-05-20 20:19:30,375 epoch 46 - iter 10/107 - loss 0.06124802 - samples/sec: 146.16 - lr: 0.000195
2022-05-20 20:19:32,636 epoch 46 - iter 20/107 - loss 0.05140404 - samples/sec: 141.64 - lr: 0.000195
2022-05-20 20:19:34,834 epoch 46 - iter 30/107 - loss 0.05301887 - samples/sec: 145.63 - lr: 0.000195
2022-05-20 20:19:37,273 epoch 46 - iter 40/107 - loss 0.05043796 - samples/sec: 131.23 - lr: 0.000195
2022-05-20 20:19:39,725 epoch 46 - iter 50/107 - loss 0.05006740 - samples/sec: 130.58 - lr: 0.000195
2022-05-20 20:19:42,214 epoch 46 - iter 60/107 - loss 0.05092602 - samples/sec: 128.60 - lr: 0.000195
2022-05-20 20:19:44,812 epoch 46 - iter 70/107 - loss 0.05155050 - samples/sec: 123.20 - lr: 0.000195
2022-05-20 20:19:47,205 epoch 46 - iter 80/107 - loss 0.05117136 - samples/sec: 133.80 - lr: 0.000195
2022-05-20 20:19:49,641 epoch 46 - iter 90/107 - loss 0.05085870 - samples/sec: 131.42 - lr: 0.000195
2022-05-20 20:19:52,057 epoch 46 - iter 100/107 - loss 0.05006623 - samples/sec: 132.51 - lr: 0.000195
2022-05-20 20:19:53,511 ----------------------------------------------------------------------------------------------------
2022-05-20 20:19:53,511 EPOCH 46 done: loss 0.0498 - lr 0.000195
2022-05-20 20:20:01,186 Evaluating as a multi-label problem: False
2022-05-20 20:20:01,198 DEV : loss 0.20045699179172516 - f1-score (micro avg)  0.5101
2022-05-20 20:20:01,271 BAD EPOCHS (no improvement): 3
2022-05-20 20:20:01,274 ----------------------------------------------------------------------------------------------------
2022-05-20 20:20:03,531 epoch 47 - iter 10/107 - loss 0.05801054 - samples/sec: 141.87 - lr: 0.000195
2022-05-20 20:20:05,833 epoch 47 - iter 20/107 - loss 0.05385439 - samples/sec: 139.05 - lr: 0.000195
2022-05-20 20:20:07,531 epoch 47 - iter 30/107 - loss 0.05304813 - samples/sec: 188.63 - lr: 0.000195
2022-05-20 20:20:09,688 epoch 47 - iter 40/107 - loss 0.05583780 - samples/sec: 148.43 - lr: 0.000195
2022-05-20 20:20:12,178 epoch 47 - iter 50/107 - loss 0.05440259 - samples/sec: 128.57 - lr: 0.000195
2022-05-20 20:20:14,708 epoch 47 - iter 60/107 - loss 0.05220476 - samples/sec: 126.49 - lr: 0.000195
2022-05-20 20:20:17,147 epoch 47 - iter 70/107 - loss 0.05269443 - samples/sec: 131.27 - lr: 0.000195
2022-05-20 20:20:19,546 epoch 47 - iter 80/107 - loss 0.05137014 - samples/sec: 133.43 - lr: 0.000195
2022-05-20 20:20:21,915 epoch 47 - iter 90/107 - loss 0.05073151 - samples/sec: 135.15 - lr: 0.000195
2022-05-20 20:20:24,307 epoch 47 - iter 100/107 - loss 0.05112831 - samples/sec: 133.85 - lr: 0.000195
2022-05-20 20:20:25,840 ----------------------------------------------------------------------------------------------------
2022-05-20 20:20:25,840 EPOCH 47 done: loss 0.0509 - lr 0.000195
2022-05-20 20:20:33,467 Evaluating as a multi-label problem: False
2022-05-20 20:20:33,478 DEV : loss 0.20073221623897552 - f1-score (micro avg)  0.5097
2022-05-20 20:20:33,550 Epoch    47: reducing learning rate of group 0 to 9.7656e-05.
2022-05-20 20:20:33,550 BAD EPOCHS (no improvement): 4
2022-05-20 20:20:33,552 ----------------------------------------------------------------------------------------------------
2022-05-20 20:20:33,552 ----------------------------------------------------------------------------------------------------
2022-05-20 20:20:33,552 learning rate too small - quitting training!
2022-05-20 20:20:33,552 ----------------------------------------------------------------------------------------------------
2022-05-20 20:20:40,857 ----------------------------------------------------------------------------------------------------
2022-05-20 20:20:40,865 loading file resources/taggers/model_04_r12_run_2/best-model.pt
2022-05-20 20:20:50,360 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-05-20 20:21:10,067 Evaluating as a multi-label problem: False
2022-05-20 20:21:10,080 0.5329	0.3299	0.4076	0.279
2022-05-20 20:21:10,080 
Results:
- F-score (micro) 0.4076
- F-score (macro) 0.2569
- Accuracy 0.279

By class:
               precision    recall  f1-score   support

       person     0.5882    0.5594    0.5735       429
     location     0.4903    0.5067    0.4984       150
        group     0.4464    0.1515    0.2262       165
creative-work     0.6154    0.0563    0.1032       142
      product     0.1667    0.0157    0.0288       127
  corporation     0.2083    0.0758    0.1111        66

    micro avg     0.5329    0.3299    0.4076      1079
    macro avg     0.4192    0.2276    0.2569      1079
 weighted avg     0.4837    0.3299    0.3557      1079

2022-05-20 20:21:10,080 ----------------------------------------------------------------------------------------------------
