2022-05-20 23:05:03,913 ----------------------------------------------------------------------------------------------------
2022-05-20 23:05:03,914 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_3): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4213, out_features=4213, bias=True)
  (rnn): LSTM(4213, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-05-20 23:05:03,914 ----------------------------------------------------------------------------------------------------
2022-05-20 23:05:03,914 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-05-20 23:05:03,914 ----------------------------------------------------------------------------------------------------
2022-05-20 23:05:03,914 Parameters:
2022-05-20 23:05:03,914  - learning_rate: "0.100000"
2022-05-20 23:05:03,914  - mini_batch_size: "32"
2022-05-20 23:05:03,914  - patience: "3"
2022-05-20 23:05:03,914  - anneal_factor: "0.5"
2022-05-20 23:05:03,914  - max_epochs: "150"
2022-05-20 23:05:03,914  - shuffle: "True"
2022-05-20 23:05:03,914  - train_with_dev: "False"
2022-05-20 23:05:03,914  - batch_growth_annealing: "False"
2022-05-20 23:05:03,914 ----------------------------------------------------------------------------------------------------
2022-05-20 23:05:03,914 Model training base path: "resources/taggers/model_08_r13_run_2"
2022-05-20 23:05:03,914 ----------------------------------------------------------------------------------------------------
2022-05-20 23:05:03,915 Device: cuda:2
2022-05-20 23:05:03,915 ----------------------------------------------------------------------------------------------------
2022-05-20 23:05:03,915 Embeddings storage mode: cpu
2022-05-20 23:05:03,915 ----------------------------------------------------------------------------------------------------
2022-05-20 23:05:07,114 epoch 1 - iter 10/107 - loss 1.14176821 - samples/sec: 100.06 - lr: 0.100000
2022-05-20 23:05:10,345 epoch 1 - iter 20/107 - loss 0.71171845 - samples/sec: 99.05 - lr: 0.100000
2022-05-20 23:05:13,691 epoch 1 - iter 30/107 - loss 0.56640745 - samples/sec: 95.67 - lr: 0.100000
2022-05-20 23:05:16,523 epoch 1 - iter 40/107 - loss 0.48878571 - samples/sec: 113.05 - lr: 0.100000
2022-05-20 23:05:19,339 epoch 1 - iter 50/107 - loss 0.43379175 - samples/sec: 113.67 - lr: 0.100000
2022-05-20 23:05:22,005 epoch 1 - iter 60/107 - loss 0.41106035 - samples/sec: 120.13 - lr: 0.100000
2022-05-20 23:05:24,731 epoch 1 - iter 70/107 - loss 0.39181188 - samples/sec: 117.42 - lr: 0.100000
2022-05-20 23:05:26,915 epoch 1 - iter 80/107 - loss 0.38174857 - samples/sec: 146.58 - lr: 0.100000
2022-05-20 23:05:29,496 epoch 1 - iter 90/107 - loss 0.37440144 - samples/sec: 124.05 - lr: 0.100000
2022-05-20 23:05:32,108 epoch 1 - iter 100/107 - loss 0.36658740 - samples/sec: 122.56 - lr: 0.100000
2022-05-20 23:05:33,702 ----------------------------------------------------------------------------------------------------
2022-05-20 23:05:33,702 EPOCH 1 done: loss 0.3598 - lr 0.100000
2022-05-20 23:05:41,848 Evaluating as a multi-label problem: False
2022-05-20 23:05:41,860 DEV : loss 0.42459461092948914 - f1-score (micro avg)  0.1264
2022-05-20 23:05:41,955 BAD EPOCHS (no improvement): 0
2022-05-20 23:05:41,958 saving best model
2022-05-20 23:06:00,891 ----------------------------------------------------------------------------------------------------
2022-05-20 23:06:04,246 epoch 2 - iter 10/107 - loss 0.19634628 - samples/sec: 95.43 - lr: 0.100000
2022-05-20 23:06:07,284 epoch 2 - iter 20/107 - loss 0.20383706 - samples/sec: 105.38 - lr: 0.100000
2022-05-20 23:06:10,441 epoch 2 - iter 30/107 - loss 0.20013404 - samples/sec: 101.43 - lr: 0.100000
2022-05-20 23:06:13,401 epoch 2 - iter 40/107 - loss 0.20567954 - samples/sec: 108.15 - lr: 0.100000
2022-05-20 23:06:16,519 epoch 2 - iter 50/107 - loss 0.20071066 - samples/sec: 102.68 - lr: 0.100000
2022-05-20 23:06:19,563 epoch 2 - iter 60/107 - loss 0.20465869 - samples/sec: 105.15 - lr: 0.100000
2022-05-20 23:06:22,604 epoch 2 - iter 70/107 - loss 0.20440683 - samples/sec: 105.26 - lr: 0.100000
2022-05-20 23:06:25,463 epoch 2 - iter 80/107 - loss 0.20187508 - samples/sec: 111.99 - lr: 0.100000
2022-05-20 23:06:28,514 epoch 2 - iter 90/107 - loss 0.19723574 - samples/sec: 104.89 - lr: 0.100000
2022-05-20 23:06:31,495 epoch 2 - iter 100/107 - loss 0.19850466 - samples/sec: 107.39 - lr: 0.100000
2022-05-20 23:06:33,239 ----------------------------------------------------------------------------------------------------
2022-05-20 23:06:33,240 EPOCH 2 done: loss 0.1957 - lr 0.100000
2022-05-20 23:06:40,850 Evaluating as a multi-label problem: False
2022-05-20 23:06:40,861 DEV : loss 0.307697594165802 - f1-score (micro avg)  0.4284
2022-05-20 23:06:40,954 BAD EPOCHS (no improvement): 0
2022-05-20 23:06:40,956 saving best model
2022-05-20 23:07:00,182 ----------------------------------------------------------------------------------------------------
2022-05-20 23:07:03,409 epoch 3 - iter 10/107 - loss 0.17586628 - samples/sec: 99.23 - lr: 0.100000
2022-05-20 23:07:06,231 epoch 3 - iter 20/107 - loss 0.19372748 - samples/sec: 113.46 - lr: 0.100000
2022-05-20 23:07:09,017 epoch 3 - iter 30/107 - loss 0.18485208 - samples/sec: 114.90 - lr: 0.100000
2022-05-20 23:07:12,143 epoch 3 - iter 40/107 - loss 0.17814230 - samples/sec: 102.39 - lr: 0.100000
2022-05-20 23:07:14,830 epoch 3 - iter 50/107 - loss 0.17410206 - samples/sec: 119.16 - lr: 0.100000
2022-05-20 23:07:17,770 epoch 3 - iter 60/107 - loss 0.17404827 - samples/sec: 108.88 - lr: 0.100000
2022-05-20 23:07:20,341 epoch 3 - iter 70/107 - loss 0.17009258 - samples/sec: 124.52 - lr: 0.100000
2022-05-20 23:07:23,018 epoch 3 - iter 80/107 - loss 0.16809384 - samples/sec: 119.57 - lr: 0.100000
2022-05-20 23:07:25,798 epoch 3 - iter 90/107 - loss 0.16457683 - samples/sec: 115.17 - lr: 0.100000
2022-05-20 23:07:28,886 epoch 3 - iter 100/107 - loss 0.16239760 - samples/sec: 103.65 - lr: 0.100000
2022-05-20 23:07:30,868 ----------------------------------------------------------------------------------------------------
2022-05-20 23:07:30,869 EPOCH 3 done: loss 0.1604 - lr 0.100000
2022-05-20 23:07:39,200 Evaluating as a multi-label problem: False
2022-05-20 23:07:39,212 DEV : loss 0.2895877957344055 - f1-score (micro avg)  0.3713
2022-05-20 23:07:39,306 BAD EPOCHS (no improvement): 1
2022-05-20 23:07:39,352 ----------------------------------------------------------------------------------------------------
2022-05-20 23:07:42,286 epoch 4 - iter 10/107 - loss 0.16531284 - samples/sec: 109.12 - lr: 0.100000
2022-05-20 23:07:45,228 epoch 4 - iter 20/107 - loss 0.15842750 - samples/sec: 108.83 - lr: 0.100000
2022-05-20 23:07:48,195 epoch 4 - iter 30/107 - loss 0.15643790 - samples/sec: 107.90 - lr: 0.100000
2022-05-20 23:07:51,174 epoch 4 - iter 40/107 - loss 0.15131190 - samples/sec: 107.48 - lr: 0.100000
2022-05-20 23:07:54,203 epoch 4 - iter 50/107 - loss 0.14953356 - samples/sec: 105.69 - lr: 0.100000
2022-05-20 23:07:57,090 epoch 4 - iter 60/107 - loss 0.15040332 - samples/sec: 110.86 - lr: 0.100000
2022-05-20 23:08:00,313 epoch 4 - iter 70/107 - loss 0.14822643 - samples/sec: 99.34 - lr: 0.100000
2022-05-20 23:08:03,353 epoch 4 - iter 80/107 - loss 0.14715816 - samples/sec: 105.31 - lr: 0.100000
2022-05-20 23:08:05,950 epoch 4 - iter 90/107 - loss 0.14584847 - samples/sec: 123.25 - lr: 0.100000
2022-05-20 23:08:08,584 epoch 4 - iter 100/107 - loss 0.14439039 - samples/sec: 121.53 - lr: 0.100000
2022-05-20 23:08:10,184 ----------------------------------------------------------------------------------------------------
2022-05-20 23:08:10,185 EPOCH 4 done: loss 0.1443 - lr 0.100000
2022-05-20 23:08:18,142 Evaluating as a multi-label problem: False
2022-05-20 23:08:18,154 DEV : loss 0.2591592073440552 - f1-score (micro avg)  0.4712
2022-05-20 23:08:18,248 BAD EPOCHS (no improvement): 0
2022-05-20 23:08:18,251 saving best model
2022-05-20 23:08:37,721 ----------------------------------------------------------------------------------------------------
2022-05-20 23:08:40,369 epoch 5 - iter 10/107 - loss 0.14755842 - samples/sec: 120.95 - lr: 0.100000
2022-05-20 23:08:43,040 epoch 5 - iter 20/107 - loss 0.14177392 - samples/sec: 119.86 - lr: 0.100000
2022-05-20 23:08:45,504 epoch 5 - iter 30/107 - loss 0.13472577 - samples/sec: 129.90 - lr: 0.100000
2022-05-20 23:08:48,168 epoch 5 - iter 40/107 - loss 0.13620484 - samples/sec: 120.18 - lr: 0.100000
2022-05-20 23:08:50,996 epoch 5 - iter 50/107 - loss 0.14040149 - samples/sec: 113.22 - lr: 0.100000
2022-05-20 23:08:54,166 epoch 5 - iter 60/107 - loss 0.13815677 - samples/sec: 100.97 - lr: 0.100000
2022-05-20 23:08:57,236 epoch 5 - iter 70/107 - loss 0.13576002 - samples/sec: 104.28 - lr: 0.100000
2022-05-20 23:09:00,216 epoch 5 - iter 80/107 - loss 0.13231078 - samples/sec: 107.42 - lr: 0.100000
2022-05-20 23:09:03,101 epoch 5 - iter 90/107 - loss 0.13070091 - samples/sec: 110.96 - lr: 0.100000
2022-05-20 23:09:06,282 epoch 5 - iter 100/107 - loss 0.12971286 - samples/sec: 100.62 - lr: 0.100000
2022-05-20 23:09:08,236 ----------------------------------------------------------------------------------------------------
2022-05-20 23:09:08,236 EPOCH 5 done: loss 0.1298 - lr 0.100000
2022-05-20 23:09:16,467 Evaluating as a multi-label problem: False
2022-05-20 23:09:16,479 DEV : loss 0.23053018748760223 - f1-score (micro avg)  0.4665
2022-05-20 23:09:16,570 BAD EPOCHS (no improvement): 1
2022-05-20 23:09:16,585 ----------------------------------------------------------------------------------------------------
2022-05-20 23:09:19,523 epoch 6 - iter 10/107 - loss 0.10182066 - samples/sec: 108.98 - lr: 0.100000
2022-05-20 23:09:22,560 epoch 6 - iter 20/107 - loss 0.10039404 - samples/sec: 105.42 - lr: 0.100000
2022-05-20 23:09:25,620 epoch 6 - iter 30/107 - loss 0.11152942 - samples/sec: 104.60 - lr: 0.100000
2022-05-20 23:09:28,329 epoch 6 - iter 40/107 - loss 0.11783376 - samples/sec: 118.21 - lr: 0.100000
2022-05-20 23:09:31,311 epoch 6 - iter 50/107 - loss 0.12247132 - samples/sec: 107.34 - lr: 0.100000
2022-05-20 23:09:33,922 epoch 6 - iter 60/107 - loss 0.12378859 - samples/sec: 122.61 - lr: 0.100000
2022-05-20 23:09:36,512 epoch 6 - iter 70/107 - loss 0.12262400 - samples/sec: 123.59 - lr: 0.100000
2022-05-20 23:09:39,222 epoch 6 - iter 80/107 - loss 0.12215440 - samples/sec: 118.16 - lr: 0.100000
2022-05-20 23:09:42,295 epoch 6 - iter 90/107 - loss 0.12214744 - samples/sec: 104.17 - lr: 0.100000
2022-05-20 23:09:45,123 epoch 6 - iter 100/107 - loss 0.12045653 - samples/sec: 113.17 - lr: 0.100000
2022-05-20 23:09:47,131 ----------------------------------------------------------------------------------------------------
2022-05-20 23:09:47,131 EPOCH 6 done: loss 0.1214 - lr 0.100000
2022-05-20 23:09:55,182 Evaluating as a multi-label problem: False
2022-05-20 23:09:55,194 DEV : loss 0.20218510925769806 - f1-score (micro avg)  0.5219
2022-05-20 23:09:55,289 BAD EPOCHS (no improvement): 0
2022-05-20 23:09:55,291 saving best model
2022-05-20 23:10:14,391 ----------------------------------------------------------------------------------------------------
2022-05-20 23:10:17,544 epoch 7 - iter 10/107 - loss 0.12451762 - samples/sec: 101.54 - lr: 0.100000
2022-05-20 23:10:20,493 epoch 7 - iter 20/107 - loss 0.11665225 - samples/sec: 108.58 - lr: 0.100000
2022-05-20 23:10:23,456 epoch 7 - iter 30/107 - loss 0.12213286 - samples/sec: 108.02 - lr: 0.100000
2022-05-20 23:10:26,501 epoch 7 - iter 40/107 - loss 0.12313430 - samples/sec: 105.13 - lr: 0.100000
2022-05-20 23:10:29,485 epoch 7 - iter 50/107 - loss 0.11974117 - samples/sec: 107.27 - lr: 0.100000
2022-05-20 23:10:32,440 epoch 7 - iter 60/107 - loss 0.11651809 - samples/sec: 108.36 - lr: 0.100000
2022-05-20 23:10:35,608 epoch 7 - iter 70/107 - loss 0.11464542 - samples/sec: 101.05 - lr: 0.100000
2022-05-20 23:10:38,828 epoch 7 - iter 80/107 - loss 0.11186270 - samples/sec: 99.41 - lr: 0.100000
2022-05-20 23:10:41,904 epoch 7 - iter 90/107 - loss 0.11238399 - samples/sec: 104.06 - lr: 0.100000
2022-05-20 23:10:44,949 epoch 7 - iter 100/107 - loss 0.11231761 - samples/sec: 105.13 - lr: 0.100000
2022-05-20 23:10:46,943 ----------------------------------------------------------------------------------------------------
2022-05-20 23:10:46,943 EPOCH 7 done: loss 0.1125 - lr 0.100000
2022-05-20 23:10:54,537 Evaluating as a multi-label problem: False
2022-05-20 23:10:54,549 DEV : loss 0.1910388469696045 - f1-score (micro avg)  0.5448
2022-05-20 23:10:54,643 BAD EPOCHS (no improvement): 0
2022-05-20 23:10:54,650 saving best model
2022-05-20 23:11:13,867 ----------------------------------------------------------------------------------------------------
2022-05-20 23:11:16,947 epoch 8 - iter 10/107 - loss 0.09060667 - samples/sec: 103.96 - lr: 0.100000
2022-05-20 23:11:19,962 epoch 8 - iter 20/107 - loss 0.10009420 - samples/sec: 106.19 - lr: 0.100000
2022-05-20 23:11:23,245 epoch 8 - iter 30/107 - loss 0.09875150 - samples/sec: 97.54 - lr: 0.100000
2022-05-20 23:11:26,312 epoch 8 - iter 40/107 - loss 0.10237762 - samples/sec: 104.37 - lr: 0.100000
2022-05-20 23:11:29,304 epoch 8 - iter 50/107 - loss 0.10546039 - samples/sec: 107.02 - lr: 0.100000
2022-05-20 23:11:32,180 epoch 8 - iter 60/107 - loss 0.10497009 - samples/sec: 111.29 - lr: 0.100000
2022-05-20 23:11:34,947 epoch 8 - iter 70/107 - loss 0.10517559 - samples/sec: 115.70 - lr: 0.100000
2022-05-20 23:11:37,773 epoch 8 - iter 80/107 - loss 0.10357369 - samples/sec: 113.31 - lr: 0.100000
2022-05-20 23:11:40,264 epoch 8 - iter 90/107 - loss 0.10361872 - samples/sec: 128.54 - lr: 0.100000
2022-05-20 23:11:43,224 epoch 8 - iter 100/107 - loss 0.10516087 - samples/sec: 108.15 - lr: 0.100000
2022-05-20 23:11:45,252 ----------------------------------------------------------------------------------------------------
2022-05-20 23:11:45,252 EPOCH 8 done: loss 0.1058 - lr 0.100000
2022-05-20 23:11:53,757 Evaluating as a multi-label problem: False
2022-05-20 23:11:53,771 DEV : loss 0.18906539678573608 - f1-score (micro avg)  0.5429
2022-05-20 23:11:53,866 BAD EPOCHS (no improvement): 1
2022-05-20 23:11:53,869 ----------------------------------------------------------------------------------------------------
2022-05-20 23:11:57,101 epoch 9 - iter 10/107 - loss 0.08951014 - samples/sec: 99.05 - lr: 0.100000
2022-05-20 23:12:00,085 epoch 9 - iter 20/107 - loss 0.09742537 - samples/sec: 107.30 - lr: 0.100000
2022-05-20 23:12:03,048 epoch 9 - iter 30/107 - loss 0.10803463 - samples/sec: 108.06 - lr: 0.100000
2022-05-20 23:12:05,991 epoch 9 - iter 40/107 - loss 0.10104981 - samples/sec: 108.80 - lr: 0.100000
2022-05-20 23:12:09,009 epoch 9 - iter 50/107 - loss 0.09922433 - samples/sec: 106.08 - lr: 0.100000
2022-05-20 23:12:11,879 epoch 9 - iter 60/107 - loss 0.09953936 - samples/sec: 111.54 - lr: 0.100000
2022-05-20 23:12:15,081 epoch 9 - iter 70/107 - loss 0.10067642 - samples/sec: 99.97 - lr: 0.100000
2022-05-20 23:12:17,927 epoch 9 - iter 80/107 - loss 0.10028570 - samples/sec: 112.49 - lr: 0.100000
2022-05-20 23:12:20,858 epoch 9 - iter 90/107 - loss 0.10206875 - samples/sec: 109.22 - lr: 0.100000
2022-05-20 23:12:23,615 epoch 9 - iter 100/107 - loss 0.10039805 - samples/sec: 116.09 - lr: 0.100000
2022-05-20 23:12:25,258 ----------------------------------------------------------------------------------------------------
2022-05-20 23:12:25,258 EPOCH 9 done: loss 0.0997 - lr 0.100000
2022-05-20 23:12:33,106 Evaluating as a multi-label problem: False
2022-05-20 23:12:33,120 DEV : loss 0.18883633613586426 - f1-score (micro avg)  0.5351
2022-05-20 23:12:33,214 BAD EPOCHS (no improvement): 2
2022-05-20 23:12:33,218 ----------------------------------------------------------------------------------------------------
2022-05-20 23:12:36,129 epoch 10 - iter 10/107 - loss 0.09494122 - samples/sec: 109.98 - lr: 0.100000
2022-05-20 23:12:39,158 epoch 10 - iter 20/107 - loss 0.09380924 - samples/sec: 105.66 - lr: 0.100000
2022-05-20 23:12:42,287 epoch 10 - iter 30/107 - loss 0.09976893 - samples/sec: 102.31 - lr: 0.100000
2022-05-20 23:12:45,052 epoch 10 - iter 40/107 - loss 0.09983491 - samples/sec: 115.81 - lr: 0.100000
2022-05-20 23:12:48,142 epoch 10 - iter 50/107 - loss 0.09707693 - samples/sec: 103.59 - lr: 0.100000
2022-05-20 23:12:51,146 epoch 10 - iter 60/107 - loss 0.09852685 - samples/sec: 106.59 - lr: 0.100000
2022-05-20 23:12:54,092 epoch 10 - iter 70/107 - loss 0.09699728 - samples/sec: 108.66 - lr: 0.100000
2022-05-20 23:12:57,017 epoch 10 - iter 80/107 - loss 0.09579073 - samples/sec: 109.44 - lr: 0.100000
2022-05-20 23:12:59,745 epoch 10 - iter 90/107 - loss 0.09559346 - samples/sec: 117.37 - lr: 0.100000
2022-05-20 23:13:02,881 epoch 10 - iter 100/107 - loss 0.09655579 - samples/sec: 102.05 - lr: 0.100000
2022-05-20 23:13:04,736 ----------------------------------------------------------------------------------------------------
2022-05-20 23:13:04,736 EPOCH 10 done: loss 0.0963 - lr 0.100000
2022-05-20 23:13:12,642 Evaluating as a multi-label problem: False
2022-05-20 23:13:12,654 DEV : loss 0.17479056119918823 - f1-score (micro avg)  0.5219
2022-05-20 23:13:12,747 BAD EPOCHS (no improvement): 3
2022-05-20 23:13:12,749 ----------------------------------------------------------------------------------------------------
2022-05-20 23:13:15,456 epoch 11 - iter 10/107 - loss 0.10012012 - samples/sec: 118.28 - lr: 0.100000
2022-05-20 23:13:18,313 epoch 11 - iter 20/107 - loss 0.09251205 - samples/sec: 112.05 - lr: 0.100000
2022-05-20 23:13:21,479 epoch 11 - iter 30/107 - loss 0.09203753 - samples/sec: 101.13 - lr: 0.100000
2022-05-20 23:13:24,493 epoch 11 - iter 40/107 - loss 0.09417673 - samples/sec: 106.21 - lr: 0.100000
2022-05-20 23:13:27,674 epoch 11 - iter 50/107 - loss 0.09096906 - samples/sec: 100.62 - lr: 0.100000
2022-05-20 23:13:30,729 epoch 11 - iter 60/107 - loss 0.09074702 - samples/sec: 104.81 - lr: 0.100000
2022-05-20 23:13:33,654 epoch 11 - iter 70/107 - loss 0.09031927 - samples/sec: 109.42 - lr: 0.100000
2022-05-20 23:13:36,774 epoch 11 - iter 80/107 - loss 0.08852487 - samples/sec: 102.63 - lr: 0.100000
2022-05-20 23:13:39,852 epoch 11 - iter 90/107 - loss 0.08946631 - samples/sec: 104.02 - lr: 0.100000
2022-05-20 23:13:42,836 epoch 11 - iter 100/107 - loss 0.09093159 - samples/sec: 107.27 - lr: 0.100000
2022-05-20 23:13:44,703 ----------------------------------------------------------------------------------------------------
2022-05-20 23:13:44,703 EPOCH 11 done: loss 0.0901 - lr 0.100000
2022-05-20 23:13:52,794 Evaluating as a multi-label problem: False
2022-05-20 23:13:52,806 DEV : loss 0.22312739491462708 - f1-score (micro avg)  0.4722
2022-05-20 23:13:52,897 Epoch    11: reducing learning rate of group 0 to 5.0000e-02.
2022-05-20 23:13:52,898 BAD EPOCHS (no improvement): 4
2022-05-20 23:13:52,900 ----------------------------------------------------------------------------------------------------
2022-05-20 23:13:55,733 epoch 12 - iter 10/107 - loss 0.09214886 - samples/sec: 113.01 - lr: 0.050000
2022-05-20 23:13:58,632 epoch 12 - iter 20/107 - loss 0.08228490 - samples/sec: 110.43 - lr: 0.050000
2022-05-20 23:14:01,354 epoch 12 - iter 30/107 - loss 0.08420098 - samples/sec: 117.61 - lr: 0.050000
2022-05-20 23:14:03,863 epoch 12 - iter 40/107 - loss 0.08427475 - samples/sec: 127.58 - lr: 0.050000
2022-05-20 23:14:06,444 epoch 12 - iter 50/107 - loss 0.08172939 - samples/sec: 124.05 - lr: 0.050000
2022-05-20 23:14:08,845 epoch 12 - iter 60/107 - loss 0.08162073 - samples/sec: 133.33 - lr: 0.050000
2022-05-20 23:14:11,762 epoch 12 - iter 70/107 - loss 0.08025482 - samples/sec: 109.74 - lr: 0.050000
2022-05-20 23:14:14,889 epoch 12 - iter 80/107 - loss 0.08043497 - samples/sec: 102.37 - lr: 0.050000
2022-05-20 23:14:17,834 epoch 12 - iter 90/107 - loss 0.08158609 - samples/sec: 108.70 - lr: 0.050000
2022-05-20 23:14:20,826 epoch 12 - iter 100/107 - loss 0.08018917 - samples/sec: 107.00 - lr: 0.050000
2022-05-20 23:14:22,485 ----------------------------------------------------------------------------------------------------
2022-05-20 23:14:22,485 EPOCH 12 done: loss 0.0791 - lr 0.050000
2022-05-20 23:14:31,506 Evaluating as a multi-label problem: False
2022-05-20 23:14:31,519 DEV : loss 0.19380180537700653 - f1-score (micro avg)  0.5024
2022-05-20 23:14:31,616 BAD EPOCHS (no improvement): 1
2022-05-20 23:14:31,742 ----------------------------------------------------------------------------------------------------
2022-05-20 23:14:34,838 epoch 13 - iter 10/107 - loss 0.06998726 - samples/sec: 103.41 - lr: 0.050000
2022-05-20 23:14:37,911 epoch 13 - iter 20/107 - loss 0.07505515 - samples/sec: 104.18 - lr: 0.050000
2022-05-20 23:14:41,152 epoch 13 - iter 30/107 - loss 0.07486597 - samples/sec: 98.78 - lr: 0.050000
2022-05-20 23:14:44,316 epoch 13 - iter 40/107 - loss 0.07839664 - samples/sec: 101.15 - lr: 0.050000
2022-05-20 23:14:47,020 epoch 13 - iter 50/107 - loss 0.08036136 - samples/sec: 118.39 - lr: 0.050000
2022-05-20 23:14:49,934 epoch 13 - iter 60/107 - loss 0.08129964 - samples/sec: 109.86 - lr: 0.050000
2022-05-20 23:14:52,703 epoch 13 - iter 70/107 - loss 0.07923197 - samples/sec: 115.63 - lr: 0.050000
2022-05-20 23:14:55,190 epoch 13 - iter 80/107 - loss 0.08032090 - samples/sec: 128.76 - lr: 0.050000
2022-05-20 23:14:57,757 epoch 13 - iter 90/107 - loss 0.07913337 - samples/sec: 124.72 - lr: 0.050000
2022-05-20 23:15:03,055 epoch 13 - iter 100/107 - loss 0.07858185 - samples/sec: 60.41 - lr: 0.050000
2022-05-20 23:15:05,016 ----------------------------------------------------------------------------------------------------
2022-05-20 23:15:05,016 EPOCH 13 done: loss 0.0777 - lr 0.050000
2022-05-20 23:15:13,065 Evaluating as a multi-label problem: False
2022-05-20 23:15:13,077 DEV : loss 0.18907427787780762 - f1-score (micro avg)  0.5225
2022-05-20 23:15:13,168 BAD EPOCHS (no improvement): 2
2022-05-20 23:15:13,171 ----------------------------------------------------------------------------------------------------
2022-05-20 23:15:16,069 epoch 14 - iter 10/107 - loss 0.07535966 - samples/sec: 110.47 - lr: 0.050000
2022-05-20 23:15:19,141 epoch 14 - iter 20/107 - loss 0.07297831 - samples/sec: 104.19 - lr: 0.050000
2022-05-20 23:15:22,137 epoch 14 - iter 30/107 - loss 0.07140562 - samples/sec: 106.84 - lr: 0.050000
2022-05-20 23:15:25,065 epoch 14 - iter 40/107 - loss 0.07281534 - samples/sec: 109.33 - lr: 0.050000
2022-05-20 23:15:28,139 epoch 14 - iter 50/107 - loss 0.07822718 - samples/sec: 104.13 - lr: 0.050000
2022-05-20 23:15:31,222 epoch 14 - iter 60/107 - loss 0.07919768 - samples/sec: 103.86 - lr: 0.050000
2022-05-20 23:15:34,004 epoch 14 - iter 70/107 - loss 0.08076464 - samples/sec: 115.04 - lr: 0.050000
2022-05-20 23:15:36,705 epoch 14 - iter 80/107 - loss 0.07869686 - samples/sec: 118.53 - lr: 0.050000
2022-05-20 23:15:39,413 epoch 14 - iter 90/107 - loss 0.07574239 - samples/sec: 118.22 - lr: 0.050000
2022-05-20 23:15:42,107 epoch 14 - iter 100/107 - loss 0.07574103 - samples/sec: 118.84 - lr: 0.050000
2022-05-20 23:15:43,617 ----------------------------------------------------------------------------------------------------
2022-05-20 23:15:43,617 EPOCH 14 done: loss 0.0751 - lr 0.050000
2022-05-20 23:15:50,984 Evaluating as a multi-label problem: False
2022-05-20 23:15:50,996 DEV : loss 0.19443786144256592 - f1-score (micro avg)  0.5187
2022-05-20 23:15:51,088 BAD EPOCHS (no improvement): 3
2022-05-20 23:15:51,101 ----------------------------------------------------------------------------------------------------
2022-05-20 23:15:54,017 epoch 15 - iter 10/107 - loss 0.06786224 - samples/sec: 109.80 - lr: 0.050000
2022-05-20 23:15:57,034 epoch 15 - iter 20/107 - loss 0.07365559 - samples/sec: 106.11 - lr: 0.050000
2022-05-20 23:16:00,118 epoch 15 - iter 30/107 - loss 0.07107741 - samples/sec: 103.81 - lr: 0.050000
2022-05-20 23:16:03,189 epoch 15 - iter 40/107 - loss 0.07270655 - samples/sec: 104.23 - lr: 0.050000
2022-05-20 23:16:06,162 epoch 15 - iter 50/107 - loss 0.07272463 - samples/sec: 107.68 - lr: 0.050000
2022-05-20 23:16:09,066 epoch 15 - iter 60/107 - loss 0.07296903 - samples/sec: 110.24 - lr: 0.050000
2022-05-20 23:16:12,126 epoch 15 - iter 70/107 - loss 0.07113187 - samples/sec: 104.63 - lr: 0.050000
2022-05-20 23:16:15,093 epoch 15 - iter 80/107 - loss 0.07011879 - samples/sec: 107.87 - lr: 0.050000
2022-05-20 23:16:18,078 epoch 15 - iter 90/107 - loss 0.07014577 - samples/sec: 107.23 - lr: 0.050000
2022-05-20 23:16:21,174 epoch 15 - iter 100/107 - loss 0.07115778 - samples/sec: 103.42 - lr: 0.050000
2022-05-20 23:16:22,938 ----------------------------------------------------------------------------------------------------
2022-05-20 23:16:22,938 EPOCH 15 done: loss 0.0717 - lr 0.050000
2022-05-20 23:16:30,986 Evaluating as a multi-label problem: False
2022-05-20 23:16:30,998 DEV : loss 0.19438427686691284 - f1-score (micro avg)  0.5008
2022-05-20 23:16:31,092 Epoch    15: reducing learning rate of group 0 to 2.5000e-02.
2022-05-20 23:16:31,093 BAD EPOCHS (no improvement): 4
2022-05-20 23:16:31,096 ----------------------------------------------------------------------------------------------------
2022-05-20 23:16:33,915 epoch 16 - iter 10/107 - loss 0.06822278 - samples/sec: 113.57 - lr: 0.025000
2022-05-20 23:16:36,866 epoch 16 - iter 20/107 - loss 0.06826430 - samples/sec: 108.50 - lr: 0.025000
2022-05-20 23:16:39,837 epoch 16 - iter 30/107 - loss 0.06697707 - samples/sec: 107.77 - lr: 0.025000
2022-05-20 23:16:42,738 epoch 16 - iter 40/107 - loss 0.06609334 - samples/sec: 110.33 - lr: 0.025000
2022-05-20 23:16:45,644 epoch 16 - iter 50/107 - loss 0.06552410 - samples/sec: 110.16 - lr: 0.025000
2022-05-20 23:16:48,766 epoch 16 - iter 60/107 - loss 0.06622575 - samples/sec: 102.54 - lr: 0.025000
2022-05-20 23:16:51,866 epoch 16 - iter 70/107 - loss 0.06733915 - samples/sec: 103.27 - lr: 0.025000
2022-05-20 23:16:54,913 epoch 16 - iter 80/107 - loss 0.06837556 - samples/sec: 105.05 - lr: 0.025000
2022-05-20 23:16:58,027 epoch 16 - iter 90/107 - loss 0.06905821 - samples/sec: 102.81 - lr: 0.025000
2022-05-20 23:17:01,025 epoch 16 - iter 100/107 - loss 0.06902248 - samples/sec: 106.77 - lr: 0.025000
2022-05-20 23:17:02,912 ----------------------------------------------------------------------------------------------------
2022-05-20 23:17:02,912 EPOCH 16 done: loss 0.0692 - lr 0.025000
2022-05-20 23:17:11,241 Evaluating as a multi-label problem: False
2022-05-20 23:17:11,253 DEV : loss 0.1770012378692627 - f1-score (micro avg)  0.5188
2022-05-20 23:17:11,346 BAD EPOCHS (no improvement): 1
2022-05-20 23:17:11,348 ----------------------------------------------------------------------------------------------------
2022-05-20 23:17:14,193 epoch 17 - iter 10/107 - loss 0.06499833 - samples/sec: 112.52 - lr: 0.025000
2022-05-20 23:17:16,713 epoch 17 - iter 20/107 - loss 0.06265210 - samples/sec: 127.08 - lr: 0.025000
2022-05-20 23:17:18,200 epoch 17 - iter 30/107 - loss 0.06366640 - samples/sec: 215.39 - lr: 0.025000
2022-05-20 23:17:19,764 epoch 17 - iter 40/107 - loss 0.06494308 - samples/sec: 204.75 - lr: 0.025000
2022-05-20 23:17:22,628 epoch 17 - iter 50/107 - loss 0.06543192 - samples/sec: 111.79 - lr: 0.025000
2022-05-20 23:17:25,134 epoch 17 - iter 60/107 - loss 0.06495393 - samples/sec: 127.76 - lr: 0.025000
2022-05-20 23:17:27,574 epoch 17 - iter 70/107 - loss 0.06674021 - samples/sec: 131.22 - lr: 0.025000
2022-05-20 23:17:30,647 epoch 17 - iter 80/107 - loss 0.06776297 - samples/sec: 104.16 - lr: 0.025000
2022-05-20 23:17:33,768 epoch 17 - iter 90/107 - loss 0.06674694 - samples/sec: 102.55 - lr: 0.025000
2022-05-20 23:17:36,793 epoch 17 - iter 100/107 - loss 0.06651167 - samples/sec: 105.85 - lr: 0.025000
2022-05-20 23:17:38,575 ----------------------------------------------------------------------------------------------------
2022-05-20 23:17:38,575 EPOCH 17 done: loss 0.0656 - lr 0.025000
2022-05-20 23:17:47,287 Evaluating as a multi-label problem: False
2022-05-20 23:17:47,299 DEV : loss 0.18957524001598358 - f1-score (micro avg)  0.5016
2022-05-20 23:17:47,395 BAD EPOCHS (no improvement): 2
2022-05-20 23:17:47,397 ----------------------------------------------------------------------------------------------------
2022-05-20 23:17:50,603 epoch 18 - iter 10/107 - loss 0.06904550 - samples/sec: 99.86 - lr: 0.025000
2022-05-20 23:17:53,491 epoch 18 - iter 20/107 - loss 0.06935821 - samples/sec: 110.85 - lr: 0.025000
2022-05-20 23:17:56,670 epoch 18 - iter 30/107 - loss 0.06596104 - samples/sec: 100.72 - lr: 0.025000
2022-05-20 23:17:59,600 epoch 18 - iter 40/107 - loss 0.06320835 - samples/sec: 109.23 - lr: 0.025000
2022-05-20 23:18:02,626 epoch 18 - iter 50/107 - loss 0.06208868 - samples/sec: 105.80 - lr: 0.025000
2022-05-20 23:18:05,495 epoch 18 - iter 60/107 - loss 0.06353424 - samples/sec: 111.56 - lr: 0.025000
2022-05-20 23:18:08,319 epoch 18 - iter 70/107 - loss 0.06285662 - samples/sec: 113.39 - lr: 0.025000
2022-05-20 23:18:10,869 epoch 18 - iter 80/107 - loss 0.06432198 - samples/sec: 125.58 - lr: 0.025000
2022-05-20 23:18:13,585 epoch 18 - iter 90/107 - loss 0.06378335 - samples/sec: 117.87 - lr: 0.025000
2022-05-20 23:18:16,099 epoch 18 - iter 100/107 - loss 0.06434924 - samples/sec: 127.36 - lr: 0.025000
2022-05-20 23:18:17,894 ----------------------------------------------------------------------------------------------------
2022-05-20 23:18:17,895 EPOCH 18 done: loss 0.0651 - lr 0.025000
2022-05-20 23:18:26,182 Evaluating as a multi-label problem: False
2022-05-20 23:18:26,194 DEV : loss 0.17502836883068085 - f1-score (micro avg)  0.5258
2022-05-20 23:18:26,284 BAD EPOCHS (no improvement): 3
2022-05-20 23:18:26,286 ----------------------------------------------------------------------------------------------------
2022-05-20 23:18:29,155 epoch 19 - iter 10/107 - loss 0.05713828 - samples/sec: 111.61 - lr: 0.025000
2022-05-20 23:18:32,260 epoch 19 - iter 20/107 - loss 0.05750567 - samples/sec: 103.11 - lr: 0.025000
2022-05-20 23:18:35,292 epoch 19 - iter 30/107 - loss 0.06312379 - samples/sec: 105.55 - lr: 0.025000
2022-05-20 23:18:38,328 epoch 19 - iter 40/107 - loss 0.06390806 - samples/sec: 105.47 - lr: 0.025000
2022-05-20 23:18:41,349 epoch 19 - iter 50/107 - loss 0.06270677 - samples/sec: 105.94 - lr: 0.025000
2022-05-20 23:18:44,443 epoch 19 - iter 60/107 - loss 0.06274280 - samples/sec: 103.46 - lr: 0.025000
2022-05-20 23:18:47,486 epoch 19 - iter 70/107 - loss 0.06364843 - samples/sec: 105.20 - lr: 0.025000
2022-05-20 23:18:50,397 epoch 19 - iter 80/107 - loss 0.06389492 - samples/sec: 109.98 - lr: 0.025000
2022-05-20 23:18:53,454 epoch 19 - iter 90/107 - loss 0.06436209 - samples/sec: 104.71 - lr: 0.025000
2022-05-20 23:18:56,233 epoch 19 - iter 100/107 - loss 0.06457411 - samples/sec: 115.20 - lr: 0.025000
2022-05-20 23:18:58,048 ----------------------------------------------------------------------------------------------------
2022-05-20 23:18:58,048 EPOCH 19 done: loss 0.0640 - lr 0.025000
2022-05-20 23:19:06,126 Evaluating as a multi-label problem: False
2022-05-20 23:19:06,138 DEV : loss 0.18667247891426086 - f1-score (micro avg)  0.5153
2022-05-20 23:19:06,230 Epoch    19: reducing learning rate of group 0 to 1.2500e-02.
2022-05-20 23:19:06,230 BAD EPOCHS (no improvement): 4
2022-05-20 23:19:06,232 ----------------------------------------------------------------------------------------------------
2022-05-20 23:19:09,070 epoch 20 - iter 10/107 - loss 0.07381934 - samples/sec: 112.83 - lr: 0.012500
2022-05-20 23:19:12,022 epoch 20 - iter 20/107 - loss 0.06552909 - samples/sec: 108.45 - lr: 0.012500
2022-05-20 23:19:15,091 epoch 20 - iter 30/107 - loss 0.06243543 - samples/sec: 104.30 - lr: 0.012500
2022-05-20 23:19:18,108 epoch 20 - iter 40/107 - loss 0.06127833 - samples/sec: 106.10 - lr: 0.012500
2022-05-20 23:19:21,219 epoch 20 - iter 50/107 - loss 0.06152925 - samples/sec: 102.91 - lr: 0.012500
2022-05-20 23:19:24,388 epoch 20 - iter 60/107 - loss 0.06206385 - samples/sec: 101.01 - lr: 0.012500
2022-05-20 23:19:27,403 epoch 20 - iter 70/107 - loss 0.06300424 - samples/sec: 106.15 - lr: 0.012500
2022-05-20 23:19:30,377 epoch 20 - iter 80/107 - loss 0.06343701 - samples/sec: 107.63 - lr: 0.012500
2022-05-20 23:19:33,453 epoch 20 - iter 90/107 - loss 0.06258134 - samples/sec: 104.08 - lr: 0.012500
2022-05-20 23:19:36,400 epoch 20 - iter 100/107 - loss 0.06255756 - samples/sec: 108.61 - lr: 0.012500
2022-05-20 23:19:38,234 ----------------------------------------------------------------------------------------------------
2022-05-20 23:19:38,234 EPOCH 20 done: loss 0.0629 - lr 0.012500
2022-05-20 23:19:45,846 Evaluating as a multi-label problem: False
2022-05-20 23:19:45,858 DEV : loss 0.18301022052764893 - f1-score (micro avg)  0.5249
2022-05-20 23:19:45,951 BAD EPOCHS (no improvement): 1
2022-05-20 23:19:45,953 ----------------------------------------------------------------------------------------------------
2022-05-20 23:19:48,524 epoch 21 - iter 10/107 - loss 0.06376426 - samples/sec: 124.59 - lr: 0.012500
2022-05-20 23:19:51,313 epoch 21 - iter 20/107 - loss 0.06387705 - samples/sec: 114.80 - lr: 0.012500
2022-05-20 23:19:53,947 epoch 21 - iter 30/107 - loss 0.06092230 - samples/sec: 121.54 - lr: 0.012500
2022-05-20 23:19:56,509 epoch 21 - iter 40/107 - loss 0.05956853 - samples/sec: 124.96 - lr: 0.012500
2022-05-20 23:19:59,536 epoch 21 - iter 50/107 - loss 0.06082806 - samples/sec: 105.76 - lr: 0.012500
2022-05-20 23:20:02,573 epoch 21 - iter 60/107 - loss 0.06167815 - samples/sec: 105.38 - lr: 0.012500
2022-05-20 23:20:05,737 epoch 21 - iter 70/107 - loss 0.06330977 - samples/sec: 101.20 - lr: 0.012500
2022-05-20 23:20:08,777 epoch 21 - iter 80/107 - loss 0.06091091 - samples/sec: 105.27 - lr: 0.012500
2022-05-20 23:20:11,847 epoch 21 - iter 90/107 - loss 0.06099310 - samples/sec: 104.27 - lr: 0.012500
2022-05-20 23:20:14,976 epoch 21 - iter 100/107 - loss 0.05996317 - samples/sec: 102.33 - lr: 0.012500
2022-05-20 23:20:16,586 ----------------------------------------------------------------------------------------------------
2022-05-20 23:20:16,586 EPOCH 21 done: loss 0.0604 - lr 0.012500
2022-05-20 23:20:26,871 Evaluating as a multi-label problem: False
2022-05-20 23:20:26,882 DEV : loss 0.1806342750787735 - f1-score (micro avg)  0.5291
2022-05-20 23:20:26,977 BAD EPOCHS (no improvement): 2
2022-05-20 23:20:26,981 ----------------------------------------------------------------------------------------------------
2022-05-20 23:20:29,776 epoch 22 - iter 10/107 - loss 0.04819185 - samples/sec: 114.56 - lr: 0.012500
2022-05-20 23:20:32,496 epoch 22 - iter 20/107 - loss 0.05171924 - samples/sec: 117.70 - lr: 0.012500
2022-05-20 23:20:35,101 epoch 22 - iter 30/107 - loss 0.05076934 - samples/sec: 122.90 - lr: 0.012500
2022-05-20 23:20:37,803 epoch 22 - iter 40/107 - loss 0.05562428 - samples/sec: 118.50 - lr: 0.012500
2022-05-20 23:20:40,435 epoch 22 - iter 50/107 - loss 0.05458299 - samples/sec: 121.60 - lr: 0.012500
2022-05-20 23:20:43,292 epoch 22 - iter 60/107 - loss 0.05545932 - samples/sec: 112.06 - lr: 0.012500
2022-05-20 23:20:46,418 epoch 22 - iter 70/107 - loss 0.05661830 - samples/sec: 102.40 - lr: 0.012500
2022-05-20 23:20:49,404 epoch 22 - iter 80/107 - loss 0.05819600 - samples/sec: 107.23 - lr: 0.012500
2022-05-20 23:20:52,531 epoch 22 - iter 90/107 - loss 0.05801580 - samples/sec: 102.35 - lr: 0.012500
2022-05-20 23:20:55,646 epoch 22 - iter 100/107 - loss 0.05791948 - samples/sec: 102.76 - lr: 0.012500
2022-05-20 23:20:57,538 ----------------------------------------------------------------------------------------------------
2022-05-20 23:20:57,538 EPOCH 22 done: loss 0.0587 - lr 0.012500
2022-05-20 23:21:05,477 Evaluating as a multi-label problem: False
2022-05-20 23:21:05,489 DEV : loss 0.18280602991580963 - f1-score (micro avg)  0.5299
2022-05-20 23:21:05,582 BAD EPOCHS (no improvement): 3
2022-05-20 23:21:05,592 ----------------------------------------------------------------------------------------------------
2022-05-20 23:21:08,698 epoch 23 - iter 10/107 - loss 0.06487607 - samples/sec: 103.07 - lr: 0.012500
2022-05-20 23:21:11,609 epoch 23 - iter 20/107 - loss 0.06212928 - samples/sec: 109.96 - lr: 0.012500
2022-05-20 23:21:14,650 epoch 23 - iter 30/107 - loss 0.06048742 - samples/sec: 105.29 - lr: 0.012500
2022-05-20 23:21:17,403 epoch 23 - iter 40/107 - loss 0.06466748 - samples/sec: 116.26 - lr: 0.012500
2022-05-20 23:21:20,199 epoch 23 - iter 50/107 - loss 0.06333627 - samples/sec: 114.51 - lr: 0.012500
2022-05-20 23:21:22,872 epoch 23 - iter 60/107 - loss 0.06235383 - samples/sec: 119.77 - lr: 0.012500
2022-05-20 23:21:25,480 epoch 23 - iter 70/107 - loss 0.06193686 - samples/sec: 122.80 - lr: 0.012500
2022-05-20 23:21:27,994 epoch 23 - iter 80/107 - loss 0.06171654 - samples/sec: 127.34 - lr: 0.012500
2022-05-20 23:21:30,756 epoch 23 - iter 90/107 - loss 0.06053234 - samples/sec: 115.91 - lr: 0.012500
2022-05-20 23:21:33,889 epoch 23 - iter 100/107 - loss 0.06027933 - samples/sec: 102.16 - lr: 0.012500
2022-05-20 23:21:35,621 ----------------------------------------------------------------------------------------------------
2022-05-20 23:21:35,622 EPOCH 23 done: loss 0.0600 - lr 0.012500
2022-05-20 23:21:44,467 Evaluating as a multi-label problem: False
2022-05-20 23:21:44,479 DEV : loss 0.18935976922512054 - f1-score (micro avg)  0.5139
2022-05-20 23:21:44,574 Epoch    23: reducing learning rate of group 0 to 6.2500e-03.
2022-05-20 23:21:44,574 BAD EPOCHS (no improvement): 4
2022-05-20 23:21:44,576 ----------------------------------------------------------------------------------------------------
2022-05-20 23:21:47,686 epoch 24 - iter 10/107 - loss 0.07538258 - samples/sec: 102.95 - lr: 0.006250
2022-05-20 23:21:50,842 epoch 24 - iter 20/107 - loss 0.06721417 - samples/sec: 101.42 - lr: 0.006250
2022-05-20 23:21:53,950 epoch 24 - iter 30/107 - loss 0.06080357 - samples/sec: 103.00 - lr: 0.006250
2022-05-20 23:21:57,105 epoch 24 - iter 40/107 - loss 0.06037056 - samples/sec: 101.47 - lr: 0.006250
2022-05-20 23:22:00,155 epoch 24 - iter 50/107 - loss 0.05867807 - samples/sec: 104.93 - lr: 0.006250
2022-05-20 23:22:03,024 epoch 24 - iter 60/107 - loss 0.05739111 - samples/sec: 111.59 - lr: 0.006250
2022-05-20 23:22:06,068 epoch 24 - iter 70/107 - loss 0.05653069 - samples/sec: 105.20 - lr: 0.006250
2022-05-20 23:22:08,967 epoch 24 - iter 80/107 - loss 0.05754395 - samples/sec: 110.43 - lr: 0.006250
2022-05-20 23:22:11,810 epoch 24 - iter 90/107 - loss 0.05623456 - samples/sec: 112.61 - lr: 0.006250
2022-05-20 23:22:14,349 epoch 24 - iter 100/107 - loss 0.05650874 - samples/sec: 126.08 - lr: 0.006250
2022-05-20 23:22:15,949 ----------------------------------------------------------------------------------------------------
2022-05-20 23:22:15,949 EPOCH 24 done: loss 0.0572 - lr 0.006250
2022-05-20 23:22:22,332 Evaluating as a multi-label problem: False
2022-05-20 23:22:22,344 DEV : loss 0.1846122294664383 - f1-score (micro avg)  0.5253
2022-05-20 23:22:22,436 BAD EPOCHS (no improvement): 1
2022-05-20 23:22:22,438 ----------------------------------------------------------------------------------------------------
2022-05-20 23:22:24,021 epoch 25 - iter 10/107 - loss 0.05401253 - samples/sec: 202.35 - lr: 0.006250
2022-05-20 23:22:25,602 epoch 25 - iter 20/107 - loss 0.05443593 - samples/sec: 202.64 - lr: 0.006250
2022-05-20 23:22:27,245 epoch 25 - iter 30/107 - loss 0.05605376 - samples/sec: 194.85 - lr: 0.006250
2022-05-20 23:22:28,912 epoch 25 - iter 40/107 - loss 0.05781221 - samples/sec: 192.11 - lr: 0.006250
2022-05-20 23:22:30,445 epoch 25 - iter 50/107 - loss 0.05944003 - samples/sec: 208.89 - lr: 0.006250
2022-05-20 23:22:32,078 epoch 25 - iter 60/107 - loss 0.05982823 - samples/sec: 196.06 - lr: 0.006250
2022-05-20 23:22:33,696 epoch 25 - iter 70/107 - loss 0.05950065 - samples/sec: 197.89 - lr: 0.006250
2022-05-20 23:22:35,293 epoch 25 - iter 80/107 - loss 0.05967540 - samples/sec: 200.60 - lr: 0.006250
2022-05-20 23:22:36,840 epoch 25 - iter 90/107 - loss 0.05933223 - samples/sec: 206.88 - lr: 0.006250
2022-05-20 23:22:38,468 epoch 25 - iter 100/107 - loss 0.05868911 - samples/sec: 196.70 - lr: 0.006250
2022-05-20 23:22:39,489 ----------------------------------------------------------------------------------------------------
2022-05-20 23:22:39,489 EPOCH 25 done: loss 0.0580 - lr 0.006250
2022-05-20 23:22:45,023 Evaluating as a multi-label problem: False
2022-05-20 23:22:45,035 DEV : loss 0.1887182742357254 - f1-score (micro avg)  0.514
2022-05-20 23:22:45,127 BAD EPOCHS (no improvement): 2
2022-05-20 23:22:45,129 ----------------------------------------------------------------------------------------------------
2022-05-20 23:22:46,726 epoch 26 - iter 10/107 - loss 0.06425901 - samples/sec: 200.57 - lr: 0.006250
2022-05-20 23:22:48,262 epoch 26 - iter 20/107 - loss 0.05859724 - samples/sec: 208.49 - lr: 0.006250
2022-05-20 23:22:49,827 epoch 26 - iter 30/107 - loss 0.06211048 - samples/sec: 204.59 - lr: 0.006250
2022-05-20 23:22:51,319 epoch 26 - iter 40/107 - loss 0.06018730 - samples/sec: 214.69 - lr: 0.006250
2022-05-20 23:22:52,859 epoch 26 - iter 50/107 - loss 0.06170673 - samples/sec: 208.00 - lr: 0.006250
2022-05-20 23:22:54,409 epoch 26 - iter 60/107 - loss 0.06145556 - samples/sec: 206.63 - lr: 0.006250
2022-05-20 23:22:55,933 epoch 26 - iter 70/107 - loss 0.06010484 - samples/sec: 210.06 - lr: 0.006250
2022-05-20 23:22:57,511 epoch 26 - iter 80/107 - loss 0.05968928 - samples/sec: 203.01 - lr: 0.006250
2022-05-20 23:22:59,075 epoch 26 - iter 90/107 - loss 0.05873026 - samples/sec: 204.78 - lr: 0.006250
2022-05-20 23:23:00,649 epoch 26 - iter 100/107 - loss 0.05807975 - samples/sec: 203.39 - lr: 0.006250
2022-05-20 23:23:01,569 ----------------------------------------------------------------------------------------------------
2022-05-20 23:23:01,569 EPOCH 26 done: loss 0.0580 - lr 0.006250
2022-05-20 23:23:06,948 Evaluating as a multi-label problem: False
2022-05-20 23:23:06,961 DEV : loss 0.18410784006118774 - f1-score (micro avg)  0.5282
2022-05-20 23:23:07,054 BAD EPOCHS (no improvement): 3
2022-05-20 23:23:07,056 ----------------------------------------------------------------------------------------------------
2022-05-20 23:23:08,722 epoch 27 - iter 10/107 - loss 0.05226120 - samples/sec: 192.30 - lr: 0.006250
2022-05-20 23:23:10,242 epoch 27 - iter 20/107 - loss 0.05013615 - samples/sec: 210.65 - lr: 0.006250
2022-05-20 23:23:11,785 epoch 27 - iter 30/107 - loss 0.05304762 - samples/sec: 207.55 - lr: 0.006250
2022-05-20 23:23:13,351 epoch 27 - iter 40/107 - loss 0.05356304 - samples/sec: 204.54 - lr: 0.006250
2022-05-20 23:23:14,955 epoch 27 - iter 50/107 - loss 0.05432920 - samples/sec: 199.58 - lr: 0.006250
2022-05-20 23:23:16,522 epoch 27 - iter 60/107 - loss 0.05444069 - samples/sec: 204.37 - lr: 0.006250
2022-05-20 23:23:18,052 epoch 27 - iter 70/107 - loss 0.05762787 - samples/sec: 209.30 - lr: 0.006250
2022-05-20 23:23:19,550 epoch 27 - iter 80/107 - loss 0.05760041 - samples/sec: 213.82 - lr: 0.006250
2022-05-20 23:23:21,047 epoch 27 - iter 90/107 - loss 0.05809694 - samples/sec: 213.87 - lr: 0.006250
2022-05-20 23:23:22,476 epoch 27 - iter 100/107 - loss 0.05772958 - samples/sec: 224.01 - lr: 0.006250
2022-05-20 23:23:23,368 ----------------------------------------------------------------------------------------------------
2022-05-20 23:23:23,368 EPOCH 27 done: loss 0.0579 - lr 0.006250
2022-05-20 23:23:28,784 Evaluating as a multi-label problem: False
2022-05-20 23:23:28,796 DEV : loss 0.18341249227523804 - f1-score (micro avg)  0.5251
2022-05-20 23:23:28,890 Epoch    27: reducing learning rate of group 0 to 3.1250e-03.
2022-05-20 23:23:28,890 BAD EPOCHS (no improvement): 4
2022-05-20 23:23:28,892 ----------------------------------------------------------------------------------------------------
2022-05-20 23:23:30,643 epoch 28 - iter 10/107 - loss 0.06467979 - samples/sec: 182.86 - lr: 0.003125
2022-05-20 23:23:32,258 epoch 28 - iter 20/107 - loss 0.05789339 - samples/sec: 198.31 - lr: 0.003125
2022-05-20 23:23:33,878 epoch 28 - iter 30/107 - loss 0.05801623 - samples/sec: 197.68 - lr: 0.003125
2022-05-20 23:23:35,461 epoch 28 - iter 40/107 - loss 0.05769940 - samples/sec: 202.33 - lr: 0.003125
2022-05-20 23:23:37,101 epoch 28 - iter 50/107 - loss 0.05801512 - samples/sec: 195.19 - lr: 0.003125
2022-05-20 23:23:38,990 epoch 28 - iter 60/107 - loss 0.05763624 - samples/sec: 169.58 - lr: 0.003125
2022-05-20 23:23:42,954 epoch 28 - iter 70/107 - loss 0.05885128 - samples/sec: 80.75 - lr: 0.003125
2022-05-20 23:23:46,776 epoch 28 - iter 80/107 - loss 0.05780797 - samples/sec: 83.74 - lr: 0.003125
2022-05-20 23:23:50,695 epoch 28 - iter 90/107 - loss 0.05687788 - samples/sec: 81.70 - lr: 0.003125
2022-05-20 23:23:54,108 epoch 28 - iter 100/107 - loss 0.05703834 - samples/sec: 93.79 - lr: 0.003125
2022-05-20 23:23:56,371 ----------------------------------------------------------------------------------------------------
2022-05-20 23:23:56,371 EPOCH 28 done: loss 0.0570 - lr 0.003125
2022-05-20 23:24:05,340 Evaluating as a multi-label problem: False
2022-05-20 23:24:05,352 DEV : loss 0.18594451248645782 - f1-score (micro avg)  0.5275
2022-05-20 23:24:05,443 BAD EPOCHS (no improvement): 1
2022-05-20 23:24:05,457 ----------------------------------------------------------------------------------------------------
2022-05-20 23:24:08,486 epoch 29 - iter 10/107 - loss 0.05742689 - samples/sec: 105.70 - lr: 0.003125
2022-05-20 23:24:11,492 epoch 29 - iter 20/107 - loss 0.05119887 - samples/sec: 106.49 - lr: 0.003125
2022-05-20 23:24:14,528 epoch 29 - iter 30/107 - loss 0.04939826 - samples/sec: 105.43 - lr: 0.003125
2022-05-20 23:24:17,623 epoch 29 - iter 40/107 - loss 0.05648272 - samples/sec: 103.44 - lr: 0.003125
2022-05-20 23:24:20,452 epoch 29 - iter 50/107 - loss 0.05687202 - samples/sec: 113.14 - lr: 0.003125
2022-05-20 23:24:23,567 epoch 29 - iter 60/107 - loss 0.05575913 - samples/sec: 102.76 - lr: 0.003125
2022-05-20 23:24:26,442 epoch 29 - iter 70/107 - loss 0.05525351 - samples/sec: 111.37 - lr: 0.003125
2022-05-20 23:24:29,509 epoch 29 - iter 80/107 - loss 0.05517787 - samples/sec: 104.39 - lr: 0.003125
2022-05-20 23:24:32,491 epoch 29 - iter 90/107 - loss 0.05476208 - samples/sec: 107.33 - lr: 0.003125
2022-05-20 23:24:35,306 epoch 29 - iter 100/107 - loss 0.05597660 - samples/sec: 113.73 - lr: 0.003125
2022-05-20 23:24:37,092 ----------------------------------------------------------------------------------------------------
2022-05-20 23:24:37,092 EPOCH 29 done: loss 0.0558 - lr 0.003125
2022-05-20 23:24:45,931 Evaluating as a multi-label problem: False
2022-05-20 23:24:45,942 DEV : loss 0.18729530274868011 - f1-score (micro avg)  0.5235
2022-05-20 23:24:46,034 BAD EPOCHS (no improvement): 2
2022-05-20 23:24:46,037 ----------------------------------------------------------------------------------------------------
2022-05-20 23:24:47,560 epoch 30 - iter 10/107 - loss 0.05222613 - samples/sec: 210.38 - lr: 0.003125
2022-05-20 23:24:49,083 epoch 30 - iter 20/107 - loss 0.05225028 - samples/sec: 210.17 - lr: 0.003125
2022-05-20 23:24:50,692 epoch 30 - iter 30/107 - loss 0.05302229 - samples/sec: 199.04 - lr: 0.003125
2022-05-20 23:24:52,329 epoch 30 - iter 40/107 - loss 0.05643911 - samples/sec: 195.64 - lr: 0.003125
2022-05-20 23:24:53,917 epoch 30 - iter 50/107 - loss 0.05702445 - samples/sec: 201.58 - lr: 0.003125
2022-05-20 23:24:55,504 epoch 30 - iter 60/107 - loss 0.05780433 - samples/sec: 201.80 - lr: 0.003125
2022-05-20 23:24:57,057 epoch 30 - iter 70/107 - loss 0.05919117 - samples/sec: 206.17 - lr: 0.003125
2022-05-20 23:24:58,565 epoch 30 - iter 80/107 - loss 0.05819302 - samples/sec: 212.37 - lr: 0.003125
2022-05-20 23:25:00,118 epoch 30 - iter 90/107 - loss 0.05738175 - samples/sec: 206.18 - lr: 0.003125
2022-05-20 23:25:01,727 epoch 30 - iter 100/107 - loss 0.05831591 - samples/sec: 198.97 - lr: 0.003125
2022-05-20 23:25:02,685 ----------------------------------------------------------------------------------------------------
2022-05-20 23:25:02,685 EPOCH 30 done: loss 0.0583 - lr 0.003125
2022-05-20 23:25:08,212 Evaluating as a multi-label problem: False
2022-05-20 23:25:08,223 DEV : loss 0.1832430213689804 - f1-score (micro avg)  0.53
2022-05-20 23:25:08,315 BAD EPOCHS (no improvement): 3
2022-05-20 23:25:08,331 ----------------------------------------------------------------------------------------------------
2022-05-20 23:25:09,957 epoch 31 - iter 10/107 - loss 0.05656612 - samples/sec: 197.13 - lr: 0.003125
2022-05-20 23:25:11,511 epoch 31 - iter 20/107 - loss 0.06254522 - samples/sec: 206.07 - lr: 0.003125
2022-05-20 23:25:13,103 epoch 31 - iter 30/107 - loss 0.05802863 - samples/sec: 201.10 - lr: 0.003125
2022-05-20 23:25:14,656 epoch 31 - iter 40/107 - loss 0.05660416 - samples/sec: 206.24 - lr: 0.003125
2022-05-20 23:25:16,194 epoch 31 - iter 50/107 - loss 0.05691241 - samples/sec: 208.28 - lr: 0.003125
2022-05-20 23:25:17,708 epoch 31 - iter 60/107 - loss 0.05697419 - samples/sec: 211.52 - lr: 0.003125
2022-05-20 23:25:19,220 epoch 31 - iter 70/107 - loss 0.05532256 - samples/sec: 211.70 - lr: 0.003125
2022-05-20 23:25:20,737 epoch 31 - iter 80/107 - loss 0.05560839 - samples/sec: 211.11 - lr: 0.003125
2022-05-20 23:25:22,207 epoch 31 - iter 90/107 - loss 0.05474066 - samples/sec: 217.97 - lr: 0.003125
2022-05-20 23:25:23,555 epoch 31 - iter 100/107 - loss 0.05446597 - samples/sec: 237.50 - lr: 0.003125
2022-05-20 23:25:24,458 ----------------------------------------------------------------------------------------------------
2022-05-20 23:25:24,458 EPOCH 31 done: loss 0.0550 - lr 0.003125
2022-05-20 23:25:29,844 Evaluating as a multi-label problem: False
2022-05-20 23:25:29,857 DEV : loss 0.18186303973197937 - f1-score (micro avg)  0.5329
2022-05-20 23:25:29,952 Epoch    31: reducing learning rate of group 0 to 1.5625e-03.
2022-05-20 23:25:29,952 BAD EPOCHS (no improvement): 4
2022-05-20 23:25:29,999 ----------------------------------------------------------------------------------------------------
2022-05-20 23:25:31,547 epoch 32 - iter 10/107 - loss 0.06642857 - samples/sec: 206.98 - lr: 0.001563
2022-05-20 23:25:33,897 epoch 32 - iter 20/107 - loss 0.06127330 - samples/sec: 136.22 - lr: 0.001563
2022-05-20 23:25:36,734 epoch 32 - iter 30/107 - loss 0.06108698 - samples/sec: 112.86 - lr: 0.001563
2022-05-20 23:25:39,746 epoch 32 - iter 40/107 - loss 0.05981624 - samples/sec: 106.26 - lr: 0.001563
2022-05-20 23:25:42,569 epoch 32 - iter 50/107 - loss 0.06122307 - samples/sec: 113.39 - lr: 0.001563
2022-05-20 23:25:45,564 epoch 32 - iter 60/107 - loss 0.05921009 - samples/sec: 106.90 - lr: 0.001563
2022-05-20 23:25:48,596 epoch 32 - iter 70/107 - loss 0.05876944 - samples/sec: 105.56 - lr: 0.001563
2022-05-20 23:25:51,572 epoch 32 - iter 80/107 - loss 0.05707683 - samples/sec: 107.60 - lr: 0.001563
2022-05-20 23:25:54,460 epoch 32 - iter 90/107 - loss 0.05767594 - samples/sec: 110.84 - lr: 0.001563
2022-05-20 23:25:57,633 epoch 32 - iter 100/107 - loss 0.05713096 - samples/sec: 100.89 - lr: 0.001563
2022-05-20 23:25:59,703 ----------------------------------------------------------------------------------------------------
2022-05-20 23:25:59,704 EPOCH 32 done: loss 0.0573 - lr 0.001563
2022-05-20 23:26:07,594 Evaluating as a multi-label problem: False
2022-05-20 23:26:07,607 DEV : loss 0.18445488810539246 - f1-score (micro avg)  0.5252
2022-05-20 23:26:07,698 BAD EPOCHS (no improvement): 1
2022-05-20 23:26:07,715 ----------------------------------------------------------------------------------------------------
2022-05-20 23:26:10,567 epoch 33 - iter 10/107 - loss 0.05781745 - samples/sec: 112.27 - lr: 0.001563
2022-05-20 23:26:13,251 epoch 33 - iter 20/107 - loss 0.05246623 - samples/sec: 119.28 - lr: 0.001563
2022-05-20 23:26:15,733 epoch 33 - iter 30/107 - loss 0.05754875 - samples/sec: 129.00 - lr: 0.001563
2022-05-20 23:26:18,541 epoch 33 - iter 40/107 - loss 0.05832036 - samples/sec: 114.00 - lr: 0.001563
2022-05-20 23:26:21,085 epoch 33 - iter 50/107 - loss 0.05676860 - samples/sec: 125.85 - lr: 0.001563
2022-05-20 23:26:22,633 epoch 33 - iter 60/107 - loss 0.05624533 - samples/sec: 206.82 - lr: 0.001563
2022-05-20 23:26:24,007 epoch 33 - iter 70/107 - loss 0.05628261 - samples/sec: 233.05 - lr: 0.001563
2022-05-20 23:26:25,431 epoch 33 - iter 80/107 - loss 0.05651437 - samples/sec: 224.87 - lr: 0.001563
2022-05-20 23:26:26,934 epoch 33 - iter 90/107 - loss 0.05724908 - samples/sec: 213.03 - lr: 0.001563
2022-05-20 23:26:28,408 epoch 33 - iter 100/107 - loss 0.05724611 - samples/sec: 217.37 - lr: 0.001563
2022-05-20 23:26:29,356 ----------------------------------------------------------------------------------------------------
2022-05-20 23:26:29,356 EPOCH 33 done: loss 0.0568 - lr 0.001563
2022-05-20 23:26:34,683 Evaluating as a multi-label problem: False
2022-05-20 23:26:34,695 DEV : loss 0.18584902584552765 - f1-score (micro avg)  0.5227
2022-05-20 23:26:34,786 BAD EPOCHS (no improvement): 2
2022-05-20 23:26:34,788 ----------------------------------------------------------------------------------------------------
2022-05-20 23:26:36,452 epoch 34 - iter 10/107 - loss 0.05035953 - samples/sec: 192.52 - lr: 0.001563
2022-05-20 23:26:38,033 epoch 34 - iter 20/107 - loss 0.05296339 - samples/sec: 202.50 - lr: 0.001563
2022-05-20 23:26:39,554 epoch 34 - iter 30/107 - loss 0.04983067 - samples/sec: 210.49 - lr: 0.001563
2022-05-20 23:26:41,091 epoch 34 - iter 40/107 - loss 0.05240368 - samples/sec: 208.44 - lr: 0.001563
2022-05-20 23:26:42,688 epoch 34 - iter 50/107 - loss 0.05312148 - samples/sec: 200.45 - lr: 0.001563
2022-05-20 23:26:44,229 epoch 34 - iter 60/107 - loss 0.05493210 - samples/sec: 207.83 - lr: 0.001563
2022-05-20 23:26:45,744 epoch 34 - iter 70/107 - loss 0.05544464 - samples/sec: 211.42 - lr: 0.001563
2022-05-20 23:26:47,262 epoch 34 - iter 80/107 - loss 0.05535464 - samples/sec: 211.02 - lr: 0.001563
2022-05-20 23:26:48,783 epoch 34 - iter 90/107 - loss 0.05596114 - samples/sec: 210.59 - lr: 0.001563
2022-05-20 23:26:50,309 epoch 34 - iter 100/107 - loss 0.05540840 - samples/sec: 209.75 - lr: 0.001563
2022-05-20 23:26:51,264 ----------------------------------------------------------------------------------------------------
2022-05-20 23:26:51,264 EPOCH 34 done: loss 0.0555 - lr 0.001563
2022-05-20 23:26:56,653 Evaluating as a multi-label problem: False
2022-05-20 23:26:56,666 DEV : loss 0.18519681692123413 - f1-score (micro avg)  0.5304
2022-05-20 23:26:56,757 BAD EPOCHS (no improvement): 3
2022-05-20 23:26:56,759 ----------------------------------------------------------------------------------------------------
2022-05-20 23:26:58,387 epoch 35 - iter 10/107 - loss 0.04957780 - samples/sec: 196.77 - lr: 0.001563
2022-05-20 23:26:59,901 epoch 35 - iter 20/107 - loss 0.05763784 - samples/sec: 211.58 - lr: 0.001563
2022-05-20 23:27:01,473 epoch 35 - iter 30/107 - loss 0.05675897 - samples/sec: 203.64 - lr: 0.001563
2022-05-20 23:27:03,058 epoch 35 - iter 40/107 - loss 0.05757748 - samples/sec: 202.09 - lr: 0.001563
2022-05-20 23:27:04,639 epoch 35 - iter 50/107 - loss 0.05625290 - samples/sec: 202.47 - lr: 0.001563
2022-05-20 23:27:06,311 epoch 35 - iter 60/107 - loss 0.05671980 - samples/sec: 191.59 - lr: 0.001563
2022-05-20 23:27:08,536 epoch 35 - iter 70/107 - loss 0.05684944 - samples/sec: 143.86 - lr: 0.001563
2022-05-20 23:27:11,376 epoch 35 - iter 80/107 - loss 0.05535985 - samples/sec: 112.73 - lr: 0.001563
2022-05-20 23:27:14,433 epoch 35 - iter 90/107 - loss 0.05466303 - samples/sec: 104.70 - lr: 0.001563
2022-05-20 23:27:17,413 epoch 35 - iter 100/107 - loss 0.05474516 - samples/sec: 107.45 - lr: 0.001563
2022-05-20 23:27:19,164 ----------------------------------------------------------------------------------------------------
2022-05-20 23:27:19,164 EPOCH 35 done: loss 0.0545 - lr 0.001563
2022-05-20 23:27:27,180 Evaluating as a multi-label problem: False
2022-05-20 23:27:27,192 DEV : loss 0.18457303941249847 - f1-score (micro avg)  0.5281
2022-05-20 23:27:27,284 Epoch    35: reducing learning rate of group 0 to 7.8125e-04.
2022-05-20 23:27:27,285 BAD EPOCHS (no improvement): 4
2022-05-20 23:27:27,287 ----------------------------------------------------------------------------------------------------
2022-05-20 23:27:30,195 epoch 36 - iter 10/107 - loss 0.05192413 - samples/sec: 110.08 - lr: 0.000781
2022-05-20 23:27:33,337 epoch 36 - iter 20/107 - loss 0.05315996 - samples/sec: 101.90 - lr: 0.000781
2022-05-20 23:27:36,217 epoch 36 - iter 30/107 - loss 0.05335204 - samples/sec: 111.19 - lr: 0.000781
2022-05-20 23:27:39,191 epoch 36 - iter 40/107 - loss 0.05672073 - samples/sec: 107.63 - lr: 0.000781
2022-05-20 23:27:42,156 epoch 36 - iter 50/107 - loss 0.05851310 - samples/sec: 107.98 - lr: 0.000781
2022-05-20 23:27:44,962 epoch 36 - iter 60/107 - loss 0.05674329 - samples/sec: 114.09 - lr: 0.000781
2022-05-20 23:27:47,499 epoch 36 - iter 70/107 - loss 0.05641444 - samples/sec: 126.17 - lr: 0.000781
2022-05-20 23:27:50,152 epoch 36 - iter 80/107 - loss 0.05765009 - samples/sec: 120.68 - lr: 0.000781
2022-05-20 23:27:52,639 epoch 36 - iter 90/107 - loss 0.05825070 - samples/sec: 128.68 - lr: 0.000781
2022-05-20 23:27:55,398 epoch 36 - iter 100/107 - loss 0.05762666 - samples/sec: 116.03 - lr: 0.000781
2022-05-20 23:27:57,051 ----------------------------------------------------------------------------------------------------
2022-05-20 23:27:57,051 EPOCH 36 done: loss 0.0576 - lr 0.000781
2022-05-20 23:28:05,461 Evaluating as a multi-label problem: False
2022-05-20 23:28:05,473 DEV : loss 0.18518434464931488 - f1-score (micro avg)  0.5293
2022-05-20 23:28:05,564 BAD EPOCHS (no improvement): 1
2022-05-20 23:28:05,603 ----------------------------------------------------------------------------------------------------
2022-05-20 23:28:08,674 epoch 37 - iter 10/107 - loss 0.04678182 - samples/sec: 104.27 - lr: 0.000781
2022-05-20 23:28:11,774 epoch 37 - iter 20/107 - loss 0.04649498 - samples/sec: 103.27 - lr: 0.000781
2022-05-20 23:28:15,005 epoch 37 - iter 30/107 - loss 0.04894612 - samples/sec: 99.07 - lr: 0.000781
2022-05-20 23:28:17,911 epoch 37 - iter 40/107 - loss 0.04951310 - samples/sec: 110.15 - lr: 0.000781
2022-05-20 23:28:20,883 epoch 37 - iter 50/107 - loss 0.05049652 - samples/sec: 107.73 - lr: 0.000781
2022-05-20 23:28:24,007 epoch 37 - iter 60/107 - loss 0.05214884 - samples/sec: 102.48 - lr: 0.000781
2022-05-20 23:28:26,847 epoch 37 - iter 70/107 - loss 0.05093751 - samples/sec: 112.74 - lr: 0.000781
2022-05-20 23:28:29,996 epoch 37 - iter 80/107 - loss 0.05206360 - samples/sec: 101.63 - lr: 0.000781
2022-05-20 23:28:33,031 epoch 37 - iter 90/107 - loss 0.05209811 - samples/sec: 105.49 - lr: 0.000781
2022-05-20 23:28:35,800 epoch 37 - iter 100/107 - loss 0.05342744 - samples/sec: 115.62 - lr: 0.000781
2022-05-20 23:28:37,503 ----------------------------------------------------------------------------------------------------
2022-05-20 23:28:37,503 EPOCH 37 done: loss 0.0541 - lr 0.000781
2022-05-20 23:28:46,638 Evaluating as a multi-label problem: False
2022-05-20 23:28:46,650 DEV : loss 0.1842711716890335 - f1-score (micro avg)  0.5299
2022-05-20 23:28:46,742 BAD EPOCHS (no improvement): 2
2022-05-20 23:28:46,744 ----------------------------------------------------------------------------------------------------
2022-05-20 23:28:48,459 epoch 38 - iter 10/107 - loss 0.06696359 - samples/sec: 186.71 - lr: 0.000781
2022-05-20 23:28:50,036 epoch 38 - iter 20/107 - loss 0.05678994 - samples/sec: 203.06 - lr: 0.000781
2022-05-20 23:28:51,612 epoch 38 - iter 30/107 - loss 0.05711436 - samples/sec: 203.26 - lr: 0.000781
2022-05-20 23:28:53,234 epoch 38 - iter 40/107 - loss 0.06001401 - samples/sec: 197.38 - lr: 0.000781
2022-05-20 23:28:54,811 epoch 38 - iter 50/107 - loss 0.06145406 - samples/sec: 203.13 - lr: 0.000781
2022-05-20 23:28:56,378 epoch 38 - iter 60/107 - loss 0.05859751 - samples/sec: 204.35 - lr: 0.000781
2022-05-20 23:28:57,901 epoch 38 - iter 70/107 - loss 0.05824672 - samples/sec: 210.27 - lr: 0.000781
2022-05-20 23:28:59,492 epoch 38 - iter 80/107 - loss 0.05684993 - samples/sec: 201.26 - lr: 0.000781
2022-05-20 23:29:01,052 epoch 38 - iter 90/107 - loss 0.05641092 - samples/sec: 205.17 - lr: 0.000781
2022-05-20 23:29:02,578 epoch 38 - iter 100/107 - loss 0.05668175 - samples/sec: 209.86 - lr: 0.000781
2022-05-20 23:29:03,550 ----------------------------------------------------------------------------------------------------
2022-05-20 23:29:03,550 EPOCH 38 done: loss 0.0555 - lr 0.000781
2022-05-20 23:29:08,914 Evaluating as a multi-label problem: False
2022-05-20 23:29:08,926 DEV : loss 0.18513049185276031 - f1-score (micro avg)  0.5278
2022-05-20 23:29:09,020 BAD EPOCHS (no improvement): 3
2022-05-20 23:29:09,022 ----------------------------------------------------------------------------------------------------
2022-05-20 23:29:10,600 epoch 39 - iter 10/107 - loss 0.06044386 - samples/sec: 202.97 - lr: 0.000781
2022-05-20 23:29:12,000 epoch 39 - iter 20/107 - loss 0.05866101 - samples/sec: 228.72 - lr: 0.000781
2022-05-20 23:29:13,530 epoch 39 - iter 30/107 - loss 0.05531362 - samples/sec: 209.35 - lr: 0.000781
2022-05-20 23:29:15,022 epoch 39 - iter 40/107 - loss 0.05566027 - samples/sec: 214.60 - lr: 0.000781
2022-05-20 23:29:16,566 epoch 39 - iter 50/107 - loss 0.05493849 - samples/sec: 207.50 - lr: 0.000781
2022-05-20 23:29:18,090 epoch 39 - iter 60/107 - loss 0.05522523 - samples/sec: 210.13 - lr: 0.000781
2022-05-20 23:29:19,583 epoch 39 - iter 70/107 - loss 0.05454227 - samples/sec: 214.48 - lr: 0.000781
2022-05-20 23:29:21,128 epoch 39 - iter 80/107 - loss 0.05650135 - samples/sec: 207.27 - lr: 0.000781
2022-05-20 23:29:22,667 epoch 39 - iter 90/107 - loss 0.05586863 - samples/sec: 208.01 - lr: 0.000781
2022-05-20 23:29:24,193 epoch 39 - iter 100/107 - loss 0.05476466 - samples/sec: 209.92 - lr: 0.000781
2022-05-20 23:29:25,139 ----------------------------------------------------------------------------------------------------
2022-05-20 23:29:25,139 EPOCH 39 done: loss 0.0549 - lr 0.000781
2022-05-20 23:29:30,969 Evaluating as a multi-label problem: False
2022-05-20 23:29:30,980 DEV : loss 0.18574343621730804 - f1-score (micro avg)  0.5282
2022-05-20 23:29:31,070 Epoch    39: reducing learning rate of group 0 to 3.9063e-04.
2022-05-20 23:29:31,070 BAD EPOCHS (no improvement): 4
2022-05-20 23:29:31,072 ----------------------------------------------------------------------------------------------------
2022-05-20 23:29:34,044 epoch 40 - iter 10/107 - loss 0.05956765 - samples/sec: 107.73 - lr: 0.000391
2022-05-20 23:29:37,173 epoch 40 - iter 20/107 - loss 0.06019315 - samples/sec: 102.31 - lr: 0.000391
2022-05-20 23:29:40,312 epoch 40 - iter 30/107 - loss 0.05804813 - samples/sec: 101.98 - lr: 0.000391
2022-05-20 23:29:43,235 epoch 40 - iter 40/107 - loss 0.05827985 - samples/sec: 109.50 - lr: 0.000391
2022-05-20 23:29:46,408 epoch 40 - iter 50/107 - loss 0.05858615 - samples/sec: 100.91 - lr: 0.000391
2022-05-20 23:29:49,292 epoch 40 - iter 60/107 - loss 0.05717303 - samples/sec: 110.97 - lr: 0.000391
2022-05-20 23:29:52,212 epoch 40 - iter 70/107 - loss 0.05740687 - samples/sec: 109.68 - lr: 0.000391
2022-05-20 23:29:55,129 epoch 40 - iter 80/107 - loss 0.05507638 - samples/sec: 109.74 - lr: 0.000391
2022-05-20 23:29:58,252 epoch 40 - iter 90/107 - loss 0.05529917 - samples/sec: 102.51 - lr: 0.000391
2022-05-20 23:30:01,262 epoch 40 - iter 100/107 - loss 0.05477083 - samples/sec: 106.35 - lr: 0.000391
2022-05-20 23:30:03,305 ----------------------------------------------------------------------------------------------------
2022-05-20 23:30:03,305 EPOCH 40 done: loss 0.0548 - lr 0.000391
2022-05-20 23:30:11,265 Evaluating as a multi-label problem: False
2022-05-20 23:30:11,277 DEV : loss 0.18581199645996094 - f1-score (micro avg)  0.5279
2022-05-20 23:30:11,369 BAD EPOCHS (no improvement): 1
2022-05-20 23:30:11,405 ----------------------------------------------------------------------------------------------------
2022-05-20 23:30:14,163 epoch 41 - iter 10/107 - loss 0.04938202 - samples/sec: 116.11 - lr: 0.000391
2022-05-20 23:30:16,705 epoch 41 - iter 20/107 - loss 0.05459428 - samples/sec: 125.93 - lr: 0.000391
2022-05-20 23:30:19,303 epoch 41 - iter 30/107 - loss 0.05499840 - samples/sec: 123.22 - lr: 0.000391
2022-05-20 23:30:22,232 epoch 41 - iter 40/107 - loss 0.05143724 - samples/sec: 109.29 - lr: 0.000391
2022-05-20 23:30:25,113 epoch 41 - iter 50/107 - loss 0.05059728 - samples/sec: 111.12 - lr: 0.000391
2022-05-20 23:30:28,061 epoch 41 - iter 60/107 - loss 0.05242760 - samples/sec: 108.57 - lr: 0.000391
2022-05-20 23:30:30,960 epoch 41 - iter 70/107 - loss 0.05343524 - samples/sec: 110.45 - lr: 0.000391
2022-05-20 23:30:33,977 epoch 41 - iter 80/107 - loss 0.05491767 - samples/sec: 106.10 - lr: 0.000391
2022-05-20 23:30:37,068 epoch 41 - iter 90/107 - loss 0.05441601 - samples/sec: 103.56 - lr: 0.000391
2022-05-20 23:30:40,065 epoch 41 - iter 100/107 - loss 0.05416977 - samples/sec: 106.81 - lr: 0.000391
2022-05-20 23:30:41,915 ----------------------------------------------------------------------------------------------------
2022-05-20 23:30:41,915 EPOCH 41 done: loss 0.0540 - lr 0.000391
2022-05-20 23:30:50,089 Evaluating as a multi-label problem: False
2022-05-20 23:30:50,101 DEV : loss 0.1856851428747177 - f1-score (micro avg)  0.5275
2022-05-20 23:30:50,193 BAD EPOCHS (no improvement): 2
2022-05-20 23:30:50,331 ----------------------------------------------------------------------------------------------------
2022-05-20 23:30:53,311 epoch 42 - iter 10/107 - loss 0.06725788 - samples/sec: 107.44 - lr: 0.000391
2022-05-20 23:30:56,294 epoch 42 - iter 20/107 - loss 0.06615662 - samples/sec: 107.33 - lr: 0.000391
2022-05-20 23:30:59,044 epoch 42 - iter 30/107 - loss 0.06370051 - samples/sec: 116.40 - lr: 0.000391
2022-05-20 23:31:01,679 epoch 42 - iter 40/107 - loss 0.06344504 - samples/sec: 121.54 - lr: 0.000391
2022-05-20 23:31:04,356 epoch 42 - iter 50/107 - loss 0.06093427 - samples/sec: 119.57 - lr: 0.000391
2022-05-20 23:31:07,010 epoch 42 - iter 60/107 - loss 0.05926407 - samples/sec: 120.60 - lr: 0.000391
2022-05-20 23:31:09,568 epoch 42 - iter 70/107 - loss 0.05779687 - samples/sec: 125.17 - lr: 0.000391
2022-05-20 23:31:10,931 epoch 42 - iter 80/107 - loss 0.05696600 - samples/sec: 234.85 - lr: 0.000391
2022-05-20 23:31:12,418 epoch 42 - iter 90/107 - loss 0.05689188 - samples/sec: 215.44 - lr: 0.000391
2022-05-20 23:31:13,876 epoch 42 - iter 100/107 - loss 0.05618121 - samples/sec: 219.66 - lr: 0.000391
2022-05-20 23:31:14,758 ----------------------------------------------------------------------------------------------------
2022-05-20 23:31:14,758 EPOCH 42 done: loss 0.0561 - lr 0.000391
2022-05-20 23:31:19,977 Evaluating as a multi-label problem: False
2022-05-20 23:31:19,989 DEV : loss 0.18548719584941864 - f1-score (micro avg)  0.5275
2022-05-20 23:31:20,080 BAD EPOCHS (no improvement): 3
2022-05-20 23:31:20,082 ----------------------------------------------------------------------------------------------------
2022-05-20 23:31:21,644 epoch 43 - iter 10/107 - loss 0.06045724 - samples/sec: 205.07 - lr: 0.000391
2022-05-20 23:31:23,110 epoch 43 - iter 20/107 - loss 0.05589420 - samples/sec: 218.48 - lr: 0.000391
2022-05-20 23:31:24,670 epoch 43 - iter 30/107 - loss 0.05552090 - samples/sec: 205.22 - lr: 0.000391
2022-05-20 23:31:26,181 epoch 43 - iter 40/107 - loss 0.05457343 - samples/sec: 211.95 - lr: 0.000391
2022-05-20 23:31:27,768 epoch 43 - iter 50/107 - loss 0.05382453 - samples/sec: 201.82 - lr: 0.000391
2022-05-20 23:31:29,322 epoch 43 - iter 60/107 - loss 0.05311180 - samples/sec: 206.16 - lr: 0.000391
2022-05-20 23:31:30,883 epoch 43 - iter 70/107 - loss 0.05254753 - samples/sec: 205.08 - lr: 0.000391
2022-05-20 23:31:32,420 epoch 43 - iter 80/107 - loss 0.05160093 - samples/sec: 208.39 - lr: 0.000391
2022-05-20 23:31:33,925 epoch 43 - iter 90/107 - loss 0.05100750 - samples/sec: 212.85 - lr: 0.000391
2022-05-20 23:31:35,388 epoch 43 - iter 100/107 - loss 0.05190568 - samples/sec: 218.86 - lr: 0.000391
2022-05-20 23:31:36,261 ----------------------------------------------------------------------------------------------------
2022-05-20 23:31:36,261 EPOCH 43 done: loss 0.0526 - lr 0.000391
2022-05-20 23:31:41,349 Evaluating as a multi-label problem: False
2022-05-20 23:31:41,361 DEV : loss 0.1851382553577423 - f1-score (micro avg)  0.5274
2022-05-20 23:31:41,452 Epoch    43: reducing learning rate of group 0 to 1.9531e-04.
2022-05-20 23:31:41,452 BAD EPOCHS (no improvement): 4
2022-05-20 23:31:41,454 ----------------------------------------------------------------------------------------------------
2022-05-20 23:31:42,953 epoch 44 - iter 10/107 - loss 0.06839772 - samples/sec: 213.76 - lr: 0.000195
2022-05-20 23:31:44,382 epoch 44 - iter 20/107 - loss 0.06533374 - samples/sec: 224.10 - lr: 0.000195
2022-05-20 23:31:45,772 epoch 44 - iter 30/107 - loss 0.06274285 - samples/sec: 230.29 - lr: 0.000195
2022-05-20 23:31:47,224 epoch 44 - iter 40/107 - loss 0.06159152 - samples/sec: 220.58 - lr: 0.000195
2022-05-20 23:31:48,835 epoch 44 - iter 50/107 - loss 0.06102864 - samples/sec: 198.74 - lr: 0.000195
2022-05-20 23:31:50,472 epoch 44 - iter 60/107 - loss 0.05810358 - samples/sec: 195.65 - lr: 0.000195
2022-05-20 23:31:52,047 epoch 44 - iter 70/107 - loss 0.05798155 - samples/sec: 203.35 - lr: 0.000195
2022-05-20 23:31:53,611 epoch 44 - iter 80/107 - loss 0.05711268 - samples/sec: 204.75 - lr: 0.000195
2022-05-20 23:31:55,662 epoch 44 - iter 90/107 - loss 0.05693471 - samples/sec: 156.04 - lr: 0.000195
2022-05-20 23:31:58,609 epoch 44 - iter 100/107 - loss 0.05668521 - samples/sec: 108.65 - lr: 0.000195
2022-05-20 23:32:00,388 ----------------------------------------------------------------------------------------------------
2022-05-20 23:32:00,388 EPOCH 44 done: loss 0.0566 - lr 0.000195
2022-05-20 23:32:08,676 Evaluating as a multi-label problem: False
2022-05-20 23:32:08,688 DEV : loss 0.1851215809583664 - f1-score (micro avg)  0.5278
2022-05-20 23:32:08,779 BAD EPOCHS (no improvement): 1
2022-05-20 23:32:08,840 ----------------------------------------------------------------------------------------------------
2022-05-20 23:32:11,769 epoch 45 - iter 10/107 - loss 0.05303355 - samples/sec: 109.29 - lr: 0.000195
2022-05-20 23:32:14,616 epoch 45 - iter 20/107 - loss 0.05128787 - samples/sec: 112.45 - lr: 0.000195
2022-05-20 23:32:17,627 epoch 45 - iter 30/107 - loss 0.05290048 - samples/sec: 106.35 - lr: 0.000195
2022-05-20 23:32:20,622 epoch 45 - iter 40/107 - loss 0.05737628 - samples/sec: 106.88 - lr: 0.000195
2022-05-20 23:32:23,828 epoch 45 - iter 50/107 - loss 0.05621770 - samples/sec: 99.86 - lr: 0.000195
2022-05-20 23:32:26,821 epoch 45 - iter 60/107 - loss 0.05773711 - samples/sec: 106.97 - lr: 0.000195
2022-05-20 23:32:29,624 epoch 45 - iter 70/107 - loss 0.05646702 - samples/sec: 114.19 - lr: 0.000195
2022-05-20 23:32:32,541 epoch 45 - iter 80/107 - loss 0.05541696 - samples/sec: 109.73 - lr: 0.000195
2022-05-20 23:32:35,265 epoch 45 - iter 90/107 - loss 0.05560712 - samples/sec: 117.53 - lr: 0.000195
2022-05-20 23:32:37,856 epoch 45 - iter 100/107 - loss 0.05527463 - samples/sec: 123.54 - lr: 0.000195
2022-05-20 23:32:39,449 ----------------------------------------------------------------------------------------------------
2022-05-20 23:32:39,449 EPOCH 45 done: loss 0.0555 - lr 0.000195
2022-05-20 23:32:47,876 Evaluating as a multi-label problem: False
2022-05-20 23:32:47,887 DEV : loss 0.1854754239320755 - f1-score (micro avg)  0.5282
2022-05-20 23:32:47,980 BAD EPOCHS (no improvement): 2
2022-05-20 23:32:47,981 ----------------------------------------------------------------------------------------------------
2022-05-20 23:32:49,626 epoch 46 - iter 10/107 - loss 0.05052185 - samples/sec: 194.80 - lr: 0.000195
2022-05-20 23:32:51,105 epoch 46 - iter 20/107 - loss 0.05208719 - samples/sec: 216.49 - lr: 0.000195
2022-05-20 23:32:52,629 epoch 46 - iter 30/107 - loss 0.05422314 - samples/sec: 210.12 - lr: 0.000195
2022-05-20 23:32:54,243 epoch 46 - iter 40/107 - loss 0.05618781 - samples/sec: 198.44 - lr: 0.000195
2022-05-20 23:32:55,834 epoch 46 - iter 50/107 - loss 0.05458735 - samples/sec: 201.27 - lr: 0.000195
2022-05-20 23:32:57,388 epoch 46 - iter 60/107 - loss 0.05686246 - samples/sec: 205.95 - lr: 0.000195
2022-05-20 23:32:58,933 epoch 46 - iter 70/107 - loss 0.05602308 - samples/sec: 207.32 - lr: 0.000195
2022-05-20 23:33:00,510 epoch 46 - iter 80/107 - loss 0.05550816 - samples/sec: 203.10 - lr: 0.000195
2022-05-20 23:33:02,035 epoch 46 - iter 90/107 - loss 0.05521226 - samples/sec: 209.94 - lr: 0.000195
2022-05-20 23:33:03,496 epoch 46 - iter 100/107 - loss 0.05491944 - samples/sec: 219.22 - lr: 0.000195
2022-05-20 23:33:04,439 ----------------------------------------------------------------------------------------------------
2022-05-20 23:33:04,439 EPOCH 46 done: loss 0.0544 - lr 0.000195
2022-05-20 23:33:09,676 Evaluating as a multi-label problem: False
2022-05-20 23:33:09,687 DEV : loss 0.18533381819725037 - f1-score (micro avg)  0.5282
2022-05-20 23:33:09,778 BAD EPOCHS (no improvement): 3
2022-05-20 23:33:09,780 ----------------------------------------------------------------------------------------------------
2022-05-20 23:33:11,313 epoch 47 - iter 10/107 - loss 0.04920011 - samples/sec: 209.04 - lr: 0.000195
2022-05-20 23:33:12,837 epoch 47 - iter 20/107 - loss 0.04895766 - samples/sec: 210.13 - lr: 0.000195
2022-05-20 23:33:14,289 epoch 47 - iter 30/107 - loss 0.05269729 - samples/sec: 220.45 - lr: 0.000195
2022-05-20 23:33:15,746 epoch 47 - iter 40/107 - loss 0.05501205 - samples/sec: 219.78 - lr: 0.000195
2022-05-20 23:33:17,334 epoch 47 - iter 50/107 - loss 0.05405298 - samples/sec: 201.68 - lr: 0.000195
2022-05-20 23:33:18,911 epoch 47 - iter 60/107 - loss 0.05412932 - samples/sec: 203.16 - lr: 0.000195
2022-05-20 23:33:20,496 epoch 47 - iter 70/107 - loss 0.05445826 - samples/sec: 201.96 - lr: 0.000195
2022-05-20 23:33:22,088 epoch 47 - iter 80/107 - loss 0.05493081 - samples/sec: 201.09 - lr: 0.000195
2022-05-20 23:33:23,698 epoch 47 - iter 90/107 - loss 0.05451327 - samples/sec: 198.92 - lr: 0.000195
2022-05-20 23:33:25,272 epoch 47 - iter 100/107 - loss 0.05504084 - samples/sec: 203.51 - lr: 0.000195
2022-05-20 23:33:26,298 ----------------------------------------------------------------------------------------------------
2022-05-20 23:33:26,298 EPOCH 47 done: loss 0.0554 - lr 0.000195
2022-05-20 23:33:33,309 Evaluating as a multi-label problem: False
2022-05-20 23:33:33,320 DEV : loss 0.18555013835430145 - f1-score (micro avg)  0.5278
2022-05-20 23:33:33,411 Epoch    47: reducing learning rate of group 0 to 9.7656e-05.
2022-05-20 23:33:33,411 BAD EPOCHS (no improvement): 4
2022-05-20 23:33:33,471 ----------------------------------------------------------------------------------------------------
2022-05-20 23:33:33,471 ----------------------------------------------------------------------------------------------------
2022-05-20 23:33:33,471 learning rate too small - quitting training!
2022-05-20 23:33:33,471 ----------------------------------------------------------------------------------------------------
2022-05-20 23:33:52,224 ----------------------------------------------------------------------------------------------------
2022-05-20 23:33:52,225 loading file resources/taggers/model_08_r13_run_2/best-model.pt
2022-05-20 23:34:02,492 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-05-20 23:34:22,241 Evaluating as a multi-label problem: False
2022-05-20 23:34:22,254 0.5615	0.3299	0.4156	0.2839
2022-05-20 23:34:22,254 
Results:
- F-score (micro) 0.4156
- F-score (macro) 0.2672
- Accuracy 0.2839

By class:
               precision    recall  f1-score   support

       person     0.6951    0.5315    0.6024       429
     location     0.4815    0.6067    0.5369       150
        group     0.6538    0.1030    0.1780       165
creative-work     0.6667    0.0141    0.0276       142
      product     0.2000    0.0236    0.0423       127
  corporation     0.2055    0.2273    0.2158        66

    micro avg     0.5615    0.3299    0.4156      1079
    macro avg     0.4838    0.2510    0.2672      1079
 weighted avg     0.5671    0.3299    0.3632      1079

2022-05-20 23:34:22,255 ----------------------------------------------------------------------------------------------------
