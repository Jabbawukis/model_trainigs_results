2022-04-28 21:09:52,046 ----------------------------------------------------------------------------------------------------
2022-04-28 21:09:52,046 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_3): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=5072, out_features=5072, bias=True)
  (rnn): LSTM(5072, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-04-28 21:09:52,046 ----------------------------------------------------------------------------------------------------
2022-04-28 21:09:52,047 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-04-28 21:09:52,047 ----------------------------------------------------------------------------------------------------
2022-04-28 21:09:52,047 Parameters:
2022-04-28 21:09:52,047  - learning_rate: "0.100000"
2022-04-28 21:09:52,047  - mini_batch_size: "32"
2022-04-28 21:09:52,047  - patience: "3"
2022-04-28 21:09:52,047  - anneal_factor: "0.5"
2022-04-28 21:09:52,047  - max_epochs: "150"
2022-04-28 21:09:52,047  - shuffle: "True"
2022-04-28 21:09:52,047  - train_with_dev: "False"
2022-04-28 21:09:52,047  - batch_growth_annealing: "False"
2022-04-28 21:09:52,047 ----------------------------------------------------------------------------------------------------
2022-04-28 21:09:52,047 Model training base path: "resources/taggers/model_06_r5_run_3"
2022-04-28 21:09:52,047 ----------------------------------------------------------------------------------------------------
2022-04-28 21:09:52,047 Device: cuda:1
2022-04-28 21:09:52,047 ----------------------------------------------------------------------------------------------------
2022-04-28 21:09:52,047 Embeddings storage mode: cpu
2022-04-28 21:09:52,047 ----------------------------------------------------------------------------------------------------
2022-04-28 21:09:55,096 epoch 1 - iter 10/107 - loss 1.37098821 - samples/sec: 105.01 - lr: 0.100000
2022-04-28 21:09:58,338 epoch 1 - iter 20/107 - loss 0.83024408 - samples/sec: 98.74 - lr: 0.100000
2022-04-28 21:10:01,569 epoch 1 - iter 30/107 - loss 0.65110012 - samples/sec: 99.07 - lr: 0.100000
2022-04-28 21:10:04,739 epoch 1 - iter 40/107 - loss 0.55392087 - samples/sec: 100.97 - lr: 0.100000
2022-04-28 21:10:07,745 epoch 1 - iter 50/107 - loss 0.48873323 - samples/sec: 106.50 - lr: 0.100000
2022-04-28 21:10:10,741 epoch 1 - iter 60/107 - loss 0.45616237 - samples/sec: 106.86 - lr: 0.100000
2022-04-28 21:10:13,828 epoch 1 - iter 70/107 - loss 0.43248302 - samples/sec: 103.69 - lr: 0.100000
2022-04-28 21:10:16,635 epoch 1 - iter 80/107 - loss 0.41915618 - samples/sec: 114.02 - lr: 0.100000
2022-04-28 21:10:19,277 epoch 1 - iter 90/107 - loss 0.41173723 - samples/sec: 121.21 - lr: 0.100000
2022-04-28 21:10:22,077 epoch 1 - iter 100/107 - loss 0.39968479 - samples/sec: 114.32 - lr: 0.100000
2022-04-28 21:10:23,759 ----------------------------------------------------------------------------------------------------
2022-04-28 21:10:23,759 EPOCH 1 done: loss 0.3905 - lr 0.100000
2022-04-28 21:10:33,415 Evaluating as a multi-label problem: False
2022-04-28 21:10:33,426 DEV : loss 0.4407839775085449 - f1-score (micro avg)  0.2465
2022-04-28 21:10:33,515 BAD EPOCHS (no improvement): 0
2022-04-28 21:10:33,518 saving best model
2022-04-28 21:11:34,839 ----------------------------------------------------------------------------------------------------
2022-04-28 21:11:38,169 epoch 2 - iter 10/107 - loss 0.23670946 - samples/sec: 96.16 - lr: 0.100000
2022-04-28 21:11:41,285 epoch 2 - iter 20/107 - loss 0.21345369 - samples/sec: 102.74 - lr: 0.100000
2022-04-28 21:11:44,339 epoch 2 - iter 30/107 - loss 0.21833241 - samples/sec: 104.86 - lr: 0.100000
2022-04-28 21:11:47,378 epoch 2 - iter 40/107 - loss 0.21717489 - samples/sec: 105.32 - lr: 0.100000
2022-04-28 21:11:50,381 epoch 2 - iter 50/107 - loss 0.21746974 - samples/sec: 106.60 - lr: 0.100000
2022-04-28 21:11:53,426 epoch 2 - iter 60/107 - loss 0.21451753 - samples/sec: 105.11 - lr: 0.100000
2022-04-28 21:11:56,509 epoch 2 - iter 70/107 - loss 0.21270988 - samples/sec: 103.84 - lr: 0.100000
2022-04-28 21:11:59,535 epoch 2 - iter 80/107 - loss 0.21083416 - samples/sec: 105.76 - lr: 0.100000
2022-04-28 21:12:02,635 epoch 2 - iter 90/107 - loss 0.20362335 - samples/sec: 103.29 - lr: 0.100000
2022-04-28 21:12:05,727 epoch 2 - iter 100/107 - loss 0.19795039 - samples/sec: 103.52 - lr: 0.100000
2022-04-28 21:12:07,615 ----------------------------------------------------------------------------------------------------
2022-04-28 21:12:07,615 EPOCH 2 done: loss 0.1973 - lr 0.100000
2022-04-28 21:12:17,083 Evaluating as a multi-label problem: False
2022-04-28 21:12:17,094 DEV : loss 0.3658071458339691 - f1-score (micro avg)  0.3572
2022-04-28 21:12:17,179 BAD EPOCHS (no improvement): 0
2022-04-28 21:12:17,182 saving best model
2022-04-28 21:13:21,359 ----------------------------------------------------------------------------------------------------
2022-04-28 21:13:24,568 epoch 3 - iter 10/107 - loss 0.19445295 - samples/sec: 99.77 - lr: 0.100000
2022-04-28 21:13:27,703 epoch 3 - iter 20/107 - loss 0.18024325 - samples/sec: 102.11 - lr: 0.100000
2022-04-28 21:13:30,706 epoch 3 - iter 30/107 - loss 0.18446529 - samples/sec: 106.61 - lr: 0.100000
2022-04-28 21:13:33,822 epoch 3 - iter 40/107 - loss 0.18684019 - samples/sec: 102.74 - lr: 0.100000
2022-04-28 21:13:36,918 epoch 3 - iter 50/107 - loss 0.18083598 - samples/sec: 103.38 - lr: 0.100000
2022-04-28 21:13:39,894 epoch 3 - iter 60/107 - loss 0.17488991 - samples/sec: 107.57 - lr: 0.100000
2022-04-28 21:13:43,121 epoch 3 - iter 70/107 - loss 0.17003326 - samples/sec: 99.21 - lr: 0.100000
2022-04-28 21:13:46,342 epoch 3 - iter 80/107 - loss 0.16928145 - samples/sec: 99.40 - lr: 0.100000
2022-04-28 21:13:49,438 epoch 3 - iter 90/107 - loss 0.17173448 - samples/sec: 103.39 - lr: 0.100000
2022-04-28 21:13:52,555 epoch 3 - iter 100/107 - loss 0.17027929 - samples/sec: 102.71 - lr: 0.100000
2022-04-28 21:13:54,324 ----------------------------------------------------------------------------------------------------
2022-04-28 21:13:54,324 EPOCH 3 done: loss 0.1690 - lr 0.100000
2022-04-28 21:14:03,883 Evaluating as a multi-label problem: False
2022-04-28 21:14:03,895 DEV : loss 0.26575160026550293 - f1-score (micro avg)  0.4853
2022-04-28 21:14:03,985 BAD EPOCHS (no improvement): 0
2022-04-28 21:14:04,000 saving best model
2022-04-28 21:15:00,857 ----------------------------------------------------------------------------------------------------
2022-04-28 21:15:04,092 epoch 4 - iter 10/107 - loss 0.15149060 - samples/sec: 99.01 - lr: 0.100000
2022-04-28 21:15:07,176 epoch 4 - iter 20/107 - loss 0.15707587 - samples/sec: 103.80 - lr: 0.100000
2022-04-28 21:15:10,300 epoch 4 - iter 30/107 - loss 0.15903736 - samples/sec: 102.45 - lr: 0.100000
2022-04-28 21:15:13,392 epoch 4 - iter 40/107 - loss 0.15266842 - samples/sec: 103.56 - lr: 0.100000
2022-04-28 21:15:16,603 epoch 4 - iter 50/107 - loss 0.15118058 - samples/sec: 99.69 - lr: 0.100000
2022-04-28 21:15:19,569 epoch 4 - iter 60/107 - loss 0.15184500 - samples/sec: 107.90 - lr: 0.100000
2022-04-28 21:15:22,363 epoch 4 - iter 70/107 - loss 0.15262147 - samples/sec: 114.58 - lr: 0.100000
2022-04-28 21:15:25,367 epoch 4 - iter 80/107 - loss 0.14988581 - samples/sec: 106.56 - lr: 0.100000
2022-04-28 21:15:28,445 epoch 4 - iter 90/107 - loss 0.15036294 - samples/sec: 104.00 - lr: 0.100000
2022-04-28 21:15:31,321 epoch 4 - iter 100/107 - loss 0.14942676 - samples/sec: 111.30 - lr: 0.100000
2022-04-28 21:15:33,202 ----------------------------------------------------------------------------------------------------
2022-04-28 21:15:33,202 EPOCH 4 done: loss 0.1469 - lr 0.100000
2022-04-28 21:15:42,707 Evaluating as a multi-label problem: False
2022-04-28 21:15:42,718 DEV : loss 0.2510375380516052 - f1-score (micro avg)  0.5004
2022-04-28 21:15:42,807 BAD EPOCHS (no improvement): 0
2022-04-28 21:15:42,820 saving best model
2022-04-28 21:16:38,768 ----------------------------------------------------------------------------------------------------
2022-04-28 21:16:41,952 epoch 5 - iter 10/107 - loss 0.12952484 - samples/sec: 100.57 - lr: 0.100000
2022-04-28 21:16:45,110 epoch 5 - iter 20/107 - loss 0.13922542 - samples/sec: 101.38 - lr: 0.100000
2022-04-28 21:16:48,265 epoch 5 - iter 30/107 - loss 0.13129205 - samples/sec: 101.45 - lr: 0.100000
2022-04-28 21:16:51,334 epoch 5 - iter 40/107 - loss 0.13199171 - samples/sec: 104.32 - lr: 0.100000
2022-04-28 21:16:54,325 epoch 5 - iter 50/107 - loss 0.13204880 - samples/sec: 107.04 - lr: 0.100000
2022-04-28 21:16:57,471 epoch 5 - iter 60/107 - loss 0.13310177 - samples/sec: 101.75 - lr: 0.100000
2022-04-28 21:17:00,458 epoch 5 - iter 70/107 - loss 0.13073945 - samples/sec: 107.17 - lr: 0.100000
2022-04-28 21:17:03,469 epoch 5 - iter 80/107 - loss 0.13208699 - samples/sec: 106.30 - lr: 0.100000
2022-04-28 21:17:06,440 epoch 5 - iter 90/107 - loss 0.13276060 - samples/sec: 107.75 - lr: 0.100000
2022-04-28 21:17:09,514 epoch 5 - iter 100/107 - loss 0.13271510 - samples/sec: 104.13 - lr: 0.100000
2022-04-28 21:17:11,510 ----------------------------------------------------------------------------------------------------
2022-04-28 21:17:11,510 EPOCH 5 done: loss 0.1329 - lr 0.100000
2022-04-28 21:17:20,965 Evaluating as a multi-label problem: False
2022-04-28 21:17:20,976 DEV : loss 0.2413744330406189 - f1-score (micro avg)  0.4391
2022-04-28 21:17:21,067 BAD EPOCHS (no improvement): 1
2022-04-28 21:17:21,090 ----------------------------------------------------------------------------------------------------
2022-04-28 21:17:24,188 epoch 6 - iter 10/107 - loss 0.12740820 - samples/sec: 103.34 - lr: 0.100000
2022-04-28 21:17:27,295 epoch 6 - iter 20/107 - loss 0.11972849 - samples/sec: 103.01 - lr: 0.100000
2022-04-28 21:17:30,325 epoch 6 - iter 30/107 - loss 0.11697203 - samples/sec: 105.64 - lr: 0.100000
2022-04-28 21:17:33,396 epoch 6 - iter 40/107 - loss 0.11836358 - samples/sec: 104.26 - lr: 0.100000
2022-04-28 21:17:36,486 epoch 6 - iter 50/107 - loss 0.12253221 - samples/sec: 103.58 - lr: 0.100000
2022-04-28 21:17:39,477 epoch 6 - iter 60/107 - loss 0.12300660 - samples/sec: 107.04 - lr: 0.100000
2022-04-28 21:17:42,623 epoch 6 - iter 70/107 - loss 0.12382338 - samples/sec: 101.72 - lr: 0.100000
2022-04-28 21:17:45,590 epoch 6 - iter 80/107 - loss 0.12280978 - samples/sec: 107.92 - lr: 0.100000
2022-04-28 21:17:48,741 epoch 6 - iter 90/107 - loss 0.12486216 - samples/sec: 101.56 - lr: 0.100000
2022-04-28 21:17:51,791 epoch 6 - iter 100/107 - loss 0.12648887 - samples/sec: 104.99 - lr: 0.100000
2022-04-28 21:17:53,608 ----------------------------------------------------------------------------------------------------
2022-04-28 21:17:53,608 EPOCH 6 done: loss 0.1250 - lr 0.100000
2022-04-28 21:18:02,901 Evaluating as a multi-label problem: False
2022-04-28 21:18:02,912 DEV : loss 0.242101788520813 - f1-score (micro avg)  0.4756
2022-04-28 21:18:02,998 BAD EPOCHS (no improvement): 2
2022-04-28 21:18:03,001 ----------------------------------------------------------------------------------------------------
2022-04-28 21:18:06,089 epoch 7 - iter 10/107 - loss 0.11388104 - samples/sec: 103.66 - lr: 0.100000
2022-04-28 21:18:09,138 epoch 7 - iter 20/107 - loss 0.11468636 - samples/sec: 104.99 - lr: 0.100000
2022-04-28 21:18:12,234 epoch 7 - iter 30/107 - loss 0.11471193 - samples/sec: 103.39 - lr: 0.100000
2022-04-28 21:18:15,342 epoch 7 - iter 40/107 - loss 0.11357728 - samples/sec: 103.01 - lr: 0.100000
2022-04-28 21:18:18,281 epoch 7 - iter 50/107 - loss 0.11257779 - samples/sec: 108.90 - lr: 0.100000
2022-04-28 21:18:21,271 epoch 7 - iter 60/107 - loss 0.11554919 - samples/sec: 107.06 - lr: 0.100000
2022-04-28 21:18:24,389 epoch 7 - iter 70/107 - loss 0.11504960 - samples/sec: 102.68 - lr: 0.100000
2022-04-28 21:18:27,415 epoch 7 - iter 80/107 - loss 0.11564964 - samples/sec: 105.79 - lr: 0.100000
2022-04-28 21:18:30,568 epoch 7 - iter 90/107 - loss 0.11463303 - samples/sec: 101.50 - lr: 0.100000
2022-04-28 21:18:33,712 epoch 7 - iter 100/107 - loss 0.11317374 - samples/sec: 101.83 - lr: 0.100000
2022-04-28 21:18:35,609 ----------------------------------------------------------------------------------------------------
2022-04-28 21:18:35,609 EPOCH 7 done: loss 0.1145 - lr 0.100000
2022-04-28 21:18:45,012 Evaluating as a multi-label problem: False
2022-04-28 21:18:45,023 DEV : loss 0.20616450905799866 - f1-score (micro avg)  0.5043
2022-04-28 21:18:45,108 BAD EPOCHS (no improvement): 0
2022-04-28 21:18:45,111 saving best model
2022-04-28 21:19:40,672 ----------------------------------------------------------------------------------------------------
2022-04-28 21:19:43,837 epoch 8 - iter 10/107 - loss 0.10462496 - samples/sec: 101.16 - lr: 0.100000
2022-04-28 21:19:46,915 epoch 8 - iter 20/107 - loss 0.10144877 - samples/sec: 104.02 - lr: 0.100000
2022-04-28 21:19:50,040 epoch 8 - iter 30/107 - loss 0.10449384 - samples/sec: 102.42 - lr: 0.100000
2022-04-28 21:19:53,103 epoch 8 - iter 40/107 - loss 0.10238856 - samples/sec: 104.50 - lr: 0.100000
2022-04-28 21:19:56,166 epoch 8 - iter 50/107 - loss 0.10241580 - samples/sec: 104.53 - lr: 0.100000
2022-04-28 21:19:59,219 epoch 8 - iter 60/107 - loss 0.10025050 - samples/sec: 104.86 - lr: 0.100000
2022-04-28 21:20:02,357 epoch 8 - iter 70/107 - loss 0.10104287 - samples/sec: 101.99 - lr: 0.100000
2022-04-28 21:20:05,407 epoch 8 - iter 80/107 - loss 0.10579798 - samples/sec: 104.96 - lr: 0.100000
2022-04-28 21:20:08,492 epoch 8 - iter 90/107 - loss 0.10433329 - samples/sec: 103.77 - lr: 0.100000
2022-04-28 21:20:11,522 epoch 8 - iter 100/107 - loss 0.10618131 - samples/sec: 105.64 - lr: 0.100000
2022-04-28 21:20:13,500 ----------------------------------------------------------------------------------------------------
2022-04-28 21:20:13,500 EPOCH 8 done: loss 0.1081 - lr 0.100000
2022-04-28 21:20:22,972 Evaluating as a multi-label problem: False
2022-04-28 21:20:22,983 DEV : loss 0.26569050550460815 - f1-score (micro avg)  0.4446
2022-04-28 21:20:23,069 BAD EPOCHS (no improvement): 1
2022-04-28 21:20:23,072 ----------------------------------------------------------------------------------------------------
2022-04-28 21:20:26,211 epoch 9 - iter 10/107 - loss 0.09100122 - samples/sec: 101.98 - lr: 0.100000
2022-04-28 21:20:29,281 epoch 9 - iter 20/107 - loss 0.09192659 - samples/sec: 104.27 - lr: 0.100000
2022-04-28 21:20:32,356 epoch 9 - iter 30/107 - loss 0.09249786 - samples/sec: 104.09 - lr: 0.100000
2022-04-28 21:20:35,490 epoch 9 - iter 40/107 - loss 0.09423696 - samples/sec: 102.15 - lr: 0.100000
2022-04-28 21:20:38,614 epoch 9 - iter 50/107 - loss 0.09442159 - samples/sec: 102.45 - lr: 0.100000
2022-04-28 21:20:41,556 epoch 9 - iter 60/107 - loss 0.09478736 - samples/sec: 108.79 - lr: 0.100000
2022-04-28 21:20:44,602 epoch 9 - iter 70/107 - loss 0.09583729 - samples/sec: 105.10 - lr: 0.100000
2022-04-28 21:20:47,578 epoch 9 - iter 80/107 - loss 0.09521329 - samples/sec: 107.58 - lr: 0.100000
2022-04-28 21:20:50,495 epoch 9 - iter 90/107 - loss 0.09474193 - samples/sec: 109.71 - lr: 0.100000
2022-04-28 21:20:53,254 epoch 9 - iter 100/107 - loss 0.09745681 - samples/sec: 116.07 - lr: 0.100000
2022-04-28 21:20:55,029 ----------------------------------------------------------------------------------------------------
2022-04-28 21:20:55,029 EPOCH 9 done: loss 0.0996 - lr 0.100000
2022-04-28 21:21:04,344 Evaluating as a multi-label problem: False
2022-04-28 21:21:04,355 DEV : loss 0.21661394834518433 - f1-score (micro avg)  0.4875
2022-04-28 21:21:04,442 BAD EPOCHS (no improvement): 2
2022-04-28 21:21:04,445 ----------------------------------------------------------------------------------------------------
2022-04-28 21:21:07,583 epoch 10 - iter 10/107 - loss 0.08508299 - samples/sec: 102.02 - lr: 0.100000
2022-04-28 21:21:10,614 epoch 10 - iter 20/107 - loss 0.08511071 - samples/sec: 105.60 - lr: 0.100000
2022-04-28 21:21:13,736 epoch 10 - iter 30/107 - loss 0.08382559 - samples/sec: 102.55 - lr: 0.100000
2022-04-28 21:21:16,863 epoch 10 - iter 40/107 - loss 0.08968175 - samples/sec: 102.36 - lr: 0.100000
2022-04-28 21:21:20,007 epoch 10 - iter 50/107 - loss 0.09142889 - samples/sec: 101.81 - lr: 0.100000
2022-04-28 21:21:23,087 epoch 10 - iter 60/107 - loss 0.09227150 - samples/sec: 103.93 - lr: 0.100000
2022-04-28 21:21:26,202 epoch 10 - iter 70/107 - loss 0.09509991 - samples/sec: 102.78 - lr: 0.100000
2022-04-28 21:21:29,297 epoch 10 - iter 80/107 - loss 0.09639378 - samples/sec: 103.41 - lr: 0.100000
2022-04-28 21:21:32,332 epoch 10 - iter 90/107 - loss 0.09535301 - samples/sec: 105.48 - lr: 0.100000
2022-04-28 21:21:35,345 epoch 10 - iter 100/107 - loss 0.09446997 - samples/sec: 106.25 - lr: 0.100000
2022-04-28 21:21:37,227 ----------------------------------------------------------------------------------------------------
2022-04-28 21:21:37,228 EPOCH 10 done: loss 0.0952 - lr 0.100000
2022-04-28 21:21:46,631 Evaluating as a multi-label problem: False
2022-04-28 21:21:46,642 DEV : loss 0.2155049592256546 - f1-score (micro avg)  0.4887
2022-04-28 21:21:46,731 BAD EPOCHS (no improvement): 3
2022-04-28 21:21:46,734 ----------------------------------------------------------------------------------------------------
2022-04-28 21:21:49,722 epoch 11 - iter 10/107 - loss 0.08646228 - samples/sec: 107.16 - lr: 0.100000
2022-04-28 21:21:52,883 epoch 11 - iter 20/107 - loss 0.10234270 - samples/sec: 101.26 - lr: 0.100000
2022-04-28 21:21:56,088 epoch 11 - iter 30/107 - loss 0.09409068 - samples/sec: 99.88 - lr: 0.100000
2022-04-28 21:21:59,210 epoch 11 - iter 40/107 - loss 0.09311006 - samples/sec: 102.53 - lr: 0.100000
2022-04-28 21:22:02,255 epoch 11 - iter 50/107 - loss 0.08962459 - samples/sec: 105.16 - lr: 0.100000
2022-04-28 21:22:05,420 epoch 11 - iter 60/107 - loss 0.09197655 - samples/sec: 101.13 - lr: 0.100000
2022-04-28 21:22:08,540 epoch 11 - iter 70/107 - loss 0.09058800 - samples/sec: 102.62 - lr: 0.100000
2022-04-28 21:22:11,596 epoch 11 - iter 80/107 - loss 0.09038544 - samples/sec: 104.73 - lr: 0.100000
2022-04-28 21:22:14,792 epoch 11 - iter 90/107 - loss 0.09109788 - samples/sec: 100.16 - lr: 0.100000
2022-04-28 21:22:17,956 epoch 11 - iter 100/107 - loss 0.08944329 - samples/sec: 101.17 - lr: 0.100000
2022-04-28 21:22:19,824 ----------------------------------------------------------------------------------------------------
2022-04-28 21:22:19,825 EPOCH 11 done: loss 0.0892 - lr 0.100000
2022-04-28 21:22:29,254 Evaluating as a multi-label problem: False
2022-04-28 21:22:29,266 DEV : loss 0.2294805496931076 - f1-score (micro avg)  0.4932
2022-04-28 21:22:29,352 Epoch    11: reducing learning rate of group 0 to 5.0000e-02.
2022-04-28 21:22:29,352 BAD EPOCHS (no improvement): 4
2022-04-28 21:22:29,354 ----------------------------------------------------------------------------------------------------
2022-04-28 21:22:32,412 epoch 12 - iter 10/107 - loss 0.07237928 - samples/sec: 104.70 - lr: 0.050000
2022-04-28 21:22:35,553 epoch 12 - iter 20/107 - loss 0.07631650 - samples/sec: 101.92 - lr: 0.050000
2022-04-28 21:22:38,683 epoch 12 - iter 30/107 - loss 0.07543703 - samples/sec: 102.28 - lr: 0.050000
2022-04-28 21:22:41,786 epoch 12 - iter 40/107 - loss 0.07425346 - samples/sec: 103.15 - lr: 0.050000
2022-04-28 21:22:44,887 epoch 12 - iter 50/107 - loss 0.07574206 - samples/sec: 103.21 - lr: 0.050000
2022-04-28 21:22:47,978 epoch 12 - iter 60/107 - loss 0.07738688 - samples/sec: 103.57 - lr: 0.050000
2022-04-28 21:22:51,091 epoch 12 - iter 70/107 - loss 0.07558735 - samples/sec: 102.84 - lr: 0.050000
2022-04-28 21:22:54,215 epoch 12 - iter 80/107 - loss 0.07824181 - samples/sec: 102.44 - lr: 0.050000
2022-04-28 21:22:57,325 epoch 12 - iter 90/107 - loss 0.07827647 - samples/sec: 102.95 - lr: 0.050000
2022-04-28 21:23:00,314 epoch 12 - iter 100/107 - loss 0.07952728 - samples/sec: 107.12 - lr: 0.050000
2022-04-28 21:23:02,238 ----------------------------------------------------------------------------------------------------
2022-04-28 21:23:02,238 EPOCH 12 done: loss 0.0800 - lr 0.050000
2022-04-28 21:23:11,749 Evaluating as a multi-label problem: False
2022-04-28 21:23:11,762 DEV : loss 0.18822365999221802 - f1-score (micro avg)  0.5392
2022-04-28 21:23:11,854 BAD EPOCHS (no improvement): 0
2022-04-28 21:23:11,857 saving best model
2022-04-28 21:24:08,330 ----------------------------------------------------------------------------------------------------
2022-04-28 21:24:11,612 epoch 13 - iter 10/107 - loss 0.07756866 - samples/sec: 97.57 - lr: 0.050000
2022-04-28 21:24:14,573 epoch 13 - iter 20/107 - loss 0.07519259 - samples/sec: 108.10 - lr: 0.050000
2022-04-28 21:24:17,550 epoch 13 - iter 30/107 - loss 0.07521375 - samples/sec: 107.56 - lr: 0.050000
2022-04-28 21:24:20,684 epoch 13 - iter 40/107 - loss 0.07477543 - samples/sec: 102.12 - lr: 0.050000
2022-04-28 21:24:23,656 epoch 13 - iter 50/107 - loss 0.07559775 - samples/sec: 107.70 - lr: 0.050000
2022-04-28 21:24:26,688 epoch 13 - iter 60/107 - loss 0.07553615 - samples/sec: 105.60 - lr: 0.050000
2022-04-28 21:24:29,925 epoch 13 - iter 70/107 - loss 0.07560539 - samples/sec: 98.89 - lr: 0.050000
2022-04-28 21:24:32,920 epoch 13 - iter 80/107 - loss 0.07444087 - samples/sec: 106.84 - lr: 0.050000
2022-04-28 21:24:36,105 epoch 13 - iter 90/107 - loss 0.07530122 - samples/sec: 100.51 - lr: 0.050000
2022-04-28 21:24:39,180 epoch 13 - iter 100/107 - loss 0.07480916 - samples/sec: 104.11 - lr: 0.050000
2022-04-28 21:24:41,022 ----------------------------------------------------------------------------------------------------
2022-04-28 21:24:41,022 EPOCH 13 done: loss 0.0758 - lr 0.050000
2022-04-28 21:24:50,539 Evaluating as a multi-label problem: False
2022-04-28 21:24:50,551 DEV : loss 0.2011483758687973 - f1-score (micro avg)  0.51
2022-04-28 21:24:50,637 BAD EPOCHS (no improvement): 1
2022-04-28 21:24:50,784 ----------------------------------------------------------------------------------------------------
2022-04-28 21:24:53,857 epoch 14 - iter 10/107 - loss 0.06737372 - samples/sec: 104.21 - lr: 0.050000
2022-04-28 21:24:56,956 epoch 14 - iter 20/107 - loss 0.07525563 - samples/sec: 103.29 - lr: 0.050000
2022-04-28 21:24:59,979 epoch 14 - iter 30/107 - loss 0.07567893 - samples/sec: 105.87 - lr: 0.050000
2022-04-28 21:25:03,021 epoch 14 - iter 40/107 - loss 0.07938966 - samples/sec: 105.23 - lr: 0.050000
2022-04-28 21:25:06,094 epoch 14 - iter 50/107 - loss 0.07765668 - samples/sec: 104.19 - lr: 0.050000
2022-04-28 21:25:09,073 epoch 14 - iter 60/107 - loss 0.07544476 - samples/sec: 107.45 - lr: 0.050000
2022-04-28 21:25:12,187 epoch 14 - iter 70/107 - loss 0.07274201 - samples/sec: 102.80 - lr: 0.050000
2022-04-28 21:25:15,341 epoch 14 - iter 80/107 - loss 0.07200791 - samples/sec: 101.48 - lr: 0.050000
2022-04-28 21:25:18,416 epoch 14 - iter 90/107 - loss 0.07232033 - samples/sec: 104.09 - lr: 0.050000
2022-04-28 21:25:21,615 epoch 14 - iter 100/107 - loss 0.07223764 - samples/sec: 100.05 - lr: 0.050000
2022-04-28 21:25:23,461 ----------------------------------------------------------------------------------------------------
2022-04-28 21:25:23,461 EPOCH 14 done: loss 0.0718 - lr 0.050000
2022-04-28 21:25:32,944 Evaluating as a multi-label problem: False
2022-04-28 21:25:32,955 DEV : loss 0.20774631202220917 - f1-score (micro avg)  0.5106
2022-04-28 21:25:33,043 BAD EPOCHS (no improvement): 2
2022-04-28 21:25:33,045 ----------------------------------------------------------------------------------------------------
2022-04-28 21:25:36,143 epoch 15 - iter 10/107 - loss 0.06122561 - samples/sec: 103.34 - lr: 0.050000
2022-04-28 21:25:39,201 epoch 15 - iter 20/107 - loss 0.06296499 - samples/sec: 104.69 - lr: 0.050000
2022-04-28 21:25:42,255 epoch 15 - iter 30/107 - loss 0.06460674 - samples/sec: 104.80 - lr: 0.050000
2022-04-28 21:25:45,209 epoch 15 - iter 40/107 - loss 0.06640584 - samples/sec: 108.39 - lr: 0.050000
2022-04-28 21:25:48,256 epoch 15 - iter 50/107 - loss 0.06647870 - samples/sec: 105.06 - lr: 0.050000
2022-04-28 21:25:51,148 epoch 15 - iter 60/107 - loss 0.06756808 - samples/sec: 110.71 - lr: 0.050000
2022-04-28 21:25:54,011 epoch 15 - iter 70/107 - loss 0.06719314 - samples/sec: 111.79 - lr: 0.050000
2022-04-28 21:25:56,969 epoch 15 - iter 80/107 - loss 0.06855276 - samples/sec: 108.23 - lr: 0.050000
2022-04-28 21:25:59,999 epoch 15 - iter 90/107 - loss 0.06855093 - samples/sec: 105.64 - lr: 0.050000
2022-04-28 21:26:02,998 epoch 15 - iter 100/107 - loss 0.06845744 - samples/sec: 106.75 - lr: 0.050000
2022-04-28 21:26:04,813 ----------------------------------------------------------------------------------------------------
2022-04-28 21:26:04,813 EPOCH 15 done: loss 0.0683 - lr 0.050000
2022-04-28 21:26:14,215 Evaluating as a multi-label problem: False
2022-04-28 21:26:14,226 DEV : loss 0.20606184005737305 - f1-score (micro avg)  0.509
2022-04-28 21:26:14,315 BAD EPOCHS (no improvement): 3
2022-04-28 21:26:14,318 ----------------------------------------------------------------------------------------------------
2022-04-28 21:26:17,524 epoch 16 - iter 10/107 - loss 0.05925823 - samples/sec: 99.85 - lr: 0.050000
2022-04-28 21:26:20,671 epoch 16 - iter 20/107 - loss 0.05703287 - samples/sec: 101.72 - lr: 0.050000
2022-04-28 21:26:23,800 epoch 16 - iter 30/107 - loss 0.05922637 - samples/sec: 102.29 - lr: 0.050000
2022-04-28 21:26:26,942 epoch 16 - iter 40/107 - loss 0.06215411 - samples/sec: 101.89 - lr: 0.050000
2022-04-28 21:26:29,946 epoch 16 - iter 50/107 - loss 0.06306669 - samples/sec: 106.55 - lr: 0.050000
2022-04-28 21:26:32,894 epoch 16 - iter 60/107 - loss 0.06661059 - samples/sec: 108.59 - lr: 0.050000
2022-04-28 21:26:35,943 epoch 16 - iter 70/107 - loss 0.06814949 - samples/sec: 104.99 - lr: 0.050000
2022-04-28 21:26:39,009 epoch 16 - iter 80/107 - loss 0.06776896 - samples/sec: 104.39 - lr: 0.050000
2022-04-28 21:26:42,094 epoch 16 - iter 90/107 - loss 0.06861106 - samples/sec: 103.77 - lr: 0.050000
2022-04-28 21:26:45,037 epoch 16 - iter 100/107 - loss 0.06773338 - samples/sec: 108.77 - lr: 0.050000
2022-04-28 21:26:46,912 ----------------------------------------------------------------------------------------------------
2022-04-28 21:26:46,912 EPOCH 16 done: loss 0.0679 - lr 0.050000
2022-04-28 21:27:01,593 Evaluating as a multi-label problem: False
2022-04-28 21:27:01,604 DEV : loss 0.21014419198036194 - f1-score (micro avg)  0.5102
2022-04-28 21:27:01,694 Epoch    16: reducing learning rate of group 0 to 2.5000e-02.
2022-04-28 21:27:01,694 BAD EPOCHS (no improvement): 4
2022-04-28 21:27:01,696 ----------------------------------------------------------------------------------------------------
2022-04-28 21:27:04,861 epoch 17 - iter 10/107 - loss 0.06761794 - samples/sec: 101.17 - lr: 0.025000
2022-04-28 21:27:07,960 epoch 17 - iter 20/107 - loss 0.06650955 - samples/sec: 103.27 - lr: 0.025000
2022-04-28 21:27:11,059 epoch 17 - iter 30/107 - loss 0.06510685 - samples/sec: 103.31 - lr: 0.025000
2022-04-28 21:27:14,132 epoch 17 - iter 40/107 - loss 0.06443547 - samples/sec: 104.15 - lr: 0.025000
2022-04-28 21:27:17,251 epoch 17 - iter 50/107 - loss 0.06369312 - samples/sec: 102.64 - lr: 0.025000
2022-04-28 21:27:20,219 epoch 17 - iter 60/107 - loss 0.06353979 - samples/sec: 107.84 - lr: 0.025000
2022-04-28 21:27:23,396 epoch 17 - iter 70/107 - loss 0.06242747 - samples/sec: 100.75 - lr: 0.025000
2022-04-28 21:27:26,330 epoch 17 - iter 80/107 - loss 0.06191281 - samples/sec: 109.11 - lr: 0.025000
2022-04-28 21:27:29,412 epoch 17 - iter 90/107 - loss 0.06200336 - samples/sec: 103.85 - lr: 0.025000
2022-04-28 21:27:32,487 epoch 17 - iter 100/107 - loss 0.06165755 - samples/sec: 104.13 - lr: 0.025000
2022-04-28 21:27:34,334 ----------------------------------------------------------------------------------------------------
2022-04-28 21:27:34,334 EPOCH 17 done: loss 0.0623 - lr 0.025000
2022-04-28 21:27:43,798 Evaluating as a multi-label problem: False
2022-04-28 21:27:43,810 DEV : loss 0.20105305314064026 - f1-score (micro avg)  0.5341
2022-04-28 21:27:43,897 BAD EPOCHS (no improvement): 1
2022-04-28 21:27:43,900 ----------------------------------------------------------------------------------------------------
2022-04-28 21:27:47,019 epoch 18 - iter 10/107 - loss 0.04279409 - samples/sec: 102.66 - lr: 0.025000
2022-04-28 21:27:50,045 epoch 18 - iter 20/107 - loss 0.04957648 - samples/sec: 105.79 - lr: 0.025000
2022-04-28 21:27:53,170 epoch 18 - iter 30/107 - loss 0.05411730 - samples/sec: 102.44 - lr: 0.025000
2022-04-28 21:27:56,208 epoch 18 - iter 40/107 - loss 0.05146930 - samples/sec: 105.36 - lr: 0.025000
2022-04-28 21:27:59,420 epoch 18 - iter 50/107 - loss 0.05307808 - samples/sec: 99.66 - lr: 0.025000
2022-04-28 21:28:02,587 epoch 18 - iter 60/107 - loss 0.05369000 - samples/sec: 101.07 - lr: 0.025000
2022-04-28 21:28:05,481 epoch 18 - iter 70/107 - loss 0.05672089 - samples/sec: 110.63 - lr: 0.025000
2022-04-28 21:28:08,465 epoch 18 - iter 80/107 - loss 0.05733452 - samples/sec: 107.25 - lr: 0.025000
2022-04-28 21:28:11,562 epoch 18 - iter 90/107 - loss 0.05808842 - samples/sec: 103.38 - lr: 0.025000
2022-04-28 21:28:14,614 epoch 18 - iter 100/107 - loss 0.05810294 - samples/sec: 104.88 - lr: 0.025000
2022-04-28 21:28:16,642 ----------------------------------------------------------------------------------------------------
2022-04-28 21:28:16,642 EPOCH 18 done: loss 0.0578 - lr 0.025000
2022-04-28 21:28:26,182 Evaluating as a multi-label problem: False
2022-04-28 21:28:26,193 DEV : loss 0.21203424036502838 - f1-score (micro avg)  0.5148
2022-04-28 21:28:26,281 BAD EPOCHS (no improvement): 2
2022-04-28 21:28:26,283 ----------------------------------------------------------------------------------------------------
2022-04-28 21:28:29,417 epoch 19 - iter 10/107 - loss 0.06486174 - samples/sec: 102.14 - lr: 0.025000
2022-04-28 21:28:32,444 epoch 19 - iter 20/107 - loss 0.06157272 - samples/sec: 105.75 - lr: 0.025000
2022-04-28 21:28:35,519 epoch 19 - iter 30/107 - loss 0.05724220 - samples/sec: 104.08 - lr: 0.025000
2022-04-28 21:28:38,604 epoch 19 - iter 40/107 - loss 0.05868531 - samples/sec: 103.77 - lr: 0.025000
2022-04-28 21:28:41,489 epoch 19 - iter 50/107 - loss 0.05925580 - samples/sec: 110.99 - lr: 0.025000
2022-04-28 21:28:44,530 epoch 19 - iter 60/107 - loss 0.06009964 - samples/sec: 105.27 - lr: 0.025000
2022-04-28 21:28:47,695 epoch 19 - iter 70/107 - loss 0.05862368 - samples/sec: 101.13 - lr: 0.025000
2022-04-28 21:28:50,760 epoch 19 - iter 80/107 - loss 0.05880022 - samples/sec: 104.46 - lr: 0.025000
2022-04-28 21:28:53,803 epoch 19 - iter 90/107 - loss 0.05892825 - samples/sec: 105.19 - lr: 0.025000
2022-04-28 21:28:56,923 epoch 19 - iter 100/107 - loss 0.05947113 - samples/sec: 102.61 - lr: 0.025000
2022-04-28 21:28:58,814 ----------------------------------------------------------------------------------------------------
2022-04-28 21:28:58,814 EPOCH 19 done: loss 0.0592 - lr 0.025000
2022-04-28 21:29:08,241 Evaluating as a multi-label problem: False
2022-04-28 21:29:08,253 DEV : loss 0.20665378868579865 - f1-score (micro avg)  0.5285
2022-04-28 21:29:08,339 BAD EPOCHS (no improvement): 3
2022-04-28 21:29:08,342 ----------------------------------------------------------------------------------------------------
2022-04-28 21:29:11,511 epoch 20 - iter 10/107 - loss 0.06917478 - samples/sec: 101.01 - lr: 0.025000
2022-04-28 21:29:14,578 epoch 20 - iter 20/107 - loss 0.06500599 - samples/sec: 104.39 - lr: 0.025000
2022-04-28 21:29:17,561 epoch 20 - iter 30/107 - loss 0.06420378 - samples/sec: 107.29 - lr: 0.025000
2022-04-28 21:29:20,783 epoch 20 - iter 40/107 - loss 0.06133805 - samples/sec: 99.36 - lr: 0.025000
2022-04-28 21:29:23,840 epoch 20 - iter 50/107 - loss 0.05953179 - samples/sec: 104.72 - lr: 0.025000
2022-04-28 21:29:26,848 epoch 20 - iter 60/107 - loss 0.05940298 - samples/sec: 106.41 - lr: 0.025000
2022-04-28 21:29:29,905 epoch 20 - iter 70/107 - loss 0.06035152 - samples/sec: 104.71 - lr: 0.025000
2022-04-28 21:29:32,968 epoch 20 - iter 80/107 - loss 0.05946323 - samples/sec: 104.50 - lr: 0.025000
2022-04-28 21:29:36,015 epoch 20 - iter 90/107 - loss 0.05811857 - samples/sec: 105.07 - lr: 0.025000
2022-04-28 21:29:39,191 epoch 20 - iter 100/107 - loss 0.05752294 - samples/sec: 100.79 - lr: 0.025000
2022-04-28 21:29:41,138 ----------------------------------------------------------------------------------------------------
2022-04-28 21:29:41,138 EPOCH 20 done: loss 0.0583 - lr 0.025000
2022-04-28 21:29:50,535 Evaluating as a multi-label problem: False
2022-04-28 21:29:50,547 DEV : loss 0.20055995881557465 - f1-score (micro avg)  0.5263
2022-04-28 21:29:50,633 Epoch    20: reducing learning rate of group 0 to 1.2500e-02.
2022-04-28 21:29:50,633 BAD EPOCHS (no improvement): 4
2022-04-28 21:29:50,643 ----------------------------------------------------------------------------------------------------
2022-04-28 21:29:53,764 epoch 21 - iter 10/107 - loss 0.05810086 - samples/sec: 102.56 - lr: 0.012500
2022-04-28 21:29:56,960 epoch 21 - iter 20/107 - loss 0.06443612 - samples/sec: 100.17 - lr: 0.012500
2022-04-28 21:30:00,073 epoch 21 - iter 30/107 - loss 0.06133906 - samples/sec: 102.82 - lr: 0.012500
2022-04-28 21:30:03,147 epoch 21 - iter 40/107 - loss 0.05741590 - samples/sec: 104.11 - lr: 0.012500
2022-04-28 21:30:06,179 epoch 21 - iter 50/107 - loss 0.05950532 - samples/sec: 105.60 - lr: 0.012500
2022-04-28 21:30:09,180 epoch 21 - iter 60/107 - loss 0.05834947 - samples/sec: 106.65 - lr: 0.012500
2022-04-28 21:30:12,143 epoch 21 - iter 70/107 - loss 0.05823375 - samples/sec: 108.04 - lr: 0.012500
2022-04-28 21:30:15,309 epoch 21 - iter 80/107 - loss 0.05793472 - samples/sec: 101.12 - lr: 0.012500
2022-04-28 21:30:18,351 epoch 21 - iter 90/107 - loss 0.05780541 - samples/sec: 105.20 - lr: 0.012500
2022-04-28 21:30:21,318 epoch 21 - iter 100/107 - loss 0.05674920 - samples/sec: 107.92 - lr: 0.012500
2022-04-28 21:30:23,178 ----------------------------------------------------------------------------------------------------
2022-04-28 21:30:23,178 EPOCH 21 done: loss 0.0557 - lr 0.012500
2022-04-28 21:30:32,727 Evaluating as a multi-label problem: False
2022-04-28 21:30:32,739 DEV : loss 0.21356157958507538 - f1-score (micro avg)  0.5207
2022-04-28 21:30:32,827 BAD EPOCHS (no improvement): 1
2022-04-28 21:30:32,829 ----------------------------------------------------------------------------------------------------
2022-04-28 21:30:35,970 epoch 22 - iter 10/107 - loss 0.05199154 - samples/sec: 101.93 - lr: 0.012500
2022-04-28 21:30:39,005 epoch 22 - iter 20/107 - loss 0.05021612 - samples/sec: 105.48 - lr: 0.012500
2022-04-28 21:30:42,088 epoch 22 - iter 30/107 - loss 0.05441691 - samples/sec: 103.83 - lr: 0.012500
2022-04-28 21:30:45,216 epoch 22 - iter 40/107 - loss 0.05506352 - samples/sec: 102.36 - lr: 0.012500
2022-04-28 21:30:48,307 epoch 22 - iter 50/107 - loss 0.05516021 - samples/sec: 103.54 - lr: 0.012500
2022-04-28 21:30:51,387 epoch 22 - iter 60/107 - loss 0.05771164 - samples/sec: 103.95 - lr: 0.012500
2022-04-28 21:30:54,630 epoch 22 - iter 70/107 - loss 0.05640637 - samples/sec: 98.71 - lr: 0.012500
2022-04-28 21:30:57,680 epoch 22 - iter 80/107 - loss 0.05647970 - samples/sec: 104.94 - lr: 0.012500
2022-04-28 21:31:00,612 epoch 22 - iter 90/107 - loss 0.05525009 - samples/sec: 109.17 - lr: 0.012500
2022-04-28 21:31:03,448 epoch 22 - iter 100/107 - loss 0.05400312 - samples/sec: 112.90 - lr: 0.012500
2022-04-28 21:31:05,328 ----------------------------------------------------------------------------------------------------
2022-04-28 21:31:05,328 EPOCH 22 done: loss 0.0530 - lr 0.012500
2022-04-28 21:31:14,589 Evaluating as a multi-label problem: False
2022-04-28 21:31:14,600 DEV : loss 0.21308988332748413 - f1-score (micro avg)  0.5267
2022-04-28 21:31:14,686 BAD EPOCHS (no improvement): 2
2022-04-28 21:31:14,689 ----------------------------------------------------------------------------------------------------
2022-04-28 21:31:17,727 epoch 23 - iter 10/107 - loss 0.04799360 - samples/sec: 105.38 - lr: 0.012500
2022-04-28 21:31:20,873 epoch 23 - iter 20/107 - loss 0.04917736 - samples/sec: 101.74 - lr: 0.012500
2022-04-28 21:31:23,894 epoch 23 - iter 30/107 - loss 0.04725523 - samples/sec: 105.96 - lr: 0.012500
2022-04-28 21:31:26,989 epoch 23 - iter 40/107 - loss 0.04838227 - samples/sec: 103.43 - lr: 0.012500
2022-04-28 21:31:29,999 epoch 23 - iter 50/107 - loss 0.04886396 - samples/sec: 106.38 - lr: 0.012500
2022-04-28 21:31:33,067 epoch 23 - iter 60/107 - loss 0.05156524 - samples/sec: 104.33 - lr: 0.012500
2022-04-28 21:31:36,086 epoch 23 - iter 70/107 - loss 0.05254106 - samples/sec: 106.02 - lr: 0.012500
2022-04-28 21:31:39,122 epoch 23 - iter 80/107 - loss 0.05263472 - samples/sec: 105.47 - lr: 0.012500
2022-04-28 21:31:42,160 epoch 23 - iter 90/107 - loss 0.05235750 - samples/sec: 105.35 - lr: 0.012500
2022-04-28 21:31:45,322 epoch 23 - iter 100/107 - loss 0.05249347 - samples/sec: 101.24 - lr: 0.012500
2022-04-28 21:31:47,181 ----------------------------------------------------------------------------------------------------
2022-04-28 21:31:47,181 EPOCH 23 done: loss 0.0521 - lr 0.012500
2022-04-28 21:31:56,610 Evaluating as a multi-label problem: False
2022-04-28 21:31:56,622 DEV : loss 0.2096197009086609 - f1-score (micro avg)  0.5278
2022-04-28 21:31:56,710 BAD EPOCHS (no improvement): 3
2022-04-28 21:31:56,712 ----------------------------------------------------------------------------------------------------
2022-04-28 21:31:59,766 epoch 24 - iter 10/107 - loss 0.05096678 - samples/sec: 104.85 - lr: 0.012500
2022-04-28 21:32:02,881 epoch 24 - iter 20/107 - loss 0.04598120 - samples/sec: 102.74 - lr: 0.012500
2022-04-28 21:32:06,006 epoch 24 - iter 30/107 - loss 0.05019519 - samples/sec: 102.45 - lr: 0.012500
2022-04-28 21:32:09,040 epoch 24 - iter 40/107 - loss 0.05128755 - samples/sec: 105.49 - lr: 0.012500
2022-04-28 21:32:12,036 epoch 24 - iter 50/107 - loss 0.05109395 - samples/sec: 106.86 - lr: 0.012500
2022-04-28 21:32:15,232 epoch 24 - iter 60/107 - loss 0.05117662 - samples/sec: 100.15 - lr: 0.012500
2022-04-28 21:32:18,316 epoch 24 - iter 70/107 - loss 0.05121188 - samples/sec: 103.78 - lr: 0.012500
2022-04-28 21:32:21,300 epoch 24 - iter 80/107 - loss 0.05116404 - samples/sec: 107.28 - lr: 0.012500
2022-04-28 21:32:24,334 epoch 24 - iter 90/107 - loss 0.05186923 - samples/sec: 105.52 - lr: 0.012500
2022-04-28 21:32:27,394 epoch 24 - iter 100/107 - loss 0.05210300 - samples/sec: 104.63 - lr: 0.012500
2022-04-28 21:32:29,343 ----------------------------------------------------------------------------------------------------
2022-04-28 21:32:29,343 EPOCH 24 done: loss 0.0527 - lr 0.012500
2022-04-28 21:32:38,749 Evaluating as a multi-label problem: False
2022-04-28 21:32:38,761 DEV : loss 0.20605231821537018 - f1-score (micro avg)  0.5262
2022-04-28 21:32:38,853 Epoch    24: reducing learning rate of group 0 to 6.2500e-03.
2022-04-28 21:32:38,853 BAD EPOCHS (no improvement): 4
2022-04-28 21:32:38,856 ----------------------------------------------------------------------------------------------------
2022-04-28 21:32:42,220 epoch 25 - iter 10/107 - loss 0.05982988 - samples/sec: 95.17 - lr: 0.006250
2022-04-28 21:32:45,240 epoch 25 - iter 20/107 - loss 0.05355300 - samples/sec: 106.01 - lr: 0.006250
2022-04-28 21:32:48,259 epoch 25 - iter 30/107 - loss 0.05408892 - samples/sec: 106.02 - lr: 0.006250
2022-04-28 21:32:51,350 epoch 25 - iter 40/107 - loss 0.05279311 - samples/sec: 103.55 - lr: 0.006250
2022-04-28 21:32:54,459 epoch 25 - iter 50/107 - loss 0.05154574 - samples/sec: 103.00 - lr: 0.006250
2022-04-28 21:32:57,674 epoch 25 - iter 60/107 - loss 0.05079624 - samples/sec: 99.57 - lr: 0.006250
2022-04-28 21:33:00,767 epoch 25 - iter 70/107 - loss 0.05013024 - samples/sec: 103.48 - lr: 0.006250
2022-04-28 21:33:03,868 epoch 25 - iter 80/107 - loss 0.05015017 - samples/sec: 103.23 - lr: 0.006250
2022-04-28 21:33:06,939 epoch 25 - iter 90/107 - loss 0.04982598 - samples/sec: 104.26 - lr: 0.006250
2022-04-28 21:33:10,066 epoch 25 - iter 100/107 - loss 0.04989988 - samples/sec: 102.36 - lr: 0.006250
2022-04-28 21:33:12,009 ----------------------------------------------------------------------------------------------------
2022-04-28 21:33:12,010 EPOCH 25 done: loss 0.0500 - lr 0.006250
2022-04-28 21:33:21,497 Evaluating as a multi-label problem: False
2022-04-28 21:33:21,508 DEV : loss 0.21008408069610596 - f1-score (micro avg)  0.5242
2022-04-28 21:33:21,595 BAD EPOCHS (no improvement): 1
2022-04-28 21:33:21,598 ----------------------------------------------------------------------------------------------------
2022-04-28 21:33:24,669 epoch 26 - iter 10/107 - loss 0.05042509 - samples/sec: 104.26 - lr: 0.006250
2022-04-28 21:33:27,734 epoch 26 - iter 20/107 - loss 0.04972477 - samples/sec: 104.43 - lr: 0.006250
2022-04-28 21:33:30,828 epoch 26 - iter 30/107 - loss 0.05093210 - samples/sec: 103.45 - lr: 0.006250
2022-04-28 21:33:33,926 epoch 26 - iter 40/107 - loss 0.05014635 - samples/sec: 103.33 - lr: 0.006250
2022-04-28 21:33:36,932 epoch 26 - iter 50/107 - loss 0.05198907 - samples/sec: 106.50 - lr: 0.006250
2022-04-28 21:33:40,061 epoch 26 - iter 60/107 - loss 0.05204883 - samples/sec: 102.30 - lr: 0.006250
2022-04-28 21:33:43,211 epoch 26 - iter 70/107 - loss 0.05298652 - samples/sec: 101.60 - lr: 0.006250
2022-04-28 21:33:46,358 epoch 26 - iter 80/107 - loss 0.05147930 - samples/sec: 101.75 - lr: 0.006250
2022-04-28 21:33:49,501 epoch 26 - iter 90/107 - loss 0.05129335 - samples/sec: 101.82 - lr: 0.006250
2022-04-28 21:33:52,504 epoch 26 - iter 100/107 - loss 0.05074562 - samples/sec: 106.61 - lr: 0.006250
2022-04-28 21:33:54,363 ----------------------------------------------------------------------------------------------------
2022-04-28 21:33:54,364 EPOCH 26 done: loss 0.0506 - lr 0.006250
2022-04-28 21:34:03,839 Evaluating as a multi-label problem: False
2022-04-28 21:34:03,851 DEV : loss 0.21106238663196564 - f1-score (micro avg)  0.5217
2022-04-28 21:34:03,939 BAD EPOCHS (no improvement): 2
2022-04-28 21:34:03,942 ----------------------------------------------------------------------------------------------------
2022-04-28 21:34:07,069 epoch 27 - iter 10/107 - loss 0.05383545 - samples/sec: 102.38 - lr: 0.006250
2022-04-28 21:34:10,236 epoch 27 - iter 20/107 - loss 0.04872325 - samples/sec: 101.09 - lr: 0.006250
2022-04-28 21:34:13,187 epoch 27 - iter 30/107 - loss 0.04688088 - samples/sec: 108.47 - lr: 0.006250
2022-04-28 21:34:16,229 epoch 27 - iter 40/107 - loss 0.04879487 - samples/sec: 105.24 - lr: 0.006250
2022-04-28 21:34:19,277 epoch 27 - iter 50/107 - loss 0.04767653 - samples/sec: 105.00 - lr: 0.006250
2022-04-28 21:34:22,327 epoch 27 - iter 60/107 - loss 0.04730904 - samples/sec: 104.96 - lr: 0.006250
2022-04-28 21:34:25,454 epoch 27 - iter 70/107 - loss 0.04739334 - samples/sec: 102.39 - lr: 0.006250
2022-04-28 21:34:28,468 epoch 27 - iter 80/107 - loss 0.04714445 - samples/sec: 106.18 - lr: 0.006250
2022-04-28 21:34:31,523 epoch 27 - iter 90/107 - loss 0.04836941 - samples/sec: 104.78 - lr: 0.006250
2022-04-28 21:34:34,633 epoch 27 - iter 100/107 - loss 0.04947138 - samples/sec: 102.92 - lr: 0.006250
2022-04-28 21:34:36,524 ----------------------------------------------------------------------------------------------------
2022-04-28 21:34:36,524 EPOCH 27 done: loss 0.0503 - lr 0.006250
2022-04-28 21:34:45,954 Evaluating as a multi-label problem: False
2022-04-28 21:34:45,966 DEV : loss 0.20505072176456451 - f1-score (micro avg)  0.5284
2022-04-28 21:34:46,055 BAD EPOCHS (no improvement): 3
2022-04-28 21:34:46,058 ----------------------------------------------------------------------------------------------------
2022-04-28 21:34:49,061 epoch 28 - iter 10/107 - loss 0.04605024 - samples/sec: 106.62 - lr: 0.006250
2022-04-28 21:34:52,164 epoch 28 - iter 20/107 - loss 0.04355456 - samples/sec: 103.18 - lr: 0.006250
2022-04-28 21:34:55,146 epoch 28 - iter 30/107 - loss 0.05010333 - samples/sec: 107.35 - lr: 0.006250
2022-04-28 21:34:58,072 epoch 28 - iter 40/107 - loss 0.04984220 - samples/sec: 109.41 - lr: 0.006250
2022-04-28 21:35:01,083 epoch 28 - iter 50/107 - loss 0.04810685 - samples/sec: 106.29 - lr: 0.006250
2022-04-28 21:35:04,195 epoch 28 - iter 60/107 - loss 0.04769155 - samples/sec: 102.87 - lr: 0.006250
2022-04-28 21:35:07,347 epoch 28 - iter 70/107 - loss 0.04899645 - samples/sec: 101.54 - lr: 0.006250
2022-04-28 21:35:10,456 epoch 28 - iter 80/107 - loss 0.05003592 - samples/sec: 102.97 - lr: 0.006250
2022-04-28 21:35:13,461 epoch 28 - iter 90/107 - loss 0.05001327 - samples/sec: 106.52 - lr: 0.006250
2022-04-28 21:35:16,446 epoch 28 - iter 100/107 - loss 0.04967323 - samples/sec: 107.25 - lr: 0.006250
2022-04-28 21:35:18,280 ----------------------------------------------------------------------------------------------------
2022-04-28 21:35:18,281 EPOCH 28 done: loss 0.0502 - lr 0.006250
2022-04-28 21:35:27,494 Evaluating as a multi-label problem: False
2022-04-28 21:35:27,505 DEV : loss 0.20804932713508606 - f1-score (micro avg)  0.5268
2022-04-28 21:35:27,591 Epoch    28: reducing learning rate of group 0 to 3.1250e-03.
2022-04-28 21:35:27,591 BAD EPOCHS (no improvement): 4
2022-04-28 21:35:27,600 ----------------------------------------------------------------------------------------------------
2022-04-28 21:35:30,592 epoch 29 - iter 10/107 - loss 0.04446871 - samples/sec: 107.02 - lr: 0.003125
2022-04-28 21:35:33,562 epoch 29 - iter 20/107 - loss 0.04636115 - samples/sec: 107.77 - lr: 0.003125
2022-04-28 21:35:36,552 epoch 29 - iter 30/107 - loss 0.04765456 - samples/sec: 107.05 - lr: 0.003125
2022-04-28 21:35:39,604 epoch 29 - iter 40/107 - loss 0.04922380 - samples/sec: 104.88 - lr: 0.003125
2022-04-28 21:35:42,689 epoch 29 - iter 50/107 - loss 0.04809282 - samples/sec: 103.78 - lr: 0.003125
2022-04-28 21:35:45,751 epoch 29 - iter 60/107 - loss 0.04690455 - samples/sec: 104.55 - lr: 0.003125
2022-04-28 21:35:48,919 epoch 29 - iter 70/107 - loss 0.04801052 - samples/sec: 101.06 - lr: 0.003125
2022-04-28 21:35:51,846 epoch 29 - iter 80/107 - loss 0.04743419 - samples/sec: 109.36 - lr: 0.003125
2022-04-28 21:35:54,874 epoch 29 - iter 90/107 - loss 0.04847134 - samples/sec: 105.72 - lr: 0.003125
2022-04-28 21:35:58,030 epoch 29 - iter 100/107 - loss 0.04794795 - samples/sec: 101.41 - lr: 0.003125
2022-04-28 21:35:59,824 ----------------------------------------------------------------------------------------------------
2022-04-28 21:35:59,824 EPOCH 29 done: loss 0.0486 - lr 0.003125
2022-04-28 21:36:09,301 Evaluating as a multi-label problem: False
2022-04-28 21:36:09,312 DEV : loss 0.20872724056243896 - f1-score (micro avg)  0.525
2022-04-28 21:36:09,398 BAD EPOCHS (no improvement): 1
2022-04-28 21:36:09,401 ----------------------------------------------------------------------------------------------------
2022-04-28 21:36:12,524 epoch 30 - iter 10/107 - loss 0.05247388 - samples/sec: 102.50 - lr: 0.003125
2022-04-28 21:36:15,545 epoch 30 - iter 20/107 - loss 0.05147944 - samples/sec: 105.99 - lr: 0.003125
2022-04-28 21:36:18,526 epoch 30 - iter 30/107 - loss 0.05021638 - samples/sec: 107.37 - lr: 0.003125
2022-04-28 21:36:21,674 epoch 30 - iter 40/107 - loss 0.05133343 - samples/sec: 101.67 - lr: 0.003125
2022-04-28 21:36:24,738 epoch 30 - iter 50/107 - loss 0.05210294 - samples/sec: 104.47 - lr: 0.003125
2022-04-28 21:36:27,765 epoch 30 - iter 60/107 - loss 0.05140898 - samples/sec: 105.77 - lr: 0.003125
2022-04-28 21:36:30,936 epoch 30 - iter 70/107 - loss 0.05143243 - samples/sec: 100.93 - lr: 0.003125
2022-04-28 21:36:33,994 epoch 30 - iter 80/107 - loss 0.05197295 - samples/sec: 104.68 - lr: 0.003125
2022-04-28 21:36:37,059 epoch 30 - iter 90/107 - loss 0.05061226 - samples/sec: 104.43 - lr: 0.003125
2022-04-28 21:36:40,107 epoch 30 - iter 100/107 - loss 0.04922941 - samples/sec: 105.03 - lr: 0.003125
2022-04-28 21:36:42,020 ----------------------------------------------------------------------------------------------------
2022-04-28 21:36:42,020 EPOCH 30 done: loss 0.0490 - lr 0.003125
2022-04-28 21:36:51,382 Evaluating as a multi-label problem: False
2022-04-28 21:36:51,394 DEV : loss 0.21300895512104034 - f1-score (micro avg)  0.5244
2022-04-28 21:36:51,480 BAD EPOCHS (no improvement): 2
2022-04-28 21:36:51,482 ----------------------------------------------------------------------------------------------------
2022-04-28 21:36:54,539 epoch 31 - iter 10/107 - loss 0.06168320 - samples/sec: 104.74 - lr: 0.003125
2022-04-28 21:36:57,652 epoch 31 - iter 20/107 - loss 0.05783660 - samples/sec: 102.82 - lr: 0.003125
2022-04-28 21:37:00,782 epoch 31 - iter 30/107 - loss 0.05563780 - samples/sec: 102.29 - lr: 0.003125
2022-04-28 21:37:03,865 epoch 31 - iter 40/107 - loss 0.05156379 - samples/sec: 103.82 - lr: 0.003125
2022-04-28 21:37:06,870 epoch 31 - iter 50/107 - loss 0.05194502 - samples/sec: 106.53 - lr: 0.003125
2022-04-28 21:37:09,866 epoch 31 - iter 60/107 - loss 0.05066666 - samples/sec: 106.87 - lr: 0.003125
2022-04-28 21:37:12,833 epoch 31 - iter 70/107 - loss 0.05049370 - samples/sec: 107.87 - lr: 0.003125
2022-04-28 21:37:16,011 epoch 31 - iter 80/107 - loss 0.04974492 - samples/sec: 100.73 - lr: 0.003125
2022-04-28 21:37:19,078 epoch 31 - iter 90/107 - loss 0.04988676 - samples/sec: 104.36 - lr: 0.003125
2022-04-28 21:37:22,196 epoch 31 - iter 100/107 - loss 0.04964640 - samples/sec: 102.66 - lr: 0.003125
2022-04-28 21:37:24,017 ----------------------------------------------------------------------------------------------------
2022-04-28 21:37:24,017 EPOCH 31 done: loss 0.0492 - lr 0.003125
2022-04-28 21:37:33,407 Evaluating as a multi-label problem: False
2022-04-28 21:37:33,419 DEV : loss 0.2058137059211731 - f1-score (micro avg)  0.5297
2022-04-28 21:37:33,505 BAD EPOCHS (no improvement): 3
2022-04-28 21:37:33,507 ----------------------------------------------------------------------------------------------------
2022-04-28 21:37:36,446 epoch 32 - iter 10/107 - loss 0.04429160 - samples/sec: 108.95 - lr: 0.003125
2022-04-28 21:37:39,457 epoch 32 - iter 20/107 - loss 0.04354133 - samples/sec: 106.30 - lr: 0.003125
2022-04-28 21:37:42,447 epoch 32 - iter 30/107 - loss 0.04700388 - samples/sec: 107.08 - lr: 0.003125
2022-04-28 21:37:45,589 epoch 32 - iter 40/107 - loss 0.04701627 - samples/sec: 101.87 - lr: 0.003125
2022-04-28 21:37:48,709 epoch 32 - iter 50/107 - loss 0.04866229 - samples/sec: 102.61 - lr: 0.003125
2022-04-28 21:37:51,661 epoch 32 - iter 60/107 - loss 0.04976359 - samples/sec: 108.44 - lr: 0.003125
2022-04-28 21:37:54,736 epoch 32 - iter 70/107 - loss 0.04973593 - samples/sec: 104.08 - lr: 0.003125
2022-04-28 21:37:57,893 epoch 32 - iter 80/107 - loss 0.04868136 - samples/sec: 101.41 - lr: 0.003125
2022-04-28 21:38:00,911 epoch 32 - iter 90/107 - loss 0.04821438 - samples/sec: 106.05 - lr: 0.003125
2022-04-28 21:38:04,037 epoch 32 - iter 100/107 - loss 0.04862148 - samples/sec: 102.39 - lr: 0.003125
2022-04-28 21:38:05,932 ----------------------------------------------------------------------------------------------------
2022-04-28 21:38:05,932 EPOCH 32 done: loss 0.0487 - lr 0.003125
2022-04-28 21:38:15,453 Evaluating as a multi-label problem: False
2022-04-28 21:38:15,465 DEV : loss 0.20871815085411072 - f1-score (micro avg)  0.525
2022-04-28 21:38:15,552 Epoch    32: reducing learning rate of group 0 to 1.5625e-03.
2022-04-28 21:38:15,552 BAD EPOCHS (no improvement): 4
2022-04-28 21:38:15,594 ----------------------------------------------------------------------------------------------------
2022-04-28 21:38:18,762 epoch 33 - iter 10/107 - loss 0.06235198 - samples/sec: 101.05 - lr: 0.001563
2022-04-28 21:38:21,850 epoch 33 - iter 20/107 - loss 0.05306889 - samples/sec: 103.67 - lr: 0.001563
2022-04-28 21:38:24,871 epoch 33 - iter 30/107 - loss 0.05436741 - samples/sec: 105.96 - lr: 0.001563
2022-04-28 21:38:27,913 epoch 33 - iter 40/107 - loss 0.05258480 - samples/sec: 105.21 - lr: 0.001563
2022-04-28 21:38:30,883 epoch 33 - iter 50/107 - loss 0.05044943 - samples/sec: 107.81 - lr: 0.001563
2022-04-28 21:38:33,944 epoch 33 - iter 60/107 - loss 0.04893025 - samples/sec: 104.58 - lr: 0.001563
2022-04-28 21:38:36,961 epoch 33 - iter 70/107 - loss 0.04946996 - samples/sec: 106.10 - lr: 0.001563
2022-04-28 21:38:40,143 epoch 33 - iter 80/107 - loss 0.04899001 - samples/sec: 100.62 - lr: 0.001563
2022-04-28 21:38:43,172 epoch 33 - iter 90/107 - loss 0.04772887 - samples/sec: 105.67 - lr: 0.001563
2022-04-28 21:38:46,169 epoch 33 - iter 100/107 - loss 0.04728923 - samples/sec: 106.81 - lr: 0.001563
2022-04-28 21:38:48,003 ----------------------------------------------------------------------------------------------------
2022-04-28 21:38:48,003 EPOCH 33 done: loss 0.0479 - lr 0.001563
2022-04-28 21:38:57,479 Evaluating as a multi-label problem: False
2022-04-28 21:38:57,491 DEV : loss 0.21104265749454498 - f1-score (micro avg)  0.5224
2022-04-28 21:38:57,579 BAD EPOCHS (no improvement): 1
2022-04-28 21:38:57,582 ----------------------------------------------------------------------------------------------------
2022-04-28 21:39:00,719 epoch 34 - iter 10/107 - loss 0.04683447 - samples/sec: 102.05 - lr: 0.001563
2022-04-28 21:39:03,805 epoch 34 - iter 20/107 - loss 0.04401372 - samples/sec: 103.72 - lr: 0.001563
2022-04-28 21:39:06,908 epoch 34 - iter 30/107 - loss 0.04605564 - samples/sec: 103.15 - lr: 0.001563
2022-04-28 21:39:10,054 epoch 34 - iter 40/107 - loss 0.04626769 - samples/sec: 101.75 - lr: 0.001563
2022-04-28 21:39:13,055 epoch 34 - iter 50/107 - loss 0.04799276 - samples/sec: 106.68 - lr: 0.001563
2022-04-28 21:39:16,078 epoch 34 - iter 60/107 - loss 0.04651961 - samples/sec: 105.86 - lr: 0.001563
2022-04-28 21:39:19,123 epoch 34 - iter 70/107 - loss 0.04722755 - samples/sec: 105.12 - lr: 0.001563
2022-04-28 21:39:22,151 epoch 34 - iter 80/107 - loss 0.04724232 - samples/sec: 105.73 - lr: 0.001563
2022-04-28 21:39:25,166 epoch 34 - iter 90/107 - loss 0.04736930 - samples/sec: 106.18 - lr: 0.001563
2022-04-28 21:39:28,212 epoch 34 - iter 100/107 - loss 0.04865716 - samples/sec: 105.09 - lr: 0.001563
2022-04-28 21:39:30,025 ----------------------------------------------------------------------------------------------------
2022-04-28 21:39:30,025 EPOCH 34 done: loss 0.0484 - lr 0.001563
2022-04-28 21:39:39,432 Evaluating as a multi-label problem: False
2022-04-28 21:39:39,443 DEV : loss 0.20890286564826965 - f1-score (micro avg)  0.5251
2022-04-28 21:39:39,529 BAD EPOCHS (no improvement): 2
2022-04-28 21:39:39,532 ----------------------------------------------------------------------------------------------------
2022-04-28 21:39:42,556 epoch 35 - iter 10/107 - loss 0.03842625 - samples/sec: 105.87 - lr: 0.001563
2022-04-28 21:39:45,663 epoch 35 - iter 20/107 - loss 0.04126808 - samples/sec: 103.05 - lr: 0.001563
2022-04-28 21:39:48,952 epoch 35 - iter 30/107 - loss 0.04263070 - samples/sec: 97.31 - lr: 0.001563
2022-04-28 21:39:51,941 epoch 35 - iter 40/107 - loss 0.04653944 - samples/sec: 107.08 - lr: 0.001563
2022-04-28 21:39:55,061 epoch 35 - iter 50/107 - loss 0.04738066 - samples/sec: 102.63 - lr: 0.001563
2022-04-28 21:39:58,119 epoch 35 - iter 60/107 - loss 0.04793100 - samples/sec: 104.68 - lr: 0.001563
2022-04-28 21:40:01,199 epoch 35 - iter 70/107 - loss 0.04957542 - samples/sec: 103.91 - lr: 0.001563
2022-04-28 21:40:04,284 epoch 35 - iter 80/107 - loss 0.04886682 - samples/sec: 103.76 - lr: 0.001563
2022-04-28 21:40:07,316 epoch 35 - iter 90/107 - loss 0.04930977 - samples/sec: 105.59 - lr: 0.001563
2022-04-28 21:40:10,336 epoch 35 - iter 100/107 - loss 0.04849115 - samples/sec: 106.00 - lr: 0.001563
2022-04-28 21:40:12,202 ----------------------------------------------------------------------------------------------------
2022-04-28 21:40:12,202 EPOCH 35 done: loss 0.0479 - lr 0.001563
2022-04-28 21:40:21,650 Evaluating as a multi-label problem: False
2022-04-28 21:40:21,661 DEV : loss 0.20944608747959137 - f1-score (micro avg)  0.5254
2022-04-28 21:40:21,746 BAD EPOCHS (no improvement): 3
2022-04-28 21:40:21,749 ----------------------------------------------------------------------------------------------------
2022-04-28 21:40:24,751 epoch 36 - iter 10/107 - loss 0.04724671 - samples/sec: 106.66 - lr: 0.001563
2022-04-28 21:40:27,678 epoch 36 - iter 20/107 - loss 0.04900710 - samples/sec: 109.36 - lr: 0.001563
2022-04-28 21:40:30,764 epoch 36 - iter 30/107 - loss 0.05010530 - samples/sec: 103.75 - lr: 0.001563
2022-04-28 21:40:33,674 epoch 36 - iter 40/107 - loss 0.05168668 - samples/sec: 110.01 - lr: 0.001563
2022-04-28 21:40:36,602 epoch 36 - iter 50/107 - loss 0.04976929 - samples/sec: 109.31 - lr: 0.001563
2022-04-28 21:40:39,564 epoch 36 - iter 60/107 - loss 0.05070748 - samples/sec: 108.07 - lr: 0.001563
2022-04-28 21:40:42,661 epoch 36 - iter 70/107 - loss 0.05070636 - samples/sec: 103.36 - lr: 0.001563
2022-04-28 21:40:45,904 epoch 36 - iter 80/107 - loss 0.04988996 - samples/sec: 98.69 - lr: 0.001563
2022-04-28 21:40:48,975 epoch 36 - iter 90/107 - loss 0.04909182 - samples/sec: 104.25 - lr: 0.001563
2022-04-28 21:40:51,968 epoch 36 - iter 100/107 - loss 0.04849328 - samples/sec: 106.96 - lr: 0.001563
2022-04-28 21:40:53,719 ----------------------------------------------------------------------------------------------------
2022-04-28 21:40:53,719 EPOCH 36 done: loss 0.0482 - lr 0.001563
2022-04-28 21:41:03,186 Evaluating as a multi-label problem: False
2022-04-28 21:41:03,198 DEV : loss 0.2118210345506668 - f1-score (micro avg)  0.5232
2022-04-28 21:41:03,284 Epoch    36: reducing learning rate of group 0 to 7.8125e-04.
2022-04-28 21:41:03,285 BAD EPOCHS (no improvement): 4
2022-04-28 21:41:03,287 ----------------------------------------------------------------------------------------------------
2022-04-28 21:41:06,515 epoch 37 - iter 10/107 - loss 0.04861237 - samples/sec: 99.17 - lr: 0.000781
2022-04-28 21:41:09,548 epoch 37 - iter 20/107 - loss 0.05055728 - samples/sec: 105.54 - lr: 0.000781
2022-04-28 21:41:12,586 epoch 37 - iter 30/107 - loss 0.05162872 - samples/sec: 105.38 - lr: 0.000781
2022-04-28 21:41:15,707 epoch 37 - iter 40/107 - loss 0.04968913 - samples/sec: 102.55 - lr: 0.000781
2022-04-28 21:41:18,669 epoch 37 - iter 50/107 - loss 0.04944443 - samples/sec: 108.07 - lr: 0.000781
2022-04-28 21:41:21,531 epoch 37 - iter 60/107 - loss 0.04977627 - samples/sec: 111.87 - lr: 0.000781
2022-04-28 21:41:24,694 epoch 37 - iter 70/107 - loss 0.04801405 - samples/sec: 101.21 - lr: 0.000781
2022-04-28 21:41:27,762 epoch 37 - iter 80/107 - loss 0.04805948 - samples/sec: 104.35 - lr: 0.000781
2022-04-28 21:41:30,804 epoch 37 - iter 90/107 - loss 0.04779968 - samples/sec: 105.22 - lr: 0.000781
2022-04-28 21:41:33,866 epoch 37 - iter 100/107 - loss 0.04753536 - samples/sec: 104.56 - lr: 0.000781
2022-04-28 21:41:35,787 ----------------------------------------------------------------------------------------------------
2022-04-28 21:41:35,787 EPOCH 37 done: loss 0.0481 - lr 0.000781
2022-04-28 21:41:45,206 Evaluating as a multi-label problem: False
2022-04-28 21:41:45,218 DEV : loss 0.21053513884544373 - f1-score (micro avg)  0.5266
2022-04-28 21:41:45,307 BAD EPOCHS (no improvement): 1
2022-04-28 21:41:45,310 ----------------------------------------------------------------------------------------------------
2022-04-28 21:41:48,480 epoch 38 - iter 10/107 - loss 0.04520062 - samples/sec: 100.99 - lr: 0.000781
2022-04-28 21:41:51,575 epoch 38 - iter 20/107 - loss 0.04869454 - samples/sec: 103.41 - lr: 0.000781
2022-04-28 21:41:54,662 epoch 38 - iter 30/107 - loss 0.04789680 - samples/sec: 103.68 - lr: 0.000781
2022-04-28 21:41:57,621 epoch 38 - iter 40/107 - loss 0.04701330 - samples/sec: 108.21 - lr: 0.000781
2022-04-28 21:42:00,691 epoch 38 - iter 50/107 - loss 0.04736847 - samples/sec: 104.24 - lr: 0.000781
2022-04-28 21:42:03,684 epoch 38 - iter 60/107 - loss 0.04888949 - samples/sec: 106.95 - lr: 0.000781
2022-04-28 21:42:06,761 epoch 38 - iter 70/107 - loss 0.04907431 - samples/sec: 104.05 - lr: 0.000781
2022-04-28 21:42:09,820 epoch 38 - iter 80/107 - loss 0.04794880 - samples/sec: 104.63 - lr: 0.000781
2022-04-28 21:42:12,909 epoch 38 - iter 90/107 - loss 0.04813723 - samples/sec: 103.63 - lr: 0.000781
2022-04-28 21:42:16,025 epoch 38 - iter 100/107 - loss 0.04713048 - samples/sec: 102.76 - lr: 0.000781
2022-04-28 21:42:17,946 ----------------------------------------------------------------------------------------------------
2022-04-28 21:42:17,946 EPOCH 38 done: loss 0.0470 - lr 0.000781
2022-04-28 21:42:27,341 Evaluating as a multi-label problem: False
2022-04-28 21:42:27,353 DEV : loss 0.20909695327281952 - f1-score (micro avg)  0.5262
2022-04-28 21:42:27,439 BAD EPOCHS (no improvement): 2
2022-04-28 21:42:27,442 ----------------------------------------------------------------------------------------------------
2022-04-28 21:42:30,485 epoch 39 - iter 10/107 - loss 0.05200692 - samples/sec: 105.23 - lr: 0.000781
2022-04-28 21:42:33,526 epoch 39 - iter 20/107 - loss 0.04772732 - samples/sec: 105.27 - lr: 0.000781
2022-04-28 21:42:36,613 epoch 39 - iter 30/107 - loss 0.04930405 - samples/sec: 103.70 - lr: 0.000781
2022-04-28 21:42:39,835 epoch 39 - iter 40/107 - loss 0.04626670 - samples/sec: 99.35 - lr: 0.000781
2022-04-28 21:42:42,915 epoch 39 - iter 50/107 - loss 0.04688763 - samples/sec: 103.91 - lr: 0.000781
2022-04-28 21:42:45,947 epoch 39 - iter 60/107 - loss 0.04654999 - samples/sec: 105.58 - lr: 0.000781
2022-04-28 21:42:49,033 epoch 39 - iter 70/107 - loss 0.04799616 - samples/sec: 103.73 - lr: 0.000781
2022-04-28 21:42:52,142 epoch 39 - iter 80/107 - loss 0.04780236 - samples/sec: 102.96 - lr: 0.000781
2022-04-28 21:42:55,238 epoch 39 - iter 90/107 - loss 0.04751940 - samples/sec: 103.41 - lr: 0.000781
2022-04-28 21:42:58,291 epoch 39 - iter 100/107 - loss 0.04802627 - samples/sec: 104.84 - lr: 0.000781
2022-04-28 21:43:00,191 ----------------------------------------------------------------------------------------------------
2022-04-28 21:43:00,191 EPOCH 39 done: loss 0.0478 - lr 0.000781
2022-04-28 21:43:09,625 Evaluating as a multi-label problem: False
2022-04-28 21:43:09,636 DEV : loss 0.20938962697982788 - f1-score (micro avg)  0.5262
2022-04-28 21:43:09,725 BAD EPOCHS (no improvement): 3
2022-04-28 21:43:09,786 ----------------------------------------------------------------------------------------------------
2022-04-28 21:43:12,880 epoch 40 - iter 10/107 - loss 0.04940783 - samples/sec: 103.49 - lr: 0.000781
2022-04-28 21:43:15,882 epoch 40 - iter 20/107 - loss 0.04404918 - samples/sec: 106.62 - lr: 0.000781
2022-04-28 21:43:18,847 epoch 40 - iter 30/107 - loss 0.04500199 - samples/sec: 107.96 - lr: 0.000781
2022-04-28 21:43:21,904 epoch 40 - iter 40/107 - loss 0.04542797 - samples/sec: 104.72 - lr: 0.000781
2022-04-28 21:43:24,993 epoch 40 - iter 50/107 - loss 0.04542208 - samples/sec: 103.63 - lr: 0.000781
2022-04-28 21:43:28,093 epoch 40 - iter 60/107 - loss 0.04616780 - samples/sec: 103.28 - lr: 0.000781
2022-04-28 21:43:31,378 epoch 40 - iter 70/107 - loss 0.04627926 - samples/sec: 97.42 - lr: 0.000781
2022-04-28 21:43:34,397 epoch 40 - iter 80/107 - loss 0.04740843 - samples/sec: 106.03 - lr: 0.000781
2022-04-28 21:43:37,427 epoch 40 - iter 90/107 - loss 0.04676744 - samples/sec: 105.66 - lr: 0.000781
2022-04-28 21:43:40,571 epoch 40 - iter 100/107 - loss 0.04650481 - samples/sec: 101.79 - lr: 0.000781
2022-04-28 21:43:42,371 ----------------------------------------------------------------------------------------------------
2022-04-28 21:43:42,371 EPOCH 40 done: loss 0.0472 - lr 0.000781
2022-04-28 21:43:51,847 Evaluating as a multi-label problem: False
2022-04-28 21:43:51,857 DEV : loss 0.20888322591781616 - f1-score (micro avg)  0.5257
2022-04-28 21:43:51,944 Epoch    40: reducing learning rate of group 0 to 3.9063e-04.
2022-04-28 21:43:51,945 BAD EPOCHS (no improvement): 4
2022-04-28 21:43:51,947 ----------------------------------------------------------------------------------------------------
2022-04-28 21:43:55,072 epoch 41 - iter 10/107 - loss 0.04984584 - samples/sec: 102.46 - lr: 0.000391
2022-04-28 21:43:58,119 epoch 41 - iter 20/107 - loss 0.05312655 - samples/sec: 105.04 - lr: 0.000391
2022-04-28 21:44:01,209 epoch 41 - iter 30/107 - loss 0.04649864 - samples/sec: 103.60 - lr: 0.000391
2022-04-28 21:44:04,233 epoch 41 - iter 40/107 - loss 0.04669634 - samples/sec: 105.86 - lr: 0.000391
2022-04-28 21:44:07,294 epoch 41 - iter 50/107 - loss 0.04747857 - samples/sec: 104.59 - lr: 0.000391
2022-04-28 21:44:10,418 epoch 41 - iter 60/107 - loss 0.04942038 - samples/sec: 102.47 - lr: 0.000391
2022-04-28 21:44:13,384 epoch 41 - iter 70/107 - loss 0.04909514 - samples/sec: 107.94 - lr: 0.000391
2022-04-28 21:44:21,704 epoch 41 - iter 80/107 - loss 0.04767829 - samples/sec: 38.46 - lr: 0.000391
2022-04-28 21:44:24,698 epoch 41 - iter 90/107 - loss 0.04711513 - samples/sec: 106.92 - lr: 0.000391
2022-04-28 21:44:27,750 epoch 41 - iter 100/107 - loss 0.04730137 - samples/sec: 104.87 - lr: 0.000391
2022-04-28 21:44:29,694 ----------------------------------------------------------------------------------------------------
2022-04-28 21:44:29,694 EPOCH 41 done: loss 0.0482 - lr 0.000391
2022-04-28 21:44:39,140 Evaluating as a multi-label problem: False
2022-04-28 21:44:39,151 DEV : loss 0.20931293070316315 - f1-score (micro avg)  0.5257
2022-04-28 21:44:39,239 BAD EPOCHS (no improvement): 1
2022-04-28 21:44:39,241 ----------------------------------------------------------------------------------------------------
2022-04-28 21:44:42,382 epoch 42 - iter 10/107 - loss 0.04324041 - samples/sec: 101.93 - lr: 0.000391
2022-04-28 21:44:45,379 epoch 42 - iter 20/107 - loss 0.04421110 - samples/sec: 106.83 - lr: 0.000391
2022-04-28 21:44:48,505 epoch 42 - iter 30/107 - loss 0.04484377 - samples/sec: 102.38 - lr: 0.000391
2022-04-28 21:44:51,640 epoch 42 - iter 40/107 - loss 0.04866272 - samples/sec: 102.13 - lr: 0.000391
2022-04-28 21:44:54,657 epoch 42 - iter 50/107 - loss 0.04998794 - samples/sec: 106.08 - lr: 0.000391
2022-04-28 21:44:57,812 epoch 42 - iter 60/107 - loss 0.04935612 - samples/sec: 101.46 - lr: 0.000391
2022-04-28 21:45:00,820 epoch 42 - iter 70/107 - loss 0.04819500 - samples/sec: 106.42 - lr: 0.000391
2022-04-28 21:45:03,892 epoch 42 - iter 80/107 - loss 0.04685888 - samples/sec: 104.20 - lr: 0.000391
2022-04-28 21:45:06,922 epoch 42 - iter 90/107 - loss 0.04701861 - samples/sec: 105.65 - lr: 0.000391
2022-04-28 21:45:09,901 epoch 42 - iter 100/107 - loss 0.04626031 - samples/sec: 107.46 - lr: 0.000391
2022-04-28 21:45:11,765 ----------------------------------------------------------------------------------------------------
2022-04-28 21:45:11,765 EPOCH 42 done: loss 0.0464 - lr 0.000391
2022-04-28 21:45:21,140 Evaluating as a multi-label problem: False
2022-04-28 21:45:21,152 DEV : loss 0.21041415631771088 - f1-score (micro avg)  0.5254
2022-04-28 21:45:21,251 BAD EPOCHS (no improvement): 2
2022-04-28 21:45:21,253 ----------------------------------------------------------------------------------------------------
2022-04-28 21:45:24,359 epoch 43 - iter 10/107 - loss 0.04455050 - samples/sec: 103.09 - lr: 0.000391
2022-04-28 21:45:27,434 epoch 43 - iter 20/107 - loss 0.04274147 - samples/sec: 104.11 - lr: 0.000391
2022-04-28 21:45:30,381 epoch 43 - iter 30/107 - loss 0.04594076 - samples/sec: 108.59 - lr: 0.000391
2022-04-28 21:45:33,376 epoch 43 - iter 40/107 - loss 0.04628547 - samples/sec: 106.90 - lr: 0.000391
2022-04-28 21:45:36,386 epoch 43 - iter 50/107 - loss 0.04557694 - samples/sec: 106.35 - lr: 0.000391
2022-04-28 21:45:39,489 epoch 43 - iter 60/107 - loss 0.04588936 - samples/sec: 103.17 - lr: 0.000391
2022-04-28 21:45:42,546 epoch 43 - iter 70/107 - loss 0.04624226 - samples/sec: 104.71 - lr: 0.000391
2022-04-28 21:45:45,470 epoch 43 - iter 80/107 - loss 0.04646108 - samples/sec: 109.47 - lr: 0.000391
2022-04-28 21:45:48,495 epoch 43 - iter 90/107 - loss 0.04807954 - samples/sec: 105.80 - lr: 0.000391
2022-04-28 21:45:51,476 epoch 43 - iter 100/107 - loss 0.04791628 - samples/sec: 107.39 - lr: 0.000391
2022-04-28 21:45:53,439 ----------------------------------------------------------------------------------------------------
2022-04-28 21:45:53,440 EPOCH 43 done: loss 0.0473 - lr 0.000391
2022-04-28 21:46:02,764 Evaluating as a multi-label problem: False
2022-04-28 21:46:02,775 DEV : loss 0.20990461111068726 - f1-score (micro avg)  0.5266
2022-04-28 21:46:02,861 BAD EPOCHS (no improvement): 3
2022-04-28 21:46:02,864 ----------------------------------------------------------------------------------------------------
2022-04-28 21:46:05,962 epoch 44 - iter 10/107 - loss 0.04467023 - samples/sec: 103.35 - lr: 0.000391
2022-04-28 21:46:08,930 epoch 44 - iter 20/107 - loss 0.04258257 - samples/sec: 107.87 - lr: 0.000391
2022-04-28 21:46:12,055 epoch 44 - iter 30/107 - loss 0.04674525 - samples/sec: 102.44 - lr: 0.000391
2022-04-28 21:46:15,118 epoch 44 - iter 40/107 - loss 0.04615000 - samples/sec: 104.51 - lr: 0.000391
2022-04-28 21:46:18,197 epoch 44 - iter 50/107 - loss 0.04666268 - samples/sec: 103.95 - lr: 0.000391
2022-04-28 21:46:21,329 epoch 44 - iter 60/107 - loss 0.04882346 - samples/sec: 102.21 - lr: 0.000391
2022-04-28 21:46:24,419 epoch 44 - iter 70/107 - loss 0.04837051 - samples/sec: 103.60 - lr: 0.000391
2022-04-28 21:46:27,539 epoch 44 - iter 80/107 - loss 0.04928053 - samples/sec: 102.61 - lr: 0.000391
2022-04-28 21:46:30,477 epoch 44 - iter 90/107 - loss 0.04795801 - samples/sec: 108.95 - lr: 0.000391
2022-04-28 21:46:33,665 epoch 44 - iter 100/107 - loss 0.04843176 - samples/sec: 100.39 - lr: 0.000391
2022-04-28 21:46:35,494 ----------------------------------------------------------------------------------------------------
2022-04-28 21:46:35,495 EPOCH 44 done: loss 0.0487 - lr 0.000391
2022-04-28 21:46:45,046 Evaluating as a multi-label problem: False
2022-04-28 21:46:45,058 DEV : loss 0.2094096690416336 - f1-score (micro avg)  0.5262
2022-04-28 21:46:45,144 Epoch    44: reducing learning rate of group 0 to 1.9531e-04.
2022-04-28 21:46:45,144 BAD EPOCHS (no improvement): 4
2022-04-28 21:46:45,147 ----------------------------------------------------------------------------------------------------
2022-04-28 21:46:48,367 epoch 45 - iter 10/107 - loss 0.04270518 - samples/sec: 99.42 - lr: 0.000195
2022-04-28 21:46:51,273 epoch 45 - iter 20/107 - loss 0.04701434 - samples/sec: 110.16 - lr: 0.000195
2022-04-28 21:46:54,298 epoch 45 - iter 30/107 - loss 0.04848348 - samples/sec: 105.82 - lr: 0.000195
2022-04-28 21:46:57,376 epoch 45 - iter 40/107 - loss 0.04738842 - samples/sec: 103.98 - lr: 0.000195
2022-04-28 21:47:00,452 epoch 45 - iter 50/107 - loss 0.05023707 - samples/sec: 104.09 - lr: 0.000195
2022-04-28 21:47:03,466 epoch 45 - iter 60/107 - loss 0.05017410 - samples/sec: 106.21 - lr: 0.000195
2022-04-28 21:47:06,490 epoch 45 - iter 70/107 - loss 0.04858659 - samples/sec: 105.85 - lr: 0.000195
2022-04-28 21:47:09,673 epoch 45 - iter 80/107 - loss 0.04848721 - samples/sec: 100.58 - lr: 0.000195
2022-04-28 21:47:12,651 epoch 45 - iter 90/107 - loss 0.04908866 - samples/sec: 107.49 - lr: 0.000195
2022-04-28 21:47:15,737 epoch 45 - iter 100/107 - loss 0.04901415 - samples/sec: 103.72 - lr: 0.000195
2022-04-28 21:47:17,638 ----------------------------------------------------------------------------------------------------
2022-04-28 21:47:17,638 EPOCH 45 done: loss 0.0488 - lr 0.000195
2022-04-28 21:47:27,032 Evaluating as a multi-label problem: False
2022-04-28 21:47:27,044 DEV : loss 0.2094639390707016 - f1-score (micro avg)  0.5266
2022-04-28 21:47:27,131 BAD EPOCHS (no improvement): 1
2022-04-28 21:47:27,141 ----------------------------------------------------------------------------------------------------
2022-04-28 21:47:30,347 epoch 46 - iter 10/107 - loss 0.04595124 - samples/sec: 99.85 - lr: 0.000195
2022-04-28 21:47:33,518 epoch 46 - iter 20/107 - loss 0.04852249 - samples/sec: 100.96 - lr: 0.000195
2022-04-28 21:47:36,596 epoch 46 - iter 30/107 - loss 0.04837376 - samples/sec: 103.99 - lr: 0.000195
2022-04-28 21:47:39,653 epoch 46 - iter 40/107 - loss 0.04833999 - samples/sec: 104.71 - lr: 0.000195
2022-04-28 21:47:42,634 epoch 46 - iter 50/107 - loss 0.04652365 - samples/sec: 107.41 - lr: 0.000195
2022-04-28 21:47:45,574 epoch 46 - iter 60/107 - loss 0.04628512 - samples/sec: 108.84 - lr: 0.000195
2022-04-28 21:47:48,665 epoch 46 - iter 70/107 - loss 0.04706732 - samples/sec: 103.58 - lr: 0.000195
2022-04-28 21:47:51,814 epoch 46 - iter 80/107 - loss 0.04779153 - samples/sec: 101.65 - lr: 0.000195
2022-04-28 21:47:54,814 epoch 46 - iter 90/107 - loss 0.04816559 - samples/sec: 106.73 - lr: 0.000195
2022-04-28 21:47:57,845 epoch 46 - iter 100/107 - loss 0.04828720 - samples/sec: 105.59 - lr: 0.000195
2022-04-28 21:47:59,731 ----------------------------------------------------------------------------------------------------
2022-04-28 21:47:59,731 EPOCH 46 done: loss 0.0479 - lr 0.000195
2022-04-28 21:48:09,167 Evaluating as a multi-label problem: False
2022-04-28 21:48:09,179 DEV : loss 0.20949767529964447 - f1-score (micro avg)  0.527
2022-04-28 21:48:09,273 BAD EPOCHS (no improvement): 2
2022-04-28 21:48:09,276 ----------------------------------------------------------------------------------------------------
2022-04-28 21:48:12,568 epoch 47 - iter 10/107 - loss 0.05489859 - samples/sec: 97.24 - lr: 0.000195
2022-04-28 21:48:15,627 epoch 47 - iter 20/107 - loss 0.05547149 - samples/sec: 104.66 - lr: 0.000195
2022-04-28 21:48:18,566 epoch 47 - iter 30/107 - loss 0.05240963 - samples/sec: 108.90 - lr: 0.000195
2022-04-28 21:48:21,688 epoch 47 - iter 40/107 - loss 0.05127610 - samples/sec: 102.52 - lr: 0.000195
2022-04-28 21:48:24,688 epoch 47 - iter 50/107 - loss 0.04914741 - samples/sec: 106.71 - lr: 0.000195
2022-04-28 21:48:27,899 epoch 47 - iter 60/107 - loss 0.04858000 - samples/sec: 99.68 - lr: 0.000195
2022-04-28 21:48:31,071 epoch 47 - iter 70/107 - loss 0.04926054 - samples/sec: 100.93 - lr: 0.000195
2022-04-28 21:48:34,129 epoch 47 - iter 80/107 - loss 0.04932774 - samples/sec: 104.67 - lr: 0.000195
2022-04-28 21:48:37,160 epoch 47 - iter 90/107 - loss 0.04885105 - samples/sec: 105.63 - lr: 0.000195
2022-04-28 21:48:40,190 epoch 47 - iter 100/107 - loss 0.04900413 - samples/sec: 105.64 - lr: 0.000195
2022-04-28 21:48:42,076 ----------------------------------------------------------------------------------------------------
2022-04-28 21:48:42,077 EPOCH 47 done: loss 0.0484 - lr 0.000195
2022-04-28 21:48:51,511 Evaluating as a multi-label problem: False
2022-04-28 21:48:51,522 DEV : loss 0.20921875536441803 - f1-score (micro avg)  0.5262
2022-04-28 21:48:51,611 BAD EPOCHS (no improvement): 3
2022-04-28 21:48:51,614 ----------------------------------------------------------------------------------------------------
2022-04-28 21:48:54,765 epoch 48 - iter 10/107 - loss 0.04245303 - samples/sec: 101.62 - lr: 0.000195
2022-04-28 21:48:57,891 epoch 48 - iter 20/107 - loss 0.04176580 - samples/sec: 102.39 - lr: 0.000195
2022-04-28 21:49:01,078 epoch 48 - iter 30/107 - loss 0.04411272 - samples/sec: 100.44 - lr: 0.000195
2022-04-28 21:49:03,953 epoch 48 - iter 40/107 - loss 0.04816478 - samples/sec: 111.36 - lr: 0.000195
2022-04-28 21:49:07,055 epoch 48 - iter 50/107 - loss 0.04842228 - samples/sec: 103.19 - lr: 0.000195
2022-04-28 21:49:10,239 epoch 48 - iter 60/107 - loss 0.04861741 - samples/sec: 100.55 - lr: 0.000195
2022-04-28 21:49:13,208 epoch 48 - iter 70/107 - loss 0.04741096 - samples/sec: 107.81 - lr: 0.000195
2022-04-28 21:49:16,229 epoch 48 - iter 80/107 - loss 0.04736038 - samples/sec: 105.95 - lr: 0.000195
2022-04-28 21:49:19,208 epoch 48 - iter 90/107 - loss 0.04696211 - samples/sec: 107.46 - lr: 0.000195
2022-04-28 21:49:22,138 epoch 48 - iter 100/107 - loss 0.04710494 - samples/sec: 109.27 - lr: 0.000195
2022-04-28 21:49:24,044 ----------------------------------------------------------------------------------------------------
2022-04-28 21:49:24,044 EPOCH 48 done: loss 0.0472 - lr 0.000195
2022-04-28 21:49:33,532 Evaluating as a multi-label problem: False
2022-04-28 21:49:33,543 DEV : loss 0.20942719280719757 - f1-score (micro avg)  0.525
2022-04-28 21:49:33,629 Epoch    48: reducing learning rate of group 0 to 9.7656e-05.
2022-04-28 21:49:33,630 BAD EPOCHS (no improvement): 4
2022-04-28 21:49:33,662 ----------------------------------------------------------------------------------------------------
2022-04-28 21:49:33,662 ----------------------------------------------------------------------------------------------------
2022-04-28 21:49:33,662 learning rate too small - quitting training!
2022-04-28 21:49:33,662 ----------------------------------------------------------------------------------------------------
2022-04-28 21:50:29,113 ----------------------------------------------------------------------------------------------------
2022-04-28 21:50:29,114 loading file resources/taggers/model_06_r5_run_3/best-model.pt
2022-04-28 21:51:33,478 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-04-28 21:51:56,775 Evaluating as a multi-label problem: False
2022-04-28 21:51:56,788 0.6304	0.3494	0.4496	0.3093
2022-04-28 21:51:56,788 
Results:
- F-score (micro) 0.4496
- F-score (macro) 0.3474
- Accuracy 0.3093

By class:
               precision    recall  f1-score   support

       person     0.7934    0.5012    0.6143       429
     location     0.5417    0.6067    0.5723       150
        group     0.4773    0.1273    0.2010       165
creative-work     0.6000    0.1056    0.1796       142
      product     0.4167    0.1181    0.1840       127
  corporation     0.3704    0.3030    0.3333        66

    micro avg     0.6304    0.3494    0.4496      1079
    macro avg     0.5332    0.2936    0.3474      1079
 weighted avg     0.6144    0.3494    0.4202      1079

2022-04-28 21:51:56,788 ----------------------------------------------------------------------------------------------------
