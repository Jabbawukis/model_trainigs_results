2022-04-28 19:59:43,245 ----------------------------------------------------------------------------------------------------
2022-04-28 19:59:43,245 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4797, out_features=4797, bias=True)
  (rnn): LSTM(4797, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-04-28 19:59:43,245 ----------------------------------------------------------------------------------------------------
2022-04-28 19:59:43,245 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-04-28 19:59:43,245 ----------------------------------------------------------------------------------------------------
2022-04-28 19:59:43,245 Parameters:
2022-04-28 19:59:43,246  - learning_rate: "0.100000"
2022-04-28 19:59:43,246  - mini_batch_size: "32"
2022-04-28 19:59:43,246  - patience: "3"
2022-04-28 19:59:43,246  - anneal_factor: "0.5"
2022-04-28 19:59:43,246  - max_epochs: "150"
2022-04-28 19:59:43,246  - shuffle: "True"
2022-04-28 19:59:43,246  - train_with_dev: "False"
2022-04-28 19:59:43,246  - batch_growth_annealing: "False"
2022-04-28 19:59:43,246 ----------------------------------------------------------------------------------------------------
2022-04-28 19:59:43,246 Model training base path: "resources/taggers/model_05_r5_run_2"
2022-04-28 19:59:43,246 ----------------------------------------------------------------------------------------------------
2022-04-28 19:59:43,246 Device: cuda:0
2022-04-28 19:59:43,246 ----------------------------------------------------------------------------------------------------
2022-04-28 19:59:43,246 Embeddings storage mode: cpu
2022-04-28 19:59:43,246 ----------------------------------------------------------------------------------------------------
2022-04-28 19:59:48,031 epoch 1 - iter 10/107 - loss 0.90444502 - samples/sec: 66.89 - lr: 0.100000
2022-04-28 19:59:52,882 epoch 1 - iter 20/107 - loss 0.60174559 - samples/sec: 65.98 - lr: 0.100000
2022-04-28 19:59:57,536 epoch 1 - iter 30/107 - loss 0.50060005 - samples/sec: 68.78 - lr: 0.100000
2022-04-28 20:00:01,837 epoch 1 - iter 40/107 - loss 0.44256664 - samples/sec: 74.42 - lr: 0.100000
2022-04-28 20:00:06,199 epoch 1 - iter 50/107 - loss 0.39879467 - samples/sec: 73.38 - lr: 0.100000
2022-04-28 20:00:11,298 epoch 1 - iter 60/107 - loss 0.38164223 - samples/sec: 62.77 - lr: 0.100000
2022-04-28 20:00:16,034 epoch 1 - iter 70/107 - loss 0.36831214 - samples/sec: 67.58 - lr: 0.100000
2022-04-28 20:00:20,775 epoch 1 - iter 80/107 - loss 0.36225792 - samples/sec: 67.51 - lr: 0.100000
2022-04-28 20:00:24,975 epoch 1 - iter 90/107 - loss 0.35636109 - samples/sec: 76.21 - lr: 0.100000
2022-04-28 20:00:29,376 epoch 1 - iter 100/107 - loss 0.34994778 - samples/sec: 72.74 - lr: 0.100000
2022-04-28 20:00:32,220 ----------------------------------------------------------------------------------------------------
2022-04-28 20:00:32,220 EPOCH 1 done: loss 0.3434 - lr 0.100000
2022-04-28 20:00:44,459 Evaluating as a multi-label problem: False
2022-04-28 20:00:44,470 DEV : loss 0.4745209515094757 - f1-score (micro avg)  0.0235
2022-04-28 20:00:44,540 BAD EPOCHS (no improvement): 0
2022-04-28 20:00:44,542 saving best model
2022-04-28 20:01:03,082 ----------------------------------------------------------------------------------------------------
2022-04-28 20:01:08,072 epoch 2 - iter 10/107 - loss 0.25674622 - samples/sec: 64.16 - lr: 0.100000
2022-04-28 20:01:13,090 epoch 2 - iter 20/107 - loss 0.23501618 - samples/sec: 63.78 - lr: 0.100000
2022-04-28 20:01:18,007 epoch 2 - iter 30/107 - loss 0.22097849 - samples/sec: 65.09 - lr: 0.100000
2022-04-28 20:01:22,726 epoch 2 - iter 40/107 - loss 0.21852288 - samples/sec: 67.84 - lr: 0.100000
2022-04-28 20:01:27,200 epoch 2 - iter 50/107 - loss 0.21860983 - samples/sec: 71.54 - lr: 0.100000
2022-04-28 20:01:31,848 epoch 2 - iter 60/107 - loss 0.21209100 - samples/sec: 68.93 - lr: 0.100000
2022-04-28 20:01:35,780 epoch 2 - iter 70/107 - loss 0.20895513 - samples/sec: 81.39 - lr: 0.100000
2022-04-28 20:01:40,164 epoch 2 - iter 80/107 - loss 0.20929637 - samples/sec: 73.01 - lr: 0.100000
2022-04-28 20:01:44,956 epoch 2 - iter 90/107 - loss 0.20584375 - samples/sec: 66.80 - lr: 0.100000
2022-04-28 20:01:49,299 epoch 2 - iter 100/107 - loss 0.20622392 - samples/sec: 73.69 - lr: 0.100000
2022-04-28 20:01:52,161 ----------------------------------------------------------------------------------------------------
2022-04-28 20:01:52,161 EPOCH 2 done: loss 0.2037 - lr 0.100000
2022-04-28 20:02:05,542 Evaluating as a multi-label problem: False
2022-04-28 20:02:05,553 DEV : loss 0.2805134654045105 - f1-score (micro avg)  0.4292
2022-04-28 20:02:05,623 BAD EPOCHS (no improvement): 0
2022-04-28 20:02:05,626 saving best model
2022-04-28 20:02:25,043 ----------------------------------------------------------------------------------------------------
2022-04-28 20:02:30,126 epoch 3 - iter 10/107 - loss 0.16936957 - samples/sec: 62.98 - lr: 0.100000
2022-04-28 20:02:34,698 epoch 3 - iter 20/107 - loss 0.17762117 - samples/sec: 70.01 - lr: 0.100000
2022-04-28 20:02:39,597 epoch 3 - iter 30/107 - loss 0.18298913 - samples/sec: 65.33 - lr: 0.100000
2022-04-28 20:02:44,125 epoch 3 - iter 40/107 - loss 0.17135843 - samples/sec: 70.70 - lr: 0.100000
2022-04-28 20:02:49,150 epoch 3 - iter 50/107 - loss 0.17097340 - samples/sec: 63.69 - lr: 0.100000
2022-04-28 20:02:53,751 epoch 3 - iter 60/107 - loss 0.17031913 - samples/sec: 69.56 - lr: 0.100000
2022-04-28 20:02:57,912 epoch 3 - iter 70/107 - loss 0.17521301 - samples/sec: 76.93 - lr: 0.100000
2022-04-28 20:03:02,101 epoch 3 - iter 80/107 - loss 0.17885177 - samples/sec: 76.40 - lr: 0.100000
2022-04-28 20:03:06,124 epoch 3 - iter 90/107 - loss 0.17750555 - samples/sec: 79.56 - lr: 0.100000
2022-04-28 20:03:10,561 epoch 3 - iter 100/107 - loss 0.17303847 - samples/sec: 72.15 - lr: 0.100000
2022-04-28 20:03:13,434 ----------------------------------------------------------------------------------------------------
2022-04-28 20:03:13,434 EPOCH 3 done: loss 0.1723 - lr 0.100000
2022-04-28 20:03:27,418 Evaluating as a multi-label problem: False
2022-04-28 20:03:27,429 DEV : loss 0.3136766254901886 - f1-score (micro avg)  0.3123
2022-04-28 20:03:27,501 BAD EPOCHS (no improvement): 1
2022-04-28 20:03:27,504 ----------------------------------------------------------------------------------------------------
2022-04-28 20:03:32,135 epoch 4 - iter 10/107 - loss 0.13159790 - samples/sec: 69.11 - lr: 0.100000
2022-04-28 20:03:36,908 epoch 4 - iter 20/107 - loss 0.12272821 - samples/sec: 67.06 - lr: 0.100000
2022-04-28 20:03:41,534 epoch 4 - iter 30/107 - loss 0.13356491 - samples/sec: 69.18 - lr: 0.100000
2022-04-28 20:03:46,183 epoch 4 - iter 40/107 - loss 0.13916735 - samples/sec: 68.86 - lr: 0.100000
2022-04-28 20:03:50,391 epoch 4 - iter 50/107 - loss 0.14253721 - samples/sec: 76.06 - lr: 0.100000
2022-04-28 20:03:54,748 epoch 4 - iter 60/107 - loss 0.14860615 - samples/sec: 73.46 - lr: 0.100000
2022-04-28 20:03:58,902 epoch 4 - iter 70/107 - loss 0.15000507 - samples/sec: 77.05 - lr: 0.100000
2022-04-28 20:04:02,998 epoch 4 - iter 80/107 - loss 0.14816268 - samples/sec: 78.16 - lr: 0.100000
2022-04-28 20:04:07,895 epoch 4 - iter 90/107 - loss 0.14800464 - samples/sec: 65.36 - lr: 0.100000
2022-04-28 20:04:12,326 epoch 4 - iter 100/107 - loss 0.14803540 - samples/sec: 72.23 - lr: 0.100000
2022-04-28 20:04:15,093 ----------------------------------------------------------------------------------------------------
2022-04-28 20:04:15,093 EPOCH 4 done: loss 0.1486 - lr 0.100000
2022-04-28 20:04:28,979 Evaluating as a multi-label problem: False
2022-04-28 20:04:28,989 DEV : loss 0.26117196679115295 - f1-score (micro avg)  0.4364
2022-04-28 20:04:29,059 BAD EPOCHS (no improvement): 0
2022-04-28 20:04:29,062 saving best model
2022-04-28 20:04:48,074 ----------------------------------------------------------------------------------------------------
2022-04-28 20:04:50,922 epoch 5 - iter 10/107 - loss 0.13683088 - samples/sec: 112.43 - lr: 0.100000
2022-04-28 20:04:53,631 epoch 5 - iter 20/107 - loss 0.12602059 - samples/sec: 118.21 - lr: 0.100000
2022-04-28 20:04:56,295 epoch 5 - iter 30/107 - loss 0.13779882 - samples/sec: 120.14 - lr: 0.100000
2022-04-28 20:04:58,778 epoch 5 - iter 40/107 - loss 0.13660576 - samples/sec: 128.92 - lr: 0.100000
2022-04-28 20:05:01,340 epoch 5 - iter 50/107 - loss 0.13529130 - samples/sec: 124.94 - lr: 0.100000
2022-04-28 20:05:05,590 epoch 5 - iter 60/107 - loss 0.13837392 - samples/sec: 75.33 - lr: 0.100000
2022-04-28 20:05:08,258 epoch 5 - iter 70/107 - loss 0.14020676 - samples/sec: 119.96 - lr: 0.100000
2022-04-28 20:05:11,267 epoch 5 - iter 80/107 - loss 0.13959556 - samples/sec: 106.40 - lr: 0.100000
2022-04-28 20:05:14,096 epoch 5 - iter 90/107 - loss 0.14106603 - samples/sec: 113.12 - lr: 0.100000
2022-04-28 20:05:17,371 epoch 5 - iter 100/107 - loss 0.13784910 - samples/sec: 97.76 - lr: 0.100000
2022-04-28 20:05:20,329 ----------------------------------------------------------------------------------------------------
2022-04-28 20:05:20,329 EPOCH 5 done: loss 0.1366 - lr 0.100000
2022-04-28 20:05:33,921 Evaluating as a multi-label problem: False
2022-04-28 20:05:33,933 DEV : loss 0.27077025175094604 - f1-score (micro avg)  0.4277
2022-04-28 20:05:34,005 BAD EPOCHS (no improvement): 1
2022-04-28 20:05:34,009 ----------------------------------------------------------------------------------------------------
2022-04-28 20:05:38,592 epoch 6 - iter 10/107 - loss 0.11966164 - samples/sec: 69.85 - lr: 0.100000
2022-04-28 20:05:43,196 epoch 6 - iter 20/107 - loss 0.11606476 - samples/sec: 69.51 - lr: 0.100000
2022-04-28 20:05:47,831 epoch 6 - iter 30/107 - loss 0.12010709 - samples/sec: 69.06 - lr: 0.100000
2022-04-28 20:05:52,354 epoch 6 - iter 40/107 - loss 0.12759678 - samples/sec: 70.77 - lr: 0.100000
2022-04-28 20:05:57,220 epoch 6 - iter 50/107 - loss 0.12653686 - samples/sec: 65.77 - lr: 0.100000
2022-04-28 20:06:01,207 epoch 6 - iter 60/107 - loss 0.12371357 - samples/sec: 80.28 - lr: 0.100000
2022-04-28 20:06:04,849 epoch 6 - iter 70/107 - loss 0.12704251 - samples/sec: 87.87 - lr: 0.100000
2022-04-28 20:06:08,511 epoch 6 - iter 80/107 - loss 0.12651231 - samples/sec: 87.42 - lr: 0.100000
2022-04-28 20:06:11,809 epoch 6 - iter 90/107 - loss 0.12607857 - samples/sec: 97.06 - lr: 0.100000
2022-04-28 20:06:15,924 epoch 6 - iter 100/107 - loss 0.12362985 - samples/sec: 77.78 - lr: 0.100000
2022-04-28 20:06:18,663 ----------------------------------------------------------------------------------------------------
2022-04-28 20:06:18,663 EPOCH 6 done: loss 0.1232 - lr 0.100000
2022-04-28 20:06:32,554 Evaluating as a multi-label problem: False
2022-04-28 20:06:32,566 DEV : loss 0.26859983801841736 - f1-score (micro avg)  0.3534
2022-04-28 20:06:32,636 BAD EPOCHS (no improvement): 2
2022-04-28 20:06:32,639 ----------------------------------------------------------------------------------------------------
2022-04-28 20:06:37,353 epoch 7 - iter 10/107 - loss 0.14856063 - samples/sec: 67.90 - lr: 0.100000
2022-04-28 20:06:42,352 epoch 7 - iter 20/107 - loss 0.12278289 - samples/sec: 64.03 - lr: 0.100000
2022-04-28 20:06:46,699 epoch 7 - iter 30/107 - loss 0.11727002 - samples/sec: 73.62 - lr: 0.100000
2022-04-28 20:06:50,824 epoch 7 - iter 40/107 - loss 0.11788033 - samples/sec: 77.60 - lr: 0.100000
2022-04-28 20:06:55,082 epoch 7 - iter 50/107 - loss 0.11882009 - samples/sec: 75.16 - lr: 0.100000
2022-04-28 20:06:59,612 epoch 7 - iter 60/107 - loss 0.11922969 - samples/sec: 70.66 - lr: 0.100000
2022-04-28 20:07:04,411 epoch 7 - iter 70/107 - loss 0.11565841 - samples/sec: 66.70 - lr: 0.100000
2022-04-28 20:07:09,008 epoch 7 - iter 80/107 - loss 0.11548971 - samples/sec: 69.63 - lr: 0.100000
2022-04-28 20:07:13,968 epoch 7 - iter 90/107 - loss 0.11533712 - samples/sec: 64.54 - lr: 0.100000
2022-04-28 20:07:18,469 epoch 7 - iter 100/107 - loss 0.11678773 - samples/sec: 71.10 - lr: 0.100000
2022-04-28 20:07:21,150 ----------------------------------------------------------------------------------------------------
2022-04-28 20:07:21,150 EPOCH 7 done: loss 0.1172 - lr 0.100000
2022-04-28 20:07:34,404 Evaluating as a multi-label problem: False
2022-04-28 20:07:34,415 DEV : loss 0.19693857431411743 - f1-score (micro avg)  0.5004
2022-04-28 20:07:34,487 BAD EPOCHS (no improvement): 0
2022-04-28 20:07:34,490 saving best model
2022-04-28 20:07:53,509 ----------------------------------------------------------------------------------------------------
2022-04-28 20:07:58,392 epoch 8 - iter 10/107 - loss 0.10685231 - samples/sec: 65.56 - lr: 0.100000
2022-04-28 20:08:03,039 epoch 8 - iter 20/107 - loss 0.11642563 - samples/sec: 68.88 - lr: 0.100000
2022-04-28 20:08:07,607 epoch 8 - iter 30/107 - loss 0.11284997 - samples/sec: 70.07 - lr: 0.100000
2022-04-28 20:08:12,104 epoch 8 - iter 40/107 - loss 0.11219431 - samples/sec: 71.17 - lr: 0.100000
2022-04-28 20:08:16,694 epoch 8 - iter 50/107 - loss 0.11045410 - samples/sec: 69.74 - lr: 0.100000
2022-04-28 20:08:20,450 epoch 8 - iter 60/107 - loss 0.10952416 - samples/sec: 85.21 - lr: 0.100000
2022-04-28 20:08:24,180 epoch 8 - iter 70/107 - loss 0.11144167 - samples/sec: 85.83 - lr: 0.100000
2022-04-28 20:08:28,210 epoch 8 - iter 80/107 - loss 0.11118708 - samples/sec: 79.41 - lr: 0.100000
2022-04-28 20:08:32,793 epoch 8 - iter 90/107 - loss 0.11059615 - samples/sec: 69.84 - lr: 0.100000
2022-04-28 20:08:37,457 epoch 8 - iter 100/107 - loss 0.11112683 - samples/sec: 68.62 - lr: 0.100000
2022-04-28 20:08:40,466 ----------------------------------------------------------------------------------------------------
2022-04-28 20:08:40,466 EPOCH 8 done: loss 0.1105 - lr 0.100000
2022-04-28 20:08:54,446 Evaluating as a multi-label problem: False
2022-04-28 20:08:54,458 DEV : loss 0.19596076011657715 - f1-score (micro avg)  0.4899
2022-04-28 20:08:54,530 BAD EPOCHS (no improvement): 1
2022-04-28 20:08:54,533 ----------------------------------------------------------------------------------------------------
2022-04-28 20:08:59,357 epoch 9 - iter 10/107 - loss 0.10334151 - samples/sec: 66.35 - lr: 0.100000
2022-04-28 20:09:04,025 epoch 9 - iter 20/107 - loss 0.10294666 - samples/sec: 68.58 - lr: 0.100000
2022-04-28 20:09:08,226 epoch 9 - iter 30/107 - loss 0.11044154 - samples/sec: 76.19 - lr: 0.100000
2022-04-28 20:09:12,363 epoch 9 - iter 40/107 - loss 0.10312808 - samples/sec: 77.36 - lr: 0.100000
2022-04-28 20:09:16,631 epoch 9 - iter 50/107 - loss 0.10288959 - samples/sec: 74.99 - lr: 0.100000
2022-04-28 20:09:21,381 epoch 9 - iter 60/107 - loss 0.10124442 - samples/sec: 67.40 - lr: 0.100000
2022-04-28 20:09:25,677 epoch 9 - iter 70/107 - loss 0.09989448 - samples/sec: 74.50 - lr: 0.100000
2022-04-28 20:09:30,147 epoch 9 - iter 80/107 - loss 0.09854819 - samples/sec: 71.61 - lr: 0.100000
2022-04-28 20:09:34,403 epoch 9 - iter 90/107 - loss 0.10051306 - samples/sec: 75.22 - lr: 0.100000
2022-04-28 20:09:38,550 epoch 9 - iter 100/107 - loss 0.10144343 - samples/sec: 77.17 - lr: 0.100000
2022-04-28 20:09:41,358 ----------------------------------------------------------------------------------------------------
2022-04-28 20:09:41,358 EPOCH 9 done: loss 0.1019 - lr 0.100000
2022-04-28 20:09:55,006 Evaluating as a multi-label problem: False
2022-04-28 20:09:55,017 DEV : loss 0.21761760115623474 - f1-score (micro avg)  0.5004
2022-04-28 20:09:55,089 BAD EPOCHS (no improvement): 0
2022-04-28 20:09:55,092 saving best model
2022-04-28 20:10:14,241 ----------------------------------------------------------------------------------------------------
2022-04-28 20:10:19,084 epoch 10 - iter 10/107 - loss 0.09781241 - samples/sec: 66.09 - lr: 0.100000
2022-04-28 20:10:23,736 epoch 10 - iter 20/107 - loss 0.08905463 - samples/sec: 68.81 - lr: 0.100000
2022-04-28 20:10:28,450 epoch 10 - iter 30/107 - loss 0.08549845 - samples/sec: 67.90 - lr: 0.100000
2022-04-28 20:10:33,039 epoch 10 - iter 40/107 - loss 0.08858923 - samples/sec: 69.75 - lr: 0.100000
2022-04-28 20:10:36,925 epoch 10 - iter 50/107 - loss 0.09211711 - samples/sec: 82.36 - lr: 0.100000
2022-04-28 20:10:40,461 epoch 10 - iter 60/107 - loss 0.09031275 - samples/sec: 90.52 - lr: 0.100000
2022-04-28 20:10:44,353 epoch 10 - iter 70/107 - loss 0.09244520 - samples/sec: 82.25 - lr: 0.100000
2022-04-28 20:10:48,987 epoch 10 - iter 80/107 - loss 0.09303932 - samples/sec: 69.07 - lr: 0.100000
2022-04-28 20:10:53,973 epoch 10 - iter 90/107 - loss 0.09420487 - samples/sec: 64.19 - lr: 0.100000
2022-04-28 20:10:58,633 epoch 10 - iter 100/107 - loss 0.09604978 - samples/sec: 68.69 - lr: 0.100000
2022-04-28 20:11:01,434 ----------------------------------------------------------------------------------------------------
2022-04-28 20:11:01,434 EPOCH 10 done: loss 0.0968 - lr 0.100000
2022-04-28 20:11:15,282 Evaluating as a multi-label problem: False
2022-04-28 20:11:15,294 DEV : loss 0.1949201375246048 - f1-score (micro avg)  0.4816
2022-04-28 20:11:15,366 BAD EPOCHS (no improvement): 1
2022-04-28 20:11:15,385 ----------------------------------------------------------------------------------------------------
2022-04-28 20:11:19,978 epoch 11 - iter 10/107 - loss 0.08041476 - samples/sec: 69.69 - lr: 0.100000
2022-04-28 20:11:24,566 epoch 11 - iter 20/107 - loss 0.09405412 - samples/sec: 69.77 - lr: 0.100000
2022-04-28 20:11:28,665 epoch 11 - iter 30/107 - loss 0.09662125 - samples/sec: 78.07 - lr: 0.100000
2022-04-28 20:11:32,601 epoch 11 - iter 40/107 - loss 0.09450678 - samples/sec: 81.34 - lr: 0.100000
2022-04-28 20:11:36,838 epoch 11 - iter 50/107 - loss 0.09254003 - samples/sec: 75.54 - lr: 0.100000
2022-04-28 20:11:41,653 epoch 11 - iter 60/107 - loss 0.09306755 - samples/sec: 66.47 - lr: 0.100000
2022-04-28 20:11:46,115 epoch 11 - iter 70/107 - loss 0.09093296 - samples/sec: 71.73 - lr: 0.100000
2022-04-28 20:11:50,470 epoch 11 - iter 80/107 - loss 0.09079068 - samples/sec: 73.51 - lr: 0.100000
2022-04-28 20:11:54,769 epoch 11 - iter 90/107 - loss 0.09131552 - samples/sec: 74.44 - lr: 0.100000
2022-04-28 20:11:59,316 epoch 11 - iter 100/107 - loss 0.09142411 - samples/sec: 70.40 - lr: 0.100000
2022-04-28 20:12:02,338 ----------------------------------------------------------------------------------------------------
2022-04-28 20:12:02,338 EPOCH 11 done: loss 0.0904 - lr 0.100000
2022-04-28 20:12:15,794 Evaluating as a multi-label problem: False
2022-04-28 20:12:15,807 DEV : loss 0.20623385906219482 - f1-score (micro avg)  0.481
2022-04-28 20:12:15,878 BAD EPOCHS (no improvement): 2
2022-04-28 20:12:15,880 ----------------------------------------------------------------------------------------------------
2022-04-28 20:12:20,013 epoch 12 - iter 10/107 - loss 0.06627684 - samples/sec: 77.46 - lr: 0.100000
2022-04-28 20:12:24,037 epoch 12 - iter 20/107 - loss 0.08556965 - samples/sec: 79.55 - lr: 0.100000
2022-04-28 20:12:28,721 epoch 12 - iter 30/107 - loss 0.08194579 - samples/sec: 68.33 - lr: 0.100000
2022-04-28 20:12:33,614 epoch 12 - iter 40/107 - loss 0.08914027 - samples/sec: 65.42 - lr: 0.100000
2022-04-28 20:12:38,357 epoch 12 - iter 50/107 - loss 0.08566390 - samples/sec: 67.47 - lr: 0.100000
2022-04-28 20:12:43,239 epoch 12 - iter 60/107 - loss 0.08600964 - samples/sec: 65.56 - lr: 0.100000
2022-04-28 20:12:48,053 epoch 12 - iter 70/107 - loss 0.08604654 - samples/sec: 66.49 - lr: 0.100000
2022-04-28 20:12:52,512 epoch 12 - iter 80/107 - loss 0.08837070 - samples/sec: 71.78 - lr: 0.100000
2022-04-28 20:12:56,854 epoch 12 - iter 90/107 - loss 0.08894654 - samples/sec: 73.72 - lr: 0.100000
2022-04-28 20:13:01,287 epoch 12 - iter 100/107 - loss 0.08768859 - samples/sec: 72.21 - lr: 0.100000
2022-04-28 20:13:03,891 ----------------------------------------------------------------------------------------------------
2022-04-28 20:13:03,891 EPOCH 12 done: loss 0.0885 - lr 0.100000
2022-04-28 20:13:16,092 Evaluating as a multi-label problem: False
2022-04-28 20:13:16,102 DEV : loss 0.21854490041732788 - f1-score (micro avg)  0.4795
2022-04-28 20:13:16,178 BAD EPOCHS (no improvement): 3
2022-04-28 20:13:16,181 ----------------------------------------------------------------------------------------------------
2022-04-28 20:13:20,738 epoch 13 - iter 10/107 - loss 0.07918873 - samples/sec: 70.24 - lr: 0.100000
2022-04-28 20:13:25,501 epoch 13 - iter 20/107 - loss 0.08009201 - samples/sec: 67.21 - lr: 0.100000
2022-04-28 20:13:30,248 epoch 13 - iter 30/107 - loss 0.08054431 - samples/sec: 67.43 - lr: 0.100000
2022-04-28 20:13:35,024 epoch 13 - iter 40/107 - loss 0.08144692 - samples/sec: 67.00 - lr: 0.100000
2022-04-28 20:13:41,613 epoch 13 - iter 50/107 - loss 0.08298647 - samples/sec: 48.57 - lr: 0.100000
2022-04-28 20:13:46,289 epoch 13 - iter 60/107 - loss 0.07985880 - samples/sec: 68.46 - lr: 0.100000
2022-04-28 20:13:51,010 epoch 13 - iter 70/107 - loss 0.08176313 - samples/sec: 67.79 - lr: 0.100000
2022-04-28 20:13:55,845 epoch 13 - iter 80/107 - loss 0.08267338 - samples/sec: 66.20 - lr: 0.100000
2022-04-28 20:14:00,308 epoch 13 - iter 90/107 - loss 0.08250415 - samples/sec: 71.70 - lr: 0.100000
2022-04-28 20:14:04,498 epoch 13 - iter 100/107 - loss 0.08217528 - samples/sec: 76.40 - lr: 0.100000
2022-04-28 20:14:06,788 ----------------------------------------------------------------------------------------------------
2022-04-28 20:14:06,788 EPOCH 13 done: loss 0.0823 - lr 0.100000
2022-04-28 20:14:19,391 Evaluating as a multi-label problem: False
2022-04-28 20:14:19,405 DEV : loss 0.17615348100662231 - f1-score (micro avg)  0.5293
2022-04-28 20:14:19,475 BAD EPOCHS (no improvement): 0
2022-04-28 20:14:19,523 saving best model
2022-04-28 20:14:38,616 ----------------------------------------------------------------------------------------------------
2022-04-28 20:14:42,898 epoch 14 - iter 10/107 - loss 0.10088349 - samples/sec: 74.76 - lr: 0.100000
2022-04-28 20:14:46,793 epoch 14 - iter 20/107 - loss 0.08550539 - samples/sec: 82.19 - lr: 0.100000
2022-04-28 20:14:51,430 epoch 14 - iter 30/107 - loss 0.08090605 - samples/sec: 69.02 - lr: 0.100000
2022-04-28 20:14:56,166 epoch 14 - iter 40/107 - loss 0.07879250 - samples/sec: 67.58 - lr: 0.100000
2022-04-28 20:15:00,882 epoch 14 - iter 50/107 - loss 0.08089067 - samples/sec: 67.88 - lr: 0.100000
2022-04-28 20:15:05,839 epoch 14 - iter 60/107 - loss 0.08104914 - samples/sec: 64.57 - lr: 0.100000
2022-04-28 20:15:10,151 epoch 14 - iter 70/107 - loss 0.07981405 - samples/sec: 74.22 - lr: 0.100000
2022-04-28 20:15:14,549 epoch 14 - iter 80/107 - loss 0.07814612 - samples/sec: 72.78 - lr: 0.100000
2022-04-28 20:15:19,035 epoch 14 - iter 90/107 - loss 0.07905084 - samples/sec: 71.35 - lr: 0.100000
2022-04-28 20:15:23,786 epoch 14 - iter 100/107 - loss 0.07881768 - samples/sec: 67.37 - lr: 0.100000
2022-04-28 20:15:26,509 ----------------------------------------------------------------------------------------------------
2022-04-28 20:15:26,509 EPOCH 14 done: loss 0.0784 - lr 0.100000
2022-04-28 20:15:39,257 Evaluating as a multi-label problem: False
2022-04-28 20:15:39,270 DEV : loss 0.19945630431175232 - f1-score (micro avg)  0.493
2022-04-28 20:15:39,341 BAD EPOCHS (no improvement): 1
2022-04-28 20:15:39,351 ----------------------------------------------------------------------------------------------------
2022-04-28 20:15:44,180 epoch 15 - iter 10/107 - loss 0.07972989 - samples/sec: 66.28 - lr: 0.100000
2022-04-28 20:15:48,800 epoch 15 - iter 20/107 - loss 0.07784970 - samples/sec: 69.28 - lr: 0.100000
2022-04-28 20:15:53,636 epoch 15 - iter 30/107 - loss 0.07609714 - samples/sec: 66.18 - lr: 0.100000
2022-04-28 20:15:58,300 epoch 15 - iter 40/107 - loss 0.07333996 - samples/sec: 68.62 - lr: 0.100000
2022-04-28 20:16:02,966 epoch 15 - iter 50/107 - loss 0.07003404 - samples/sec: 68.61 - lr: 0.100000
2022-04-28 20:16:07,873 epoch 15 - iter 60/107 - loss 0.06885201 - samples/sec: 65.23 - lr: 0.100000
2022-04-28 20:16:12,395 epoch 15 - iter 70/107 - loss 0.06911656 - samples/sec: 70.78 - lr: 0.100000
2022-04-28 20:16:17,026 epoch 15 - iter 80/107 - loss 0.07003710 - samples/sec: 69.12 - lr: 0.100000
2022-04-28 20:16:21,370 epoch 15 - iter 90/107 - loss 0.07184745 - samples/sec: 73.67 - lr: 0.100000
2022-04-28 20:16:24,999 epoch 15 - iter 100/107 - loss 0.07435564 - samples/sec: 88.22 - lr: 0.100000
2022-04-28 20:16:27,424 ----------------------------------------------------------------------------------------------------
2022-04-28 20:16:27,424 EPOCH 15 done: loss 0.0735 - lr 0.100000
2022-04-28 20:16:40,702 Evaluating as a multi-label problem: False
2022-04-28 20:16:40,713 DEV : loss 0.2060522586107254 - f1-score (micro avg)  0.4988
2022-04-28 20:16:40,787 BAD EPOCHS (no improvement): 2
2022-04-28 20:16:40,789 ----------------------------------------------------------------------------------------------------
2022-04-28 20:16:45,522 epoch 16 - iter 10/107 - loss 0.07578793 - samples/sec: 67.64 - lr: 0.100000
2022-04-28 20:16:50,307 epoch 16 - iter 20/107 - loss 0.07107436 - samples/sec: 66.88 - lr: 0.100000
2022-04-28 20:16:54,811 epoch 16 - iter 30/107 - loss 0.06633377 - samples/sec: 71.07 - lr: 0.100000
2022-04-28 20:16:59,832 epoch 16 - iter 40/107 - loss 0.06581305 - samples/sec: 63.75 - lr: 0.100000
2022-04-28 20:17:04,464 epoch 16 - iter 50/107 - loss 0.06890946 - samples/sec: 69.11 - lr: 0.100000
2022-04-28 20:17:08,628 epoch 16 - iter 60/107 - loss 0.06983445 - samples/sec: 76.86 - lr: 0.100000
2022-04-28 20:17:12,502 epoch 16 - iter 70/107 - loss 0.07243294 - samples/sec: 82.63 - lr: 0.100000
2022-04-28 20:17:15,799 epoch 16 - iter 80/107 - loss 0.07262208 - samples/sec: 97.10 - lr: 0.100000
2022-04-28 20:17:19,774 epoch 16 - iter 90/107 - loss 0.07258273 - samples/sec: 80.51 - lr: 0.100000
2022-04-28 20:17:24,479 epoch 16 - iter 100/107 - loss 0.07190934 - samples/sec: 68.04 - lr: 0.100000
2022-04-28 20:17:27,451 ----------------------------------------------------------------------------------------------------
2022-04-28 20:17:27,451 EPOCH 16 done: loss 0.0724 - lr 0.100000
2022-04-28 20:17:40,656 Evaluating as a multi-label problem: False
2022-04-28 20:17:40,667 DEV : loss 0.19319060444831848 - f1-score (micro avg)  0.5191
2022-04-28 20:17:40,742 BAD EPOCHS (no improvement): 3
2022-04-28 20:17:40,757 ----------------------------------------------------------------------------------------------------
2022-04-28 20:17:45,440 epoch 17 - iter 10/107 - loss 0.05237222 - samples/sec: 68.35 - lr: 0.100000
2022-04-28 20:17:49,697 epoch 17 - iter 20/107 - loss 0.06188106 - samples/sec: 75.19 - lr: 0.100000
2022-04-28 20:17:54,616 epoch 17 - iter 30/107 - loss 0.06718021 - samples/sec: 65.08 - lr: 0.100000
2022-04-28 20:17:59,286 epoch 17 - iter 40/107 - loss 0.06804314 - samples/sec: 68.53 - lr: 0.100000
2022-04-28 20:18:03,455 epoch 17 - iter 50/107 - loss 0.06864516 - samples/sec: 76.78 - lr: 0.100000
2022-04-28 20:18:07,425 epoch 17 - iter 60/107 - loss 0.06749340 - samples/sec: 80.64 - lr: 0.100000
2022-04-28 20:18:11,785 epoch 17 - iter 70/107 - loss 0.06774433 - samples/sec: 73.41 - lr: 0.100000
2022-04-28 20:18:16,576 epoch 17 - iter 80/107 - loss 0.06677122 - samples/sec: 66.80 - lr: 0.100000
2022-04-28 20:18:21,391 epoch 17 - iter 90/107 - loss 0.06482330 - samples/sec: 66.47 - lr: 0.100000
2022-04-28 20:18:26,136 epoch 17 - iter 100/107 - loss 0.06566137 - samples/sec: 67.45 - lr: 0.100000
2022-04-28 20:18:28,828 ----------------------------------------------------------------------------------------------------
2022-04-28 20:18:28,828 EPOCH 17 done: loss 0.0657 - lr 0.100000
2022-04-28 20:18:42,664 Evaluating as a multi-label problem: False
2022-04-28 20:18:42,675 DEV : loss 0.20922209322452545 - f1-score (micro avg)  0.5297
2022-04-28 20:18:42,745 BAD EPOCHS (no improvement): 0
2022-04-28 20:18:42,748 saving best model
2022-04-28 20:19:02,888 ----------------------------------------------------------------------------------------------------
2022-04-28 20:19:07,924 epoch 18 - iter 10/107 - loss 0.06092884 - samples/sec: 63.57 - lr: 0.100000
2022-04-28 20:19:12,450 epoch 18 - iter 20/107 - loss 0.06067759 - samples/sec: 70.73 - lr: 0.100000
2022-04-28 20:19:17,403 epoch 18 - iter 30/107 - loss 0.06081416 - samples/sec: 64.62 - lr: 0.100000
2022-04-28 20:19:22,264 epoch 18 - iter 40/107 - loss 0.05902144 - samples/sec: 65.86 - lr: 0.100000
2022-04-28 20:19:27,157 epoch 18 - iter 50/107 - loss 0.05877880 - samples/sec: 65.41 - lr: 0.100000
2022-04-28 20:19:31,492 epoch 18 - iter 60/107 - loss 0.05829345 - samples/sec: 73.85 - lr: 0.100000
2022-04-28 20:19:35,476 epoch 18 - iter 70/107 - loss 0.06051848 - samples/sec: 80.34 - lr: 0.100000
2022-04-28 20:19:39,635 epoch 18 - iter 80/107 - loss 0.06235151 - samples/sec: 76.96 - lr: 0.100000
2022-04-28 20:19:44,607 epoch 18 - iter 90/107 - loss 0.06322883 - samples/sec: 64.37 - lr: 0.100000
2022-04-28 20:19:48,868 epoch 18 - iter 100/107 - loss 0.06275740 - samples/sec: 75.13 - lr: 0.100000
2022-04-28 20:19:51,616 ----------------------------------------------------------------------------------------------------
2022-04-28 20:19:51,616 EPOCH 18 done: loss 0.0626 - lr 0.100000
2022-04-28 20:20:04,706 Evaluating as a multi-label problem: False
2022-04-28 20:20:04,718 DEV : loss 0.18701064586639404 - f1-score (micro avg)  0.4879
2022-04-28 20:20:04,796 BAD EPOCHS (no improvement): 1
2022-04-28 20:20:04,800 ----------------------------------------------------------------------------------------------------
2022-04-28 20:20:09,461 epoch 19 - iter 10/107 - loss 0.07088626 - samples/sec: 68.67 - lr: 0.100000
2022-04-28 20:20:14,268 epoch 19 - iter 20/107 - loss 0.06416783 - samples/sec: 66.59 - lr: 0.100000
2022-04-28 20:20:18,965 epoch 19 - iter 30/107 - loss 0.06012418 - samples/sec: 68.15 - lr: 0.100000
2022-04-28 20:20:23,056 epoch 19 - iter 40/107 - loss 0.06258995 - samples/sec: 78.25 - lr: 0.100000
2022-04-28 20:20:27,634 epoch 19 - iter 50/107 - loss 0.06248487 - samples/sec: 69.91 - lr: 0.100000
2022-04-28 20:20:32,212 epoch 19 - iter 60/107 - loss 0.06354217 - samples/sec: 69.92 - lr: 0.100000
2022-04-28 20:20:36,880 epoch 19 - iter 70/107 - loss 0.06408167 - samples/sec: 68.57 - lr: 0.100000
2022-04-28 20:20:41,672 epoch 19 - iter 80/107 - loss 0.06187546 - samples/sec: 66.80 - lr: 0.100000
2022-04-28 20:20:46,211 epoch 19 - iter 90/107 - loss 0.06169207 - samples/sec: 70.51 - lr: 0.100000
2022-04-28 20:20:50,866 epoch 19 - iter 100/107 - loss 0.06141423 - samples/sec: 68.76 - lr: 0.100000
2022-04-28 20:20:53,889 ----------------------------------------------------------------------------------------------------
2022-04-28 20:20:53,889 EPOCH 19 done: loss 0.0609 - lr 0.100000
2022-04-28 20:21:07,248 Evaluating as a multi-label problem: False
2022-04-28 20:21:07,259 DEV : loss 0.21692636609077454 - f1-score (micro avg)  0.502
2022-04-28 20:21:07,330 BAD EPOCHS (no improvement): 2
2022-04-28 20:21:07,345 ----------------------------------------------------------------------------------------------------
2022-04-28 20:21:11,629 epoch 20 - iter 10/107 - loss 0.05011488 - samples/sec: 74.71 - lr: 0.100000
2022-04-28 20:21:15,523 epoch 20 - iter 20/107 - loss 0.04989579 - samples/sec: 82.20 - lr: 0.100000
2022-04-28 20:21:20,035 epoch 20 - iter 30/107 - loss 0.05225043 - samples/sec: 70.93 - lr: 0.100000
2022-04-28 20:21:24,491 epoch 20 - iter 40/107 - loss 0.05602888 - samples/sec: 71.84 - lr: 0.100000
2022-04-28 20:21:29,105 epoch 20 - iter 50/107 - loss 0.05830801 - samples/sec: 69.36 - lr: 0.100000
2022-04-28 20:21:33,988 epoch 20 - iter 60/107 - loss 0.05842291 - samples/sec: 65.55 - lr: 0.100000
2022-04-28 20:21:38,551 epoch 20 - iter 70/107 - loss 0.05868919 - samples/sec: 70.16 - lr: 0.100000
2022-04-28 20:21:43,563 epoch 20 - iter 80/107 - loss 0.05893595 - samples/sec: 63.86 - lr: 0.100000
2022-04-28 20:21:48,196 epoch 20 - iter 90/107 - loss 0.06024589 - samples/sec: 69.08 - lr: 0.100000
2022-04-28 20:21:52,986 epoch 20 - iter 100/107 - loss 0.06046744 - samples/sec: 66.83 - lr: 0.100000
2022-04-28 20:21:55,831 ----------------------------------------------------------------------------------------------------
2022-04-28 20:21:55,831 EPOCH 20 done: loss 0.0597 - lr 0.100000
2022-04-28 20:22:08,514 Evaluating as a multi-label problem: False
2022-04-28 20:22:08,526 DEV : loss 0.21894173324108124 - f1-score (micro avg)  0.4729
2022-04-28 20:22:08,598 BAD EPOCHS (no improvement): 3
2022-04-28 20:22:08,625 ----------------------------------------------------------------------------------------------------
2022-04-28 20:22:12,533 epoch 21 - iter 10/107 - loss 0.04654801 - samples/sec: 81.92 - lr: 0.100000
2022-04-28 20:22:18,331 epoch 21 - iter 20/107 - loss 0.04646389 - samples/sec: 55.20 - lr: 0.100000
2022-04-28 20:22:22,783 epoch 21 - iter 30/107 - loss 0.05058932 - samples/sec: 71.90 - lr: 0.100000
2022-04-28 20:22:27,592 epoch 21 - iter 40/107 - loss 0.05294543 - samples/sec: 66.56 - lr: 0.100000
2022-04-28 20:22:32,653 epoch 21 - iter 50/107 - loss 0.05321634 - samples/sec: 63.24 - lr: 0.100000
2022-04-28 20:22:37,841 epoch 21 - iter 60/107 - loss 0.05365089 - samples/sec: 61.70 - lr: 0.100000
2022-04-28 20:22:42,265 epoch 21 - iter 70/107 - loss 0.05409749 - samples/sec: 72.34 - lr: 0.100000
2022-04-28 20:22:47,054 epoch 21 - iter 80/107 - loss 0.05461882 - samples/sec: 66.84 - lr: 0.100000
2022-04-28 20:22:52,172 epoch 21 - iter 90/107 - loss 0.05460087 - samples/sec: 62.53 - lr: 0.100000
2022-04-28 20:22:56,453 epoch 21 - iter 100/107 - loss 0.05463193 - samples/sec: 74.77 - lr: 0.100000
2022-04-28 20:22:59,013 ----------------------------------------------------------------------------------------------------
2022-04-28 20:22:59,013 EPOCH 21 done: loss 0.0551 - lr 0.100000
2022-04-28 20:23:12,660 Evaluating as a multi-label problem: False
2022-04-28 20:23:12,671 DEV : loss 0.2420472800731659 - f1-score (micro avg)  0.487
2022-04-28 20:23:12,742 Epoch    21: reducing learning rate of group 0 to 5.0000e-02.
2022-04-28 20:23:12,742 BAD EPOCHS (no improvement): 4
2022-04-28 20:23:12,744 ----------------------------------------------------------------------------------------------------
2022-04-28 20:23:17,660 epoch 22 - iter 10/107 - loss 0.04609532 - samples/sec: 65.12 - lr: 0.050000
2022-04-28 20:23:22,298 epoch 22 - iter 20/107 - loss 0.04468740 - samples/sec: 69.00 - lr: 0.050000
2022-04-28 20:23:26,909 epoch 22 - iter 30/107 - loss 0.04817917 - samples/sec: 69.42 - lr: 0.050000
2022-04-28 20:23:31,185 epoch 22 - iter 40/107 - loss 0.04675937 - samples/sec: 74.85 - lr: 0.050000
2022-04-28 20:23:35,526 epoch 22 - iter 50/107 - loss 0.04850385 - samples/sec: 73.74 - lr: 0.050000
2022-04-28 20:23:40,289 epoch 22 - iter 60/107 - loss 0.05023782 - samples/sec: 67.20 - lr: 0.050000
2022-04-28 20:23:44,975 epoch 22 - iter 70/107 - loss 0.05003022 - samples/sec: 68.30 - lr: 0.050000
2022-04-28 20:23:48,923 epoch 22 - iter 80/107 - loss 0.04929406 - samples/sec: 81.08 - lr: 0.050000
2022-04-28 20:23:53,109 epoch 22 - iter 90/107 - loss 0.04854362 - samples/sec: 76.47 - lr: 0.050000
2022-04-28 20:23:58,049 epoch 22 - iter 100/107 - loss 0.04885204 - samples/sec: 64.80 - lr: 0.050000
2022-04-28 20:24:01,070 ----------------------------------------------------------------------------------------------------
2022-04-28 20:24:01,070 EPOCH 22 done: loss 0.0493 - lr 0.050000
2022-04-28 20:24:14,990 Evaluating as a multi-label problem: False
2022-04-28 20:24:15,002 DEV : loss 0.20059658586978912 - f1-score (micro avg)  0.535
2022-04-28 20:24:15,078 BAD EPOCHS (no improvement): 0
2022-04-28 20:24:15,081 saving best model
2022-04-28 20:24:35,477 ----------------------------------------------------------------------------------------------------
2022-04-28 20:24:39,640 epoch 23 - iter 10/107 - loss 0.03839656 - samples/sec: 76.92 - lr: 0.050000
2022-04-28 20:24:44,825 epoch 23 - iter 20/107 - loss 0.04156348 - samples/sec: 61.73 - lr: 0.050000
2022-04-28 20:24:49,456 epoch 23 - iter 30/107 - loss 0.04159098 - samples/sec: 69.11 - lr: 0.050000
2022-04-28 20:24:54,328 epoch 23 - iter 40/107 - loss 0.04184478 - samples/sec: 65.69 - lr: 0.050000
2022-04-28 20:24:59,269 epoch 23 - iter 50/107 - loss 0.04147595 - samples/sec: 64.78 - lr: 0.050000
2022-04-28 20:25:03,807 epoch 23 - iter 60/107 - loss 0.04313790 - samples/sec: 70.53 - lr: 0.050000
2022-04-28 20:25:08,607 epoch 23 - iter 70/107 - loss 0.04516699 - samples/sec: 66.68 - lr: 0.050000
2022-04-28 20:25:13,161 epoch 23 - iter 80/107 - loss 0.04496243 - samples/sec: 70.28 - lr: 0.050000
2022-04-28 20:25:17,015 epoch 23 - iter 90/107 - loss 0.04494022 - samples/sec: 83.05 - lr: 0.050000
2022-04-28 20:25:21,051 epoch 23 - iter 100/107 - loss 0.04566781 - samples/sec: 79.31 - lr: 0.050000
2022-04-28 20:25:23,775 ----------------------------------------------------------------------------------------------------
2022-04-28 20:25:23,775 EPOCH 23 done: loss 0.0456 - lr 0.050000
2022-04-28 20:25:37,775 Evaluating as a multi-label problem: False
2022-04-28 20:25:37,789 DEV : loss 0.23144680261611938 - f1-score (micro avg)  0.4984
2022-04-28 20:25:37,859 BAD EPOCHS (no improvement): 1
2022-04-28 20:25:37,861 ----------------------------------------------------------------------------------------------------
2022-04-28 20:25:42,441 epoch 24 - iter 10/107 - loss 0.03949754 - samples/sec: 69.90 - lr: 0.050000
2022-04-28 20:25:46,834 epoch 24 - iter 20/107 - loss 0.04080626 - samples/sec: 72.86 - lr: 0.050000
2022-04-28 20:25:51,678 epoch 24 - iter 30/107 - loss 0.04501579 - samples/sec: 66.07 - lr: 0.050000
2022-04-28 20:25:56,345 epoch 24 - iter 40/107 - loss 0.04473250 - samples/sec: 68.58 - lr: 0.050000
2022-04-28 20:26:00,891 epoch 24 - iter 50/107 - loss 0.04472004 - samples/sec: 70.41 - lr: 0.050000
2022-04-28 20:26:05,084 epoch 24 - iter 60/107 - loss 0.04408511 - samples/sec: 76.33 - lr: 0.050000
2022-04-28 20:26:09,154 epoch 24 - iter 70/107 - loss 0.04384376 - samples/sec: 78.63 - lr: 0.050000
2022-04-28 20:26:13,398 epoch 24 - iter 80/107 - loss 0.04403281 - samples/sec: 75.43 - lr: 0.050000
2022-04-28 20:26:18,137 epoch 24 - iter 90/107 - loss 0.04440790 - samples/sec: 67.54 - lr: 0.050000
2022-04-28 20:26:22,907 epoch 24 - iter 100/107 - loss 0.04430847 - samples/sec: 67.10 - lr: 0.050000
2022-04-28 20:26:25,687 ----------------------------------------------------------------------------------------------------
2022-04-28 20:26:25,687 EPOCH 24 done: loss 0.0448 - lr 0.050000
2022-04-28 20:26:39,519 Evaluating as a multi-label problem: False
2022-04-28 20:26:39,530 DEV : loss 0.2249743640422821 - f1-score (micro avg)  0.5108
2022-04-28 20:26:39,602 BAD EPOCHS (no improvement): 2
2022-04-28 20:26:39,604 ----------------------------------------------------------------------------------------------------
2022-04-28 20:26:44,390 epoch 25 - iter 10/107 - loss 0.04115662 - samples/sec: 66.87 - lr: 0.050000
2022-04-28 20:26:49,219 epoch 25 - iter 20/107 - loss 0.04018372 - samples/sec: 66.29 - lr: 0.050000
2022-04-28 20:26:53,589 epoch 25 - iter 30/107 - loss 0.04087092 - samples/sec: 73.23 - lr: 0.050000
2022-04-28 20:26:57,603 epoch 25 - iter 40/107 - loss 0.04225180 - samples/sec: 79.75 - lr: 0.050000
2022-04-28 20:27:00,959 epoch 25 - iter 50/107 - loss 0.04197998 - samples/sec: 95.38 - lr: 0.050000
2022-04-28 20:27:05,522 epoch 25 - iter 60/107 - loss 0.04249147 - samples/sec: 70.15 - lr: 0.050000
2022-04-28 20:27:10,026 epoch 25 - iter 70/107 - loss 0.04330735 - samples/sec: 71.07 - lr: 0.050000
2022-04-28 20:27:14,664 epoch 25 - iter 80/107 - loss 0.04268994 - samples/sec: 69.01 - lr: 0.050000
2022-04-28 20:27:19,236 epoch 25 - iter 90/107 - loss 0.04251899 - samples/sec: 70.01 - lr: 0.050000
2022-04-28 20:27:24,242 epoch 25 - iter 100/107 - loss 0.04232088 - samples/sec: 63.93 - lr: 0.050000
2022-04-28 20:27:27,082 ----------------------------------------------------------------------------------------------------
2022-04-28 20:27:27,082 EPOCH 25 done: loss 0.0416 - lr 0.050000
2022-04-28 20:27:41,255 Evaluating as a multi-label problem: False
2022-04-28 20:27:41,266 DEV : loss 0.2129412740468979 - f1-score (micro avg)  0.5267
2022-04-28 20:27:41,338 BAD EPOCHS (no improvement): 3
2022-04-28 20:27:41,341 ----------------------------------------------------------------------------------------------------
2022-04-28 20:27:45,568 epoch 26 - iter 10/107 - loss 0.03281436 - samples/sec: 75.72 - lr: 0.050000
2022-04-28 20:27:49,743 epoch 26 - iter 20/107 - loss 0.03876965 - samples/sec: 76.66 - lr: 0.050000
2022-04-28 20:27:53,701 epoch 26 - iter 30/107 - loss 0.03979160 - samples/sec: 80.87 - lr: 0.050000
2022-04-28 20:27:56,470 epoch 26 - iter 40/107 - loss 0.03942716 - samples/sec: 115.65 - lr: 0.050000
2022-04-28 20:27:59,203 epoch 26 - iter 50/107 - loss 0.03910107 - samples/sec: 117.14 - lr: 0.050000
2022-04-28 20:28:01,843 epoch 26 - iter 60/107 - loss 0.04044467 - samples/sec: 121.26 - lr: 0.050000
2022-04-28 20:28:04,386 epoch 26 - iter 70/107 - loss 0.03972781 - samples/sec: 125.89 - lr: 0.050000
2022-04-28 20:28:06,812 epoch 26 - iter 80/107 - loss 0.03942546 - samples/sec: 131.93 - lr: 0.050000
2022-04-28 20:28:08,859 epoch 26 - iter 90/107 - loss 0.03980238 - samples/sec: 156.43 - lr: 0.050000
2022-04-28 20:28:11,039 epoch 26 - iter 100/107 - loss 0.04058544 - samples/sec: 146.83 - lr: 0.050000
2022-04-28 20:28:12,386 ----------------------------------------------------------------------------------------------------
2022-04-28 20:28:12,386 EPOCH 26 done: loss 0.0405 - lr 0.050000
2022-04-28 20:28:19,467 Evaluating as a multi-label problem: False
2022-04-28 20:28:19,479 DEV : loss 0.2071554809808731 - f1-score (micro avg)  0.5124
2022-04-28 20:28:19,549 Epoch    26: reducing learning rate of group 0 to 2.5000e-02.
2022-04-28 20:28:19,549 BAD EPOCHS (no improvement): 4
2022-04-28 20:28:19,552 ----------------------------------------------------------------------------------------------------
2022-04-28 20:28:21,829 epoch 27 - iter 10/107 - loss 0.03735175 - samples/sec: 140.64 - lr: 0.025000
2022-04-28 20:28:24,062 epoch 27 - iter 20/107 - loss 0.03575591 - samples/sec: 143.35 - lr: 0.025000
2022-04-28 20:28:26,378 epoch 27 - iter 30/107 - loss 0.03604533 - samples/sec: 138.22 - lr: 0.025000
2022-04-28 20:28:28,737 epoch 27 - iter 40/107 - loss 0.03882143 - samples/sec: 135.68 - lr: 0.025000
2022-04-28 20:28:30,956 epoch 27 - iter 50/107 - loss 0.03747576 - samples/sec: 144.26 - lr: 0.025000
2022-04-28 20:28:33,257 epoch 27 - iter 60/107 - loss 0.03696186 - samples/sec: 139.15 - lr: 0.025000
2022-04-28 20:28:35,551 epoch 27 - iter 70/107 - loss 0.03695330 - samples/sec: 139.54 - lr: 0.025000
2022-04-28 20:28:37,768 epoch 27 - iter 80/107 - loss 0.03779366 - samples/sec: 144.43 - lr: 0.025000
2022-04-28 20:28:39,996 epoch 27 - iter 90/107 - loss 0.03810658 - samples/sec: 143.66 - lr: 0.025000
2022-04-28 20:28:42,292 epoch 27 - iter 100/107 - loss 0.03876107 - samples/sec: 139.42 - lr: 0.025000
2022-04-28 20:28:43,661 ----------------------------------------------------------------------------------------------------
2022-04-28 20:28:43,661 EPOCH 27 done: loss 0.0386 - lr 0.025000
2022-04-28 20:28:50,654 Evaluating as a multi-label problem: False
2022-04-28 20:28:50,666 DEV : loss 0.22094960510730743 - f1-score (micro avg)  0.5129
2022-04-28 20:28:50,738 BAD EPOCHS (no improvement): 1
2022-04-28 20:28:50,756 ----------------------------------------------------------------------------------------------------
2022-04-28 20:28:53,078 epoch 28 - iter 10/107 - loss 0.03137790 - samples/sec: 137.87 - lr: 0.025000
2022-04-28 20:28:55,247 epoch 28 - iter 20/107 - loss 0.03279374 - samples/sec: 147.65 - lr: 0.025000
2022-04-28 20:28:57,513 epoch 28 - iter 30/107 - loss 0.03623624 - samples/sec: 141.25 - lr: 0.025000
2022-04-28 20:28:59,816 epoch 28 - iter 40/107 - loss 0.03695990 - samples/sec: 139.02 - lr: 0.025000
2022-04-28 20:29:02,102 epoch 28 - iter 50/107 - loss 0.03716902 - samples/sec: 140.13 - lr: 0.025000
2022-04-28 20:29:04,257 epoch 28 - iter 60/107 - loss 0.03763452 - samples/sec: 148.58 - lr: 0.025000
2022-04-28 20:29:07,373 epoch 28 - iter 70/107 - loss 0.03770607 - samples/sec: 102.71 - lr: 0.025000
2022-04-28 20:29:12,377 epoch 28 - iter 80/107 - loss 0.03763442 - samples/sec: 63.96 - lr: 0.025000
2022-04-28 20:29:17,196 epoch 28 - iter 90/107 - loss 0.03832136 - samples/sec: 66.43 - lr: 0.025000
2022-04-28 20:29:21,688 epoch 28 - iter 100/107 - loss 0.03764273 - samples/sec: 71.25 - lr: 0.025000
2022-04-28 20:29:24,467 ----------------------------------------------------------------------------------------------------
2022-04-28 20:29:24,467 EPOCH 28 done: loss 0.0375 - lr 0.025000
2022-04-28 20:29:34,553 Evaluating as a multi-label problem: False
2022-04-28 20:29:34,565 DEV : loss 0.21974295377731323 - f1-score (micro avg)  0.5252
2022-04-28 20:29:34,635 BAD EPOCHS (no improvement): 2
2022-04-28 20:29:34,779 ----------------------------------------------------------------------------------------------------
2022-04-28 20:29:39,901 epoch 29 - iter 10/107 - loss 0.03970119 - samples/sec: 62.50 - lr: 0.025000
2022-04-28 20:29:43,521 epoch 29 - iter 20/107 - loss 0.03690845 - samples/sec: 88.43 - lr: 0.025000
2022-04-28 20:29:50,494 epoch 29 - iter 30/107 - loss 0.03791149 - samples/sec: 45.90 - lr: 0.025000
2022-04-28 20:29:57,330 epoch 29 - iter 40/107 - loss 0.03801222 - samples/sec: 46.82 - lr: 0.025000
2022-04-28 20:30:03,051 epoch 29 - iter 50/107 - loss 0.03966835 - samples/sec: 55.95 - lr: 0.025000
2022-04-28 20:30:07,822 epoch 29 - iter 60/107 - loss 0.03889551 - samples/sec: 67.07 - lr: 0.025000
2022-04-28 20:30:12,131 epoch 29 - iter 70/107 - loss 0.03839274 - samples/sec: 74.29 - lr: 0.025000
2022-04-28 20:30:15,201 epoch 29 - iter 80/107 - loss 0.03783222 - samples/sec: 104.27 - lr: 0.025000
2022-04-28 20:30:18,070 epoch 29 - iter 90/107 - loss 0.03728940 - samples/sec: 111.56 - lr: 0.025000
2022-04-28 20:30:20,998 epoch 29 - iter 100/107 - loss 0.03694550 - samples/sec: 109.33 - lr: 0.025000
2022-04-28 20:30:22,735 ----------------------------------------------------------------------------------------------------
2022-04-28 20:30:22,735 EPOCH 29 done: loss 0.0365 - lr 0.025000
2022-04-28 20:30:31,095 Evaluating as a multi-label problem: False
2022-04-28 20:30:31,106 DEV : loss 0.25789904594421387 - f1-score (micro avg)  0.4837
2022-04-28 20:30:31,178 BAD EPOCHS (no improvement): 3
2022-04-28 20:30:31,180 ----------------------------------------------------------------------------------------------------
2022-04-28 20:30:33,839 epoch 30 - iter 10/107 - loss 0.03789331 - samples/sec: 120.41 - lr: 0.025000
2022-04-28 20:30:36,703 epoch 30 - iter 20/107 - loss 0.03819473 - samples/sec: 111.78 - lr: 0.025000
2022-04-28 20:30:39,528 epoch 30 - iter 30/107 - loss 0.03754312 - samples/sec: 113.32 - lr: 0.025000
2022-04-28 20:30:42,365 epoch 30 - iter 40/107 - loss 0.03439916 - samples/sec: 112.82 - lr: 0.025000
2022-04-28 20:30:45,338 epoch 30 - iter 50/107 - loss 0.03463326 - samples/sec: 107.69 - lr: 0.025000
2022-04-28 20:30:48,151 epoch 30 - iter 60/107 - loss 0.03322937 - samples/sec: 113.79 - lr: 0.025000
2022-04-28 20:30:50,777 epoch 30 - iter 70/107 - loss 0.03329153 - samples/sec: 121.90 - lr: 0.025000
2022-04-28 20:30:55,381 epoch 30 - iter 80/107 - loss 0.03476767 - samples/sec: 69.53 - lr: 0.025000
2022-04-28 20:30:59,758 epoch 30 - iter 90/107 - loss 0.03423936 - samples/sec: 73.12 - lr: 0.025000
2022-04-28 20:31:03,395 epoch 30 - iter 100/107 - loss 0.03486874 - samples/sec: 88.02 - lr: 0.025000
2022-04-28 20:31:05,286 ----------------------------------------------------------------------------------------------------
2022-04-28 20:31:05,286 EPOCH 30 done: loss 0.0354 - lr 0.025000
2022-04-28 20:31:15,020 Evaluating as a multi-label problem: False
2022-04-28 20:31:15,031 DEV : loss 0.22296898066997528 - f1-score (micro avg)  0.5047
2022-04-28 20:31:15,102 Epoch    30: reducing learning rate of group 0 to 1.2500e-02.
2022-04-28 20:31:15,102 BAD EPOCHS (no improvement): 4
2022-04-28 20:31:15,104 ----------------------------------------------------------------------------------------------------
2022-04-28 20:31:18,401 epoch 31 - iter 10/107 - loss 0.03099746 - samples/sec: 97.10 - lr: 0.012500
2022-04-28 20:31:20,909 epoch 31 - iter 20/107 - loss 0.03086798 - samples/sec: 127.65 - lr: 0.012500
2022-04-28 20:31:23,513 epoch 31 - iter 30/107 - loss 0.02997437 - samples/sec: 122.91 - lr: 0.012500
2022-04-28 20:31:26,112 epoch 31 - iter 40/107 - loss 0.03124252 - samples/sec: 123.18 - lr: 0.012500
2022-04-28 20:31:28,183 epoch 31 - iter 50/107 - loss 0.03136539 - samples/sec: 154.60 - lr: 0.012500
2022-04-28 20:31:30,360 epoch 31 - iter 60/107 - loss 0.03149897 - samples/sec: 147.08 - lr: 0.012500
2022-04-28 20:31:32,565 epoch 31 - iter 70/107 - loss 0.03292246 - samples/sec: 145.13 - lr: 0.012500
2022-04-28 20:31:34,839 epoch 31 - iter 80/107 - loss 0.03363058 - samples/sec: 140.83 - lr: 0.012500
2022-04-28 20:31:37,150 epoch 31 - iter 90/107 - loss 0.03406387 - samples/sec: 138.48 - lr: 0.012500
2022-04-28 20:31:39,426 epoch 31 - iter 100/107 - loss 0.03391243 - samples/sec: 140.68 - lr: 0.012500
2022-04-28 20:31:40,811 ----------------------------------------------------------------------------------------------------
2022-04-28 20:31:40,811 EPOCH 31 done: loss 0.0335 - lr 0.012500
2022-04-28 20:31:47,818 Evaluating as a multi-label problem: False
2022-04-28 20:31:47,830 DEV : loss 0.22252953052520752 - f1-score (micro avg)  0.5151
2022-04-28 20:31:47,902 BAD EPOCHS (no improvement): 1
2022-04-28 20:31:47,948 ----------------------------------------------------------------------------------------------------
2022-04-28 20:31:50,245 epoch 32 - iter 10/107 - loss 0.02730181 - samples/sec: 139.42 - lr: 0.012500
2022-04-28 20:31:52,544 epoch 32 - iter 20/107 - loss 0.03199911 - samples/sec: 139.22 - lr: 0.012500
2022-04-28 20:31:55,242 epoch 32 - iter 30/107 - loss 0.03516364 - samples/sec: 118.69 - lr: 0.012500
2022-04-28 20:31:57,882 epoch 32 - iter 40/107 - loss 0.03476925 - samples/sec: 121.25 - lr: 0.012500
2022-04-28 20:32:01,231 epoch 32 - iter 50/107 - loss 0.03333810 - samples/sec: 95.58 - lr: 0.012500
2022-04-28 20:32:05,559 epoch 32 - iter 60/107 - loss 0.03465388 - samples/sec: 73.95 - lr: 0.012500
2022-04-28 20:32:10,184 epoch 32 - iter 70/107 - loss 0.03316456 - samples/sec: 69.20 - lr: 0.012500
2022-04-28 20:32:15,068 epoch 32 - iter 80/107 - loss 0.03263077 - samples/sec: 65.54 - lr: 0.012500
2022-04-28 20:32:19,545 epoch 32 - iter 90/107 - loss 0.03251521 - samples/sec: 71.49 - lr: 0.012500
2022-04-28 20:32:24,207 epoch 32 - iter 100/107 - loss 0.03268435 - samples/sec: 68.65 - lr: 0.012500
2022-04-28 20:32:27,164 ----------------------------------------------------------------------------------------------------
2022-04-28 20:32:27,165 EPOCH 32 done: loss 0.0326 - lr 0.012500
2022-04-28 20:32:40,776 Evaluating as a multi-label problem: False
2022-04-28 20:32:40,788 DEV : loss 0.2239300012588501 - f1-score (micro avg)  0.5272
2022-04-28 20:32:40,861 BAD EPOCHS (no improvement): 2
2022-04-28 20:32:40,864 ----------------------------------------------------------------------------------------------------
2022-04-28 20:32:44,785 epoch 33 - iter 10/107 - loss 0.03137464 - samples/sec: 81.63 - lr: 0.012500
2022-04-28 20:32:48,829 epoch 33 - iter 20/107 - loss 0.03128848 - samples/sec: 79.17 - lr: 0.012500
2022-04-28 20:32:52,008 epoch 33 - iter 30/107 - loss 0.03134421 - samples/sec: 100.70 - lr: 0.012500
2022-04-28 20:32:54,696 epoch 33 - iter 40/107 - loss 0.03093751 - samples/sec: 119.09 - lr: 0.012500
2022-04-28 20:32:57,318 epoch 33 - iter 50/107 - loss 0.03118129 - samples/sec: 122.09 - lr: 0.012500
2022-04-28 20:32:59,511 epoch 33 - iter 60/107 - loss 0.03078589 - samples/sec: 145.94 - lr: 0.012500
2022-04-28 20:33:01,642 epoch 33 - iter 70/107 - loss 0.03183346 - samples/sec: 150.24 - lr: 0.012500
2022-04-28 20:33:03,848 epoch 33 - iter 80/107 - loss 0.03153992 - samples/sec: 145.17 - lr: 0.012500
2022-04-28 20:33:06,175 epoch 33 - iter 90/107 - loss 0.03225236 - samples/sec: 137.53 - lr: 0.012500
2022-04-28 20:33:08,517 epoch 33 - iter 100/107 - loss 0.03198183 - samples/sec: 136.69 - lr: 0.012500
2022-04-28 20:33:09,943 ----------------------------------------------------------------------------------------------------
2022-04-28 20:33:09,943 EPOCH 33 done: loss 0.0325 - lr 0.012500
2022-04-28 20:33:16,959 Evaluating as a multi-label problem: False
2022-04-28 20:33:16,970 DEV : loss 0.2243434637784958 - f1-score (micro avg)  0.5195
2022-04-28 20:33:17,041 BAD EPOCHS (no improvement): 3
2022-04-28 20:33:17,043 ----------------------------------------------------------------------------------------------------
2022-04-28 20:33:19,498 epoch 34 - iter 10/107 - loss 0.03256069 - samples/sec: 130.43 - lr: 0.012500
2022-04-28 20:33:21,692 epoch 34 - iter 20/107 - loss 0.03033101 - samples/sec: 145.90 - lr: 0.012500
2022-04-28 20:33:24,007 epoch 34 - iter 30/107 - loss 0.03005549 - samples/sec: 138.31 - lr: 0.012500
2022-04-28 20:33:26,244 epoch 34 - iter 40/107 - loss 0.02975902 - samples/sec: 143.13 - lr: 0.012500
2022-04-28 20:33:28,552 epoch 34 - iter 50/107 - loss 0.03026400 - samples/sec: 138.68 - lr: 0.012500
2022-04-28 20:33:31,678 epoch 34 - iter 60/107 - loss 0.03074400 - samples/sec: 102.41 - lr: 0.012500
2022-04-28 20:33:34,751 epoch 34 - iter 70/107 - loss 0.02985357 - samples/sec: 104.17 - lr: 0.012500
2022-04-28 20:33:37,904 epoch 34 - iter 80/107 - loss 0.03032220 - samples/sec: 101.51 - lr: 0.012500
2022-04-28 20:33:41,094 epoch 34 - iter 90/107 - loss 0.02990390 - samples/sec: 100.33 - lr: 0.012500
2022-04-28 20:33:44,392 epoch 34 - iter 100/107 - loss 0.03034824 - samples/sec: 97.07 - lr: 0.012500
2022-04-28 20:33:46,384 ----------------------------------------------------------------------------------------------------
2022-04-28 20:33:46,384 EPOCH 34 done: loss 0.0314 - lr 0.012500
2022-04-28 20:33:58,601 Evaluating as a multi-label problem: False
2022-04-28 20:33:58,612 DEV : loss 0.22483737766742706 - f1-score (micro avg)  0.5221
2022-04-28 20:33:58,684 Epoch    34: reducing learning rate of group 0 to 6.2500e-03.
2022-04-28 20:33:58,684 BAD EPOCHS (no improvement): 4
2022-04-28 20:33:58,706 ----------------------------------------------------------------------------------------------------
2022-04-28 20:34:02,783 epoch 35 - iter 10/107 - loss 0.03313072 - samples/sec: 78.52 - lr: 0.006250
2022-04-28 20:34:06,763 epoch 35 - iter 20/107 - loss 0.03193306 - samples/sec: 80.42 - lr: 0.006250
2022-04-28 20:34:10,942 epoch 35 - iter 30/107 - loss 0.03134411 - samples/sec: 76.59 - lr: 0.006250
2022-04-28 20:34:15,838 epoch 35 - iter 40/107 - loss 0.02935076 - samples/sec: 65.36 - lr: 0.006250
2022-04-28 20:34:20,449 epoch 35 - iter 50/107 - loss 0.03065392 - samples/sec: 69.42 - lr: 0.006250
2022-04-28 20:34:25,242 epoch 35 - iter 60/107 - loss 0.03035870 - samples/sec: 66.79 - lr: 0.006250
2022-04-28 20:34:30,018 epoch 35 - iter 70/107 - loss 0.03088258 - samples/sec: 67.01 - lr: 0.006250
2022-04-28 20:34:35,022 epoch 35 - iter 80/107 - loss 0.03079588 - samples/sec: 63.96 - lr: 0.006250
2022-04-28 20:34:39,806 epoch 35 - iter 90/107 - loss 0.03094470 - samples/sec: 66.91 - lr: 0.006250
2022-04-28 20:34:44,224 epoch 35 - iter 100/107 - loss 0.03126762 - samples/sec: 72.44 - lr: 0.006250
2022-04-28 20:34:47,041 ----------------------------------------------------------------------------------------------------
2022-04-28 20:34:47,041 EPOCH 35 done: loss 0.0313 - lr 0.006250
2022-04-28 20:34:58,402 Evaluating as a multi-label problem: False
2022-04-28 20:34:58,413 DEV : loss 0.22627560794353485 - f1-score (micro avg)  0.5185
2022-04-28 20:34:58,484 BAD EPOCHS (no improvement): 1
2022-04-28 20:34:58,487 ----------------------------------------------------------------------------------------------------
2022-04-28 20:35:01,268 epoch 36 - iter 10/107 - loss 0.03080747 - samples/sec: 115.12 - lr: 0.006250
2022-04-28 20:35:04,596 epoch 36 - iter 20/107 - loss 0.02992355 - samples/sec: 96.19 - lr: 0.006250
2022-04-28 20:35:07,825 epoch 36 - iter 30/107 - loss 0.02928618 - samples/sec: 99.13 - lr: 0.006250
2022-04-28 20:35:11,081 epoch 36 - iter 40/107 - loss 0.03041074 - samples/sec: 98.32 - lr: 0.006250
2022-04-28 20:35:14,488 epoch 36 - iter 50/107 - loss 0.02992454 - samples/sec: 93.94 - lr: 0.006250
2022-04-28 20:35:17,807 epoch 36 - iter 60/107 - loss 0.02902309 - samples/sec: 96.45 - lr: 0.006250
2022-04-28 20:35:20,804 epoch 36 - iter 70/107 - loss 0.02940500 - samples/sec: 106.82 - lr: 0.006250
2022-04-28 20:35:24,181 epoch 36 - iter 80/107 - loss 0.02977181 - samples/sec: 94.79 - lr: 0.006250
2022-04-28 20:35:27,384 epoch 36 - iter 90/107 - loss 0.02882138 - samples/sec: 99.92 - lr: 0.006250
2022-04-28 20:35:29,853 epoch 36 - iter 100/107 - loss 0.02943850 - samples/sec: 129.69 - lr: 0.006250
2022-04-28 20:35:31,391 ----------------------------------------------------------------------------------------------------
2022-04-28 20:35:31,391 EPOCH 36 done: loss 0.0297 - lr 0.006250
2022-04-28 20:35:40,632 Evaluating as a multi-label problem: False
2022-04-28 20:35:40,643 DEV : loss 0.23018744587898254 - f1-score (micro avg)  0.5098
2022-04-28 20:35:40,714 BAD EPOCHS (no improvement): 2
2022-04-28 20:35:40,722 ----------------------------------------------------------------------------------------------------
2022-04-28 20:35:45,932 epoch 37 - iter 10/107 - loss 0.02999569 - samples/sec: 61.43 - lr: 0.006250
2022-04-28 20:35:48,952 epoch 37 - iter 20/107 - loss 0.03053277 - samples/sec: 106.01 - lr: 0.006250
2022-04-28 20:35:53,635 epoch 37 - iter 30/107 - loss 0.03020398 - samples/sec: 68.35 - lr: 0.006250
2022-04-28 20:35:58,434 epoch 37 - iter 40/107 - loss 0.02769693 - samples/sec: 66.70 - lr: 0.006250
2022-04-28 20:36:03,328 epoch 37 - iter 50/107 - loss 0.02910845 - samples/sec: 65.40 - lr: 0.006250
2022-04-28 20:36:07,530 epoch 37 - iter 60/107 - loss 0.02947166 - samples/sec: 76.18 - lr: 0.006250
2022-04-28 20:36:11,470 epoch 37 - iter 70/107 - loss 0.03101262 - samples/sec: 81.24 - lr: 0.006250
2022-04-28 20:36:15,859 epoch 37 - iter 80/107 - loss 0.03150819 - samples/sec: 72.92 - lr: 0.006250
2022-04-28 20:36:20,735 epoch 37 - iter 90/107 - loss 0.03091581 - samples/sec: 65.65 - lr: 0.006250
2022-04-28 20:36:25,530 epoch 37 - iter 100/107 - loss 0.03001471 - samples/sec: 66.74 - lr: 0.006250
2022-04-28 20:36:28,436 ----------------------------------------------------------------------------------------------------
2022-04-28 20:36:28,436 EPOCH 37 done: loss 0.0304 - lr 0.006250
2022-04-28 20:36:42,182 Evaluating as a multi-label problem: False
2022-04-28 20:36:42,193 DEV : loss 0.23017814755439758 - f1-score (micro avg)  0.5113
2022-04-28 20:36:42,263 BAD EPOCHS (no improvement): 3
2022-04-28 20:36:42,277 ----------------------------------------------------------------------------------------------------
2022-04-28 20:36:47,125 epoch 38 - iter 10/107 - loss 0.03337584 - samples/sec: 66.02 - lr: 0.006250
2022-04-28 20:36:51,699 epoch 38 - iter 20/107 - loss 0.03019788 - samples/sec: 69.98 - lr: 0.006250
2022-04-28 20:36:55,676 epoch 38 - iter 30/107 - loss 0.02817653 - samples/sec: 80.48 - lr: 0.006250
2022-04-28 20:36:59,702 epoch 38 - iter 40/107 - loss 0.02983050 - samples/sec: 79.52 - lr: 0.006250
2022-04-28 20:37:02,558 epoch 38 - iter 50/107 - loss 0.02997775 - samples/sec: 112.05 - lr: 0.006250
2022-04-28 20:37:05,438 epoch 38 - iter 60/107 - loss 0.02956905 - samples/sec: 111.17 - lr: 0.006250
2022-04-28 20:37:08,731 epoch 38 - iter 70/107 - loss 0.03061305 - samples/sec: 97.20 - lr: 0.006250
2022-04-28 20:37:12,041 epoch 38 - iter 80/107 - loss 0.03138499 - samples/sec: 96.69 - lr: 0.006250
2022-04-28 20:37:15,218 epoch 38 - iter 90/107 - loss 0.03134060 - samples/sec: 100.76 - lr: 0.006250
2022-04-28 20:37:18,507 epoch 38 - iter 100/107 - loss 0.03126290 - samples/sec: 97.34 - lr: 0.006250
2022-04-28 20:37:20,674 ----------------------------------------------------------------------------------------------------
2022-04-28 20:37:20,674 EPOCH 38 done: loss 0.0315 - lr 0.006250
2022-04-28 20:37:30,140 Evaluating as a multi-label problem: False
2022-04-28 20:37:30,151 DEV : loss 0.2233719676733017 - f1-score (micro avg)  0.521
2022-04-28 20:37:30,226 Epoch    38: reducing learning rate of group 0 to 3.1250e-03.
2022-04-28 20:37:30,226 BAD EPOCHS (no improvement): 4
2022-04-28 20:37:30,228 ----------------------------------------------------------------------------------------------------
2022-04-28 20:37:32,807 epoch 39 - iter 10/107 - loss 0.02364485 - samples/sec: 124.17 - lr: 0.003125
2022-04-28 20:37:35,473 epoch 39 - iter 20/107 - loss 0.02899196 - samples/sec: 120.11 - lr: 0.003125
2022-04-28 20:37:38,601 epoch 39 - iter 30/107 - loss 0.02726957 - samples/sec: 102.32 - lr: 0.003125
2022-04-28 20:37:41,805 epoch 39 - iter 40/107 - loss 0.02767921 - samples/sec: 99.92 - lr: 0.003125
2022-04-28 20:37:45,097 epoch 39 - iter 50/107 - loss 0.02862128 - samples/sec: 97.24 - lr: 0.003125
2022-04-28 20:37:48,291 epoch 39 - iter 60/107 - loss 0.02883406 - samples/sec: 100.20 - lr: 0.003125
2022-04-28 20:37:52,099 epoch 39 - iter 70/107 - loss 0.02890471 - samples/sec: 84.07 - lr: 0.003125
2022-04-28 20:37:56,709 epoch 39 - iter 80/107 - loss 0.03007924 - samples/sec: 69.43 - lr: 0.003125
2022-04-28 20:38:01,495 epoch 39 - iter 90/107 - loss 0.03043333 - samples/sec: 66.87 - lr: 0.003125
2022-04-28 20:38:06,083 epoch 39 - iter 100/107 - loss 0.03016845 - samples/sec: 69.76 - lr: 0.003125
2022-04-28 20:38:09,373 ----------------------------------------------------------------------------------------------------
2022-04-28 20:38:09,373 EPOCH 39 done: loss 0.0301 - lr 0.003125
2022-04-28 20:38:20,675 Evaluating as a multi-label problem: False
2022-04-28 20:38:20,687 DEV : loss 0.22907617688179016 - f1-score (micro avg)  0.5116
2022-04-28 20:38:20,768 BAD EPOCHS (no improvement): 1
2022-04-28 20:38:20,773 ----------------------------------------------------------------------------------------------------
2022-04-28 20:38:23,705 epoch 40 - iter 10/107 - loss 0.02938816 - samples/sec: 109.20 - lr: 0.003125
2022-04-28 20:38:26,532 epoch 40 - iter 20/107 - loss 0.02470317 - samples/sec: 113.26 - lr: 0.003125
2022-04-28 20:38:29,472 epoch 40 - iter 30/107 - loss 0.02563905 - samples/sec: 108.90 - lr: 0.003125
2022-04-28 20:38:32,299 epoch 40 - iter 40/107 - loss 0.02596090 - samples/sec: 113.23 - lr: 0.003125
2022-04-28 20:38:35,215 epoch 40 - iter 50/107 - loss 0.02728248 - samples/sec: 109.77 - lr: 0.003125
2022-04-28 20:38:38,004 epoch 40 - iter 60/107 - loss 0.02864527 - samples/sec: 114.77 - lr: 0.003125
2022-04-28 20:38:40,530 epoch 40 - iter 70/107 - loss 0.02910318 - samples/sec: 126.79 - lr: 0.003125
2022-04-28 20:38:43,081 epoch 40 - iter 80/107 - loss 0.02860613 - samples/sec: 125.46 - lr: 0.003125
2022-04-28 20:38:45,659 epoch 40 - iter 90/107 - loss 0.02870095 - samples/sec: 124.21 - lr: 0.003125
2022-04-28 20:38:48,130 epoch 40 - iter 100/107 - loss 0.02915820 - samples/sec: 129.55 - lr: 0.003125
2022-04-28 20:38:49,919 ----------------------------------------------------------------------------------------------------
2022-04-28 20:38:49,919 EPOCH 40 done: loss 0.0291 - lr 0.003125
2022-04-28 20:38:59,491 Evaluating as a multi-label problem: False
2022-04-28 20:38:59,502 DEV : loss 0.23167665302753448 - f1-score (micro avg)  0.5104
2022-04-28 20:38:59,574 BAD EPOCHS (no improvement): 2
2022-04-28 20:38:59,589 ----------------------------------------------------------------------------------------------------
2022-04-28 20:39:04,294 epoch 41 - iter 10/107 - loss 0.02149796 - samples/sec: 68.03 - lr: 0.003125
2022-04-28 20:39:08,978 epoch 41 - iter 20/107 - loss 0.02594711 - samples/sec: 68.33 - lr: 0.003125
2022-04-28 20:39:13,978 epoch 41 - iter 30/107 - loss 0.03010093 - samples/sec: 64.02 - lr: 0.003125
2022-04-28 20:39:18,600 epoch 41 - iter 40/107 - loss 0.02959871 - samples/sec: 69.25 - lr: 0.003125
2022-04-28 20:39:23,565 epoch 41 - iter 50/107 - loss 0.02921073 - samples/sec: 64.47 - lr: 0.003125
2022-04-28 20:39:28,466 epoch 41 - iter 60/107 - loss 0.02953689 - samples/sec: 65.31 - lr: 0.003125
2022-04-28 20:39:33,020 epoch 41 - iter 70/107 - loss 0.02890052 - samples/sec: 70.28 - lr: 0.003125
2022-04-28 20:39:37,936 epoch 41 - iter 80/107 - loss 0.02839891 - samples/sec: 65.11 - lr: 0.003125
2022-04-28 20:39:41,734 epoch 41 - iter 90/107 - loss 0.02958162 - samples/sec: 84.28 - lr: 0.003125
2022-04-28 20:39:45,465 epoch 41 - iter 100/107 - loss 0.03009197 - samples/sec: 85.79 - lr: 0.003125
2022-04-28 20:39:47,907 ----------------------------------------------------------------------------------------------------
2022-04-28 20:39:47,907 EPOCH 41 done: loss 0.0299 - lr 0.003125
2022-04-28 20:40:01,457 Evaluating as a multi-label problem: False
2022-04-28 20:40:01,468 DEV : loss 0.2303341180086136 - f1-score (micro avg)  0.5116
2022-04-28 20:40:01,542 BAD EPOCHS (no improvement): 3
2022-04-28 20:40:01,553 ----------------------------------------------------------------------------------------------------
2022-04-28 20:40:06,216 epoch 42 - iter 10/107 - loss 0.02678434 - samples/sec: 68.64 - lr: 0.003125
2022-04-28 20:40:11,200 epoch 42 - iter 20/107 - loss 0.03013802 - samples/sec: 64.22 - lr: 0.003125
2022-04-28 20:40:15,703 epoch 42 - iter 30/107 - loss 0.03174798 - samples/sec: 71.09 - lr: 0.003125
2022-04-28 20:40:20,569 epoch 42 - iter 40/107 - loss 0.03191841 - samples/sec: 65.78 - lr: 0.003125
2022-04-28 20:40:25,319 epoch 42 - iter 50/107 - loss 0.03198572 - samples/sec: 67.39 - lr: 0.003125
2022-04-28 20:40:29,988 epoch 42 - iter 60/107 - loss 0.03166660 - samples/sec: 68.55 - lr: 0.003125
2022-04-28 20:40:33,984 epoch 42 - iter 70/107 - loss 0.03171926 - samples/sec: 80.12 - lr: 0.003125
2022-04-28 20:40:38,076 epoch 42 - iter 80/107 - loss 0.03099532 - samples/sec: 78.22 - lr: 0.003125
2022-04-28 20:40:41,274 epoch 42 - iter 90/107 - loss 0.03084949 - samples/sec: 100.09 - lr: 0.003125
2022-04-28 20:40:44,076 epoch 42 - iter 100/107 - loss 0.03078710 - samples/sec: 114.23 - lr: 0.003125
2022-04-28 20:40:45,795 ----------------------------------------------------------------------------------------------------
2022-04-28 20:40:45,796 EPOCH 42 done: loss 0.0306 - lr 0.003125
2022-04-28 20:40:53,788 Evaluating as a multi-label problem: False
2022-04-28 20:40:53,800 DEV : loss 0.2282038778066635 - f1-score (micro avg)  0.5166
2022-04-28 20:40:53,871 Epoch    42: reducing learning rate of group 0 to 1.5625e-03.
2022-04-28 20:40:53,872 BAD EPOCHS (no improvement): 4
2022-04-28 20:40:53,874 ----------------------------------------------------------------------------------------------------
2022-04-28 20:40:56,467 epoch 43 - iter 10/107 - loss 0.02388444 - samples/sec: 123.50 - lr: 0.001563
2022-04-28 20:40:58,503 epoch 43 - iter 20/107 - loss 0.02366062 - samples/sec: 157.26 - lr: 0.001563
2022-04-28 20:41:00,621 epoch 43 - iter 30/107 - loss 0.02350721 - samples/sec: 151.14 - lr: 0.001563
2022-04-28 20:41:02,791 epoch 43 - iter 40/107 - loss 0.02601828 - samples/sec: 147.53 - lr: 0.001563
2022-04-28 20:41:05,113 epoch 43 - iter 50/107 - loss 0.02603230 - samples/sec: 137.88 - lr: 0.001563
2022-04-28 20:41:07,295 epoch 43 - iter 60/107 - loss 0.02626187 - samples/sec: 146.76 - lr: 0.001563
2022-04-28 20:41:09,633 epoch 43 - iter 70/107 - loss 0.02615593 - samples/sec: 136.89 - lr: 0.001563
2022-04-28 20:41:11,913 epoch 43 - iter 80/107 - loss 0.02729966 - samples/sec: 140.45 - lr: 0.001563
2022-04-28 20:41:14,172 epoch 43 - iter 90/107 - loss 0.02738358 - samples/sec: 141.71 - lr: 0.001563
2022-04-28 20:41:16,821 epoch 43 - iter 100/107 - loss 0.02766528 - samples/sec: 120.85 - lr: 0.001563
2022-04-28 20:41:18,669 ----------------------------------------------------------------------------------------------------
2022-04-28 20:41:18,669 EPOCH 43 done: loss 0.0276 - lr 0.001563
2022-04-28 20:41:28,648 Evaluating as a multi-label problem: False
2022-04-28 20:41:28,660 DEV : loss 0.2305690050125122 - f1-score (micro avg)  0.5109
2022-04-28 20:41:28,734 BAD EPOCHS (no improvement): 1
2022-04-28 20:41:28,737 ----------------------------------------------------------------------------------------------------
2022-04-28 20:41:31,887 epoch 44 - iter 10/107 - loss 0.02612381 - samples/sec: 101.63 - lr: 0.001563
2022-04-28 20:41:35,269 epoch 44 - iter 20/107 - loss 0.03183139 - samples/sec: 94.64 - lr: 0.001563
2022-04-28 20:41:38,457 epoch 44 - iter 30/107 - loss 0.03039415 - samples/sec: 100.39 - lr: 0.001563
2022-04-28 20:41:41,836 epoch 44 - iter 40/107 - loss 0.02911507 - samples/sec: 94.75 - lr: 0.001563
2022-04-28 20:41:44,487 epoch 44 - iter 50/107 - loss 0.02854105 - samples/sec: 120.73 - lr: 0.001563
2022-04-28 20:41:46,952 epoch 44 - iter 60/107 - loss 0.02776407 - samples/sec: 129.90 - lr: 0.001563
2022-04-28 20:41:51,196 epoch 44 - iter 70/107 - loss 0.02781330 - samples/sec: 75.42 - lr: 0.001563
2022-04-28 20:41:56,143 epoch 44 - iter 80/107 - loss 0.02918055 - samples/sec: 64.70 - lr: 0.001563
2022-04-28 20:42:00,758 epoch 44 - iter 90/107 - loss 0.02939295 - samples/sec: 69.35 - lr: 0.001563
2022-04-28 20:42:05,561 epoch 44 - iter 100/107 - loss 0.02907251 - samples/sec: 66.64 - lr: 0.001563
2022-04-28 20:42:08,490 ----------------------------------------------------------------------------------------------------
2022-04-28 20:42:08,490 EPOCH 44 done: loss 0.0292 - lr 0.001563
2022-04-28 20:42:22,246 Evaluating as a multi-label problem: False
2022-04-28 20:42:22,257 DEV : loss 0.2316286563873291 - f1-score (micro avg)  0.5113
2022-04-28 20:42:22,329 BAD EPOCHS (no improvement): 2
2022-04-28 20:42:22,343 ----------------------------------------------------------------------------------------------------
2022-04-28 20:42:28,956 epoch 45 - iter 10/107 - loss 0.03106520 - samples/sec: 48.40 - lr: 0.001563
2022-04-28 20:42:33,365 epoch 45 - iter 20/107 - loss 0.02588855 - samples/sec: 72.60 - lr: 0.001563
2022-04-28 20:42:37,498 epoch 45 - iter 30/107 - loss 0.02634476 - samples/sec: 77.45 - lr: 0.001563
2022-04-28 20:42:40,455 epoch 45 - iter 40/107 - loss 0.02713406 - samples/sec: 108.23 - lr: 0.001563
2022-04-28 20:42:44,265 epoch 45 - iter 50/107 - loss 0.02878060 - samples/sec: 84.02 - lr: 0.001563
2022-04-28 20:42:48,969 epoch 45 - iter 60/107 - loss 0.02864224 - samples/sec: 68.04 - lr: 0.001563
2022-04-28 20:42:53,285 epoch 45 - iter 70/107 - loss 0.02857737 - samples/sec: 74.16 - lr: 0.001563
2022-04-28 20:42:57,716 epoch 45 - iter 80/107 - loss 0.02809283 - samples/sec: 72.23 - lr: 0.001563
2022-04-28 20:43:00,995 epoch 45 - iter 90/107 - loss 0.02823598 - samples/sec: 97.62 - lr: 0.001563
2022-04-28 20:43:04,310 epoch 45 - iter 100/107 - loss 0.02821017 - samples/sec: 96.57 - lr: 0.001563
2022-04-28 20:43:06,450 ----------------------------------------------------------------------------------------------------
2022-04-28 20:43:06,451 EPOCH 45 done: loss 0.0280 - lr 0.001563
2022-04-28 20:43:15,619 Evaluating as a multi-label problem: False
2022-04-28 20:43:15,630 DEV : loss 0.2317739576101303 - f1-score (micro avg)  0.5089
2022-04-28 20:43:15,700 BAD EPOCHS (no improvement): 3
2022-04-28 20:43:15,703 ----------------------------------------------------------------------------------------------------
2022-04-28 20:43:18,252 epoch 46 - iter 10/107 - loss 0.03620260 - samples/sec: 125.60 - lr: 0.001563
2022-04-28 20:43:21,219 epoch 46 - iter 20/107 - loss 0.03277324 - samples/sec: 107.88 - lr: 0.001563
2022-04-28 20:43:24,509 epoch 46 - iter 30/107 - loss 0.03190665 - samples/sec: 97.30 - lr: 0.001563
2022-04-28 20:43:27,491 epoch 46 - iter 40/107 - loss 0.03070133 - samples/sec: 107.34 - lr: 0.001563
2022-04-28 20:43:31,073 epoch 46 - iter 50/107 - loss 0.03014474 - samples/sec: 89.36 - lr: 0.001563
2022-04-28 20:43:34,374 epoch 46 - iter 60/107 - loss 0.02982811 - samples/sec: 96.97 - lr: 0.001563
2022-04-28 20:43:37,529 epoch 46 - iter 70/107 - loss 0.02874310 - samples/sec: 101.47 - lr: 0.001563
2022-04-28 20:43:40,907 epoch 46 - iter 80/107 - loss 0.02879973 - samples/sec: 94.77 - lr: 0.001563
2022-04-28 20:43:44,080 epoch 46 - iter 90/107 - loss 0.02876317 - samples/sec: 100.86 - lr: 0.001563
2022-04-28 20:43:47,113 epoch 46 - iter 100/107 - loss 0.02858046 - samples/sec: 105.54 - lr: 0.001563
2022-04-28 20:43:48,810 ----------------------------------------------------------------------------------------------------
2022-04-28 20:43:48,810 EPOCH 46 done: loss 0.0283 - lr 0.001563
2022-04-28 20:43:57,754 Evaluating as a multi-label problem: False
2022-04-28 20:43:57,765 DEV : loss 0.232817143201828 - f1-score (micro avg)  0.5136
2022-04-28 20:43:57,839 Epoch    46: reducing learning rate of group 0 to 7.8125e-04.
2022-04-28 20:43:57,839 BAD EPOCHS (no improvement): 4
2022-04-28 20:43:57,850 ----------------------------------------------------------------------------------------------------
2022-04-28 20:44:00,800 epoch 47 - iter 10/107 - loss 0.02679146 - samples/sec: 108.52 - lr: 0.000781
2022-04-28 20:44:03,396 epoch 47 - iter 20/107 - loss 0.02365214 - samples/sec: 123.34 - lr: 0.000781
2022-04-28 20:44:06,093 epoch 47 - iter 30/107 - loss 0.02655059 - samples/sec: 118.69 - lr: 0.000781
2022-04-28 20:44:08,873 epoch 47 - iter 40/107 - loss 0.02768259 - samples/sec: 115.12 - lr: 0.000781
2022-04-28 20:44:11,677 epoch 47 - iter 50/107 - loss 0.02783221 - samples/sec: 114.16 - lr: 0.000781
2022-04-28 20:44:14,506 epoch 47 - iter 60/107 - loss 0.02783529 - samples/sec: 113.15 - lr: 0.000781
2022-04-28 20:44:17,402 epoch 47 - iter 70/107 - loss 0.02780308 - samples/sec: 110.56 - lr: 0.000781
2022-04-28 20:44:20,114 epoch 47 - iter 80/107 - loss 0.02740294 - samples/sec: 118.02 - lr: 0.000781
2022-04-28 20:44:22,972 epoch 47 - iter 90/107 - loss 0.02801037 - samples/sec: 112.01 - lr: 0.000781
2022-04-28 20:44:25,866 epoch 47 - iter 100/107 - loss 0.02944115 - samples/sec: 110.62 - lr: 0.000781
2022-04-28 20:44:27,674 ----------------------------------------------------------------------------------------------------
2022-04-28 20:44:27,674 EPOCH 47 done: loss 0.0292 - lr 0.000781
2022-04-28 20:44:39,193 Evaluating as a multi-label problem: False
2022-04-28 20:44:39,205 DEV : loss 0.23266610503196716 - f1-score (micro avg)  0.512
2022-04-28 20:44:39,275 BAD EPOCHS (no improvement): 1
2022-04-28 20:44:39,285 ----------------------------------------------------------------------------------------------------
2022-04-28 20:44:43,401 epoch 48 - iter 10/107 - loss 0.03133546 - samples/sec: 77.77 - lr: 0.000781
2022-04-28 20:44:46,788 epoch 48 - iter 20/107 - loss 0.02702725 - samples/sec: 94.51 - lr: 0.000781
2022-04-28 20:44:50,022 epoch 48 - iter 30/107 - loss 0.02946977 - samples/sec: 98.97 - lr: 0.000781
2022-04-28 20:44:53,304 epoch 48 - iter 40/107 - loss 0.03050911 - samples/sec: 97.54 - lr: 0.000781
2022-04-28 20:44:56,611 epoch 48 - iter 50/107 - loss 0.03074612 - samples/sec: 96.78 - lr: 0.000781
2022-04-28 20:44:59,775 epoch 48 - iter 60/107 - loss 0.03098740 - samples/sec: 101.19 - lr: 0.000781
2022-04-28 20:45:02,316 epoch 48 - iter 70/107 - loss 0.03029555 - samples/sec: 125.95 - lr: 0.000781
2022-04-28 20:45:04,746 epoch 48 - iter 80/107 - loss 0.02972288 - samples/sec: 131.78 - lr: 0.000781
2022-04-28 20:45:07,520 epoch 48 - iter 90/107 - loss 0.02941765 - samples/sec: 115.40 - lr: 0.000781
2022-04-28 20:45:10,869 epoch 48 - iter 100/107 - loss 0.02983940 - samples/sec: 95.57 - lr: 0.000781
2022-04-28 20:45:12,874 ----------------------------------------------------------------------------------------------------
2022-04-28 20:45:12,874 EPOCH 48 done: loss 0.0298 - lr 0.000781
2022-04-28 20:45:22,486 Evaluating as a multi-label problem: False
2022-04-28 20:45:22,497 DEV : loss 0.23308593034744263 - f1-score (micro avg)  0.5124
2022-04-28 20:45:22,574 BAD EPOCHS (no improvement): 2
2022-04-28 20:45:22,577 ----------------------------------------------------------------------------------------------------
2022-04-28 20:45:25,954 epoch 49 - iter 10/107 - loss 0.02853236 - samples/sec: 94.80 - lr: 0.000781
2022-04-28 20:45:29,258 epoch 49 - iter 20/107 - loss 0.02921734 - samples/sec: 96.88 - lr: 0.000781
2022-04-28 20:45:32,337 epoch 49 - iter 30/107 - loss 0.03058799 - samples/sec: 103.99 - lr: 0.000781
2022-04-28 20:45:35,252 epoch 49 - iter 40/107 - loss 0.02969557 - samples/sec: 109.83 - lr: 0.000781
2022-04-28 20:45:39,251 epoch 49 - iter 50/107 - loss 0.02979899 - samples/sec: 80.04 - lr: 0.000781
2022-04-28 20:45:43,841 epoch 49 - iter 60/107 - loss 0.03012123 - samples/sec: 69.73 - lr: 0.000781
2022-04-28 20:45:48,514 epoch 49 - iter 70/107 - loss 0.03059823 - samples/sec: 68.49 - lr: 0.000781
2022-04-28 20:45:53,233 epoch 49 - iter 80/107 - loss 0.03060414 - samples/sec: 67.83 - lr: 0.000781
2022-04-28 20:45:57,901 epoch 49 - iter 90/107 - loss 0.02994421 - samples/sec: 68.57 - lr: 0.000781
2022-04-28 20:46:02,661 epoch 49 - iter 100/107 - loss 0.02911334 - samples/sec: 67.24 - lr: 0.000781
2022-04-28 20:46:05,663 ----------------------------------------------------------------------------------------------------
2022-04-28 20:46:05,663 EPOCH 49 done: loss 0.0293 - lr 0.000781
2022-04-28 20:46:19,400 Evaluating as a multi-label problem: False
2022-04-28 20:46:19,411 DEV : loss 0.23316620290279388 - f1-score (micro avg)  0.5128
2022-04-28 20:46:19,485 BAD EPOCHS (no improvement): 3
2022-04-28 20:46:19,487 ----------------------------------------------------------------------------------------------------
2022-04-28 20:46:24,130 epoch 50 - iter 10/107 - loss 0.02718677 - samples/sec: 68.94 - lr: 0.000781
2022-04-28 20:46:28,406 epoch 50 - iter 20/107 - loss 0.03007524 - samples/sec: 74.85 - lr: 0.000781
2022-04-28 20:46:32,449 epoch 50 - iter 30/107 - loss 0.02868903 - samples/sec: 79.17 - lr: 0.000781
2022-04-28 20:46:36,846 epoch 50 - iter 40/107 - loss 0.03159815 - samples/sec: 72.80 - lr: 0.000781
2022-04-28 20:46:41,420 epoch 50 - iter 50/107 - loss 0.03162056 - samples/sec: 69.99 - lr: 0.000781
2022-04-28 20:46:45,759 epoch 50 - iter 60/107 - loss 0.03131875 - samples/sec: 73.76 - lr: 0.000781
2022-04-28 20:46:50,699 epoch 50 - iter 70/107 - loss 0.03066215 - samples/sec: 64.80 - lr: 0.000781
2022-04-28 20:46:55,339 epoch 50 - iter 80/107 - loss 0.03030698 - samples/sec: 68.97 - lr: 0.000781
2022-04-28 20:47:00,107 epoch 50 - iter 90/107 - loss 0.02955128 - samples/sec: 67.14 - lr: 0.000781
2022-04-28 20:47:04,801 epoch 50 - iter 100/107 - loss 0.02991595 - samples/sec: 68.18 - lr: 0.000781
2022-04-28 20:47:07,758 ----------------------------------------------------------------------------------------------------
2022-04-28 20:47:07,758 EPOCH 50 done: loss 0.0298 - lr 0.000781
2022-04-28 20:47:20,915 Evaluating as a multi-label problem: False
2022-04-28 20:47:20,927 DEV : loss 0.23193132877349854 - f1-score (micro avg)  0.5139
2022-04-28 20:47:20,999 Epoch    50: reducing learning rate of group 0 to 3.9063e-04.
2022-04-28 20:47:20,999 BAD EPOCHS (no improvement): 4
2022-04-28 20:47:21,002 ----------------------------------------------------------------------------------------------------
2022-04-28 20:47:25,428 epoch 51 - iter 10/107 - loss 0.03590442 - samples/sec: 72.33 - lr: 0.000391
2022-04-28 20:47:30,160 epoch 51 - iter 20/107 - loss 0.03269659 - samples/sec: 67.64 - lr: 0.000391
2022-04-28 20:47:34,690 epoch 51 - iter 30/107 - loss 0.02954354 - samples/sec: 70.65 - lr: 0.000391
2022-04-28 20:47:39,460 epoch 51 - iter 40/107 - loss 0.02799202 - samples/sec: 67.10 - lr: 0.000391
2022-04-28 20:47:44,014 epoch 51 - iter 50/107 - loss 0.02873458 - samples/sec: 70.28 - lr: 0.000391
2022-04-28 20:47:48,692 epoch 51 - iter 60/107 - loss 0.02851493 - samples/sec: 68.42 - lr: 0.000391
2022-04-28 20:47:53,197 epoch 51 - iter 70/107 - loss 0.02781460 - samples/sec: 71.04 - lr: 0.000391
2022-04-28 20:47:57,866 epoch 51 - iter 80/107 - loss 0.02893866 - samples/sec: 68.56 - lr: 0.000391
2022-04-28 20:48:02,295 epoch 51 - iter 90/107 - loss 0.02852188 - samples/sec: 72.27 - lr: 0.000391
2022-04-28 20:48:06,578 epoch 51 - iter 100/107 - loss 0.02809292 - samples/sec: 74.72 - lr: 0.000391
2022-04-28 20:48:09,054 ----------------------------------------------------------------------------------------------------
2022-04-28 20:48:09,054 EPOCH 51 done: loss 0.0281 - lr 0.000391
2022-04-28 20:48:23,616 Evaluating as a multi-label problem: False
2022-04-28 20:48:23,628 DEV : loss 0.23092125356197357 - f1-score (micro avg)  0.5151
2022-04-28 20:48:23,701 BAD EPOCHS (no improvement): 1
2022-04-28 20:48:23,710 ----------------------------------------------------------------------------------------------------
2022-04-28 20:48:28,423 epoch 52 - iter 10/107 - loss 0.02979045 - samples/sec: 67.92 - lr: 0.000391
2022-04-28 20:48:33,200 epoch 52 - iter 20/107 - loss 0.02749384 - samples/sec: 67.00 - lr: 0.000391
2022-04-28 20:48:38,242 epoch 52 - iter 30/107 - loss 0.02713078 - samples/sec: 63.48 - lr: 0.000391
2022-04-28 20:48:43,435 epoch 52 - iter 40/107 - loss 0.02791026 - samples/sec: 61.64 - lr: 0.000391
2022-04-28 20:48:48,286 epoch 52 - iter 50/107 - loss 0.02853369 - samples/sec: 65.98 - lr: 0.000391
2022-04-28 20:48:53,168 epoch 52 - iter 60/107 - loss 0.02890770 - samples/sec: 65.56 - lr: 0.000391
2022-04-28 20:48:56,662 epoch 52 - iter 70/107 - loss 0.02819027 - samples/sec: 91.62 - lr: 0.000391
2022-04-28 20:49:00,533 epoch 52 - iter 80/107 - loss 0.02762277 - samples/sec: 82.70 - lr: 0.000391
2022-04-28 20:49:04,446 epoch 52 - iter 90/107 - loss 0.02781549 - samples/sec: 81.81 - lr: 0.000391
2022-04-28 20:49:08,739 epoch 52 - iter 100/107 - loss 0.02762841 - samples/sec: 74.56 - lr: 0.000391
2022-04-28 20:49:10,852 ----------------------------------------------------------------------------------------------------
2022-04-28 20:49:10,852 EPOCH 52 done: loss 0.0281 - lr 0.000391
2022-04-28 20:49:20,804 Evaluating as a multi-label problem: False
2022-04-28 20:49:20,817 DEV : loss 0.23137511312961578 - f1-score (micro avg)  0.5151
2022-04-28 20:49:20,887 BAD EPOCHS (no improvement): 2
2022-04-28 20:49:20,937 ----------------------------------------------------------------------------------------------------
2022-04-28 20:49:25,980 epoch 53 - iter 10/107 - loss 0.03184097 - samples/sec: 63.48 - lr: 0.000391
2022-04-28 20:49:29,158 epoch 53 - iter 20/107 - loss 0.03230043 - samples/sec: 100.73 - lr: 0.000391
2022-04-28 20:49:31,732 epoch 53 - iter 30/107 - loss 0.02993326 - samples/sec: 124.34 - lr: 0.000391
2022-04-28 20:49:34,305 epoch 53 - iter 40/107 - loss 0.02960799 - samples/sec: 124.40 - lr: 0.000391
2022-04-28 20:49:36,907 epoch 53 - iter 50/107 - loss 0.02892244 - samples/sec: 123.04 - lr: 0.000391
2022-04-28 20:49:39,961 epoch 53 - iter 60/107 - loss 0.02884550 - samples/sec: 104.83 - lr: 0.000391
2022-04-28 20:49:43,381 epoch 53 - iter 70/107 - loss 0.02862578 - samples/sec: 93.57 - lr: 0.000391
2022-04-28 20:49:46,615 epoch 53 - iter 80/107 - loss 0.02866713 - samples/sec: 98.99 - lr: 0.000391
2022-04-28 20:49:49,730 epoch 53 - iter 90/107 - loss 0.02862601 - samples/sec: 102.78 - lr: 0.000391
2022-04-28 20:49:53,117 epoch 53 - iter 100/107 - loss 0.02809717 - samples/sec: 94.51 - lr: 0.000391
2022-04-28 20:49:54,951 ----------------------------------------------------------------------------------------------------
2022-04-28 20:49:54,951 EPOCH 53 done: loss 0.0283 - lr 0.000391
2022-04-28 20:50:07,197 Evaluating as a multi-label problem: False
2022-04-28 20:50:07,209 DEV : loss 0.232068732380867 - f1-score (micro avg)  0.5139
2022-04-28 20:50:07,279 BAD EPOCHS (no improvement): 3
2022-04-28 20:50:07,282 ----------------------------------------------------------------------------------------------------
2022-04-28 20:50:11,667 epoch 54 - iter 10/107 - loss 0.02920109 - samples/sec: 73.00 - lr: 0.000391
2022-04-28 20:50:16,060 epoch 54 - iter 20/107 - loss 0.02993236 - samples/sec: 72.86 - lr: 0.000391
2022-04-28 20:50:20,411 epoch 54 - iter 30/107 - loss 0.02665895 - samples/sec: 73.56 - lr: 0.000391
2022-04-28 20:50:24,818 epoch 54 - iter 40/107 - loss 0.02688412 - samples/sec: 72.63 - lr: 0.000391
2022-04-28 20:50:29,518 epoch 54 - iter 50/107 - loss 0.02682097 - samples/sec: 68.11 - lr: 0.000391
2022-04-28 20:50:34,242 epoch 54 - iter 60/107 - loss 0.02667867 - samples/sec: 67.75 - lr: 0.000391
2022-04-28 20:50:38,778 epoch 54 - iter 70/107 - loss 0.02704930 - samples/sec: 70.57 - lr: 0.000391
2022-04-28 20:50:43,488 epoch 54 - iter 80/107 - loss 0.02763742 - samples/sec: 67.96 - lr: 0.000391
2022-04-28 20:50:48,310 epoch 54 - iter 90/107 - loss 0.02769406 - samples/sec: 66.37 - lr: 0.000391
2022-04-28 20:50:52,858 epoch 54 - iter 100/107 - loss 0.02847099 - samples/sec: 70.38 - lr: 0.000391
2022-04-28 20:50:55,746 ----------------------------------------------------------------------------------------------------
2022-04-28 20:50:55,746 EPOCH 54 done: loss 0.0288 - lr 0.000391
2022-04-28 20:51:05,959 Evaluating as a multi-label problem: False
2022-04-28 20:51:05,971 DEV : loss 0.2317027598619461 - f1-score (micro avg)  0.5151
2022-04-28 20:51:06,042 Epoch    54: reducing learning rate of group 0 to 1.9531e-04.
2022-04-28 20:51:06,042 BAD EPOCHS (no improvement): 4
2022-04-28 20:51:06,045 ----------------------------------------------------------------------------------------------------
2022-04-28 20:51:09,614 epoch 55 - iter 10/107 - loss 0.03192798 - samples/sec: 89.69 - lr: 0.000195
2022-04-28 20:51:13,740 epoch 55 - iter 20/107 - loss 0.02964995 - samples/sec: 77.58 - lr: 0.000195
2022-04-28 20:51:18,457 epoch 55 - iter 30/107 - loss 0.02933298 - samples/sec: 67.85 - lr: 0.000195
2022-04-28 20:51:23,647 epoch 55 - iter 40/107 - loss 0.02955412 - samples/sec: 61.66 - lr: 0.000195
2022-04-28 20:51:28,543 epoch 55 - iter 50/107 - loss 0.02914416 - samples/sec: 65.37 - lr: 0.000195
2022-04-28 20:51:33,558 epoch 55 - iter 60/107 - loss 0.02917164 - samples/sec: 63.83 - lr: 0.000195
2022-04-28 20:51:38,284 epoch 55 - iter 70/107 - loss 0.02802364 - samples/sec: 67.73 - lr: 0.000195
2022-04-28 20:51:42,870 epoch 55 - iter 80/107 - loss 0.02819591 - samples/sec: 69.79 - lr: 0.000195
2022-04-28 20:51:47,292 epoch 55 - iter 90/107 - loss 0.02795017 - samples/sec: 72.38 - lr: 0.000195
2022-04-28 20:51:51,344 epoch 55 - iter 100/107 - loss 0.02830454 - samples/sec: 79.00 - lr: 0.000195
2022-04-28 20:51:54,002 ----------------------------------------------------------------------------------------------------
2022-04-28 20:51:54,002 EPOCH 55 done: loss 0.0286 - lr 0.000195
2022-04-28 20:52:07,604 Evaluating as a multi-label problem: False
2022-04-28 20:52:07,616 DEV : loss 0.23167811334133148 - f1-score (micro avg)  0.5151
2022-04-28 20:52:07,687 BAD EPOCHS (no improvement): 1
2022-04-28 20:52:07,689 ----------------------------------------------------------------------------------------------------
2022-04-28 20:52:12,312 epoch 56 - iter 10/107 - loss 0.02091477 - samples/sec: 69.24 - lr: 0.000195
2022-04-28 20:52:16,722 epoch 56 - iter 20/107 - loss 0.02503411 - samples/sec: 72.58 - lr: 0.000195
2022-04-28 20:52:21,211 epoch 56 - iter 30/107 - loss 0.02478001 - samples/sec: 71.30 - lr: 0.000195
2022-04-28 20:52:25,944 epoch 56 - iter 40/107 - loss 0.02487054 - samples/sec: 67.63 - lr: 0.000195
2022-04-28 20:52:30,269 epoch 56 - iter 50/107 - loss 0.02463531 - samples/sec: 74.01 - lr: 0.000195
2022-04-28 20:52:35,029 epoch 56 - iter 60/107 - loss 0.02563996 - samples/sec: 67.23 - lr: 0.000195
2022-04-28 20:52:39,663 epoch 56 - iter 70/107 - loss 0.02629743 - samples/sec: 69.08 - lr: 0.000195
2022-04-28 20:52:43,621 epoch 56 - iter 80/107 - loss 0.02715555 - samples/sec: 80.86 - lr: 0.000195
2022-04-28 20:52:47,817 epoch 56 - iter 90/107 - loss 0.02787882 - samples/sec: 76.27 - lr: 0.000195
2022-04-28 20:52:52,865 epoch 56 - iter 100/107 - loss 0.02864434 - samples/sec: 63.41 - lr: 0.000195
2022-04-28 20:52:55,631 ----------------------------------------------------------------------------------------------------
2022-04-28 20:52:55,631 EPOCH 56 done: loss 0.0290 - lr 0.000195
2022-04-28 20:53:09,514 Evaluating as a multi-label problem: False
2022-04-28 20:53:09,525 DEV : loss 0.23177744448184967 - f1-score (micro avg)  0.5151
2022-04-28 20:53:09,598 BAD EPOCHS (no improvement): 2
2022-04-28 20:53:09,600 ----------------------------------------------------------------------------------------------------
2022-04-28 20:53:14,394 epoch 57 - iter 10/107 - loss 0.03216138 - samples/sec: 66.77 - lr: 0.000195
2022-04-28 20:53:19,158 epoch 57 - iter 20/107 - loss 0.02978524 - samples/sec: 67.19 - lr: 0.000195
2022-04-28 20:53:23,773 epoch 57 - iter 30/107 - loss 0.02836995 - samples/sec: 69.35 - lr: 0.000195
2022-04-28 20:53:27,729 epoch 57 - iter 40/107 - loss 0.02920673 - samples/sec: 80.92 - lr: 0.000195
2022-04-28 20:53:31,667 epoch 57 - iter 50/107 - loss 0.03061873 - samples/sec: 81.27 - lr: 0.000195
2022-04-28 20:53:35,696 epoch 57 - iter 60/107 - loss 0.03058590 - samples/sec: 79.44 - lr: 0.000195
2022-04-28 20:53:39,851 epoch 57 - iter 70/107 - loss 0.02988212 - samples/sec: 77.04 - lr: 0.000195
2022-04-28 20:53:44,495 epoch 57 - iter 80/107 - loss 0.02972416 - samples/sec: 68.92 - lr: 0.000195
2022-04-28 20:53:49,616 epoch 57 - iter 90/107 - loss 0.02827648 - samples/sec: 62.50 - lr: 0.000195
2022-04-28 20:53:54,508 epoch 57 - iter 100/107 - loss 0.02882892 - samples/sec: 65.42 - lr: 0.000195
2022-04-28 20:53:57,023 ----------------------------------------------------------------------------------------------------
2022-04-28 20:53:57,023 EPOCH 57 done: loss 0.0287 - lr 0.000195
2022-04-28 20:54:11,345 Evaluating as a multi-label problem: False
2022-04-28 20:54:11,356 DEV : loss 0.23232236504554749 - f1-score (micro avg)  0.5139
2022-04-28 20:54:11,428 BAD EPOCHS (no improvement): 3
2022-04-28 20:54:11,430 ----------------------------------------------------------------------------------------------------
2022-04-28 20:54:16,419 epoch 58 - iter 10/107 - loss 0.02416616 - samples/sec: 64.16 - lr: 0.000195
2022-04-28 20:54:20,754 epoch 58 - iter 20/107 - loss 0.02589309 - samples/sec: 73.83 - lr: 0.000195
2022-04-28 20:54:25,017 epoch 58 - iter 30/107 - loss 0.02474990 - samples/sec: 75.08 - lr: 0.000195
2022-04-28 20:54:28,766 epoch 58 - iter 40/107 - loss 0.02673722 - samples/sec: 85.38 - lr: 0.000195
2022-04-28 20:54:33,351 epoch 58 - iter 50/107 - loss 0.02767980 - samples/sec: 69.81 - lr: 0.000195
2022-04-28 20:54:37,898 epoch 58 - iter 60/107 - loss 0.02709044 - samples/sec: 70.40 - lr: 0.000195
2022-04-28 20:54:42,089 epoch 58 - iter 70/107 - loss 0.02735135 - samples/sec: 76.37 - lr: 0.000195
2022-04-28 20:54:46,768 epoch 58 - iter 80/107 - loss 0.02887531 - samples/sec: 68.40 - lr: 0.000195
2022-04-28 20:54:51,745 epoch 58 - iter 90/107 - loss 0.02871499 - samples/sec: 64.30 - lr: 0.000195
2022-04-28 20:54:56,597 epoch 58 - iter 100/107 - loss 0.02846454 - samples/sec: 65.97 - lr: 0.000195
2022-04-28 20:54:59,380 ----------------------------------------------------------------------------------------------------
2022-04-28 20:54:59,380 EPOCH 58 done: loss 0.0287 - lr 0.000195
2022-04-28 20:55:12,605 Evaluating as a multi-label problem: False
2022-04-28 20:55:12,616 DEV : loss 0.23273348808288574 - f1-score (micro avg)  0.5139
2022-04-28 20:55:12,685 Epoch    58: reducing learning rate of group 0 to 9.7656e-05.
2022-04-28 20:55:12,686 BAD EPOCHS (no improvement): 4
2022-04-28 20:55:12,688 ----------------------------------------------------------------------------------------------------
2022-04-28 20:55:12,688 ----------------------------------------------------------------------------------------------------
2022-04-28 20:55:12,688 learning rate too small - quitting training!
2022-04-28 20:55:12,688 ----------------------------------------------------------------------------------------------------
2022-04-28 20:55:31,663 ----------------------------------------------------------------------------------------------------
2022-04-28 20:55:31,664 loading file resources/taggers/model_05_r5_run_2/best-model.pt
2022-04-28 20:55:51,137 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-04-28 20:56:15,970 Evaluating as a multi-label problem: False
2022-04-28 20:56:15,983 0.6364	0.3179	0.424	0.2861
2022-04-28 20:56:15,983 
Results:
- F-score (micro) 0.424
- F-score (macro) 0.3331
- Accuracy 0.2861

By class:
               precision    recall  f1-score   support

       person     0.7683    0.4406    0.5600       429
     location     0.5695    0.5733    0.5714       150
        group     0.4821    0.1636    0.2443       165
creative-work     0.5714    0.1127    0.1882       142
      product     0.3514    0.1024    0.1585       127
  corporation     0.5714    0.1818    0.2759        66

    micro avg     0.6364    0.3179    0.4240      1079
    macro avg     0.5524    0.2624    0.3331      1079
 weighted avg     0.6099    0.3179    0.3998      1079

2022-04-28 20:56:15,983 ----------------------------------------------------------------------------------------------------
