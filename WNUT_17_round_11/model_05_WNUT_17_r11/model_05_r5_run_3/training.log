2022-04-28 16:57:21,019 ----------------------------------------------------------------------------------------------------
2022-04-28 16:57:21,019 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4797, out_features=4797, bias=True)
  (rnn): LSTM(4797, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-04-28 16:57:21,019 ----------------------------------------------------------------------------------------------------
2022-04-28 16:57:21,019 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-04-28 16:57:21,019 ----------------------------------------------------------------------------------------------------
2022-04-28 16:57:21,019 Parameters:
2022-04-28 16:57:21,019  - learning_rate: "0.100000"
2022-04-28 16:57:21,019  - mini_batch_size: "32"
2022-04-28 16:57:21,019  - patience: "3"
2022-04-28 16:57:21,019  - anneal_factor: "0.5"
2022-04-28 16:57:21,019  - max_epochs: "150"
2022-04-28 16:57:21,019  - shuffle: "True"
2022-04-28 16:57:21,019  - train_with_dev: "False"
2022-04-28 16:57:21,019  - batch_growth_annealing: "False"
2022-04-28 16:57:21,019 ----------------------------------------------------------------------------------------------------
2022-04-28 16:57:21,019 Model training base path: "resources/taggers/model_05_r5_run_3"
2022-04-28 16:57:21,020 ----------------------------------------------------------------------------------------------------
2022-04-28 16:57:21,020 Device: cuda:0
2022-04-28 16:57:21,020 ----------------------------------------------------------------------------------------------------
2022-04-28 16:57:21,020 Embeddings storage mode: cpu
2022-04-28 16:57:21,020 ----------------------------------------------------------------------------------------------------
2022-04-28 16:57:25,743 epoch 1 - iter 10/107 - loss 0.75526447 - samples/sec: 67.77 - lr: 0.100000
2022-04-28 16:57:30,120 epoch 1 - iter 20/107 - loss 0.53005807 - samples/sec: 73.14 - lr: 0.100000
2022-04-28 16:57:34,663 epoch 1 - iter 30/107 - loss 0.45051264 - samples/sec: 70.46 - lr: 0.100000
2022-04-28 16:57:39,670 epoch 1 - iter 40/107 - loss 0.40746525 - samples/sec: 63.93 - lr: 0.100000
2022-04-28 16:57:44,723 epoch 1 - iter 50/107 - loss 0.37047782 - samples/sec: 63.34 - lr: 0.100000
2022-04-28 16:57:49,932 epoch 1 - iter 60/107 - loss 0.35718559 - samples/sec: 61.44 - lr: 0.100000
2022-04-28 16:57:55,062 epoch 1 - iter 70/107 - loss 0.34770262 - samples/sec: 62.39 - lr: 0.100000
2022-04-28 16:57:59,676 epoch 1 - iter 80/107 - loss 0.34178572 - samples/sec: 69.38 - lr: 0.100000
2022-04-28 16:58:04,129 epoch 1 - iter 90/107 - loss 0.33905112 - samples/sec: 71.88 - lr: 0.100000
2022-04-28 16:58:08,535 epoch 1 - iter 100/107 - loss 0.33510897 - samples/sec: 72.65 - lr: 0.100000
2022-04-28 16:58:11,113 ----------------------------------------------------------------------------------------------------
2022-04-28 16:58:11,113 EPOCH 1 done: loss 0.3293 - lr 0.100000
2022-04-28 16:58:24,292 Evaluating as a multi-label problem: False
2022-04-28 16:58:24,302 DEV : loss 0.4141266942024231 - f1-score (micro avg)  0.0528
2022-04-28 16:58:24,374 BAD EPOCHS (no improvement): 0
2022-04-28 16:58:24,377 saving best model
2022-04-28 16:58:43,114 ----------------------------------------------------------------------------------------------------
2022-04-28 16:58:48,052 epoch 2 - iter 10/107 - loss 0.21844644 - samples/sec: 64.84 - lr: 0.100000
2022-04-28 16:58:52,360 epoch 2 - iter 20/107 - loss 0.21836847 - samples/sec: 74.28 - lr: 0.100000
2022-04-28 16:58:56,495 epoch 2 - iter 30/107 - loss 0.20808718 - samples/sec: 77.42 - lr: 0.100000
2022-04-28 16:59:01,414 epoch 2 - iter 40/107 - loss 0.20720005 - samples/sec: 65.07 - lr: 0.100000
2022-04-28 16:59:06,280 epoch 2 - iter 50/107 - loss 0.20428990 - samples/sec: 65.76 - lr: 0.100000
2022-04-28 16:59:10,950 epoch 2 - iter 60/107 - loss 0.20895698 - samples/sec: 68.55 - lr: 0.100000
2022-04-28 16:59:15,676 epoch 2 - iter 70/107 - loss 0.20530843 - samples/sec: 67.73 - lr: 0.100000
2022-04-28 16:59:20,394 epoch 2 - iter 80/107 - loss 0.20208860 - samples/sec: 67.83 - lr: 0.100000
2022-04-28 16:59:24,992 epoch 2 - iter 90/107 - loss 0.20126550 - samples/sec: 69.62 - lr: 0.100000
2022-04-28 16:59:30,023 epoch 2 - iter 100/107 - loss 0.19833223 - samples/sec: 63.61 - lr: 0.100000
2022-04-28 16:59:32,942 ----------------------------------------------------------------------------------------------------
2022-04-28 16:59:32,942 EPOCH 2 done: loss 0.1970 - lr 0.100000
2022-04-28 16:59:46,235 Evaluating as a multi-label problem: False
2022-04-28 16:59:46,247 DEV : loss 0.3055916428565979 - f1-score (micro avg)  0.4032
2022-04-28 16:59:46,319 BAD EPOCHS (no improvement): 0
2022-04-28 16:59:46,330 saving best model
2022-04-28 17:00:05,184 ----------------------------------------------------------------------------------------------------
2022-04-28 17:00:10,009 epoch 3 - iter 10/107 - loss 0.18529001 - samples/sec: 66.35 - lr: 0.100000
2022-04-28 17:00:14,603 epoch 3 - iter 20/107 - loss 0.17921468 - samples/sec: 69.67 - lr: 0.100000
2022-04-28 17:00:18,971 epoch 3 - iter 30/107 - loss 0.18459764 - samples/sec: 73.29 - lr: 0.100000
2022-04-28 17:00:22,876 epoch 3 - iter 40/107 - loss 0.17456702 - samples/sec: 81.97 - lr: 0.100000
2022-04-28 17:00:27,485 epoch 3 - iter 50/107 - loss 0.17415002 - samples/sec: 69.44 - lr: 0.100000
2022-04-28 17:00:32,364 epoch 3 - iter 60/107 - loss 0.17016437 - samples/sec: 65.60 - lr: 0.100000
2022-04-28 17:00:37,338 epoch 3 - iter 70/107 - loss 0.16764960 - samples/sec: 64.35 - lr: 0.100000
2022-04-28 17:00:42,062 epoch 3 - iter 80/107 - loss 0.16765546 - samples/sec: 67.77 - lr: 0.100000
2022-04-28 17:00:47,135 epoch 3 - iter 90/107 - loss 0.16787730 - samples/sec: 63.09 - lr: 0.100000
2022-04-28 17:00:51,802 epoch 3 - iter 100/107 - loss 0.16487832 - samples/sec: 68.59 - lr: 0.100000
2022-04-28 17:00:54,513 ----------------------------------------------------------------------------------------------------
2022-04-28 17:00:54,513 EPOCH 3 done: loss 0.1635 - lr 0.100000
2022-04-28 17:01:07,676 Evaluating as a multi-label problem: False
2022-04-28 17:01:07,686 DEV : loss 0.2915477454662323 - f1-score (micro avg)  0.3579
2022-04-28 17:01:07,758 BAD EPOCHS (no improvement): 1
2022-04-28 17:01:07,760 ----------------------------------------------------------------------------------------------------
2022-04-28 17:01:11,983 epoch 4 - iter 10/107 - loss 0.14350090 - samples/sec: 75.81 - lr: 0.100000
2022-04-28 17:01:16,449 epoch 4 - iter 20/107 - loss 0.14817515 - samples/sec: 71.67 - lr: 0.100000
2022-04-28 17:01:21,060 epoch 4 - iter 30/107 - loss 0.15131635 - samples/sec: 69.41 - lr: 0.100000
2022-04-28 17:01:26,052 epoch 4 - iter 40/107 - loss 0.14650713 - samples/sec: 64.11 - lr: 0.100000
2022-04-28 17:01:30,973 epoch 4 - iter 50/107 - loss 0.14106852 - samples/sec: 65.04 - lr: 0.100000
2022-04-28 17:01:35,956 epoch 4 - iter 60/107 - loss 0.14384489 - samples/sec: 64.24 - lr: 0.100000
2022-04-28 17:01:40,683 epoch 4 - iter 70/107 - loss 0.14673315 - samples/sec: 67.71 - lr: 0.100000
2022-04-28 17:01:45,523 epoch 4 - iter 80/107 - loss 0.14610573 - samples/sec: 66.13 - lr: 0.100000
2022-04-28 17:01:50,542 epoch 4 - iter 90/107 - loss 0.14624725 - samples/sec: 63.77 - lr: 0.100000
2022-04-28 17:01:55,017 epoch 4 - iter 100/107 - loss 0.14399610 - samples/sec: 71.53 - lr: 0.100000
2022-04-28 17:01:57,990 ----------------------------------------------------------------------------------------------------
2022-04-28 17:01:57,990 EPOCH 4 done: loss 0.1434 - lr 0.100000
2022-04-28 17:02:10,380 Evaluating as a multi-label problem: False
2022-04-28 17:02:10,392 DEV : loss 0.22964595258235931 - f1-score (micro avg)  0.488
2022-04-28 17:02:10,465 BAD EPOCHS (no improvement): 0
2022-04-28 17:02:10,467 saving best model
2022-04-28 17:02:28,997 ----------------------------------------------------------------------------------------------------
2022-04-28 17:02:34,005 epoch 5 - iter 10/107 - loss 0.16954051 - samples/sec: 63.93 - lr: 0.100000
2022-04-28 17:02:38,304 epoch 5 - iter 20/107 - loss 0.15909012 - samples/sec: 74.46 - lr: 0.100000
2022-04-28 17:02:42,655 epoch 5 - iter 30/107 - loss 0.15059349 - samples/sec: 73.55 - lr: 0.100000
2022-04-28 17:02:46,966 epoch 5 - iter 40/107 - loss 0.13733510 - samples/sec: 74.26 - lr: 0.100000
2022-04-28 17:02:51,703 epoch 5 - iter 50/107 - loss 0.14047804 - samples/sec: 67.57 - lr: 0.100000
2022-04-28 17:02:56,600 epoch 5 - iter 60/107 - loss 0.13497743 - samples/sec: 65.36 - lr: 0.100000
2022-04-28 17:03:01,545 epoch 5 - iter 70/107 - loss 0.12768966 - samples/sec: 64.72 - lr: 0.100000
2022-04-28 17:03:06,418 epoch 5 - iter 80/107 - loss 0.12684505 - samples/sec: 65.69 - lr: 0.100000
2022-04-28 17:03:11,197 epoch 5 - iter 90/107 - loss 0.12603233 - samples/sec: 66.97 - lr: 0.100000
2022-04-28 17:03:15,630 epoch 5 - iter 100/107 - loss 0.12777703 - samples/sec: 72.21 - lr: 0.100000
2022-04-28 17:03:18,453 ----------------------------------------------------------------------------------------------------
2022-04-28 17:03:18,453 EPOCH 5 done: loss 0.1295 - lr 0.100000
2022-04-28 17:03:31,354 Evaluating as a multi-label problem: False
2022-04-28 17:03:31,366 DEV : loss 0.21747811138629913 - f1-score (micro avg)  0.4233
2022-04-28 17:03:31,439 BAD EPOCHS (no improvement): 1
2022-04-28 17:03:31,458 ----------------------------------------------------------------------------------------------------
2022-04-28 17:03:35,787 epoch 6 - iter 10/107 - loss 0.13657264 - samples/sec: 73.95 - lr: 0.100000
2022-04-28 17:03:40,228 epoch 6 - iter 20/107 - loss 0.12931999 - samples/sec: 72.07 - lr: 0.100000
2022-04-28 17:03:45,021 epoch 6 - iter 30/107 - loss 0.12952065 - samples/sec: 66.77 - lr: 0.100000
2022-04-28 17:03:49,900 epoch 6 - iter 40/107 - loss 0.12349464 - samples/sec: 65.60 - lr: 0.100000
2022-04-28 17:03:54,798 epoch 6 - iter 50/107 - loss 0.12150283 - samples/sec: 65.35 - lr: 0.100000
2022-04-28 17:03:59,275 epoch 6 - iter 60/107 - loss 0.11689480 - samples/sec: 71.51 - lr: 0.100000
2022-04-28 17:04:04,213 epoch 6 - iter 70/107 - loss 0.11557591 - samples/sec: 64.81 - lr: 0.100000
2022-04-28 17:04:09,111 epoch 6 - iter 80/107 - loss 0.12125997 - samples/sec: 65.35 - lr: 0.100000
2022-04-28 17:04:14,295 epoch 6 - iter 90/107 - loss 0.12001023 - samples/sec: 61.74 - lr: 0.100000
2022-04-28 17:04:19,374 epoch 6 - iter 100/107 - loss 0.12050897 - samples/sec: 63.02 - lr: 0.100000
2022-04-28 17:04:21,951 ----------------------------------------------------------------------------------------------------
2022-04-28 17:04:21,951 EPOCH 6 done: loss 0.1207 - lr 0.100000
2022-04-28 17:04:34,514 Evaluating as a multi-label problem: False
2022-04-28 17:04:34,527 DEV : loss 0.18791794776916504 - f1-score (micro avg)  0.546
2022-04-28 17:04:34,600 BAD EPOCHS (no improvement): 0
2022-04-28 17:04:34,604 saving best model
2022-04-28 17:04:52,671 ----------------------------------------------------------------------------------------------------
2022-04-28 17:04:57,264 epoch 7 - iter 10/107 - loss 0.09578249 - samples/sec: 69.70 - lr: 0.100000
2022-04-28 17:05:01,620 epoch 7 - iter 20/107 - loss 0.09535126 - samples/sec: 73.50 - lr: 0.100000
2022-04-28 17:05:06,084 epoch 7 - iter 30/107 - loss 0.10343553 - samples/sec: 71.69 - lr: 0.100000
2022-04-28 17:05:10,481 epoch 7 - iter 40/107 - loss 0.10864349 - samples/sec: 72.79 - lr: 0.100000
2022-04-28 17:05:15,344 epoch 7 - iter 50/107 - loss 0.11296673 - samples/sec: 65.82 - lr: 0.100000
2022-04-28 17:05:20,287 epoch 7 - iter 60/107 - loss 0.11380409 - samples/sec: 64.76 - lr: 0.100000
2022-04-28 17:05:25,022 epoch 7 - iter 70/107 - loss 0.11375301 - samples/sec: 67.60 - lr: 0.100000
2022-04-28 17:05:29,771 epoch 7 - iter 80/107 - loss 0.11388868 - samples/sec: 67.39 - lr: 0.100000
2022-04-28 17:05:34,515 epoch 7 - iter 90/107 - loss 0.11420194 - samples/sec: 67.47 - lr: 0.100000
2022-04-28 17:05:39,038 epoch 7 - iter 100/107 - loss 0.11274338 - samples/sec: 70.77 - lr: 0.100000
2022-04-28 17:05:41,772 ----------------------------------------------------------------------------------------------------
2022-04-28 17:05:41,772 EPOCH 7 done: loss 0.1126 - lr 0.100000
2022-04-28 17:05:53,939 Evaluating as a multi-label problem: False
2022-04-28 17:05:53,949 DEV : loss 0.1974419355392456 - f1-score (micro avg)  0.4963
2022-04-28 17:05:54,021 BAD EPOCHS (no improvement): 1
2022-04-28 17:05:54,034 ----------------------------------------------------------------------------------------------------
2022-04-28 17:05:57,811 epoch 8 - iter 10/107 - loss 0.09285602 - samples/sec: 84.74 - lr: 0.100000
2022-04-28 17:06:02,280 epoch 8 - iter 20/107 - loss 0.10777286 - samples/sec: 71.62 - lr: 0.100000
2022-04-28 17:06:07,179 epoch 8 - iter 30/107 - loss 0.10577461 - samples/sec: 65.33 - lr: 0.100000
2022-04-28 17:06:11,852 epoch 8 - iter 40/107 - loss 0.09859758 - samples/sec: 68.50 - lr: 0.100000
2022-04-28 17:06:16,828 epoch 8 - iter 50/107 - loss 0.09853923 - samples/sec: 64.32 - lr: 0.100000
2022-04-28 17:06:21,953 epoch 8 - iter 60/107 - loss 0.10160371 - samples/sec: 62.45 - lr: 0.100000
2022-04-28 17:06:26,639 epoch 8 - iter 70/107 - loss 0.10218526 - samples/sec: 68.31 - lr: 0.100000
2022-04-28 17:06:31,485 epoch 8 - iter 80/107 - loss 0.10296227 - samples/sec: 66.05 - lr: 0.100000
2022-04-28 17:06:36,286 epoch 8 - iter 90/107 - loss 0.10348306 - samples/sec: 66.67 - lr: 0.100000
2022-04-28 17:06:40,930 epoch 8 - iter 100/107 - loss 0.10414255 - samples/sec: 68.91 - lr: 0.100000
2022-04-28 17:06:43,403 ----------------------------------------------------------------------------------------------------
2022-04-28 17:06:43,403 EPOCH 8 done: loss 0.1050 - lr 0.100000
2022-04-28 17:06:55,883 Evaluating as a multi-label problem: False
2022-04-28 17:06:55,894 DEV : loss 0.18515799939632416 - f1-score (micro avg)  0.5426
2022-04-28 17:06:55,969 BAD EPOCHS (no improvement): 2
2022-04-28 17:06:55,971 ----------------------------------------------------------------------------------------------------
2022-04-28 17:07:00,809 epoch 9 - iter 10/107 - loss 0.11221217 - samples/sec: 66.17 - lr: 0.100000
2022-04-28 17:07:05,721 epoch 9 - iter 20/107 - loss 0.11155489 - samples/sec: 65.17 - lr: 0.100000
2022-04-28 17:07:10,586 epoch 9 - iter 30/107 - loss 0.09877621 - samples/sec: 65.79 - lr: 0.100000
2022-04-28 17:07:15,386 epoch 9 - iter 40/107 - loss 0.09686199 - samples/sec: 66.68 - lr: 0.100000
2022-04-28 17:07:20,145 epoch 9 - iter 50/107 - loss 0.09742118 - samples/sec: 67.25 - lr: 0.100000
2022-04-28 17:07:24,801 epoch 9 - iter 60/107 - loss 0.09782294 - samples/sec: 68.75 - lr: 0.100000
2022-04-28 17:07:29,814 epoch 9 - iter 70/107 - loss 0.09729727 - samples/sec: 63.85 - lr: 0.100000
2022-04-28 17:07:34,521 epoch 9 - iter 80/107 - loss 0.09623014 - samples/sec: 68.00 - lr: 0.100000
2022-04-28 17:07:38,718 epoch 9 - iter 90/107 - loss 0.09793705 - samples/sec: 76.25 - lr: 0.100000
2022-04-28 17:07:42,918 epoch 9 - iter 100/107 - loss 0.09773106 - samples/sec: 76.22 - lr: 0.100000
2022-04-28 17:07:45,846 ----------------------------------------------------------------------------------------------------
2022-04-28 17:07:45,846 EPOCH 9 done: loss 0.0982 - lr 0.100000
2022-04-28 17:07:59,701 Evaluating as a multi-label problem: False
2022-04-28 17:07:59,711 DEV : loss 0.24523623287677765 - f1-score (micro avg)  0.3576
2022-04-28 17:07:59,783 BAD EPOCHS (no improvement): 3
2022-04-28 17:07:59,786 ----------------------------------------------------------------------------------------------------
2022-04-28 17:08:04,306 epoch 10 - iter 10/107 - loss 0.08871279 - samples/sec: 70.82 - lr: 0.100000
2022-04-28 17:08:08,882 epoch 10 - iter 20/107 - loss 0.09061433 - samples/sec: 69.95 - lr: 0.100000
2022-04-28 17:08:12,339 epoch 10 - iter 30/107 - loss 0.09117831 - samples/sec: 92.59 - lr: 0.100000
2022-04-28 17:08:16,285 epoch 10 - iter 40/107 - loss 0.09121428 - samples/sec: 81.11 - lr: 0.100000
2022-04-28 17:08:20,431 epoch 10 - iter 50/107 - loss 0.09496492 - samples/sec: 77.21 - lr: 0.100000
2022-04-28 17:08:24,638 epoch 10 - iter 60/107 - loss 0.09491938 - samples/sec: 76.09 - lr: 0.100000
2022-04-28 17:08:29,141 epoch 10 - iter 70/107 - loss 0.09421283 - samples/sec: 71.08 - lr: 0.100000
2022-04-28 17:08:34,194 epoch 10 - iter 80/107 - loss 0.09451732 - samples/sec: 63.34 - lr: 0.100000
2022-04-28 17:08:39,248 epoch 10 - iter 90/107 - loss 0.09477767 - samples/sec: 63.33 - lr: 0.100000
2022-04-28 17:08:44,660 epoch 10 - iter 100/107 - loss 0.09350775 - samples/sec: 59.15 - lr: 0.100000
2022-04-28 17:08:47,866 ----------------------------------------------------------------------------------------------------
2022-04-28 17:08:47,866 EPOCH 10 done: loss 0.0940 - lr 0.100000
2022-04-28 17:09:02,887 Evaluating as a multi-label problem: False
2022-04-28 17:09:02,899 DEV : loss 0.19225874543190002 - f1-score (micro avg)  0.508
2022-04-28 17:09:02,986 Epoch    10: reducing learning rate of group 0 to 5.0000e-02.
2022-04-28 17:09:02,986 BAD EPOCHS (no improvement): 4
2022-04-28 17:09:02,989 ----------------------------------------------------------------------------------------------------
2022-04-28 17:09:07,756 epoch 11 - iter 10/107 - loss 0.07088871 - samples/sec: 67.14 - lr: 0.050000
2022-04-28 17:09:12,308 epoch 11 - iter 20/107 - loss 0.08016842 - samples/sec: 70.32 - lr: 0.050000
2022-04-28 17:09:16,433 epoch 11 - iter 30/107 - loss 0.07830701 - samples/sec: 77.61 - lr: 0.050000
2022-04-28 17:09:20,859 epoch 11 - iter 40/107 - loss 0.07885630 - samples/sec: 72.32 - lr: 0.050000
2022-04-28 17:09:25,363 epoch 11 - iter 50/107 - loss 0.08002783 - samples/sec: 71.07 - lr: 0.050000
2022-04-28 17:09:30,181 epoch 11 - iter 60/107 - loss 0.07906877 - samples/sec: 66.44 - lr: 0.050000
2022-04-28 17:09:34,891 epoch 11 - iter 70/107 - loss 0.07890671 - samples/sec: 67.95 - lr: 0.050000
2022-04-28 17:09:40,263 epoch 11 - iter 80/107 - loss 0.07788232 - samples/sec: 59.58 - lr: 0.050000
2022-04-28 17:09:44,961 epoch 11 - iter 90/107 - loss 0.07868012 - samples/sec: 68.14 - lr: 0.050000
2022-04-28 17:09:49,967 epoch 11 - iter 100/107 - loss 0.08092829 - samples/sec: 63.93 - lr: 0.050000
2022-04-28 17:09:52,991 ----------------------------------------------------------------------------------------------------
2022-04-28 17:09:52,991 EPOCH 11 done: loss 0.0819 - lr 0.050000
2022-04-28 17:10:05,991 Evaluating as a multi-label problem: False
2022-04-28 17:10:06,001 DEV : loss 0.20104102790355682 - f1-score (micro avg)  0.4876
2022-04-28 17:10:06,073 BAD EPOCHS (no improvement): 1
2022-04-28 17:10:06,074 ----------------------------------------------------------------------------------------------------
2022-04-28 17:10:10,194 epoch 12 - iter 10/107 - loss 0.08311498 - samples/sec: 77.70 - lr: 0.050000
2022-04-28 17:10:15,108 epoch 12 - iter 20/107 - loss 0.07790831 - samples/sec: 65.14 - lr: 0.050000
2022-04-28 17:10:19,987 epoch 12 - iter 30/107 - loss 0.07438902 - samples/sec: 65.60 - lr: 0.050000
2022-04-28 17:10:25,193 epoch 12 - iter 40/107 - loss 0.07183479 - samples/sec: 61.48 - lr: 0.050000
2022-04-28 17:10:30,082 epoch 12 - iter 50/107 - loss 0.07512821 - samples/sec: 65.47 - lr: 0.050000
2022-04-28 17:10:34,991 epoch 12 - iter 60/107 - loss 0.07769759 - samples/sec: 65.20 - lr: 0.050000
2022-04-28 17:10:39,494 epoch 12 - iter 70/107 - loss 0.07643377 - samples/sec: 71.08 - lr: 0.050000
2022-04-28 17:10:44,102 epoch 12 - iter 80/107 - loss 0.07697025 - samples/sec: 69.46 - lr: 0.050000
2022-04-28 17:10:48,603 epoch 12 - iter 90/107 - loss 0.07631998 - samples/sec: 71.11 - lr: 0.050000
2022-04-28 17:10:52,995 epoch 12 - iter 100/107 - loss 0.07653997 - samples/sec: 72.87 - lr: 0.050000
2022-04-28 17:10:55,637 ----------------------------------------------------------------------------------------------------
2022-04-28 17:10:55,637 EPOCH 12 done: loss 0.0768 - lr 0.050000
2022-04-28 17:11:09,193 Evaluating as a multi-label problem: False
2022-04-28 17:11:09,204 DEV : loss 0.21745426952838898 - f1-score (micro avg)  0.4585
2022-04-28 17:11:09,275 BAD EPOCHS (no improvement): 2
2022-04-28 17:11:09,278 ----------------------------------------------------------------------------------------------------
2022-04-28 17:11:14,226 epoch 13 - iter 10/107 - loss 0.06107862 - samples/sec: 64.69 - lr: 0.050000
2022-04-28 17:11:19,214 epoch 13 - iter 20/107 - loss 0.06902713 - samples/sec: 64.17 - lr: 0.050000
2022-04-28 17:11:24,262 epoch 13 - iter 30/107 - loss 0.07051812 - samples/sec: 63.40 - lr: 0.050000
2022-04-28 17:11:29,153 epoch 13 - iter 40/107 - loss 0.07088887 - samples/sec: 65.43 - lr: 0.050000
2022-04-28 17:11:34,008 epoch 13 - iter 50/107 - loss 0.07348310 - samples/sec: 65.93 - lr: 0.050000
2022-04-28 17:11:38,815 epoch 13 - iter 60/107 - loss 0.07230426 - samples/sec: 66.58 - lr: 0.050000
2022-04-28 17:11:42,169 epoch 13 - iter 70/107 - loss 0.07387732 - samples/sec: 95.44 - lr: 0.050000
2022-04-28 17:11:46,166 epoch 13 - iter 80/107 - loss 0.07508310 - samples/sec: 80.07 - lr: 0.050000
2022-04-28 17:11:50,296 epoch 13 - iter 90/107 - loss 0.07613884 - samples/sec: 77.51 - lr: 0.050000
2022-04-28 17:11:56,362 epoch 13 - iter 100/107 - loss 0.07559074 - samples/sec: 52.76 - lr: 0.050000
2022-04-28 17:11:59,055 ----------------------------------------------------------------------------------------------------
2022-04-28 17:11:59,055 EPOCH 13 done: loss 0.0752 - lr 0.050000
2022-04-28 17:12:12,961 Evaluating as a multi-label problem: False
2022-04-28 17:12:12,972 DEV : loss 0.20425352454185486 - f1-score (micro avg)  0.4824
2022-04-28 17:12:13,043 BAD EPOCHS (no improvement): 3
2022-04-28 17:12:13,054 ----------------------------------------------------------------------------------------------------
2022-04-28 17:12:17,885 epoch 14 - iter 10/107 - loss 0.07016316 - samples/sec: 66.26 - lr: 0.050000
2022-04-28 17:12:22,765 epoch 14 - iter 20/107 - loss 0.07352454 - samples/sec: 65.58 - lr: 0.050000
2022-04-28 17:12:27,719 epoch 14 - iter 30/107 - loss 0.07088905 - samples/sec: 64.61 - lr: 0.050000
2022-04-28 17:12:32,198 epoch 14 - iter 40/107 - loss 0.06996335 - samples/sec: 71.46 - lr: 0.050000
2022-04-28 17:12:36,297 epoch 14 - iter 50/107 - loss 0.06972425 - samples/sec: 78.09 - lr: 0.050000
2022-04-28 17:12:40,668 epoch 14 - iter 60/107 - loss 0.07152118 - samples/sec: 73.22 - lr: 0.050000
2022-04-28 17:12:45,215 epoch 14 - iter 70/107 - loss 0.07265051 - samples/sec: 70.40 - lr: 0.050000
2022-04-28 17:12:50,147 epoch 14 - iter 80/107 - loss 0.07232806 - samples/sec: 64.90 - lr: 0.050000
2022-04-28 17:12:55,059 epoch 14 - iter 90/107 - loss 0.07246348 - samples/sec: 65.17 - lr: 0.050000
2022-04-28 17:13:00,077 epoch 14 - iter 100/107 - loss 0.07182835 - samples/sec: 63.78 - lr: 0.050000
2022-04-28 17:13:02,793 ----------------------------------------------------------------------------------------------------
2022-04-28 17:13:02,793 EPOCH 14 done: loss 0.0726 - lr 0.050000
2022-04-28 17:13:15,521 Evaluating as a multi-label problem: False
2022-04-28 17:13:15,532 DEV : loss 0.22100135684013367 - f1-score (micro avg)  0.4742
2022-04-28 17:13:15,604 Epoch    14: reducing learning rate of group 0 to 2.5000e-02.
2022-04-28 17:13:15,604 BAD EPOCHS (no improvement): 4
2022-04-28 17:13:15,607 ----------------------------------------------------------------------------------------------------
2022-04-28 17:13:19,987 epoch 15 - iter 10/107 - loss 0.06186673 - samples/sec: 73.08 - lr: 0.025000
2022-04-28 17:13:24,006 epoch 15 - iter 20/107 - loss 0.06920612 - samples/sec: 79.65 - lr: 0.025000
2022-04-28 17:13:28,587 epoch 15 - iter 30/107 - loss 0.06723812 - samples/sec: 69.86 - lr: 0.025000
2022-04-28 17:13:33,103 epoch 15 - iter 40/107 - loss 0.06782255 - samples/sec: 70.87 - lr: 0.025000
2022-04-28 17:13:37,981 epoch 15 - iter 50/107 - loss 0.06977712 - samples/sec: 65.62 - lr: 0.025000
2022-04-28 17:13:42,738 epoch 15 - iter 60/107 - loss 0.07035560 - samples/sec: 67.29 - lr: 0.025000
2022-04-28 17:13:47,632 epoch 15 - iter 70/107 - loss 0.06894633 - samples/sec: 65.40 - lr: 0.025000
2022-04-28 17:13:52,422 epoch 15 - iter 80/107 - loss 0.06791919 - samples/sec: 66.82 - lr: 0.025000
2022-04-28 17:13:57,117 epoch 15 - iter 90/107 - loss 0.06694493 - samples/sec: 68.17 - lr: 0.025000
2022-04-28 17:14:01,838 epoch 15 - iter 100/107 - loss 0.06646252 - samples/sec: 67.80 - lr: 0.025000
2022-04-28 17:14:04,754 ----------------------------------------------------------------------------------------------------
2022-04-28 17:14:04,754 EPOCH 15 done: loss 0.0658 - lr 0.025000
2022-04-28 17:14:17,828 Evaluating as a multi-label problem: False
2022-04-28 17:14:17,840 DEV : loss 0.19512984156608582 - f1-score (micro avg)  0.5098
2022-04-28 17:14:17,924 BAD EPOCHS (no improvement): 1
2022-04-28 17:14:17,927 ----------------------------------------------------------------------------------------------------
2022-04-28 17:14:22,247 epoch 16 - iter 10/107 - loss 0.05963895 - samples/sec: 74.11 - lr: 0.025000
2022-04-28 17:14:27,084 epoch 16 - iter 20/107 - loss 0.06512743 - samples/sec: 66.18 - lr: 0.025000
2022-04-28 17:14:31,882 epoch 16 - iter 30/107 - loss 0.06497067 - samples/sec: 66.72 - lr: 0.025000
2022-04-28 17:14:36,966 epoch 16 - iter 40/107 - loss 0.06502766 - samples/sec: 62.96 - lr: 0.025000
2022-04-28 17:14:41,875 epoch 16 - iter 50/107 - loss 0.06472679 - samples/sec: 65.20 - lr: 0.025000
2022-04-28 17:14:46,777 epoch 16 - iter 60/107 - loss 0.06665248 - samples/sec: 65.30 - lr: 0.025000
2022-04-28 17:14:51,430 epoch 16 - iter 70/107 - loss 0.06576611 - samples/sec: 68.80 - lr: 0.025000
2022-04-28 17:14:56,414 epoch 16 - iter 80/107 - loss 0.06502516 - samples/sec: 64.22 - lr: 0.025000
2022-04-28 17:15:01,142 epoch 16 - iter 90/107 - loss 0.06560602 - samples/sec: 67.70 - lr: 0.025000
2022-04-28 17:15:05,707 epoch 16 - iter 100/107 - loss 0.06493686 - samples/sec: 70.12 - lr: 0.025000
2022-04-28 17:15:08,105 ----------------------------------------------------------------------------------------------------
2022-04-28 17:15:08,105 EPOCH 16 done: loss 0.0649 - lr 0.025000
2022-04-28 17:15:17,796 Evaluating as a multi-label problem: False
2022-04-28 17:15:17,807 DEV : loss 0.187277689576149 - f1-score (micro avg)  0.5188
2022-04-28 17:15:17,878 BAD EPOCHS (no improvement): 2
2022-04-28 17:15:17,882 ----------------------------------------------------------------------------------------------------
2022-04-28 17:15:20,882 epoch 17 - iter 10/107 - loss 0.06454914 - samples/sec: 106.71 - lr: 0.025000
2022-04-28 17:15:23,809 epoch 17 - iter 20/107 - loss 0.06725433 - samples/sec: 109.35 - lr: 0.025000
2022-04-28 17:15:26,386 epoch 17 - iter 30/107 - loss 0.06691107 - samples/sec: 124.24 - lr: 0.025000
2022-04-28 17:15:28,993 epoch 17 - iter 40/107 - loss 0.06498038 - samples/sec: 122.79 - lr: 0.025000
2022-04-28 17:15:31,777 epoch 17 - iter 50/107 - loss 0.06517542 - samples/sec: 114.96 - lr: 0.025000
2022-04-28 17:15:34,510 epoch 17 - iter 60/107 - loss 0.06350926 - samples/sec: 117.13 - lr: 0.025000
2022-04-28 17:15:37,322 epoch 17 - iter 70/107 - loss 0.06334281 - samples/sec: 113.85 - lr: 0.025000
2022-04-28 17:15:40,095 epoch 17 - iter 80/107 - loss 0.06248455 - samples/sec: 115.45 - lr: 0.025000
2022-04-28 17:15:42,813 epoch 17 - iter 90/107 - loss 0.06201737 - samples/sec: 117.79 - lr: 0.025000
2022-04-28 17:15:45,696 epoch 17 - iter 100/107 - loss 0.06233978 - samples/sec: 111.05 - lr: 0.025000
2022-04-28 17:15:47,511 ----------------------------------------------------------------------------------------------------
2022-04-28 17:15:47,511 EPOCH 17 done: loss 0.0629 - lr 0.025000
2022-04-28 17:15:56,335 Evaluating as a multi-label problem: False
2022-04-28 17:15:56,347 DEV : loss 0.19148248434066772 - f1-score (micro avg)  0.5217
2022-04-28 17:15:56,418 BAD EPOCHS (no improvement): 3
2022-04-28 17:15:56,437 ----------------------------------------------------------------------------------------------------
2022-04-28 17:15:59,518 epoch 18 - iter 10/107 - loss 0.06562365 - samples/sec: 103.91 - lr: 0.025000
2022-04-28 17:16:02,536 epoch 18 - iter 20/107 - loss 0.06595785 - samples/sec: 106.04 - lr: 0.025000
2022-04-28 17:16:05,815 epoch 18 - iter 30/107 - loss 0.06577919 - samples/sec: 97.64 - lr: 0.025000
2022-04-28 17:16:13,346 epoch 18 - iter 40/107 - loss 0.06260690 - samples/sec: 42.49 - lr: 0.025000
2022-04-28 17:16:19,086 epoch 18 - iter 50/107 - loss 0.06250059 - samples/sec: 55.76 - lr: 0.025000
2022-04-28 17:16:24,661 epoch 18 - iter 60/107 - loss 0.06152898 - samples/sec: 57.42 - lr: 0.025000
2022-04-28 17:16:29,389 epoch 18 - iter 70/107 - loss 0.06101651 - samples/sec: 67.70 - lr: 0.025000
2022-04-28 17:16:32,130 epoch 18 - iter 80/107 - loss 0.06016414 - samples/sec: 116.79 - lr: 0.025000
2022-04-28 17:16:34,891 epoch 18 - iter 90/107 - loss 0.06080133 - samples/sec: 115.97 - lr: 0.025000
2022-04-28 17:16:37,197 epoch 18 - iter 100/107 - loss 0.06050216 - samples/sec: 138.84 - lr: 0.025000
2022-04-28 17:16:38,493 ----------------------------------------------------------------------------------------------------
2022-04-28 17:16:38,493 EPOCH 18 done: loss 0.0611 - lr 0.025000
2022-04-28 17:16:45,398 Evaluating as a multi-label problem: False
2022-04-28 17:16:45,409 DEV : loss 0.18117883801460266 - f1-score (micro avg)  0.5341
2022-04-28 17:16:45,480 Epoch    18: reducing learning rate of group 0 to 1.2500e-02.
2022-04-28 17:16:45,481 BAD EPOCHS (no improvement): 4
2022-04-28 17:16:45,484 ----------------------------------------------------------------------------------------------------
2022-04-28 17:16:47,837 epoch 19 - iter 10/107 - loss 0.06553294 - samples/sec: 136.07 - lr: 0.012500
2022-04-28 17:16:50,155 epoch 19 - iter 20/107 - loss 0.06696243 - samples/sec: 138.09 - lr: 0.012500
2022-04-28 17:16:52,563 epoch 19 - iter 30/107 - loss 0.06443010 - samples/sec: 132.95 - lr: 0.012500
2022-04-28 17:16:54,964 epoch 19 - iter 40/107 - loss 0.06084919 - samples/sec: 133.34 - lr: 0.012500
2022-04-28 17:16:57,237 epoch 19 - iter 50/107 - loss 0.05953347 - samples/sec: 140.83 - lr: 0.012500
2022-04-28 17:16:59,513 epoch 19 - iter 60/107 - loss 0.05893867 - samples/sec: 140.66 - lr: 0.012500
2022-04-28 17:17:01,826 epoch 19 - iter 70/107 - loss 0.06043039 - samples/sec: 138.43 - lr: 0.012500
2022-04-28 17:17:04,102 epoch 19 - iter 80/107 - loss 0.05941625 - samples/sec: 140.60 - lr: 0.012500
2022-04-28 17:17:06,444 epoch 19 - iter 90/107 - loss 0.05938544 - samples/sec: 136.73 - lr: 0.012500
2022-04-28 17:17:08,743 epoch 19 - iter 100/107 - loss 0.05989628 - samples/sec: 139.26 - lr: 0.012500
2022-04-28 17:17:10,139 ----------------------------------------------------------------------------------------------------
2022-04-28 17:17:10,139 EPOCH 19 done: loss 0.0595 - lr 0.012500
2022-04-28 17:17:17,141 Evaluating as a multi-label problem: False
2022-04-28 17:17:17,152 DEV : loss 0.2034497857093811 - f1-score (micro avg)  0.5078
2022-04-28 17:17:17,223 BAD EPOCHS (no improvement): 1
2022-04-28 17:17:17,235 ----------------------------------------------------------------------------------------------------
2022-04-28 17:17:19,463 epoch 20 - iter 10/107 - loss 0.05941321 - samples/sec: 143.74 - lr: 0.012500
2022-04-28 17:17:21,714 epoch 20 - iter 20/107 - loss 0.05912060 - samples/sec: 142.21 - lr: 0.012500
2022-04-28 17:17:24,049 epoch 20 - iter 30/107 - loss 0.06044101 - samples/sec: 137.15 - lr: 0.012500
2022-04-28 17:17:26,307 epoch 20 - iter 40/107 - loss 0.06303609 - samples/sec: 141.76 - lr: 0.012500
2022-04-28 17:17:28,609 epoch 20 - iter 50/107 - loss 0.06143958 - samples/sec: 139.04 - lr: 0.012500
2022-04-28 17:17:30,880 epoch 20 - iter 60/107 - loss 0.06129682 - samples/sec: 140.98 - lr: 0.012500
2022-04-28 17:17:33,203 epoch 20 - iter 70/107 - loss 0.06178920 - samples/sec: 137.81 - lr: 0.012500
2022-04-28 17:17:35,569 epoch 20 - iter 80/107 - loss 0.06071352 - samples/sec: 135.32 - lr: 0.012500
2022-04-28 17:17:37,873 epoch 20 - iter 90/107 - loss 0.05919861 - samples/sec: 138.91 - lr: 0.012500
2022-04-28 17:17:40,218 epoch 20 - iter 100/107 - loss 0.05981064 - samples/sec: 136.50 - lr: 0.012500
2022-04-28 17:17:41,606 ----------------------------------------------------------------------------------------------------
2022-04-28 17:17:41,606 EPOCH 20 done: loss 0.0596 - lr 0.012500
2022-04-28 17:17:48,539 Evaluating as a multi-label problem: False
2022-04-28 17:17:48,550 DEV : loss 0.20187418162822723 - f1-score (micro avg)  0.4884
2022-04-28 17:17:48,624 BAD EPOCHS (no improvement): 2
2022-04-28 17:17:48,627 ----------------------------------------------------------------------------------------------------
2022-04-28 17:17:50,961 epoch 21 - iter 10/107 - loss 0.07686244 - samples/sec: 137.17 - lr: 0.012500
2022-04-28 17:17:53,201 epoch 21 - iter 20/107 - loss 0.06298811 - samples/sec: 142.95 - lr: 0.012500
2022-04-28 17:17:55,441 epoch 21 - iter 30/107 - loss 0.06158768 - samples/sec: 142.88 - lr: 0.012500
2022-04-28 17:17:57,598 epoch 21 - iter 40/107 - loss 0.06346056 - samples/sec: 148.44 - lr: 0.012500
2022-04-28 17:17:59,888 epoch 21 - iter 50/107 - loss 0.06312684 - samples/sec: 139.83 - lr: 0.012500
2022-04-28 17:18:02,112 epoch 21 - iter 60/107 - loss 0.06046100 - samples/sec: 143.92 - lr: 0.012500
2022-04-28 17:18:04,340 epoch 21 - iter 70/107 - loss 0.05890707 - samples/sec: 143.67 - lr: 0.012500
2022-04-28 17:18:06,655 epoch 21 - iter 80/107 - loss 0.05936195 - samples/sec: 138.32 - lr: 0.012500
2022-04-28 17:18:10,601 epoch 21 - iter 90/107 - loss 0.05747851 - samples/sec: 81.11 - lr: 0.012500
2022-04-28 17:18:12,970 epoch 21 - iter 100/107 - loss 0.05825793 - samples/sec: 135.14 - lr: 0.012500
2022-04-28 17:18:14,481 ----------------------------------------------------------------------------------------------------
2022-04-28 17:18:14,481 EPOCH 21 done: loss 0.0580 - lr 0.012500
2022-04-28 17:18:21,707 Evaluating as a multi-label problem: False
2022-04-28 17:18:21,717 DEV : loss 0.2019355446100235 - f1-score (micro avg)  0.4996
2022-04-28 17:18:21,790 BAD EPOCHS (no improvement): 3
2022-04-28 17:18:21,793 ----------------------------------------------------------------------------------------------------
2022-04-28 17:18:26,009 epoch 22 - iter 10/107 - loss 0.06299102 - samples/sec: 75.92 - lr: 0.012500
2022-04-28 17:18:30,073 epoch 22 - iter 20/107 - loss 0.06193932 - samples/sec: 78.75 - lr: 0.012500
2022-04-28 17:18:34,343 epoch 22 - iter 30/107 - loss 0.05949699 - samples/sec: 74.96 - lr: 0.012500
2022-04-28 17:18:37,988 epoch 22 - iter 40/107 - loss 0.05744091 - samples/sec: 87.82 - lr: 0.012500
2022-04-28 17:18:41,880 epoch 22 - iter 50/107 - loss 0.05688432 - samples/sec: 82.25 - lr: 0.012500
2022-04-28 17:18:45,517 epoch 22 - iter 60/107 - loss 0.05788117 - samples/sec: 88.00 - lr: 0.012500
2022-04-28 17:18:48,138 epoch 22 - iter 70/107 - loss 0.05660624 - samples/sec: 122.14 - lr: 0.012500
2022-04-28 17:18:51,030 epoch 22 - iter 80/107 - loss 0.05852352 - samples/sec: 110.69 - lr: 0.012500
2022-04-28 17:18:53,815 epoch 22 - iter 90/107 - loss 0.05685950 - samples/sec: 114.94 - lr: 0.012500
2022-04-28 17:18:56,485 epoch 22 - iter 100/107 - loss 0.05685867 - samples/sec: 119.89 - lr: 0.012500
2022-04-28 17:18:58,158 ----------------------------------------------------------------------------------------------------
2022-04-28 17:18:58,158 EPOCH 22 done: loss 0.0564 - lr 0.012500
2022-04-28 17:19:06,742 Evaluating as a multi-label problem: False
2022-04-28 17:19:06,753 DEV : loss 0.21062098443508148 - f1-score (micro avg)  0.4988
2022-04-28 17:19:06,827 Epoch    22: reducing learning rate of group 0 to 6.2500e-03.
2022-04-28 17:19:06,827 BAD EPOCHS (no improvement): 4
2022-04-28 17:19:06,830 ----------------------------------------------------------------------------------------------------
2022-04-28 17:19:09,611 epoch 23 - iter 10/107 - loss 0.05106068 - samples/sec: 115.14 - lr: 0.006250
2022-04-28 17:19:12,473 epoch 23 - iter 20/107 - loss 0.04777215 - samples/sec: 111.82 - lr: 0.006250
2022-04-28 17:19:15,410 epoch 23 - iter 30/107 - loss 0.04884254 - samples/sec: 109.00 - lr: 0.006250
2022-04-28 17:19:18,227 epoch 23 - iter 40/107 - loss 0.05182389 - samples/sec: 113.65 - lr: 0.006250
2022-04-28 17:19:21,087 epoch 23 - iter 50/107 - loss 0.05494208 - samples/sec: 111.93 - lr: 0.006250
2022-04-28 17:19:23,972 epoch 23 - iter 60/107 - loss 0.05341946 - samples/sec: 110.96 - lr: 0.006250
2022-04-28 17:19:26,521 epoch 23 - iter 70/107 - loss 0.05322453 - samples/sec: 125.57 - lr: 0.006250
2022-04-28 17:19:29,147 epoch 23 - iter 80/107 - loss 0.05523090 - samples/sec: 121.91 - lr: 0.006250
2022-04-28 17:19:31,989 epoch 23 - iter 90/107 - loss 0.05613045 - samples/sec: 112.62 - lr: 0.006250
2022-04-28 17:19:34,500 epoch 23 - iter 100/107 - loss 0.05534868 - samples/sec: 127.48 - lr: 0.006250
2022-04-28 17:19:35,815 ----------------------------------------------------------------------------------------------------
2022-04-28 17:19:35,815 EPOCH 23 done: loss 0.0553 - lr 0.006250
2022-04-28 17:19:42,590 Evaluating as a multi-label problem: False
2022-04-28 17:19:42,601 DEV : loss 0.19807475805282593 - f1-score (micro avg)  0.5155
2022-04-28 17:19:42,674 BAD EPOCHS (no improvement): 1
2022-04-28 17:19:42,676 ----------------------------------------------------------------------------------------------------
2022-04-28 17:19:45,050 epoch 24 - iter 10/107 - loss 0.05727921 - samples/sec: 134.85 - lr: 0.006250
2022-04-28 17:19:47,418 epoch 24 - iter 20/107 - loss 0.05400960 - samples/sec: 135.23 - lr: 0.006250
2022-04-28 17:19:49,760 epoch 24 - iter 30/107 - loss 0.05378436 - samples/sec: 136.69 - lr: 0.006250
2022-04-28 17:19:51,985 epoch 24 - iter 40/107 - loss 0.05564178 - samples/sec: 143.86 - lr: 0.006250
2022-04-28 17:19:54,256 epoch 24 - iter 50/107 - loss 0.05653328 - samples/sec: 140.97 - lr: 0.006250
2022-04-28 17:19:56,527 epoch 24 - iter 60/107 - loss 0.05458291 - samples/sec: 140.97 - lr: 0.006250
2022-04-28 17:19:58,818 epoch 24 - iter 70/107 - loss 0.05493075 - samples/sec: 139.69 - lr: 0.006250
2022-04-28 17:20:01,160 epoch 24 - iter 80/107 - loss 0.05505028 - samples/sec: 136.73 - lr: 0.006250
2022-04-28 17:20:03,643 epoch 24 - iter 90/107 - loss 0.05451026 - samples/sec: 128.91 - lr: 0.006250
2022-04-28 17:20:06,079 epoch 24 - iter 100/107 - loss 0.05348605 - samples/sec: 131.42 - lr: 0.006250
2022-04-28 17:20:07,648 ----------------------------------------------------------------------------------------------------
2022-04-28 17:20:07,648 EPOCH 24 done: loss 0.0538 - lr 0.006250
2022-04-28 17:20:15,861 Evaluating as a multi-label problem: False
2022-04-28 17:20:15,873 DEV : loss 0.19852857291698456 - f1-score (micro avg)  0.5063
2022-04-28 17:20:15,959 BAD EPOCHS (no improvement): 2
2022-04-28 17:20:15,961 ----------------------------------------------------------------------------------------------------
2022-04-28 17:20:18,487 epoch 25 - iter 10/107 - loss 0.04872212 - samples/sec: 126.75 - lr: 0.006250
2022-04-28 17:20:20,978 epoch 25 - iter 20/107 - loss 0.04236885 - samples/sec: 128.56 - lr: 0.006250
2022-04-28 17:20:23,517 epoch 25 - iter 30/107 - loss 0.05130566 - samples/sec: 126.07 - lr: 0.006250
2022-04-28 17:20:26,033 epoch 25 - iter 40/107 - loss 0.05160834 - samples/sec: 127.24 - lr: 0.006250
2022-04-28 17:20:28,550 epoch 25 - iter 50/107 - loss 0.05395612 - samples/sec: 127.19 - lr: 0.006250
2022-04-28 17:20:31,308 epoch 25 - iter 60/107 - loss 0.05566568 - samples/sec: 116.07 - lr: 0.006250
2022-04-28 17:20:34,262 epoch 25 - iter 70/107 - loss 0.05574209 - samples/sec: 108.33 - lr: 0.006250
2022-04-28 17:20:37,453 epoch 25 - iter 80/107 - loss 0.05627399 - samples/sec: 100.32 - lr: 0.006250
2022-04-28 17:20:40,498 epoch 25 - iter 90/107 - loss 0.05587031 - samples/sec: 105.14 - lr: 0.006250
2022-04-28 17:20:43,463 epoch 25 - iter 100/107 - loss 0.05588939 - samples/sec: 107.94 - lr: 0.006250
2022-04-28 17:20:45,368 ----------------------------------------------------------------------------------------------------
2022-04-28 17:20:45,368 EPOCH 25 done: loss 0.0564 - lr 0.006250
2022-04-28 17:20:55,329 Evaluating as a multi-label problem: False
2022-04-28 17:20:55,340 DEV : loss 0.19670015573501587 - f1-score (micro avg)  0.5114
2022-04-28 17:20:55,427 BAD EPOCHS (no improvement): 3
2022-04-28 17:20:55,429 ----------------------------------------------------------------------------------------------------
2022-04-28 17:20:58,662 epoch 26 - iter 10/107 - loss 0.04579712 - samples/sec: 99.02 - lr: 0.006250
2022-04-28 17:21:01,675 epoch 26 - iter 20/107 - loss 0.05325208 - samples/sec: 106.25 - lr: 0.006250
2022-04-28 17:21:04,820 epoch 26 - iter 30/107 - loss 0.05466914 - samples/sec: 101.79 - lr: 0.006250
2022-04-28 17:21:08,000 epoch 26 - iter 40/107 - loss 0.05339299 - samples/sec: 100.67 - lr: 0.006250
2022-04-28 17:21:10,844 epoch 26 - iter 50/107 - loss 0.05298172 - samples/sec: 112.55 - lr: 0.006250
2022-04-28 17:21:13,826 epoch 26 - iter 60/107 - loss 0.05387066 - samples/sec: 107.36 - lr: 0.006250
2022-04-28 17:21:16,677 epoch 26 - iter 70/107 - loss 0.05406009 - samples/sec: 112.26 - lr: 0.006250
2022-04-28 17:21:19,173 epoch 26 - iter 80/107 - loss 0.05256031 - samples/sec: 128.29 - lr: 0.006250
2022-04-28 17:21:21,187 epoch 26 - iter 90/107 - loss 0.05324032 - samples/sec: 158.91 - lr: 0.006250
2022-04-28 17:21:23,300 epoch 26 - iter 100/107 - loss 0.05349048 - samples/sec: 151.56 - lr: 0.006250
2022-04-28 17:21:24,630 ----------------------------------------------------------------------------------------------------
2022-04-28 17:21:24,631 EPOCH 26 done: loss 0.0544 - lr 0.006250
2022-04-28 17:21:31,637 Evaluating as a multi-label problem: False
2022-04-28 17:21:31,648 DEV : loss 0.19731268286705017 - f1-score (micro avg)  0.5078
2022-04-28 17:21:31,719 Epoch    26: reducing learning rate of group 0 to 3.1250e-03.
2022-04-28 17:21:31,719 BAD EPOCHS (no improvement): 4
2022-04-28 17:21:31,733 ----------------------------------------------------------------------------------------------------
2022-04-28 17:21:34,008 epoch 27 - iter 10/107 - loss 0.05734592 - samples/sec: 140.78 - lr: 0.003125
2022-04-28 17:21:36,205 epoch 27 - iter 20/107 - loss 0.05309724 - samples/sec: 145.66 - lr: 0.003125
2022-04-28 17:21:38,450 epoch 27 - iter 30/107 - loss 0.05480414 - samples/sec: 142.65 - lr: 0.003125
2022-04-28 17:21:40,668 epoch 27 - iter 40/107 - loss 0.05468107 - samples/sec: 144.34 - lr: 0.003125
2022-04-28 17:21:42,989 epoch 27 - iter 50/107 - loss 0.05385633 - samples/sec: 137.95 - lr: 0.003125
2022-04-28 17:21:45,218 epoch 27 - iter 60/107 - loss 0.05325931 - samples/sec: 143.60 - lr: 0.003125
2022-04-28 17:21:47,504 epoch 27 - iter 70/107 - loss 0.05268505 - samples/sec: 140.04 - lr: 0.003125
2022-04-28 17:21:49,781 epoch 27 - iter 80/107 - loss 0.05239462 - samples/sec: 140.59 - lr: 0.003125
2022-04-28 17:21:52,073 epoch 27 - iter 90/107 - loss 0.05320758 - samples/sec: 139.69 - lr: 0.003125
2022-04-28 17:21:54,453 epoch 27 - iter 100/107 - loss 0.05382082 - samples/sec: 134.48 - lr: 0.003125
2022-04-28 17:21:55,883 ----------------------------------------------------------------------------------------------------
2022-04-28 17:21:55,883 EPOCH 27 done: loss 0.0543 - lr 0.003125
2022-04-28 17:22:02,902 Evaluating as a multi-label problem: False
2022-04-28 17:22:02,913 DEV : loss 0.19908465445041656 - f1-score (micro avg)  0.5098
2022-04-28 17:22:02,985 BAD EPOCHS (no improvement): 1
2022-04-28 17:22:02,988 ----------------------------------------------------------------------------------------------------
2022-04-28 17:22:05,294 epoch 28 - iter 10/107 - loss 0.06002129 - samples/sec: 138.84 - lr: 0.003125
2022-04-28 17:22:07,502 epoch 28 - iter 20/107 - loss 0.05417683 - samples/sec: 145.00 - lr: 0.003125
2022-04-28 17:22:09,792 epoch 28 - iter 30/107 - loss 0.05487815 - samples/sec: 139.78 - lr: 0.003125
2022-04-28 17:22:12,035 epoch 28 - iter 40/107 - loss 0.05090438 - samples/sec: 142.73 - lr: 0.003125
2022-04-28 17:22:14,337 epoch 28 - iter 50/107 - loss 0.05108775 - samples/sec: 139.07 - lr: 0.003125
2022-04-28 17:22:17,015 epoch 28 - iter 60/107 - loss 0.05273431 - samples/sec: 119.54 - lr: 0.003125
2022-04-28 17:22:19,951 epoch 28 - iter 70/107 - loss 0.05342956 - samples/sec: 109.05 - lr: 0.003125
2022-04-28 17:22:22,848 epoch 28 - iter 80/107 - loss 0.05267545 - samples/sec: 110.49 - lr: 0.003125
2022-04-28 17:22:25,672 epoch 28 - iter 90/107 - loss 0.05283635 - samples/sec: 113.36 - lr: 0.003125
2022-04-28 17:22:28,472 epoch 28 - iter 100/107 - loss 0.05305911 - samples/sec: 114.33 - lr: 0.003125
2022-04-28 17:22:30,244 ----------------------------------------------------------------------------------------------------
2022-04-28 17:22:30,244 EPOCH 28 done: loss 0.0532 - lr 0.003125
2022-04-28 17:22:38,778 Evaluating as a multi-label problem: False
2022-04-28 17:22:38,789 DEV : loss 0.1990794688463211 - f1-score (micro avg)  0.5078
2022-04-28 17:22:38,861 BAD EPOCHS (no improvement): 2
2022-04-28 17:22:38,864 ----------------------------------------------------------------------------------------------------
2022-04-28 17:22:41,709 epoch 29 - iter 10/107 - loss 0.05911350 - samples/sec: 112.51 - lr: 0.003125
2022-04-28 17:22:44,447 epoch 29 - iter 20/107 - loss 0.05523194 - samples/sec: 116.92 - lr: 0.003125
2022-04-28 17:22:47,230 epoch 29 - iter 30/107 - loss 0.05221623 - samples/sec: 115.00 - lr: 0.003125
2022-04-28 17:22:49,945 epoch 29 - iter 40/107 - loss 0.05201869 - samples/sec: 117.93 - lr: 0.003125
2022-04-28 17:22:52,865 epoch 29 - iter 50/107 - loss 0.05207408 - samples/sec: 109.63 - lr: 0.003125
2022-04-28 17:22:55,654 epoch 29 - iter 60/107 - loss 0.05409778 - samples/sec: 114.77 - lr: 0.003125
2022-04-28 17:22:58,227 epoch 29 - iter 70/107 - loss 0.05399412 - samples/sec: 124.41 - lr: 0.003125
2022-04-28 17:23:02,777 epoch 29 - iter 80/107 - loss 0.05405532 - samples/sec: 70.33 - lr: 0.003125
2022-04-28 17:23:05,249 epoch 29 - iter 90/107 - loss 0.05463990 - samples/sec: 129.51 - lr: 0.003125
2022-04-28 17:23:07,274 epoch 29 - iter 100/107 - loss 0.05442595 - samples/sec: 158.12 - lr: 0.003125
2022-04-28 17:23:08,596 ----------------------------------------------------------------------------------------------------
2022-04-28 17:23:08,596 EPOCH 29 done: loss 0.0544 - lr 0.003125
2022-04-28 17:23:15,527 Evaluating as a multi-label problem: False
2022-04-28 17:23:15,538 DEV : loss 0.19829392433166504 - f1-score (micro avg)  0.5121
2022-04-28 17:23:15,609 BAD EPOCHS (no improvement): 3
2022-04-28 17:23:15,613 ----------------------------------------------------------------------------------------------------
2022-04-28 17:23:17,903 epoch 30 - iter 10/107 - loss 0.05281597 - samples/sec: 139.79 - lr: 0.003125
2022-04-28 17:23:20,163 epoch 30 - iter 20/107 - loss 0.05604057 - samples/sec: 141.63 - lr: 0.003125
2022-04-28 17:23:22,446 epoch 30 - iter 30/107 - loss 0.05407707 - samples/sec: 140.27 - lr: 0.003125
2022-04-28 17:23:24,734 epoch 30 - iter 40/107 - loss 0.05444703 - samples/sec: 139.90 - lr: 0.003125
2022-04-28 17:23:27,051 epoch 30 - iter 50/107 - loss 0.05385025 - samples/sec: 138.14 - lr: 0.003125
2022-04-28 17:23:29,366 epoch 30 - iter 60/107 - loss 0.05346728 - samples/sec: 138.31 - lr: 0.003125
2022-04-28 17:23:31,681 epoch 30 - iter 70/107 - loss 0.05361019 - samples/sec: 138.31 - lr: 0.003125
2022-04-28 17:23:34,038 epoch 30 - iter 80/107 - loss 0.05454919 - samples/sec: 135.81 - lr: 0.003125
2022-04-28 17:23:36,363 epoch 30 - iter 90/107 - loss 0.05318733 - samples/sec: 137.66 - lr: 0.003125
2022-04-28 17:23:38,555 epoch 30 - iter 100/107 - loss 0.05291338 - samples/sec: 146.08 - lr: 0.003125
2022-04-28 17:23:39,969 ----------------------------------------------------------------------------------------------------
2022-04-28 17:23:39,969 EPOCH 30 done: loss 0.0532 - lr 0.003125
2022-04-28 17:23:46,944 Evaluating as a multi-label problem: False
2022-04-28 17:23:46,954 DEV : loss 0.20007739961147308 - f1-score (micro avg)  0.5125
2022-04-28 17:23:47,027 Epoch    30: reducing learning rate of group 0 to 1.5625e-03.
2022-04-28 17:23:47,027 BAD EPOCHS (no improvement): 4
2022-04-28 17:23:47,030 ----------------------------------------------------------------------------------------------------
2022-04-28 17:23:49,316 epoch 31 - iter 10/107 - loss 0.05661647 - samples/sec: 140.05 - lr: 0.001563
2022-04-28 17:23:51,563 epoch 31 - iter 20/107 - loss 0.05105527 - samples/sec: 142.45 - lr: 0.001563
2022-04-28 17:23:53,918 epoch 31 - iter 30/107 - loss 0.05698546 - samples/sec: 135.94 - lr: 0.001563
2022-04-28 17:23:56,112 epoch 31 - iter 40/107 - loss 0.05656442 - samples/sec: 145.93 - lr: 0.001563
2022-04-28 17:23:58,366 epoch 31 - iter 50/107 - loss 0.05606901 - samples/sec: 142.06 - lr: 0.001563
2022-04-28 17:24:01,040 epoch 31 - iter 60/107 - loss 0.05481782 - samples/sec: 119.73 - lr: 0.001563
2022-04-28 17:24:03,883 epoch 31 - iter 70/107 - loss 0.05603453 - samples/sec: 112.59 - lr: 0.001563
2022-04-28 17:24:06,534 epoch 31 - iter 80/107 - loss 0.05515183 - samples/sec: 120.74 - lr: 0.001563
2022-04-28 17:24:09,206 epoch 31 - iter 90/107 - loss 0.05377962 - samples/sec: 119.81 - lr: 0.001563
2022-04-28 17:24:11,963 epoch 31 - iter 100/107 - loss 0.05406441 - samples/sec: 116.11 - lr: 0.001563
2022-04-28 17:24:13,529 ----------------------------------------------------------------------------------------------------
2022-04-28 17:24:13,529 EPOCH 31 done: loss 0.0546 - lr 0.001563
2022-04-28 17:24:22,044 Evaluating as a multi-label problem: False
2022-04-28 17:24:22,055 DEV : loss 0.19802184402942657 - f1-score (micro avg)  0.5109
2022-04-28 17:24:22,127 BAD EPOCHS (no improvement): 1
2022-04-28 17:24:22,133 ----------------------------------------------------------------------------------------------------
2022-04-28 17:24:24,946 epoch 32 - iter 10/107 - loss 0.05009577 - samples/sec: 113.79 - lr: 0.001563
2022-04-28 17:24:27,875 epoch 32 - iter 20/107 - loss 0.05725615 - samples/sec: 109.28 - lr: 0.001563
2022-04-28 17:24:30,831 epoch 32 - iter 30/107 - loss 0.05570610 - samples/sec: 108.29 - lr: 0.001563
2022-04-28 17:24:33,565 epoch 32 - iter 40/107 - loss 0.05424328 - samples/sec: 117.09 - lr: 0.001563
2022-04-28 17:24:36,176 epoch 32 - iter 50/107 - loss 0.05112949 - samples/sec: 122.62 - lr: 0.001563
2022-04-28 17:24:39,098 epoch 32 - iter 60/107 - loss 0.04974567 - samples/sec: 109.52 - lr: 0.001563
2022-04-28 17:24:41,792 epoch 32 - iter 70/107 - loss 0.05038061 - samples/sec: 118.85 - lr: 0.001563
2022-04-28 17:24:44,363 epoch 32 - iter 80/107 - loss 0.05122671 - samples/sec: 124.54 - lr: 0.001563
2022-04-28 17:24:46,993 epoch 32 - iter 90/107 - loss 0.05246493 - samples/sec: 121.71 - lr: 0.001563
2022-04-28 17:24:49,607 epoch 32 - iter 100/107 - loss 0.05250055 - samples/sec: 122.47 - lr: 0.001563
2022-04-28 17:24:50,954 ----------------------------------------------------------------------------------------------------
2022-04-28 17:24:50,954 EPOCH 32 done: loss 0.0530 - lr 0.001563
2022-04-28 17:24:57,756 Evaluating as a multi-label problem: False
2022-04-28 17:24:57,767 DEV : loss 0.19868381321430206 - f1-score (micro avg)  0.5094
2022-04-28 17:24:57,838 BAD EPOCHS (no improvement): 2
2022-04-28 17:24:57,841 ----------------------------------------------------------------------------------------------------
2022-04-28 17:25:00,111 epoch 33 - iter 10/107 - loss 0.04951047 - samples/sec: 141.01 - lr: 0.001563
2022-04-28 17:25:02,410 epoch 33 - iter 20/107 - loss 0.05263554 - samples/sec: 139.23 - lr: 0.001563
2022-04-28 17:25:04,758 epoch 33 - iter 30/107 - loss 0.04987572 - samples/sec: 136.38 - lr: 0.001563
2022-04-28 17:25:07,039 epoch 33 - iter 40/107 - loss 0.05097206 - samples/sec: 140.36 - lr: 0.001563
2022-04-28 17:25:09,283 epoch 33 - iter 50/107 - loss 0.04884966 - samples/sec: 142.61 - lr: 0.001563
2022-04-28 17:25:11,596 epoch 33 - iter 60/107 - loss 0.04950120 - samples/sec: 138.42 - lr: 0.001563
2022-04-28 17:25:13,813 epoch 33 - iter 70/107 - loss 0.05012840 - samples/sec: 144.42 - lr: 0.001563
2022-04-28 17:25:15,941 epoch 33 - iter 80/107 - loss 0.05094794 - samples/sec: 150.47 - lr: 0.001563
2022-04-28 17:25:18,093 epoch 33 - iter 90/107 - loss 0.05117077 - samples/sec: 148.76 - lr: 0.001563
2022-04-28 17:25:20,247 epoch 33 - iter 100/107 - loss 0.05079055 - samples/sec: 148.61 - lr: 0.001563
2022-04-28 17:25:21,596 ----------------------------------------------------------------------------------------------------
2022-04-28 17:25:21,596 EPOCH 33 done: loss 0.0511 - lr 0.001563
2022-04-28 17:25:28,303 Evaluating as a multi-label problem: False
2022-04-28 17:25:28,314 DEV : loss 0.19814935326576233 - f1-score (micro avg)  0.5082
2022-04-28 17:25:28,386 BAD EPOCHS (no improvement): 3
2022-04-28 17:25:28,389 ----------------------------------------------------------------------------------------------------
2022-04-28 17:25:30,625 epoch 34 - iter 10/107 - loss 0.05234760 - samples/sec: 143.19 - lr: 0.001563
2022-04-28 17:25:32,936 epoch 34 - iter 20/107 - loss 0.05041404 - samples/sec: 138.52 - lr: 0.001563
2022-04-28 17:25:35,190 epoch 34 - iter 30/107 - loss 0.05350226 - samples/sec: 142.01 - lr: 0.001563
2022-04-28 17:25:37,491 epoch 34 - iter 40/107 - loss 0.05298090 - samples/sec: 139.15 - lr: 0.001563
2022-04-28 17:25:39,767 epoch 34 - iter 50/107 - loss 0.05159430 - samples/sec: 140.64 - lr: 0.001563
2022-04-28 17:25:41,971 epoch 34 - iter 60/107 - loss 0.04935979 - samples/sec: 145.27 - lr: 0.001563
2022-04-28 17:25:44,252 epoch 34 - iter 70/107 - loss 0.05007253 - samples/sec: 140.35 - lr: 0.001563
2022-04-28 17:25:46,780 epoch 34 - iter 80/107 - loss 0.05155815 - samples/sec: 126.63 - lr: 0.001563
2022-04-28 17:25:49,769 epoch 34 - iter 90/107 - loss 0.05271336 - samples/sec: 107.08 - lr: 0.001563
2022-04-28 17:25:52,734 epoch 34 - iter 100/107 - loss 0.05268476 - samples/sec: 107.96 - lr: 0.001563
2022-04-28 17:25:54,376 ----------------------------------------------------------------------------------------------------
2022-04-28 17:25:54,376 EPOCH 34 done: loss 0.0521 - lr 0.001563
2022-04-28 17:26:03,069 Evaluating as a multi-label problem: False
2022-04-28 17:26:03,080 DEV : loss 0.19748473167419434 - f1-score (micro avg)  0.5113
2022-04-28 17:26:03,150 Epoch    34: reducing learning rate of group 0 to 7.8125e-04.
2022-04-28 17:26:03,150 BAD EPOCHS (no improvement): 4
2022-04-28 17:26:03,220 ----------------------------------------------------------------------------------------------------
2022-04-28 17:26:06,044 epoch 35 - iter 10/107 - loss 0.04249325 - samples/sec: 113.36 - lr: 0.000781
2022-04-28 17:26:08,860 epoch 35 - iter 20/107 - loss 0.05218028 - samples/sec: 113.67 - lr: 0.000781
2022-04-28 17:26:11,584 epoch 35 - iter 30/107 - loss 0.05080334 - samples/sec: 117.54 - lr: 0.000781
2022-04-28 17:26:14,449 epoch 35 - iter 40/107 - loss 0.05043417 - samples/sec: 111.73 - lr: 0.000781
2022-04-28 17:26:17,287 epoch 35 - iter 50/107 - loss 0.05172660 - samples/sec: 112.82 - lr: 0.000781
2022-04-28 17:26:19,970 epoch 35 - iter 60/107 - loss 0.05213772 - samples/sec: 119.29 - lr: 0.000781
2022-04-28 17:26:22,780 epoch 35 - iter 70/107 - loss 0.05097421 - samples/sec: 113.91 - lr: 0.000781
2022-04-28 17:26:25,535 epoch 35 - iter 80/107 - loss 0.05121665 - samples/sec: 116.20 - lr: 0.000781
2022-04-28 17:26:28,099 epoch 35 - iter 90/107 - loss 0.05234309 - samples/sec: 124.88 - lr: 0.000781
2022-04-28 17:26:30,493 epoch 35 - iter 100/107 - loss 0.05214358 - samples/sec: 133.72 - lr: 0.000781
2022-04-28 17:26:32,069 ----------------------------------------------------------------------------------------------------
2022-04-28 17:26:32,069 EPOCH 35 done: loss 0.0523 - lr 0.000781
2022-04-28 17:26:40,472 Evaluating as a multi-label problem: False
2022-04-28 17:26:40,483 DEV : loss 0.19913551211357117 - f1-score (micro avg)  0.5102
2022-04-28 17:26:40,557 BAD EPOCHS (no improvement): 1
2022-04-28 17:26:40,560 ----------------------------------------------------------------------------------------------------
2022-04-28 17:26:43,407 epoch 36 - iter 10/107 - loss 0.05995891 - samples/sec: 112.42 - lr: 0.000781
2022-04-28 17:26:46,190 epoch 36 - iter 20/107 - loss 0.06362535 - samples/sec: 115.04 - lr: 0.000781
2022-04-28 17:26:49,028 epoch 36 - iter 30/107 - loss 0.06299477 - samples/sec: 112.80 - lr: 0.000781
2022-04-28 17:26:51,839 epoch 36 - iter 40/107 - loss 0.06020724 - samples/sec: 113.86 - lr: 0.000781
2022-04-28 17:26:54,634 epoch 36 - iter 50/107 - loss 0.05772908 - samples/sec: 114.54 - lr: 0.000781
2022-04-28 17:26:57,642 epoch 36 - iter 60/107 - loss 0.05613324 - samples/sec: 106.42 - lr: 0.000781
2022-04-28 17:27:00,364 epoch 36 - iter 70/107 - loss 0.05527703 - samples/sec: 117.60 - lr: 0.000781
2022-04-28 17:27:03,213 epoch 36 - iter 80/107 - loss 0.05466518 - samples/sec: 112.40 - lr: 0.000781
2022-04-28 17:27:06,053 epoch 36 - iter 90/107 - loss 0.05456650 - samples/sec: 112.69 - lr: 0.000781
2022-04-28 17:27:08,821 epoch 36 - iter 100/107 - loss 0.05429977 - samples/sec: 115.65 - lr: 0.000781
2022-04-28 17:27:10,520 ----------------------------------------------------------------------------------------------------
2022-04-28 17:27:10,521 EPOCH 36 done: loss 0.0541 - lr 0.000781
2022-04-28 17:27:18,567 Evaluating as a multi-label problem: False
2022-04-28 17:27:18,578 DEV : loss 0.1990443468093872 - f1-score (micro avg)  0.5098
2022-04-28 17:27:18,649 BAD EPOCHS (no improvement): 2
2022-04-28 17:27:18,652 ----------------------------------------------------------------------------------------------------
2022-04-28 17:27:21,253 epoch 37 - iter 10/107 - loss 0.05782126 - samples/sec: 123.10 - lr: 0.000781
2022-04-28 17:27:23,769 epoch 37 - iter 20/107 - loss 0.06168692 - samples/sec: 127.24 - lr: 0.000781
2022-04-28 17:27:26,472 epoch 37 - iter 30/107 - loss 0.05602099 - samples/sec: 118.40 - lr: 0.000781
2022-04-28 17:27:29,267 epoch 37 - iter 40/107 - loss 0.05497557 - samples/sec: 114.54 - lr: 0.000781
2022-04-28 17:27:32,182 epoch 37 - iter 50/107 - loss 0.05305546 - samples/sec: 109.82 - lr: 0.000781
2022-04-28 17:27:37,116 epoch 37 - iter 60/107 - loss 0.05307095 - samples/sec: 64.87 - lr: 0.000781
2022-04-28 17:27:39,881 epoch 37 - iter 70/107 - loss 0.05147171 - samples/sec: 115.76 - lr: 0.000781
2022-04-28 17:27:42,605 epoch 37 - iter 80/107 - loss 0.05150768 - samples/sec: 117.52 - lr: 0.000781
2022-04-28 17:27:45,329 epoch 37 - iter 90/107 - loss 0.05155891 - samples/sec: 117.50 - lr: 0.000781
2022-04-28 17:27:48,110 epoch 37 - iter 100/107 - loss 0.05164065 - samples/sec: 115.12 - lr: 0.000781
2022-04-28 17:27:49,715 ----------------------------------------------------------------------------------------------------
2022-04-28 17:27:49,715 EPOCH 37 done: loss 0.0516 - lr 0.000781
2022-04-28 17:27:58,155 Evaluating as a multi-label problem: False
2022-04-28 17:27:58,167 DEV : loss 0.19825144112110138 - f1-score (micro avg)  0.5098
2022-04-28 17:27:58,240 BAD EPOCHS (no improvement): 3
2022-04-28 17:27:58,242 ----------------------------------------------------------------------------------------------------
2022-04-28 17:28:00,895 epoch 38 - iter 10/107 - loss 0.05209345 - samples/sec: 120.66 - lr: 0.000781
2022-04-28 17:28:03,721 epoch 38 - iter 20/107 - loss 0.05227102 - samples/sec: 113.30 - lr: 0.000781
2022-04-28 17:28:06,366 epoch 38 - iter 30/107 - loss 0.05219184 - samples/sec: 121.00 - lr: 0.000781
2022-04-28 17:28:08,951 epoch 38 - iter 40/107 - loss 0.05056699 - samples/sec: 123.85 - lr: 0.000781
2022-04-28 17:28:11,798 epoch 38 - iter 50/107 - loss 0.05108294 - samples/sec: 112.43 - lr: 0.000781
2022-04-28 17:28:14,418 epoch 38 - iter 60/107 - loss 0.05080801 - samples/sec: 122.21 - lr: 0.000781
2022-04-28 17:28:16,507 epoch 38 - iter 70/107 - loss 0.05177595 - samples/sec: 153.19 - lr: 0.000781
2022-04-28 17:28:18,593 epoch 38 - iter 80/107 - loss 0.05169298 - samples/sec: 153.53 - lr: 0.000781
2022-04-28 17:28:20,855 epoch 38 - iter 90/107 - loss 0.05196477 - samples/sec: 141.48 - lr: 0.000781
2022-04-28 17:28:23,082 epoch 38 - iter 100/107 - loss 0.05129931 - samples/sec: 143.74 - lr: 0.000781
2022-04-28 17:28:24,489 ----------------------------------------------------------------------------------------------------
2022-04-28 17:28:24,489 EPOCH 38 done: loss 0.0515 - lr 0.000781
2022-04-28 17:28:31,509 Evaluating as a multi-label problem: False
2022-04-28 17:28:31,519 DEV : loss 0.19881555438041687 - f1-score (micro avg)  0.5109
2022-04-28 17:28:31,593 Epoch    38: reducing learning rate of group 0 to 3.9063e-04.
2022-04-28 17:28:31,593 BAD EPOCHS (no improvement): 4
2022-04-28 17:28:31,595 ----------------------------------------------------------------------------------------------------
2022-04-28 17:28:33,908 epoch 39 - iter 10/107 - loss 0.04359537 - samples/sec: 138.48 - lr: 0.000391
2022-04-28 17:28:36,130 epoch 39 - iter 20/107 - loss 0.04497215 - samples/sec: 144.04 - lr: 0.000391
2022-04-28 17:28:38,403 epoch 39 - iter 30/107 - loss 0.04640801 - samples/sec: 140.89 - lr: 0.000391
2022-04-28 17:28:40,695 epoch 39 - iter 40/107 - loss 0.04885896 - samples/sec: 139.68 - lr: 0.000391
2022-04-28 17:28:42,938 epoch 39 - iter 50/107 - loss 0.04866109 - samples/sec: 142.73 - lr: 0.000391
2022-04-28 17:28:45,224 epoch 39 - iter 60/107 - loss 0.05044953 - samples/sec: 140.03 - lr: 0.000391
2022-04-28 17:28:47,540 epoch 39 - iter 70/107 - loss 0.05073437 - samples/sec: 138.20 - lr: 0.000391
2022-04-28 17:28:49,810 epoch 39 - iter 80/107 - loss 0.05080703 - samples/sec: 141.06 - lr: 0.000391
2022-04-28 17:28:52,073 epoch 39 - iter 90/107 - loss 0.05044768 - samples/sec: 141.48 - lr: 0.000391
2022-04-28 17:28:54,319 epoch 39 - iter 100/107 - loss 0.05163192 - samples/sec: 142.52 - lr: 0.000391
2022-04-28 17:28:55,695 ----------------------------------------------------------------------------------------------------
2022-04-28 17:28:55,695 EPOCH 39 done: loss 0.0519 - lr 0.000391
2022-04-28 17:29:02,701 Evaluating as a multi-label problem: False
2022-04-28 17:29:02,712 DEV : loss 0.19820444285869598 - f1-score (micro avg)  0.5105
2022-04-28 17:29:02,785 BAD EPOCHS (no improvement): 1
2022-04-28 17:29:02,787 ----------------------------------------------------------------------------------------------------
2022-04-28 17:29:05,112 epoch 40 - iter 10/107 - loss 0.04424805 - samples/sec: 137.70 - lr: 0.000391
2022-04-28 17:29:07,369 epoch 40 - iter 20/107 - loss 0.04121852 - samples/sec: 141.80 - lr: 0.000391
2022-04-28 17:29:09,783 epoch 40 - iter 30/107 - loss 0.04535035 - samples/sec: 132.61 - lr: 0.000391
2022-04-28 17:29:12,641 epoch 40 - iter 40/107 - loss 0.04689487 - samples/sec: 112.04 - lr: 0.000391
2022-04-28 17:29:15,399 epoch 40 - iter 50/107 - loss 0.04792071 - samples/sec: 116.05 - lr: 0.000391
2022-04-28 17:29:18,134 epoch 40 - iter 60/107 - loss 0.04978447 - samples/sec: 117.05 - lr: 0.000391
2022-04-28 17:29:20,864 epoch 40 - iter 70/107 - loss 0.05063588 - samples/sec: 117.29 - lr: 0.000391
2022-04-28 17:29:23,468 epoch 40 - iter 80/107 - loss 0.05100490 - samples/sec: 122.93 - lr: 0.000391
2022-04-28 17:29:26,225 epoch 40 - iter 90/107 - loss 0.05169198 - samples/sec: 116.09 - lr: 0.000391
2022-04-28 17:29:29,019 epoch 40 - iter 100/107 - loss 0.05105479 - samples/sec: 114.56 - lr: 0.000391
2022-04-28 17:29:30,742 ----------------------------------------------------------------------------------------------------
2022-04-28 17:29:30,742 EPOCH 40 done: loss 0.0515 - lr 0.000391
2022-04-28 17:29:39,266 Evaluating as a multi-label problem: False
2022-04-28 17:29:39,277 DEV : loss 0.19842253625392914 - f1-score (micro avg)  0.5105
2022-04-28 17:29:39,350 BAD EPOCHS (no improvement): 2
2022-04-28 17:29:39,353 ----------------------------------------------------------------------------------------------------
2022-04-28 17:29:42,160 epoch 41 - iter 10/107 - loss 0.05495530 - samples/sec: 114.03 - lr: 0.000391
2022-04-28 17:29:44,963 epoch 41 - iter 20/107 - loss 0.05275394 - samples/sec: 114.21 - lr: 0.000391
2022-04-28 17:29:47,760 epoch 41 - iter 30/107 - loss 0.04972364 - samples/sec: 114.45 - lr: 0.000391
2022-04-28 17:29:50,244 epoch 41 - iter 40/107 - loss 0.05144570 - samples/sec: 128.85 - lr: 0.000391
2022-04-28 17:29:52,842 epoch 41 - iter 50/107 - loss 0.04995445 - samples/sec: 123.25 - lr: 0.000391
2022-04-28 17:29:55,415 epoch 41 - iter 60/107 - loss 0.04991652 - samples/sec: 124.40 - lr: 0.000391
2022-04-28 17:29:58,110 epoch 41 - iter 70/107 - loss 0.04953951 - samples/sec: 118.79 - lr: 0.000391
2022-04-28 17:30:00,836 epoch 41 - iter 80/107 - loss 0.05088617 - samples/sec: 117.39 - lr: 0.000391
2022-04-28 17:30:03,789 epoch 41 - iter 90/107 - loss 0.05029234 - samples/sec: 108.41 - lr: 0.000391
2022-04-28 17:30:06,364 epoch 41 - iter 100/107 - loss 0.05202459 - samples/sec: 124.36 - lr: 0.000391
2022-04-28 17:30:08,075 ----------------------------------------------------------------------------------------------------
2022-04-28 17:30:08,075 EPOCH 41 done: loss 0.0519 - lr 0.000391
2022-04-28 17:30:16,649 Evaluating as a multi-label problem: False
2022-04-28 17:30:16,661 DEV : loss 0.1987040936946869 - f1-score (micro avg)  0.5105
2022-04-28 17:30:16,732 BAD EPOCHS (no improvement): 3
2022-04-28 17:30:16,734 ----------------------------------------------------------------------------------------------------
2022-04-28 17:30:19,623 epoch 42 - iter 10/107 - loss 0.04622784 - samples/sec: 110.80 - lr: 0.000391
2022-04-28 17:30:22,182 epoch 42 - iter 20/107 - loss 0.04653365 - samples/sec: 125.09 - lr: 0.000391
2022-04-28 17:30:24,977 epoch 42 - iter 30/107 - loss 0.05073713 - samples/sec: 114.54 - lr: 0.000391
2022-04-28 17:30:27,721 epoch 42 - iter 40/107 - loss 0.05306156 - samples/sec: 116.66 - lr: 0.000391
2022-04-28 17:30:30,430 epoch 42 - iter 50/107 - loss 0.05112024 - samples/sec: 118.17 - lr: 0.000391
2022-04-28 17:30:33,199 epoch 42 - iter 60/107 - loss 0.04938165 - samples/sec: 115.62 - lr: 0.000391
2022-04-28 17:30:35,942 epoch 42 - iter 70/107 - loss 0.05022210 - samples/sec: 116.69 - lr: 0.000391
2022-04-28 17:30:38,658 epoch 42 - iter 80/107 - loss 0.05129038 - samples/sec: 117.88 - lr: 0.000391
2022-04-28 17:30:41,274 epoch 42 - iter 90/107 - loss 0.05136502 - samples/sec: 122.37 - lr: 0.000391
2022-04-28 17:30:43,864 epoch 42 - iter 100/107 - loss 0.05275972 - samples/sec: 123.59 - lr: 0.000391
2022-04-28 17:30:45,507 ----------------------------------------------------------------------------------------------------
2022-04-28 17:30:45,507 EPOCH 42 done: loss 0.0524 - lr 0.000391
2022-04-28 17:30:53,779 Evaluating as a multi-label problem: False
2022-04-28 17:30:53,790 DEV : loss 0.1991882473230362 - f1-score (micro avg)  0.5105
2022-04-28 17:30:53,863 Epoch    42: reducing learning rate of group 0 to 1.9531e-04.
2022-04-28 17:30:53,863 BAD EPOCHS (no improvement): 4
2022-04-28 17:30:53,865 ----------------------------------------------------------------------------------------------------
2022-04-28 17:30:56,826 epoch 43 - iter 10/107 - loss 0.04404666 - samples/sec: 108.12 - lr: 0.000195
2022-04-28 17:30:59,665 epoch 43 - iter 20/107 - loss 0.05117751 - samples/sec: 112.77 - lr: 0.000195
2022-04-28 17:31:02,531 epoch 43 - iter 30/107 - loss 0.04918101 - samples/sec: 111.69 - lr: 0.000195
2022-04-28 17:31:05,320 epoch 43 - iter 40/107 - loss 0.04854881 - samples/sec: 114.78 - lr: 0.000195
2022-04-28 17:31:08,256 epoch 43 - iter 50/107 - loss 0.04885444 - samples/sec: 109.04 - lr: 0.000195
2022-04-28 17:31:11,092 epoch 43 - iter 60/107 - loss 0.04901610 - samples/sec: 112.86 - lr: 0.000195
2022-04-28 17:31:13,634 epoch 43 - iter 70/107 - loss 0.05003138 - samples/sec: 125.91 - lr: 0.000195
2022-04-28 17:31:16,490 epoch 43 - iter 80/107 - loss 0.05013873 - samples/sec: 112.10 - lr: 0.000195
2022-04-28 17:31:19,357 epoch 43 - iter 90/107 - loss 0.04950322 - samples/sec: 111.65 - lr: 0.000195
2022-04-28 17:31:22,075 epoch 43 - iter 100/107 - loss 0.05027742 - samples/sec: 117.75 - lr: 0.000195
2022-04-28 17:31:23,735 ----------------------------------------------------------------------------------------------------
2022-04-28 17:31:23,735 EPOCH 43 done: loss 0.0507 - lr 0.000195
2022-04-28 17:31:31,837 Evaluating as a multi-label problem: False
2022-04-28 17:31:31,848 DEV : loss 0.19962221384048462 - f1-score (micro avg)  0.5078
2022-04-28 17:31:31,919 BAD EPOCHS (no improvement): 1
2022-04-28 17:31:31,922 ----------------------------------------------------------------------------------------------------
2022-04-28 17:31:34,685 epoch 44 - iter 10/107 - loss 0.05033117 - samples/sec: 115.87 - lr: 0.000195
2022-04-28 17:31:37,318 epoch 44 - iter 20/107 - loss 0.05194234 - samples/sec: 121.59 - lr: 0.000195
2022-04-28 17:31:40,091 epoch 44 - iter 30/107 - loss 0.04849359 - samples/sec: 115.41 - lr: 0.000195
2022-04-28 17:31:42,926 epoch 44 - iter 40/107 - loss 0.04915652 - samples/sec: 112.96 - lr: 0.000195
2022-04-28 17:31:45,699 epoch 44 - iter 50/107 - loss 0.04789193 - samples/sec: 115.42 - lr: 0.000195
2022-04-28 17:31:48,534 epoch 44 - iter 60/107 - loss 0.04895249 - samples/sec: 112.91 - lr: 0.000195
2022-04-28 17:31:51,378 epoch 44 - iter 70/107 - loss 0.04921978 - samples/sec: 112.57 - lr: 0.000195
2022-04-28 17:31:54,182 epoch 44 - iter 80/107 - loss 0.04978072 - samples/sec: 114.16 - lr: 0.000195
2022-04-28 17:31:57,137 epoch 44 - iter 90/107 - loss 0.05128931 - samples/sec: 108.34 - lr: 0.000195
2022-04-28 17:31:59,966 epoch 44 - iter 100/107 - loss 0.05134422 - samples/sec: 113.15 - lr: 0.000195
2022-04-28 17:32:01,785 ----------------------------------------------------------------------------------------------------
2022-04-28 17:32:01,785 EPOCH 44 done: loss 0.0521 - lr 0.000195
2022-04-28 17:32:10,384 Evaluating as a multi-label problem: False
2022-04-28 17:32:10,395 DEV : loss 0.1999727189540863 - f1-score (micro avg)  0.5098
2022-04-28 17:32:10,468 BAD EPOCHS (no improvement): 2
2022-04-28 17:32:10,471 ----------------------------------------------------------------------------------------------------
2022-04-28 17:32:13,396 epoch 45 - iter 10/107 - loss 0.04973184 - samples/sec: 109.45 - lr: 0.000195
2022-04-28 17:32:16,020 epoch 45 - iter 20/107 - loss 0.05459165 - samples/sec: 121.98 - lr: 0.000195
2022-04-28 17:32:19,048 epoch 45 - iter 30/107 - loss 0.05302142 - samples/sec: 105.72 - lr: 0.000195
2022-04-28 17:32:23,509 epoch 45 - iter 40/107 - loss 0.05254018 - samples/sec: 71.75 - lr: 0.000195
2022-04-28 17:32:26,055 epoch 45 - iter 50/107 - loss 0.05118028 - samples/sec: 125.71 - lr: 0.000195
2022-04-28 17:32:28,701 epoch 45 - iter 60/107 - loss 0.04971916 - samples/sec: 121.00 - lr: 0.000195
2022-04-28 17:32:31,639 epoch 45 - iter 70/107 - loss 0.05083124 - samples/sec: 108.97 - lr: 0.000195
2022-04-28 17:32:34,431 epoch 45 - iter 80/107 - loss 0.05140606 - samples/sec: 114.66 - lr: 0.000195
2022-04-28 17:32:37,210 epoch 45 - iter 90/107 - loss 0.05180013 - samples/sec: 115.18 - lr: 0.000195
2022-04-28 17:32:40,073 epoch 45 - iter 100/107 - loss 0.05181756 - samples/sec: 111.82 - lr: 0.000195
2022-04-28 17:32:41,832 ----------------------------------------------------------------------------------------------------
2022-04-28 17:32:41,832 EPOCH 45 done: loss 0.0516 - lr 0.000195
2022-04-28 17:32:50,352 Evaluating as a multi-label problem: False
2022-04-28 17:32:50,363 DEV : loss 0.1995476633310318 - f1-score (micro avg)  0.5094
2022-04-28 17:32:50,433 BAD EPOCHS (no improvement): 3
2022-04-28 17:32:50,436 ----------------------------------------------------------------------------------------------------
2022-04-28 17:32:53,280 epoch 46 - iter 10/107 - loss 0.04556456 - samples/sec: 112.58 - lr: 0.000195
2022-04-28 17:32:56,176 epoch 46 - iter 20/107 - loss 0.04616133 - samples/sec: 110.51 - lr: 0.000195
2022-04-28 17:32:59,020 epoch 46 - iter 30/107 - loss 0.04619711 - samples/sec: 112.56 - lr: 0.000195
2022-04-28 17:33:01,800 epoch 46 - iter 40/107 - loss 0.04823000 - samples/sec: 115.14 - lr: 0.000195
2022-04-28 17:33:04,673 epoch 46 - iter 50/107 - loss 0.04604157 - samples/sec: 111.44 - lr: 0.000195
2022-04-28 17:33:07,312 epoch 46 - iter 60/107 - loss 0.04761799 - samples/sec: 121.30 - lr: 0.000195
2022-04-28 17:33:09,934 epoch 46 - iter 70/107 - loss 0.04872874 - samples/sec: 122.10 - lr: 0.000195
2022-04-28 17:33:12,582 epoch 46 - iter 80/107 - loss 0.04780862 - samples/sec: 120.88 - lr: 0.000195
2022-04-28 17:33:15,192 epoch 46 - iter 90/107 - loss 0.04926018 - samples/sec: 122.62 - lr: 0.000195
2022-04-28 17:33:17,900 epoch 46 - iter 100/107 - loss 0.05043598 - samples/sec: 118.25 - lr: 0.000195
2022-04-28 17:33:19,694 ----------------------------------------------------------------------------------------------------
2022-04-28 17:33:19,694 EPOCH 46 done: loss 0.0513 - lr 0.000195
2022-04-28 17:33:28,295 Evaluating as a multi-label problem: False
2022-04-28 17:33:28,307 DEV : loss 0.19934406876564026 - f1-score (micro avg)  0.5094
2022-04-28 17:33:28,379 Epoch    46: reducing learning rate of group 0 to 9.7656e-05.
2022-04-28 17:33:28,379 BAD EPOCHS (no improvement): 4
2022-04-28 17:33:28,381 ----------------------------------------------------------------------------------------------------
2022-04-28 17:33:28,382 ----------------------------------------------------------------------------------------------------
2022-04-28 17:33:28,382 learning rate too small - quitting training!
2022-04-28 17:33:28,382 ----------------------------------------------------------------------------------------------------
2022-04-28 17:33:46,588 ----------------------------------------------------------------------------------------------------
2022-04-28 17:33:46,588 loading file resources/taggers/model_05_r5_run_3/best-model.pt
2022-04-28 17:33:56,205 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-04-28 17:34:17,793 Evaluating as a multi-label problem: False
2022-04-28 17:34:17,805 0.6042	0.3197	0.4182	0.284
2022-04-28 17:34:17,805 
Results:
- F-score (micro) 0.4182
- F-score (macro) 0.2717
- Accuracy 0.284

By class:
               precision    recall  f1-score   support

       person     0.6508    0.5431    0.5921       429
     location     0.5563    0.5267    0.5411       150
        group     0.4688    0.0909    0.1523       165
creative-work     0.5000    0.0282    0.0533       142
      product     0.3750    0.0236    0.0444       127
  corporation     0.4783    0.1667    0.2472        66

    micro avg     0.6042    0.3197    0.4182      1079
    macro avg     0.5049    0.2299    0.2717      1079
 weighted avg     0.5470    0.3197    0.3613      1079

2022-04-28 17:34:17,805 ----------------------------------------------------------------------------------------------------
