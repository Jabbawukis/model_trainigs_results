2022-05-23 18:13:07,525 ----------------------------------------------------------------------------------------------------
2022-05-23 18:13:07,525 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_3): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=5072, out_features=5072, bias=True)
  (rnn): LSTM(5072, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-05-23 18:13:07,525 ----------------------------------------------------------------------------------------------------
2022-05-23 18:13:07,525 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-05-23 18:13:07,525 ----------------------------------------------------------------------------------------------------
2022-05-23 18:13:07,525 Parameters:
2022-05-23 18:13:07,525  - learning_rate: "0.100000"
2022-05-23 18:13:07,525  - mini_batch_size: "32"
2022-05-23 18:13:07,526  - patience: "3"
2022-05-23 18:13:07,526  - anneal_factor: "0.5"
2022-05-23 18:13:07,526  - max_epochs: "150"
2022-05-23 18:13:07,526  - shuffle: "True"
2022-05-23 18:13:07,526  - train_with_dev: "False"
2022-05-23 18:13:07,526  - batch_growth_annealing: "False"
2022-05-23 18:13:07,526 ----------------------------------------------------------------------------------------------------
2022-05-23 18:13:07,526 Model training base path: "resources/taggers/model_06_r15_run_4"
2022-05-23 18:13:07,526 ----------------------------------------------------------------------------------------------------
2022-05-23 18:13:07,526 Device: cuda:1
2022-05-23 18:13:07,526 ----------------------------------------------------------------------------------------------------
2022-05-23 18:13:07,526 Embeddings storage mode: cpu
2022-05-23 18:13:07,526 ----------------------------------------------------------------------------------------------------
2022-05-23 18:13:11,661 epoch 1 - iter 10/107 - loss 1.13399423 - samples/sec: 77.41 - lr: 0.100000
2022-05-23 18:13:15,790 epoch 1 - iter 20/107 - loss 0.72617303 - samples/sec: 77.51 - lr: 0.100000
2022-05-23 18:13:20,262 epoch 1 - iter 30/107 - loss 0.58247040 - samples/sec: 71.57 - lr: 0.100000
2022-05-23 18:13:24,682 epoch 1 - iter 40/107 - loss 0.50880083 - samples/sec: 72.43 - lr: 0.100000
2022-05-23 18:13:29,255 epoch 1 - iter 50/107 - loss 0.45082291 - samples/sec: 69.99 - lr: 0.100000
2022-05-23 18:13:33,675 epoch 1 - iter 60/107 - loss 0.43025910 - samples/sec: 72.40 - lr: 0.100000
2022-05-23 18:13:38,192 epoch 1 - iter 70/107 - loss 0.41289727 - samples/sec: 70.87 - lr: 0.100000
2022-05-23 18:13:42,397 epoch 1 - iter 80/107 - loss 0.40456137 - samples/sec: 76.12 - lr: 0.100000
2022-05-23 18:13:46,241 epoch 1 - iter 90/107 - loss 0.39763087 - samples/sec: 83.28 - lr: 0.100000
2022-05-23 18:13:50,001 epoch 1 - iter 100/107 - loss 0.38991453 - samples/sec: 85.13 - lr: 0.100000
2022-05-23 18:13:52,167 ----------------------------------------------------------------------------------------------------
2022-05-23 18:13:52,167 EPOCH 1 done: loss 0.3818 - lr 0.100000
2022-05-23 18:14:05,246 Evaluating as a multi-label problem: False
2022-05-23 18:14:05,257 DEV : loss 0.48189088702201843 - f1-score (micro avg)  0.0683
2022-05-23 18:14:05,362 BAD EPOCHS (no improvement): 0
2022-05-23 18:14:05,366 saving best model
2022-05-23 18:15:45,469 ----------------------------------------------------------------------------------------------------
2022-05-23 18:15:50,109 epoch 2 - iter 10/107 - loss 0.27590851 - samples/sec: 69.00 - lr: 0.100000
2022-05-23 18:15:54,560 epoch 2 - iter 20/107 - loss 0.24267260 - samples/sec: 71.91 - lr: 0.100000
2022-05-23 18:15:58,770 epoch 2 - iter 30/107 - loss 0.23002983 - samples/sec: 76.04 - lr: 0.100000
2022-05-23 18:16:02,757 epoch 2 - iter 40/107 - loss 0.22508995 - samples/sec: 80.29 - lr: 0.100000
2022-05-23 18:16:06,617 epoch 2 - iter 50/107 - loss 0.22519586 - samples/sec: 82.92 - lr: 0.100000
2022-05-23 18:16:10,587 epoch 2 - iter 60/107 - loss 0.22187186 - samples/sec: 80.63 - lr: 0.100000
2022-05-23 18:16:14,838 epoch 2 - iter 70/107 - loss 0.21178958 - samples/sec: 75.31 - lr: 0.100000
2022-05-23 18:16:18,905 epoch 2 - iter 80/107 - loss 0.20844253 - samples/sec: 78.69 - lr: 0.100000
2022-05-23 18:16:22,831 epoch 2 - iter 90/107 - loss 0.20695253 - samples/sec: 81.53 - lr: 0.100000
2022-05-23 18:16:26,774 epoch 2 - iter 100/107 - loss 0.20503287 - samples/sec: 81.19 - lr: 0.100000
2022-05-23 18:16:29,294 ----------------------------------------------------------------------------------------------------
2022-05-23 18:16:29,295 EPOCH 2 done: loss 0.2062 - lr 0.100000
2022-05-23 18:16:40,805 Evaluating as a multi-label problem: False
2022-05-23 18:16:40,817 DEV : loss 0.2836975157260895 - f1-score (micro avg)  0.4801
2022-05-23 18:16:40,907 BAD EPOCHS (no improvement): 0
2022-05-23 18:16:40,910 saving best model
2022-05-23 18:18:20,101 ----------------------------------------------------------------------------------------------------
2022-05-23 18:18:23,925 epoch 3 - iter 10/107 - loss 0.19003592 - samples/sec: 83.73 - lr: 0.100000
2022-05-23 18:18:28,062 epoch 3 - iter 20/107 - loss 0.17284452 - samples/sec: 77.38 - lr: 0.100000
2022-05-23 18:18:31,987 epoch 3 - iter 30/107 - loss 0.17473824 - samples/sec: 81.55 - lr: 0.100000
2022-05-23 18:18:35,752 epoch 3 - iter 40/107 - loss 0.17576991 - samples/sec: 85.02 - lr: 0.100000
2022-05-23 18:18:39,736 epoch 3 - iter 50/107 - loss 0.17436493 - samples/sec: 80.34 - lr: 0.100000
2022-05-23 18:18:43,806 epoch 3 - iter 60/107 - loss 0.17833940 - samples/sec: 78.64 - lr: 0.100000
2022-05-23 18:18:48,033 epoch 3 - iter 70/107 - loss 0.17709859 - samples/sec: 75.71 - lr: 0.100000
2022-05-23 18:18:52,054 epoch 3 - iter 80/107 - loss 0.17535694 - samples/sec: 79.62 - lr: 0.100000
2022-05-23 18:18:55,589 epoch 3 - iter 90/107 - loss 0.17697619 - samples/sec: 90.54 - lr: 0.100000
2022-05-23 18:18:58,947 epoch 3 - iter 100/107 - loss 0.17552267 - samples/sec: 95.34 - lr: 0.100000
2022-05-23 18:19:01,225 ----------------------------------------------------------------------------------------------------
2022-05-23 18:19:01,225 EPOCH 3 done: loss 0.1756 - lr 0.100000
2022-05-23 18:19:12,856 Evaluating as a multi-label problem: False
2022-05-23 18:19:12,867 DEV : loss 0.3055172860622406 - f1-score (micro avg)  0.4482
2022-05-23 18:19:12,954 BAD EPOCHS (no improvement): 1
2022-05-23 18:19:12,967 ----------------------------------------------------------------------------------------------------
2022-05-23 18:19:17,110 epoch 4 - iter 10/107 - loss 0.14899727 - samples/sec: 77.27 - lr: 0.100000
2022-05-23 18:19:21,171 epoch 4 - iter 20/107 - loss 0.15477761 - samples/sec: 78.82 - lr: 0.100000
2022-05-23 18:19:25,407 epoch 4 - iter 30/107 - loss 0.16335223 - samples/sec: 75.55 - lr: 0.100000
2022-05-23 18:19:29,327 epoch 4 - iter 40/107 - loss 0.16574456 - samples/sec: 81.67 - lr: 0.100000
2022-05-23 18:19:33,192 epoch 4 - iter 50/107 - loss 0.15980088 - samples/sec: 82.81 - lr: 0.100000
2022-05-23 18:19:36,885 epoch 4 - iter 60/107 - loss 0.15994247 - samples/sec: 86.67 - lr: 0.100000
2022-05-23 18:19:40,489 epoch 4 - iter 70/107 - loss 0.15778673 - samples/sec: 88.82 - lr: 0.100000
2022-05-23 18:19:44,276 epoch 4 - iter 80/107 - loss 0.15615034 - samples/sec: 84.52 - lr: 0.100000
2022-05-23 18:19:48,420 epoch 4 - iter 90/107 - loss 0.15667669 - samples/sec: 77.24 - lr: 0.100000
2022-05-23 18:19:52,399 epoch 4 - iter 100/107 - loss 0.15491363 - samples/sec: 80.45 - lr: 0.100000
2022-05-23 18:19:54,782 ----------------------------------------------------------------------------------------------------
2022-05-23 18:19:54,782 EPOCH 4 done: loss 0.1539 - lr 0.100000
2022-05-23 18:20:06,280 Evaluating as a multi-label problem: False
2022-05-23 18:20:06,293 DEV : loss 0.3253963589668274 - f1-score (micro avg)  0.3623
2022-05-23 18:20:06,380 BAD EPOCHS (no improvement): 2
2022-05-23 18:20:06,383 ----------------------------------------------------------------------------------------------------
2022-05-23 18:20:10,307 epoch 5 - iter 10/107 - loss 0.15022118 - samples/sec: 81.58 - lr: 0.100000
2022-05-23 18:20:14,011 epoch 5 - iter 20/107 - loss 0.13696930 - samples/sec: 86.40 - lr: 0.100000
2022-05-23 18:20:17,695 epoch 5 - iter 30/107 - loss 0.14499150 - samples/sec: 86.88 - lr: 0.100000
2022-05-23 18:20:21,339 epoch 5 - iter 40/107 - loss 0.14069045 - samples/sec: 87.84 - lr: 0.100000
2022-05-23 18:20:25,198 epoch 5 - iter 50/107 - loss 0.14276791 - samples/sec: 82.96 - lr: 0.100000
2022-05-23 18:20:29,293 epoch 5 - iter 60/107 - loss 0.14290817 - samples/sec: 78.16 - lr: 0.100000
2022-05-23 18:20:33,050 epoch 5 - iter 70/107 - loss 0.14312705 - samples/sec: 85.20 - lr: 0.100000
2022-05-23 18:20:37,040 epoch 5 - iter 80/107 - loss 0.13928360 - samples/sec: 80.22 - lr: 0.100000
2022-05-23 18:20:41,166 epoch 5 - iter 90/107 - loss 0.13803513 - samples/sec: 77.58 - lr: 0.100000
2022-05-23 18:20:45,175 epoch 5 - iter 100/107 - loss 0.13914322 - samples/sec: 79.86 - lr: 0.100000
2022-05-23 18:20:47,616 ----------------------------------------------------------------------------------------------------
2022-05-23 18:20:47,616 EPOCH 5 done: loss 0.1371 - lr 0.100000
2022-05-23 18:20:58,875 Evaluating as a multi-label problem: False
2022-05-23 18:20:58,885 DEV : loss 0.31169790029525757 - f1-score (micro avg)  0.4264
2022-05-23 18:20:58,974 BAD EPOCHS (no improvement): 3
2022-05-23 18:20:58,977 ----------------------------------------------------------------------------------------------------
2022-05-23 18:21:02,539 epoch 6 - iter 10/107 - loss 0.12198527 - samples/sec: 89.88 - lr: 0.100000
2022-05-23 18:21:06,656 epoch 6 - iter 20/107 - loss 0.12076734 - samples/sec: 77.73 - lr: 0.100000
2022-05-23 18:21:10,696 epoch 6 - iter 30/107 - loss 0.13523497 - samples/sec: 79.23 - lr: 0.100000
2022-05-23 18:21:14,781 epoch 6 - iter 40/107 - loss 0.13181077 - samples/sec: 78.36 - lr: 0.100000
2022-05-23 18:21:18,976 epoch 6 - iter 50/107 - loss 0.13110090 - samples/sec: 76.29 - lr: 0.100000
2022-05-23 18:21:23,077 epoch 6 - iter 60/107 - loss 0.12583472 - samples/sec: 78.06 - lr: 0.100000
2022-05-23 18:21:27,219 epoch 6 - iter 70/107 - loss 0.12776663 - samples/sec: 77.27 - lr: 0.100000
2022-05-23 18:21:31,100 epoch 6 - iter 80/107 - loss 0.12713434 - samples/sec: 82.47 - lr: 0.100000
2022-05-23 18:21:34,726 epoch 6 - iter 90/107 - loss 0.12674959 - samples/sec: 88.28 - lr: 0.100000
2022-05-23 18:21:38,244 epoch 6 - iter 100/107 - loss 0.12954867 - samples/sec: 90.98 - lr: 0.100000
2022-05-23 18:21:40,422 ----------------------------------------------------------------------------------------------------
2022-05-23 18:21:40,422 EPOCH 6 done: loss 0.1284 - lr 0.100000
2022-05-23 18:21:52,450 Evaluating as a multi-label problem: False
2022-05-23 18:21:52,461 DEV : loss 0.23383593559265137 - f1-score (micro avg)  0.5154
2022-05-23 18:21:52,548 BAD EPOCHS (no improvement): 0
2022-05-23 18:21:52,551 saving best model
2022-05-23 18:23:31,786 ----------------------------------------------------------------------------------------------------
2022-05-23 18:23:36,028 epoch 7 - iter 10/107 - loss 0.11526202 - samples/sec: 75.48 - lr: 0.100000
2022-05-23 18:23:40,022 epoch 7 - iter 20/107 - loss 0.12483187 - samples/sec: 80.15 - lr: 0.100000
2022-05-23 18:23:43,586 epoch 7 - iter 30/107 - loss 0.11356964 - samples/sec: 89.81 - lr: 0.100000
2022-05-23 18:23:47,101 epoch 7 - iter 40/107 - loss 0.11635409 - samples/sec: 91.07 - lr: 0.100000
2022-05-23 18:23:50,947 epoch 7 - iter 50/107 - loss 0.11394082 - samples/sec: 83.22 - lr: 0.100000
2022-05-23 18:23:54,928 epoch 7 - iter 60/107 - loss 0.11778531 - samples/sec: 80.39 - lr: 0.100000
2022-05-23 18:23:58,966 epoch 7 - iter 70/107 - loss 0.11527114 - samples/sec: 79.27 - lr: 0.100000
2022-05-23 18:24:02,893 epoch 7 - iter 80/107 - loss 0.11472283 - samples/sec: 81.52 - lr: 0.100000
2022-05-23 18:24:06,964 epoch 7 - iter 90/107 - loss 0.11461750 - samples/sec: 78.63 - lr: 0.100000
2022-05-23 18:24:10,934 epoch 7 - iter 100/107 - loss 0.11681622 - samples/sec: 80.63 - lr: 0.100000
2022-05-23 18:24:13,368 ----------------------------------------------------------------------------------------------------
2022-05-23 18:24:13,368 EPOCH 7 done: loss 0.1155 - lr 0.100000
2022-05-23 18:24:24,636 Evaluating as a multi-label problem: False
2022-05-23 18:24:24,646 DEV : loss 0.3053435981273651 - f1-score (micro avg)  0.3573
2022-05-23 18:24:24,735 BAD EPOCHS (no improvement): 1
2022-05-23 18:24:24,738 ----------------------------------------------------------------------------------------------------
2022-05-23 18:24:28,245 epoch 8 - iter 10/107 - loss 0.08727890 - samples/sec: 91.29 - lr: 0.100000
2022-05-23 18:24:32,200 epoch 8 - iter 20/107 - loss 0.10229040 - samples/sec: 80.92 - lr: 0.100000
2022-05-23 18:24:35,927 epoch 8 - iter 30/107 - loss 0.10601711 - samples/sec: 85.90 - lr: 0.100000
2022-05-23 18:24:39,822 epoch 8 - iter 40/107 - loss 0.10338548 - samples/sec: 82.16 - lr: 0.100000
2022-05-23 18:24:43,889 epoch 8 - iter 50/107 - loss 0.10736414 - samples/sec: 78.70 - lr: 0.100000
2022-05-23 18:24:47,814 epoch 8 - iter 60/107 - loss 0.11041538 - samples/sec: 81.56 - lr: 0.100000
2022-05-23 18:24:51,912 epoch 8 - iter 70/107 - loss 0.10823296 - samples/sec: 78.11 - lr: 0.100000
2022-05-23 18:24:55,856 epoch 8 - iter 80/107 - loss 0.10609048 - samples/sec: 81.16 - lr: 0.100000
2022-05-23 18:24:59,957 epoch 8 - iter 90/107 - loss 0.10636523 - samples/sec: 78.04 - lr: 0.100000
2022-05-23 18:25:03,603 epoch 8 - iter 100/107 - loss 0.10590244 - samples/sec: 87.80 - lr: 0.100000
2022-05-23 18:25:05,732 ----------------------------------------------------------------------------------------------------
2022-05-23 18:25:05,732 EPOCH 8 done: loss 0.1071 - lr 0.100000
2022-05-23 18:25:17,243 Evaluating as a multi-label problem: False
2022-05-23 18:25:17,254 DEV : loss 0.23747618496418 - f1-score (micro avg)  0.5199
2022-05-23 18:25:17,343 BAD EPOCHS (no improvement): 0
2022-05-23 18:25:17,345 saving best model
2022-05-23 18:26:54,947 ----------------------------------------------------------------------------------------------------
2022-05-23 18:26:59,276 epoch 9 - iter 10/107 - loss 0.08942503 - samples/sec: 73.95 - lr: 0.100000
2022-05-23 18:27:03,417 epoch 9 - iter 20/107 - loss 0.10131896 - samples/sec: 77.31 - lr: 0.100000
2022-05-23 18:27:07,524 epoch 9 - iter 30/107 - loss 0.10051857 - samples/sec: 77.93 - lr: 0.100000
2022-05-23 18:27:11,777 epoch 9 - iter 40/107 - loss 0.10050753 - samples/sec: 75.26 - lr: 0.100000
2022-05-23 18:27:15,646 epoch 9 - iter 50/107 - loss 0.09999929 - samples/sec: 82.73 - lr: 0.100000
2022-05-23 18:27:19,299 epoch 9 - iter 60/107 - loss 0.10073578 - samples/sec: 87.62 - lr: 0.100000
2022-05-23 18:27:23,045 epoch 9 - iter 70/107 - loss 0.10110858 - samples/sec: 85.46 - lr: 0.100000
2022-05-23 18:27:27,119 epoch 9 - iter 80/107 - loss 0.10315291 - samples/sec: 78.56 - lr: 0.100000
2022-05-23 18:27:30,986 epoch 9 - iter 90/107 - loss 0.10321552 - samples/sec: 82.79 - lr: 0.100000
2022-05-23 18:27:34,868 epoch 9 - iter 100/107 - loss 0.10238207 - samples/sec: 82.44 - lr: 0.100000
2022-05-23 18:27:37,251 ----------------------------------------------------------------------------------------------------
2022-05-23 18:27:37,251 EPOCH 9 done: loss 0.1019 - lr 0.100000
2022-05-23 18:27:49,132 Evaluating as a multi-label problem: False
2022-05-23 18:27:49,144 DEV : loss 0.21676811575889587 - f1-score (micro avg)  0.5269
2022-05-23 18:27:49,232 BAD EPOCHS (no improvement): 0
2022-05-23 18:27:49,264 saving best model
2022-05-23 18:29:29,280 ----------------------------------------------------------------------------------------------------
2022-05-23 18:29:33,049 epoch 10 - iter 10/107 - loss 0.08561507 - samples/sec: 84.95 - lr: 0.100000
2022-05-23 18:29:36,716 epoch 10 - iter 20/107 - loss 0.08743393 - samples/sec: 87.30 - lr: 0.100000
2022-05-23 18:29:40,421 epoch 10 - iter 30/107 - loss 0.08796208 - samples/sec: 86.39 - lr: 0.100000
2022-05-23 18:29:44,199 epoch 10 - iter 40/107 - loss 0.08911309 - samples/sec: 84.72 - lr: 0.100000
2022-05-23 18:29:48,009 epoch 10 - iter 50/107 - loss 0.09100862 - samples/sec: 84.02 - lr: 0.100000
2022-05-23 18:29:51,942 epoch 10 - iter 60/107 - loss 0.09166513 - samples/sec: 81.37 - lr: 0.100000
2022-05-23 18:29:55,948 epoch 10 - iter 70/107 - loss 0.09555738 - samples/sec: 79.90 - lr: 0.100000
2022-05-23 18:29:59,876 epoch 10 - iter 80/107 - loss 0.09402212 - samples/sec: 81.50 - lr: 0.100000
2022-05-23 18:30:04,086 epoch 10 - iter 90/107 - loss 0.09464203 - samples/sec: 76.03 - lr: 0.100000
2022-05-23 18:30:08,096 epoch 10 - iter 100/107 - loss 0.09542329 - samples/sec: 79.83 - lr: 0.100000
2022-05-23 18:30:10,524 ----------------------------------------------------------------------------------------------------
2022-05-23 18:30:10,524 EPOCH 10 done: loss 0.0959 - lr 0.100000
2022-05-23 18:30:21,690 Evaluating as a multi-label problem: False
2022-05-23 18:30:21,701 DEV : loss 0.23490215837955475 - f1-score (micro avg)  0.4861
2022-05-23 18:30:21,788 BAD EPOCHS (no improvement): 1
2022-05-23 18:30:21,802 ----------------------------------------------------------------------------------------------------
2022-05-23 18:30:25,554 epoch 11 - iter 10/107 - loss 0.08532607 - samples/sec: 85.33 - lr: 0.100000
2022-05-23 18:30:29,561 epoch 11 - iter 20/107 - loss 0.08139709 - samples/sec: 79.89 - lr: 0.100000
2022-05-23 18:30:33,752 epoch 11 - iter 30/107 - loss 0.08279961 - samples/sec: 76.36 - lr: 0.100000
2022-05-23 18:30:37,506 epoch 11 - iter 40/107 - loss 0.08144037 - samples/sec: 85.28 - lr: 0.100000
2022-05-23 18:30:41,496 epoch 11 - iter 50/107 - loss 0.08357264 - samples/sec: 80.22 - lr: 0.100000
2022-05-23 18:30:45,562 epoch 11 - iter 60/107 - loss 0.08526846 - samples/sec: 78.71 - lr: 0.100000
2022-05-23 18:30:49,466 epoch 11 - iter 70/107 - loss 0.08477026 - samples/sec: 81.99 - lr: 0.100000
2022-05-23 18:30:52,916 epoch 11 - iter 80/107 - loss 0.08372835 - samples/sec: 92.78 - lr: 0.100000
2022-05-23 18:30:56,490 epoch 11 - iter 90/107 - loss 0.08786322 - samples/sec: 89.57 - lr: 0.100000
2022-05-23 18:31:00,227 epoch 11 - iter 100/107 - loss 0.08976764 - samples/sec: 85.65 - lr: 0.100000
2022-05-23 18:31:02,871 ----------------------------------------------------------------------------------------------------
2022-05-23 18:31:02,872 EPOCH 11 done: loss 0.0904 - lr 0.100000
2022-05-23 18:31:14,719 Evaluating as a multi-label problem: False
2022-05-23 18:31:14,730 DEV : loss 0.25518521666526794 - f1-score (micro avg)  0.4545
2022-05-23 18:31:14,817 BAD EPOCHS (no improvement): 2
2022-05-23 18:31:14,820 ----------------------------------------------------------------------------------------------------
2022-05-23 18:31:18,750 epoch 12 - iter 10/107 - loss 0.07474464 - samples/sec: 81.46 - lr: 0.100000
2022-05-23 18:31:22,586 epoch 12 - iter 20/107 - loss 0.07101472 - samples/sec: 83.44 - lr: 0.100000
2022-05-23 18:31:26,660 epoch 12 - iter 30/107 - loss 0.07371596 - samples/sec: 78.56 - lr: 0.100000
2022-05-23 18:31:30,192 epoch 12 - iter 40/107 - loss 0.07831320 - samples/sec: 90.64 - lr: 0.100000
2022-05-23 18:31:33,876 epoch 12 - iter 50/107 - loss 0.08081148 - samples/sec: 86.88 - lr: 0.100000
2022-05-23 18:31:37,750 epoch 12 - iter 60/107 - loss 0.08280942 - samples/sec: 82.63 - lr: 0.100000
2022-05-23 18:31:41,702 epoch 12 - iter 70/107 - loss 0.08515214 - samples/sec: 80.98 - lr: 0.100000
2022-05-23 18:31:45,751 epoch 12 - iter 80/107 - loss 0.08380802 - samples/sec: 79.06 - lr: 0.100000
2022-05-23 18:31:49,795 epoch 12 - iter 90/107 - loss 0.08235155 - samples/sec: 79.16 - lr: 0.100000
2022-05-23 18:31:53,819 epoch 12 - iter 100/107 - loss 0.08513179 - samples/sec: 79.54 - lr: 0.100000
2022-05-23 18:31:56,283 ----------------------------------------------------------------------------------------------------
2022-05-23 18:31:56,283 EPOCH 12 done: loss 0.0853 - lr 0.100000
2022-05-23 18:32:08,086 Evaluating as a multi-label problem: False
2022-05-23 18:32:08,097 DEV : loss 0.2172316014766693 - f1-score (micro avg)  0.5051
2022-05-23 18:32:08,186 BAD EPOCHS (no improvement): 3
2022-05-23 18:32:08,189 ----------------------------------------------------------------------------------------------------
2022-05-23 18:32:11,957 epoch 13 - iter 10/107 - loss 0.08560117 - samples/sec: 84.95 - lr: 0.100000
2022-05-23 18:32:15,379 epoch 13 - iter 20/107 - loss 0.09213119 - samples/sec: 93.56 - lr: 0.100000
2022-05-23 18:32:19,090 epoch 13 - iter 30/107 - loss 0.09316087 - samples/sec: 86.24 - lr: 0.100000
2022-05-23 18:32:23,120 epoch 13 - iter 40/107 - loss 0.08833256 - samples/sec: 79.42 - lr: 0.100000
2022-05-23 18:32:27,159 epoch 13 - iter 50/107 - loss 0.08791585 - samples/sec: 79.24 - lr: 0.100000
2022-05-23 18:32:31,214 epoch 13 - iter 60/107 - loss 0.08484273 - samples/sec: 78.95 - lr: 0.100000
2022-05-23 18:32:34,973 epoch 13 - iter 70/107 - loss 0.08614720 - samples/sec: 85.14 - lr: 0.100000
2022-05-23 18:32:38,635 epoch 13 - iter 80/107 - loss 0.08432200 - samples/sec: 87.41 - lr: 0.100000
2022-05-23 18:32:42,496 epoch 13 - iter 90/107 - loss 0.08290701 - samples/sec: 82.90 - lr: 0.100000
2022-05-23 18:32:46,642 epoch 13 - iter 100/107 - loss 0.08341287 - samples/sec: 77.22 - lr: 0.100000
2022-05-23 18:32:48,785 ----------------------------------------------------------------------------------------------------
2022-05-23 18:32:48,785 EPOCH 13 done: loss 0.0834 - lr 0.100000
2022-05-23 18:33:00,135 Evaluating as a multi-label problem: False
2022-05-23 18:33:00,146 DEV : loss 0.21166227757930756 - f1-score (micro avg)  0.5224
2022-05-23 18:33:00,234 Epoch    13: reducing learning rate of group 0 to 5.0000e-02.
2022-05-23 18:33:00,234 BAD EPOCHS (no improvement): 4
2022-05-23 18:33:00,236 ----------------------------------------------------------------------------------------------------
2022-05-23 18:33:04,100 epoch 14 - iter 10/107 - loss 0.08038662 - samples/sec: 82.85 - lr: 0.050000
2022-05-23 18:33:07,948 epoch 14 - iter 20/107 - loss 0.07893733 - samples/sec: 83.19 - lr: 0.050000
2022-05-23 18:33:12,005 epoch 14 - iter 30/107 - loss 0.07496309 - samples/sec: 78.89 - lr: 0.050000
2022-05-23 18:33:16,201 epoch 14 - iter 40/107 - loss 0.07573747 - samples/sec: 76.28 - lr: 0.050000
2022-05-23 18:33:20,182 epoch 14 - iter 50/107 - loss 0.07695020 - samples/sec: 80.41 - lr: 0.050000
2022-05-23 18:33:24,080 epoch 14 - iter 60/107 - loss 0.07455347 - samples/sec: 82.11 - lr: 0.050000
2022-05-23 18:33:27,622 epoch 14 - iter 70/107 - loss 0.07256250 - samples/sec: 90.38 - lr: 0.050000
2022-05-23 18:33:31,374 epoch 14 - iter 80/107 - loss 0.07497918 - samples/sec: 85.31 - lr: 0.050000
2022-05-23 18:33:34,523 epoch 14 - iter 90/107 - loss 0.07414243 - samples/sec: 101.66 - lr: 0.050000
2022-05-23 18:33:38,233 epoch 14 - iter 100/107 - loss 0.07408944 - samples/sec: 86.29 - lr: 0.050000
2022-05-23 18:33:40,695 ----------------------------------------------------------------------------------------------------
2022-05-23 18:33:40,695 EPOCH 14 done: loss 0.0735 - lr 0.050000
2022-05-23 18:33:52,597 Evaluating as a multi-label problem: False
2022-05-23 18:33:52,609 DEV : loss 0.2109653651714325 - f1-score (micro avg)  0.5188
2022-05-23 18:33:52,699 BAD EPOCHS (no improvement): 1
2022-05-23 18:33:52,717 ----------------------------------------------------------------------------------------------------
2022-05-23 18:33:56,930 epoch 15 - iter 10/107 - loss 0.07351077 - samples/sec: 76.00 - lr: 0.050000
2022-05-23 18:34:01,049 epoch 15 - iter 20/107 - loss 0.06619931 - samples/sec: 77.70 - lr: 0.050000
2022-05-23 18:34:05,112 epoch 15 - iter 30/107 - loss 0.06625922 - samples/sec: 78.78 - lr: 0.050000
2022-05-23 18:34:08,915 epoch 15 - iter 40/107 - loss 0.06454341 - samples/sec: 84.18 - lr: 0.050000
2022-05-23 18:34:12,601 epoch 15 - iter 50/107 - loss 0.06532479 - samples/sec: 86.84 - lr: 0.050000
2022-05-23 18:34:27,516 epoch 15 - iter 60/107 - loss 0.06712417 - samples/sec: 21.46 - lr: 0.050000
2022-05-23 18:34:31,615 epoch 15 - iter 70/107 - loss 0.06700680 - samples/sec: 78.10 - lr: 0.050000
2022-05-23 18:34:35,492 epoch 15 - iter 80/107 - loss 0.06751609 - samples/sec: 82.55 - lr: 0.050000
2022-05-23 18:34:39,415 epoch 15 - iter 90/107 - loss 0.06719827 - samples/sec: 81.59 - lr: 0.050000
2022-05-23 18:34:43,375 epoch 15 - iter 100/107 - loss 0.06710812 - samples/sec: 80.82 - lr: 0.050000
2022-05-23 18:34:45,751 ----------------------------------------------------------------------------------------------------
2022-05-23 18:34:45,751 EPOCH 15 done: loss 0.0673 - lr 0.050000
2022-05-23 18:34:56,889 Evaluating as a multi-label problem: False
2022-05-23 18:34:56,901 DEV : loss 0.19576896727085114 - f1-score (micro avg)  0.5493
2022-05-23 18:34:56,987 BAD EPOCHS (no improvement): 0
2022-05-23 18:34:56,990 saving best model
2022-05-23 18:36:35,974 ----------------------------------------------------------------------------------------------------
2022-05-23 18:36:40,094 epoch 16 - iter 10/107 - loss 0.07161817 - samples/sec: 77.72 - lr: 0.050000
2022-05-23 18:36:42,988 epoch 16 - iter 20/107 - loss 0.06456591 - samples/sec: 110.61 - lr: 0.050000
2022-05-23 18:36:46,000 epoch 16 - iter 30/107 - loss 0.06771638 - samples/sec: 106.29 - lr: 0.050000
2022-05-23 18:36:48,873 epoch 16 - iter 40/107 - loss 0.07191616 - samples/sec: 111.42 - lr: 0.050000
2022-05-23 18:36:51,752 epoch 16 - iter 50/107 - loss 0.06772289 - samples/sec: 111.17 - lr: 0.050000
2022-05-23 18:36:54,698 epoch 16 - iter 60/107 - loss 0.06576745 - samples/sec: 108.67 - lr: 0.050000
2022-05-23 18:36:57,620 epoch 16 - iter 70/107 - loss 0.06437998 - samples/sec: 109.55 - lr: 0.050000
2022-05-23 18:37:00,403 epoch 16 - iter 80/107 - loss 0.06748832 - samples/sec: 115.01 - lr: 0.050000
2022-05-23 18:37:03,234 epoch 16 - iter 90/107 - loss 0.06673294 - samples/sec: 113.06 - lr: 0.050000
2022-05-23 18:37:06,270 epoch 16 - iter 100/107 - loss 0.06641840 - samples/sec: 105.45 - lr: 0.050000
2022-05-23 18:37:08,050 ----------------------------------------------------------------------------------------------------
2022-05-23 18:37:08,050 EPOCH 16 done: loss 0.0670 - lr 0.050000
2022-05-23 18:37:17,040 Evaluating as a multi-label problem: False
2022-05-23 18:37:17,051 DEV : loss 0.21412041783332825 - f1-score (micro avg)  0.5257
2022-05-23 18:37:17,137 BAD EPOCHS (no improvement): 1
2022-05-23 18:37:17,159 ----------------------------------------------------------------------------------------------------
2022-05-23 18:37:20,224 epoch 17 - iter 10/107 - loss 0.07135656 - samples/sec: 104.43 - lr: 0.050000
2022-05-23 18:37:23,148 epoch 17 - iter 20/107 - loss 0.06324893 - samples/sec: 109.48 - lr: 0.050000
2022-05-23 18:37:26,117 epoch 17 - iter 30/107 - loss 0.06179671 - samples/sec: 107.83 - lr: 0.050000
2022-05-23 18:37:29,073 epoch 17 - iter 40/107 - loss 0.06451719 - samples/sec: 108.29 - lr: 0.050000
2022-05-23 18:37:31,944 epoch 17 - iter 50/107 - loss 0.06821647 - samples/sec: 111.50 - lr: 0.050000
2022-05-23 18:37:34,817 epoch 17 - iter 60/107 - loss 0.06690673 - samples/sec: 111.41 - lr: 0.050000
2022-05-23 18:37:37,684 epoch 17 - iter 70/107 - loss 0.06584973 - samples/sec: 111.64 - lr: 0.050000
2022-05-23 18:37:40,581 epoch 17 - iter 80/107 - loss 0.06493721 - samples/sec: 110.50 - lr: 0.050000
2022-05-23 18:37:43,419 epoch 17 - iter 90/107 - loss 0.06396304 - samples/sec: 112.81 - lr: 0.050000
2022-05-23 18:37:46,251 epoch 17 - iter 100/107 - loss 0.06346143 - samples/sec: 113.02 - lr: 0.050000
2022-05-23 18:37:48,148 ----------------------------------------------------------------------------------------------------
2022-05-23 18:37:48,148 EPOCH 17 done: loss 0.0634 - lr 0.050000
2022-05-23 18:37:57,186 Evaluating as a multi-label problem: False
2022-05-23 18:37:57,197 DEV : loss 0.20599927008152008 - f1-score (micro avg)  0.5217
2022-05-23 18:37:57,282 BAD EPOCHS (no improvement): 2
2022-05-23 18:37:57,285 ----------------------------------------------------------------------------------------------------
2022-05-23 18:38:00,365 epoch 18 - iter 10/107 - loss 0.07585505 - samples/sec: 103.94 - lr: 0.050000
2022-05-23 18:38:03,253 epoch 18 - iter 20/107 - loss 0.06747523 - samples/sec: 110.84 - lr: 0.050000
2022-05-23 18:38:06,058 epoch 18 - iter 30/107 - loss 0.06704045 - samples/sec: 114.13 - lr: 0.050000
2022-05-23 18:38:09,090 epoch 18 - iter 40/107 - loss 0.06506148 - samples/sec: 105.58 - lr: 0.050000
2022-05-23 18:38:12,035 epoch 18 - iter 50/107 - loss 0.06308787 - samples/sec: 108.70 - lr: 0.050000
2022-05-23 18:38:14,987 epoch 18 - iter 60/107 - loss 0.06104452 - samples/sec: 108.42 - lr: 0.050000
2022-05-23 18:38:17,811 epoch 18 - iter 70/107 - loss 0.06064541 - samples/sec: 113.35 - lr: 0.050000
2022-05-23 18:38:20,654 epoch 18 - iter 80/107 - loss 0.06037806 - samples/sec: 112.63 - lr: 0.050000
2022-05-23 18:38:23,452 epoch 18 - iter 90/107 - loss 0.05981962 - samples/sec: 114.38 - lr: 0.050000
2022-05-23 18:38:26,364 epoch 18 - iter 100/107 - loss 0.06036396 - samples/sec: 109.94 - lr: 0.050000
2022-05-23 18:38:28,174 ----------------------------------------------------------------------------------------------------
2022-05-23 18:38:28,175 EPOCH 18 done: loss 0.0602 - lr 0.050000
2022-05-23 18:38:37,213 Evaluating as a multi-label problem: False
2022-05-23 18:38:37,225 DEV : loss 0.2109476625919342 - f1-score (micro avg)  0.5232
2022-05-23 18:38:37,311 BAD EPOCHS (no improvement): 3
2022-05-23 18:38:37,313 ----------------------------------------------------------------------------------------------------
2022-05-23 18:38:40,342 epoch 19 - iter 10/107 - loss 0.05369011 - samples/sec: 105.69 - lr: 0.050000
2022-05-23 18:38:43,288 epoch 19 - iter 20/107 - loss 0.05950402 - samples/sec: 108.64 - lr: 0.050000
2022-05-23 18:38:46,094 epoch 19 - iter 30/107 - loss 0.05832129 - samples/sec: 114.08 - lr: 0.050000
2022-05-23 18:38:49,040 epoch 19 - iter 40/107 - loss 0.05591745 - samples/sec: 108.65 - lr: 0.050000
2022-05-23 18:38:51,874 epoch 19 - iter 50/107 - loss 0.05712985 - samples/sec: 112.97 - lr: 0.050000
2022-05-23 18:38:54,782 epoch 19 - iter 60/107 - loss 0.05823885 - samples/sec: 110.05 - lr: 0.050000
2022-05-23 18:38:57,635 epoch 19 - iter 70/107 - loss 0.05860402 - samples/sec: 112.24 - lr: 0.050000
2022-05-23 18:39:00,568 epoch 19 - iter 80/107 - loss 0.05843864 - samples/sec: 109.13 - lr: 0.050000
2022-05-23 18:39:03,476 epoch 19 - iter 90/107 - loss 0.05765122 - samples/sec: 110.08 - lr: 0.050000
2022-05-23 18:39:06,377 epoch 19 - iter 100/107 - loss 0.05799792 - samples/sec: 110.33 - lr: 0.050000
2022-05-23 18:39:08,279 ----------------------------------------------------------------------------------------------------
2022-05-23 18:39:08,279 EPOCH 19 done: loss 0.0590 - lr 0.050000
2022-05-23 18:39:17,278 Evaluating as a multi-label problem: False
2022-05-23 18:39:17,290 DEV : loss 0.20995603501796722 - f1-score (micro avg)  0.529
2022-05-23 18:39:17,376 Epoch    19: reducing learning rate of group 0 to 2.5000e-02.
2022-05-23 18:39:17,376 BAD EPOCHS (no improvement): 4
2022-05-23 18:39:17,378 ----------------------------------------------------------------------------------------------------
2022-05-23 18:39:20,320 epoch 20 - iter 10/107 - loss 0.05533758 - samples/sec: 108.80 - lr: 0.025000
2022-05-23 18:39:23,216 epoch 20 - iter 20/107 - loss 0.05425764 - samples/sec: 110.52 - lr: 0.025000
2022-05-23 18:39:26,082 epoch 20 - iter 30/107 - loss 0.05338002 - samples/sec: 111.71 - lr: 0.025000
2022-05-23 18:39:28,962 epoch 20 - iter 40/107 - loss 0.05431961 - samples/sec: 111.12 - lr: 0.025000
2022-05-23 18:39:31,864 epoch 20 - iter 50/107 - loss 0.05392236 - samples/sec: 110.32 - lr: 0.025000
2022-05-23 18:39:34,741 epoch 20 - iter 60/107 - loss 0.05365388 - samples/sec: 111.28 - lr: 0.025000
2022-05-23 18:39:37,618 epoch 20 - iter 70/107 - loss 0.05493087 - samples/sec: 111.26 - lr: 0.025000
2022-05-23 18:39:40,422 epoch 20 - iter 80/107 - loss 0.05442709 - samples/sec: 114.13 - lr: 0.025000
2022-05-23 18:39:43,432 epoch 20 - iter 90/107 - loss 0.05414537 - samples/sec: 106.37 - lr: 0.025000
2022-05-23 18:39:46,332 epoch 20 - iter 100/107 - loss 0.05349898 - samples/sec: 110.37 - lr: 0.025000
2022-05-23 18:39:48,074 ----------------------------------------------------------------------------------------------------
2022-05-23 18:39:48,074 EPOCH 20 done: loss 0.0537 - lr 0.025000
2022-05-23 18:39:57,016 Evaluating as a multi-label problem: False
2022-05-23 18:39:57,027 DEV : loss 0.21412186324596405 - f1-score (micro avg)  0.5195
2022-05-23 18:39:57,113 BAD EPOCHS (no improvement): 1
2022-05-23 18:39:57,116 ----------------------------------------------------------------------------------------------------
2022-05-23 18:40:00,087 epoch 21 - iter 10/107 - loss 0.05955772 - samples/sec: 107.77 - lr: 0.025000
2022-05-23 18:40:02,966 epoch 21 - iter 20/107 - loss 0.05408686 - samples/sec: 111.18 - lr: 0.025000
2022-05-23 18:40:05,872 epoch 21 - iter 30/107 - loss 0.05287378 - samples/sec: 110.16 - lr: 0.025000
2022-05-23 18:40:08,828 epoch 21 - iter 40/107 - loss 0.05071367 - samples/sec: 108.30 - lr: 0.025000
2022-05-23 18:40:11,690 epoch 21 - iter 50/107 - loss 0.05078846 - samples/sec: 111.82 - lr: 0.025000
2022-05-23 18:40:14,485 epoch 21 - iter 60/107 - loss 0.05067111 - samples/sec: 114.56 - lr: 0.025000
2022-05-23 18:40:17,316 epoch 21 - iter 70/107 - loss 0.05056785 - samples/sec: 113.06 - lr: 0.025000
2022-05-23 18:40:20,124 epoch 21 - iter 80/107 - loss 0.05123580 - samples/sec: 114.01 - lr: 0.025000
2022-05-23 18:40:22,877 epoch 21 - iter 90/107 - loss 0.05136395 - samples/sec: 116.26 - lr: 0.025000
2022-05-23 18:40:25,609 epoch 21 - iter 100/107 - loss 0.05068601 - samples/sec: 117.18 - lr: 0.025000
2022-05-23 18:40:27,407 ----------------------------------------------------------------------------------------------------
2022-05-23 18:40:27,408 EPOCH 21 done: loss 0.0517 - lr 0.025000
2022-05-23 18:40:36,353 Evaluating as a multi-label problem: False
2022-05-23 18:40:36,363 DEV : loss 0.20133548974990845 - f1-score (micro avg)  0.5456
2022-05-23 18:40:36,449 BAD EPOCHS (no improvement): 2
2022-05-23 18:40:36,452 ----------------------------------------------------------------------------------------------------
2022-05-23 18:40:39,324 epoch 22 - iter 10/107 - loss 0.04496464 - samples/sec: 111.45 - lr: 0.025000
2022-05-23 18:40:42,180 epoch 22 - iter 20/107 - loss 0.05395730 - samples/sec: 112.09 - lr: 0.025000
2022-05-23 18:40:45,129 epoch 22 - iter 30/107 - loss 0.04815180 - samples/sec: 108.56 - lr: 0.025000
2022-05-23 18:40:48,064 epoch 22 - iter 40/107 - loss 0.04816719 - samples/sec: 109.10 - lr: 0.025000
2022-05-23 18:40:50,979 epoch 22 - iter 50/107 - loss 0.05048031 - samples/sec: 109.78 - lr: 0.025000
2022-05-23 18:40:53,848 epoch 22 - iter 60/107 - loss 0.05077446 - samples/sec: 111.60 - lr: 0.025000
2022-05-23 18:40:56,679 epoch 22 - iter 70/107 - loss 0.05164992 - samples/sec: 113.04 - lr: 0.025000
2022-05-23 18:40:59,602 epoch 22 - iter 80/107 - loss 0.05086249 - samples/sec: 109.54 - lr: 0.025000
2022-05-23 18:41:02,534 epoch 22 - iter 90/107 - loss 0.05167961 - samples/sec: 109.16 - lr: 0.025000
2022-05-23 18:41:05,341 epoch 22 - iter 100/107 - loss 0.05132770 - samples/sec: 114.05 - lr: 0.025000
2022-05-23 18:41:07,149 ----------------------------------------------------------------------------------------------------
2022-05-23 18:41:07,149 EPOCH 22 done: loss 0.0525 - lr 0.025000
2022-05-23 18:41:16,090 Evaluating as a multi-label problem: False
2022-05-23 18:41:16,101 DEV : loss 0.19635340571403503 - f1-score (micro avg)  0.5183
2022-05-23 18:41:16,187 BAD EPOCHS (no improvement): 3
2022-05-23 18:41:16,190 ----------------------------------------------------------------------------------------------------
2022-05-23 18:41:19,077 epoch 23 - iter 10/107 - loss 0.05071703 - samples/sec: 110.91 - lr: 0.025000
2022-05-23 18:41:21,910 epoch 23 - iter 20/107 - loss 0.05646918 - samples/sec: 112.96 - lr: 0.025000
2022-05-23 18:41:24,948 epoch 23 - iter 30/107 - loss 0.05237422 - samples/sec: 105.38 - lr: 0.025000
2022-05-23 18:41:27,955 epoch 23 - iter 40/107 - loss 0.05250242 - samples/sec: 106.44 - lr: 0.025000
2022-05-23 18:41:30,898 epoch 23 - iter 50/107 - loss 0.05182148 - samples/sec: 108.76 - lr: 0.025000
2022-05-23 18:41:33,730 epoch 23 - iter 60/107 - loss 0.05198773 - samples/sec: 113.04 - lr: 0.025000
2022-05-23 18:41:36,557 epoch 23 - iter 70/107 - loss 0.05037852 - samples/sec: 113.23 - lr: 0.025000
2022-05-23 18:41:39,346 epoch 23 - iter 80/107 - loss 0.04993003 - samples/sec: 114.78 - lr: 0.025000
2022-05-23 18:41:42,196 epoch 23 - iter 90/107 - loss 0.04913824 - samples/sec: 112.31 - lr: 0.025000
2022-05-23 18:41:45,121 epoch 23 - iter 100/107 - loss 0.04990052 - samples/sec: 109.46 - lr: 0.025000
2022-05-23 18:41:46,933 ----------------------------------------------------------------------------------------------------
2022-05-23 18:41:46,933 EPOCH 23 done: loss 0.0493 - lr 0.025000
2022-05-23 18:41:56,032 Evaluating as a multi-label problem: False
2022-05-23 18:41:56,043 DEV : loss 0.21889019012451172 - f1-score (micro avg)  0.5133
2022-05-23 18:41:56,131 Epoch    23: reducing learning rate of group 0 to 1.2500e-02.
2022-05-23 18:41:56,131 BAD EPOCHS (no improvement): 4
2022-05-23 18:41:56,135 ----------------------------------------------------------------------------------------------------
2022-05-23 18:41:59,057 epoch 24 - iter 10/107 - loss 0.04195663 - samples/sec: 109.55 - lr: 0.012500
2022-05-23 18:42:02,094 epoch 24 - iter 20/107 - loss 0.04709886 - samples/sec: 105.38 - lr: 0.012500
2022-05-23 18:42:04,975 epoch 24 - iter 30/107 - loss 0.04378228 - samples/sec: 111.13 - lr: 0.012500
2022-05-23 18:42:07,837 epoch 24 - iter 40/107 - loss 0.04718839 - samples/sec: 111.85 - lr: 0.012500
2022-05-23 18:42:10,811 epoch 24 - iter 50/107 - loss 0.04820598 - samples/sec: 107.63 - lr: 0.012500
2022-05-23 18:42:13,587 epoch 24 - iter 60/107 - loss 0.04787978 - samples/sec: 115.30 - lr: 0.012500
2022-05-23 18:42:16,508 epoch 24 - iter 70/107 - loss 0.04881220 - samples/sec: 109.58 - lr: 0.012500
2022-05-23 18:42:19,515 epoch 24 - iter 80/107 - loss 0.04818735 - samples/sec: 106.45 - lr: 0.012500
2022-05-23 18:42:22,431 epoch 24 - iter 90/107 - loss 0.04802656 - samples/sec: 109.79 - lr: 0.012500
2022-05-23 18:42:25,188 epoch 24 - iter 100/107 - loss 0.04869420 - samples/sec: 116.11 - lr: 0.012500
2022-05-23 18:42:27,067 ----------------------------------------------------------------------------------------------------
2022-05-23 18:42:27,067 EPOCH 24 done: loss 0.0488 - lr 0.012500
2022-05-23 18:42:35,939 Evaluating as a multi-label problem: False
2022-05-23 18:42:35,950 DEV : loss 0.20081186294555664 - f1-score (micro avg)  0.5356
2022-05-23 18:42:36,036 BAD EPOCHS (no improvement): 1
2022-05-23 18:42:36,039 ----------------------------------------------------------------------------------------------------
2022-05-23 18:42:38,984 epoch 25 - iter 10/107 - loss 0.03460149 - samples/sec: 108.73 - lr: 0.012500
2022-05-23 18:42:41,848 epoch 25 - iter 20/107 - loss 0.04132010 - samples/sec: 111.75 - lr: 0.012500
2022-05-23 18:42:44,768 epoch 25 - iter 30/107 - loss 0.04287993 - samples/sec: 109.65 - lr: 0.012500
2022-05-23 18:42:47,651 epoch 25 - iter 40/107 - loss 0.04280489 - samples/sec: 111.02 - lr: 0.012500
2022-05-23 18:42:50,532 epoch 25 - iter 50/107 - loss 0.04347785 - samples/sec: 111.12 - lr: 0.012500
2022-05-23 18:42:53,451 epoch 25 - iter 60/107 - loss 0.04496229 - samples/sec: 109.66 - lr: 0.012500
2022-05-23 18:42:56,488 epoch 25 - iter 70/107 - loss 0.04507442 - samples/sec: 105.38 - lr: 0.012500
2022-05-23 18:42:59,387 epoch 25 - iter 80/107 - loss 0.04387961 - samples/sec: 110.43 - lr: 0.012500
2022-05-23 18:43:02,400 epoch 25 - iter 90/107 - loss 0.04358449 - samples/sec: 106.25 - lr: 0.012500
2022-05-23 18:43:05,485 epoch 25 - iter 100/107 - loss 0.04486199 - samples/sec: 103.75 - lr: 0.012500
2022-05-23 18:43:07,280 ----------------------------------------------------------------------------------------------------
2022-05-23 18:43:07,281 EPOCH 25 done: loss 0.0451 - lr 0.012500
2022-05-23 18:43:16,497 Evaluating as a multi-label problem: False
2022-05-23 18:43:16,508 DEV : loss 0.2039666473865509 - f1-score (micro avg)  0.5278
2022-05-23 18:43:16,594 BAD EPOCHS (no improvement): 2
2022-05-23 18:43:16,830 ----------------------------------------------------------------------------------------------------
2022-05-23 18:43:19,832 epoch 26 - iter 10/107 - loss 0.04435886 - samples/sec: 106.64 - lr: 0.012500
2022-05-23 18:43:22,712 epoch 26 - iter 20/107 - loss 0.04500741 - samples/sec: 111.15 - lr: 0.012500
2022-05-23 18:43:25,553 epoch 26 - iter 30/107 - loss 0.04604149 - samples/sec: 112.68 - lr: 0.012500
2022-05-23 18:43:28,296 epoch 26 - iter 40/107 - loss 0.04754062 - samples/sec: 116.72 - lr: 0.012500
2022-05-23 18:43:31,218 epoch 26 - iter 50/107 - loss 0.04648059 - samples/sec: 109.56 - lr: 0.012500
2022-05-23 18:43:34,240 epoch 26 - iter 60/107 - loss 0.04715406 - samples/sec: 105.94 - lr: 0.012500
2022-05-23 18:43:37,346 epoch 26 - iter 70/107 - loss 0.04575632 - samples/sec: 103.06 - lr: 0.012500
2022-05-23 18:43:40,374 epoch 26 - iter 80/107 - loss 0.04605951 - samples/sec: 105.69 - lr: 0.012500
2022-05-23 18:43:43,386 epoch 26 - iter 90/107 - loss 0.04556865 - samples/sec: 106.29 - lr: 0.012500
2022-05-23 18:43:46,297 epoch 26 - iter 100/107 - loss 0.04616726 - samples/sec: 109.96 - lr: 0.012500
2022-05-23 18:43:48,234 ----------------------------------------------------------------------------------------------------
2022-05-23 18:43:48,234 EPOCH 26 done: loss 0.0470 - lr 0.012500
2022-05-23 18:43:57,259 Evaluating as a multi-label problem: False
2022-05-23 18:43:57,270 DEV : loss 0.2063426524400711 - f1-score (micro avg)  0.5261
2022-05-23 18:43:57,357 BAD EPOCHS (no improvement): 3
2022-05-23 18:43:57,360 ----------------------------------------------------------------------------------------------------
2022-05-23 18:44:00,265 epoch 27 - iter 10/107 - loss 0.04969281 - samples/sec: 110.18 - lr: 0.012500
2022-05-23 18:44:03,357 epoch 27 - iter 20/107 - loss 0.04702556 - samples/sec: 103.54 - lr: 0.012500
2022-05-23 18:44:06,261 epoch 27 - iter 30/107 - loss 0.04857395 - samples/sec: 110.22 - lr: 0.012500
2022-05-23 18:44:09,224 epoch 27 - iter 40/107 - loss 0.04644118 - samples/sec: 108.05 - lr: 0.012500
2022-05-23 18:44:12,170 epoch 27 - iter 50/107 - loss 0.04702926 - samples/sec: 108.63 - lr: 0.012500
2022-05-23 18:44:15,018 epoch 27 - iter 60/107 - loss 0.04668528 - samples/sec: 112.42 - lr: 0.012500
2022-05-23 18:44:17,944 epoch 27 - iter 70/107 - loss 0.04699325 - samples/sec: 109.40 - lr: 0.012500
2022-05-23 18:44:20,827 epoch 27 - iter 80/107 - loss 0.04768081 - samples/sec: 111.02 - lr: 0.012500
2022-05-23 18:44:23,791 epoch 27 - iter 90/107 - loss 0.04804764 - samples/sec: 108.02 - lr: 0.012500
2022-05-23 18:44:26,788 epoch 27 - iter 100/107 - loss 0.04739683 - samples/sec: 106.81 - lr: 0.012500
2022-05-23 18:44:28,585 ----------------------------------------------------------------------------------------------------
2022-05-23 18:44:28,585 EPOCH 27 done: loss 0.0471 - lr 0.012500
2022-05-23 18:44:37,579 Evaluating as a multi-label problem: False
2022-05-23 18:44:37,591 DEV : loss 0.21270957589149475 - f1-score (micro avg)  0.5194
2022-05-23 18:44:37,680 Epoch    27: reducing learning rate of group 0 to 6.2500e-03.
2022-05-23 18:44:37,680 BAD EPOCHS (no improvement): 4
2022-05-23 18:44:37,682 ----------------------------------------------------------------------------------------------------
2022-05-23 18:44:40,625 epoch 28 - iter 10/107 - loss 0.04529062 - samples/sec: 108.77 - lr: 0.006250
2022-05-23 18:44:43,483 epoch 28 - iter 20/107 - loss 0.04632229 - samples/sec: 112.04 - lr: 0.006250
2022-05-23 18:44:46,380 epoch 28 - iter 30/107 - loss 0.04407427 - samples/sec: 110.47 - lr: 0.006250
2022-05-23 18:44:49,268 epoch 28 - iter 40/107 - loss 0.04222439 - samples/sec: 110.84 - lr: 0.006250
2022-05-23 18:44:52,160 epoch 28 - iter 50/107 - loss 0.04255205 - samples/sec: 110.70 - lr: 0.006250
2022-05-23 18:44:55,107 epoch 28 - iter 60/107 - loss 0.04315082 - samples/sec: 108.62 - lr: 0.006250
2022-05-23 18:44:57,982 epoch 28 - iter 70/107 - loss 0.04410381 - samples/sec: 111.33 - lr: 0.006250
2022-05-23 18:45:00,785 epoch 28 - iter 80/107 - loss 0.04461955 - samples/sec: 114.20 - lr: 0.006250
2022-05-23 18:45:03,670 epoch 28 - iter 90/107 - loss 0.04356466 - samples/sec: 110.97 - lr: 0.006250
2022-05-23 18:45:06,557 epoch 28 - iter 100/107 - loss 0.04422765 - samples/sec: 110.87 - lr: 0.006250
2022-05-23 18:45:08,386 ----------------------------------------------------------------------------------------------------
2022-05-23 18:45:08,386 EPOCH 28 done: loss 0.0444 - lr 0.006250
2022-05-23 18:45:17,467 Evaluating as a multi-label problem: False
2022-05-23 18:45:17,478 DEV : loss 0.21195271611213684 - f1-score (micro avg)  0.5284
2022-05-23 18:45:17,565 BAD EPOCHS (no improvement): 1
2022-05-23 18:45:17,598 ----------------------------------------------------------------------------------------------------
2022-05-23 18:45:20,555 epoch 29 - iter 10/107 - loss 0.04480828 - samples/sec: 108.29 - lr: 0.006250
2022-05-23 18:45:23,264 epoch 29 - iter 20/107 - loss 0.04258583 - samples/sec: 118.16 - lr: 0.006250
2022-05-23 18:45:26,183 epoch 29 - iter 30/107 - loss 0.04273942 - samples/sec: 109.66 - lr: 0.006250
2022-05-23 18:45:29,169 epoch 29 - iter 40/107 - loss 0.04531853 - samples/sec: 107.22 - lr: 0.006250
2022-05-23 18:45:32,174 epoch 29 - iter 50/107 - loss 0.04659541 - samples/sec: 106.53 - lr: 0.006250
2022-05-23 18:45:35,216 epoch 29 - iter 60/107 - loss 0.04482681 - samples/sec: 105.23 - lr: 0.006250
2022-05-23 18:45:38,184 epoch 29 - iter 70/107 - loss 0.04400992 - samples/sec: 107.85 - lr: 0.006250
2022-05-23 18:45:41,020 epoch 29 - iter 80/107 - loss 0.04400211 - samples/sec: 112.86 - lr: 0.006250
2022-05-23 18:45:43,899 epoch 29 - iter 90/107 - loss 0.04392043 - samples/sec: 111.20 - lr: 0.006250
2022-05-23 18:45:46,645 epoch 29 - iter 100/107 - loss 0.04355783 - samples/sec: 116.58 - lr: 0.006250
2022-05-23 18:45:48,350 ----------------------------------------------------------------------------------------------------
2022-05-23 18:45:48,350 EPOCH 29 done: loss 0.0435 - lr 0.006250
2022-05-23 18:45:57,136 Evaluating as a multi-label problem: False
2022-05-23 18:45:57,147 DEV : loss 0.21076960861682892 - f1-score (micro avg)  0.5278
2022-05-23 18:45:57,233 BAD EPOCHS (no improvement): 2
2022-05-23 18:45:57,236 ----------------------------------------------------------------------------------------------------
2022-05-23 18:46:00,109 epoch 30 - iter 10/107 - loss 0.03231019 - samples/sec: 111.41 - lr: 0.006250
2022-05-23 18:46:02,914 epoch 30 - iter 20/107 - loss 0.03754632 - samples/sec: 114.11 - lr: 0.006250
2022-05-23 18:46:05,680 epoch 30 - iter 30/107 - loss 0.03906151 - samples/sec: 115.76 - lr: 0.006250
2022-05-23 18:46:08,367 epoch 30 - iter 40/107 - loss 0.04241856 - samples/sec: 119.12 - lr: 0.006250
2022-05-23 18:46:11,161 epoch 30 - iter 50/107 - loss 0.04295481 - samples/sec: 114.60 - lr: 0.006250
2022-05-23 18:46:14,124 epoch 30 - iter 60/107 - loss 0.04376868 - samples/sec: 108.02 - lr: 0.006250
2022-05-23 18:46:17,141 epoch 30 - iter 70/107 - loss 0.04328710 - samples/sec: 106.12 - lr: 0.006250
2022-05-23 18:46:20,035 epoch 30 - iter 80/107 - loss 0.04388238 - samples/sec: 110.58 - lr: 0.006250
2022-05-23 18:46:22,865 epoch 30 - iter 90/107 - loss 0.04424237 - samples/sec: 113.11 - lr: 0.006250
2022-05-23 18:46:25,770 epoch 30 - iter 100/107 - loss 0.04303189 - samples/sec: 110.22 - lr: 0.006250
2022-05-23 18:46:27,574 ----------------------------------------------------------------------------------------------------
2022-05-23 18:46:27,574 EPOCH 30 done: loss 0.0433 - lr 0.006250
2022-05-23 18:46:36,771 Evaluating as a multi-label problem: False
2022-05-23 18:46:36,782 DEV : loss 0.21125788986682892 - f1-score (micro avg)  0.5276
2022-05-23 18:46:36,868 BAD EPOCHS (no improvement): 3
2022-05-23 18:46:36,912 ----------------------------------------------------------------------------------------------------
2022-05-23 18:46:39,866 epoch 31 - iter 10/107 - loss 0.03929303 - samples/sec: 108.38 - lr: 0.006250
2022-05-23 18:46:42,769 epoch 31 - iter 20/107 - loss 0.04148206 - samples/sec: 110.29 - lr: 0.006250
2022-05-23 18:46:45,637 epoch 31 - iter 30/107 - loss 0.04342161 - samples/sec: 111.61 - lr: 0.006250
2022-05-23 18:46:48,672 epoch 31 - iter 40/107 - loss 0.04384550 - samples/sec: 105.47 - lr: 0.006250
2022-05-23 18:46:51,571 epoch 31 - iter 50/107 - loss 0.04465155 - samples/sec: 110.39 - lr: 0.006250
2022-05-23 18:46:54,445 epoch 31 - iter 60/107 - loss 0.04546968 - samples/sec: 111.40 - lr: 0.006250
2022-05-23 18:46:57,272 epoch 31 - iter 70/107 - loss 0.04563186 - samples/sec: 113.23 - lr: 0.006250
2022-05-23 18:47:00,098 epoch 31 - iter 80/107 - loss 0.04533108 - samples/sec: 113.26 - lr: 0.006250
2022-05-23 18:47:02,861 epoch 31 - iter 90/107 - loss 0.04525874 - samples/sec: 115.84 - lr: 0.006250
2022-05-23 18:47:05,753 epoch 31 - iter 100/107 - loss 0.04460727 - samples/sec: 110.71 - lr: 0.006250
2022-05-23 18:47:07,490 ----------------------------------------------------------------------------------------------------
2022-05-23 18:47:07,490 EPOCH 31 done: loss 0.0438 - lr 0.006250
2022-05-23 18:47:16,442 Evaluating as a multi-label problem: False
2022-05-23 18:47:16,453 DEV : loss 0.21465237438678741 - f1-score (micro avg)  0.5212
2022-05-23 18:47:16,543 Epoch    31: reducing learning rate of group 0 to 3.1250e-03.
2022-05-23 18:47:16,543 BAD EPOCHS (no improvement): 4
2022-05-23 18:47:16,546 ----------------------------------------------------------------------------------------------------
2022-05-23 18:47:19,492 epoch 32 - iter 10/107 - loss 0.04300023 - samples/sec: 108.68 - lr: 0.003125
2022-05-23 18:47:22,500 epoch 32 - iter 20/107 - loss 0.04253744 - samples/sec: 106.41 - lr: 0.003125
2022-05-23 18:47:25,356 epoch 32 - iter 30/107 - loss 0.04813114 - samples/sec: 112.08 - lr: 0.003125
2022-05-23 18:47:28,178 epoch 32 - iter 40/107 - loss 0.04685013 - samples/sec: 113.42 - lr: 0.003125
2022-05-23 18:47:30,961 epoch 32 - iter 50/107 - loss 0.04954316 - samples/sec: 115.05 - lr: 0.003125
2022-05-23 18:47:33,928 epoch 32 - iter 60/107 - loss 0.04705873 - samples/sec: 107.86 - lr: 0.003125
2022-05-23 18:47:36,916 epoch 32 - iter 70/107 - loss 0.04641855 - samples/sec: 107.15 - lr: 0.003125
2022-05-23 18:47:39,820 epoch 32 - iter 80/107 - loss 0.04547844 - samples/sec: 110.24 - lr: 0.003125
2022-05-23 18:47:42,733 epoch 32 - iter 90/107 - loss 0.04449920 - samples/sec: 109.88 - lr: 0.003125
2022-05-23 18:47:45,664 epoch 32 - iter 100/107 - loss 0.04419083 - samples/sec: 109.22 - lr: 0.003125
2022-05-23 18:47:47,406 ----------------------------------------------------------------------------------------------------
2022-05-23 18:47:47,406 EPOCH 32 done: loss 0.0439 - lr 0.003125
2022-05-23 18:47:56,328 Evaluating as a multi-label problem: False
2022-05-23 18:47:56,338 DEV : loss 0.21267713606357574 - f1-score (micro avg)  0.5261
2022-05-23 18:47:56,424 BAD EPOCHS (no improvement): 1
2022-05-23 18:47:56,427 ----------------------------------------------------------------------------------------------------
2022-05-23 18:47:59,377 epoch 33 - iter 10/107 - loss 0.04142643 - samples/sec: 108.49 - lr: 0.003125
2022-05-23 18:48:02,209 epoch 33 - iter 20/107 - loss 0.03940648 - samples/sec: 113.06 - lr: 0.003125
2022-05-23 18:48:05,134 epoch 33 - iter 30/107 - loss 0.04220193 - samples/sec: 109.46 - lr: 0.003125
2022-05-23 18:48:08,012 epoch 33 - iter 40/107 - loss 0.04253846 - samples/sec: 111.20 - lr: 0.003125
2022-05-23 18:48:10,946 epoch 33 - iter 50/107 - loss 0.04388722 - samples/sec: 109.12 - lr: 0.003125
2022-05-23 18:48:13,855 epoch 33 - iter 60/107 - loss 0.04473042 - samples/sec: 110.02 - lr: 0.003125
2022-05-23 18:48:16,765 epoch 33 - iter 70/107 - loss 0.04370068 - samples/sec: 110.01 - lr: 0.003125
2022-05-23 18:48:19,578 epoch 33 - iter 80/107 - loss 0.04304188 - samples/sec: 113.81 - lr: 0.003125
2022-05-23 18:48:22,490 epoch 33 - iter 90/107 - loss 0.04419305 - samples/sec: 109.90 - lr: 0.003125
2022-05-23 18:48:25,404 epoch 33 - iter 100/107 - loss 0.04431207 - samples/sec: 109.85 - lr: 0.003125
2022-05-23 18:48:27,155 ----------------------------------------------------------------------------------------------------
2022-05-23 18:48:27,155 EPOCH 33 done: loss 0.0448 - lr 0.003125
2022-05-23 18:48:36,121 Evaluating as a multi-label problem: False
2022-05-23 18:48:36,132 DEV : loss 0.2080894410610199 - f1-score (micro avg)  0.5274
2022-05-23 18:48:36,218 BAD EPOCHS (no improvement): 2
2022-05-23 18:48:36,221 ----------------------------------------------------------------------------------------------------
2022-05-23 18:48:39,045 epoch 34 - iter 10/107 - loss 0.03891992 - samples/sec: 113.36 - lr: 0.003125
2022-05-23 18:48:42,002 epoch 34 - iter 20/107 - loss 0.04227669 - samples/sec: 108.23 - lr: 0.003125
2022-05-23 18:48:44,813 epoch 34 - iter 30/107 - loss 0.04583154 - samples/sec: 113.87 - lr: 0.003125
2022-05-23 18:48:47,710 epoch 34 - iter 40/107 - loss 0.04325822 - samples/sec: 110.50 - lr: 0.003125
2022-05-23 18:48:50,632 epoch 34 - iter 50/107 - loss 0.04251928 - samples/sec: 109.55 - lr: 0.003125
2022-05-23 18:48:53,545 epoch 34 - iter 60/107 - loss 0.04203944 - samples/sec: 109.88 - lr: 0.003125
2022-05-23 18:48:56,420 epoch 34 - iter 70/107 - loss 0.04082408 - samples/sec: 111.35 - lr: 0.003125
2022-05-23 18:48:59,254 epoch 34 - iter 80/107 - loss 0.04144527 - samples/sec: 112.99 - lr: 0.003125
2022-05-23 18:49:02,268 epoch 34 - iter 90/107 - loss 0.04257664 - samples/sec: 106.18 - lr: 0.003125
2022-05-23 18:49:05,196 epoch 34 - iter 100/107 - loss 0.04181064 - samples/sec: 109.34 - lr: 0.003125
2022-05-23 18:49:07,039 ----------------------------------------------------------------------------------------------------
2022-05-23 18:49:07,039 EPOCH 34 done: loss 0.0418 - lr 0.003125
2022-05-23 18:49:15,973 Evaluating as a multi-label problem: False
2022-05-23 18:49:15,984 DEV : loss 0.20969626307487488 - f1-score (micro avg)  0.5316
2022-05-23 18:49:16,071 BAD EPOCHS (no improvement): 3
2022-05-23 18:49:16,073 ----------------------------------------------------------------------------------------------------
2022-05-23 18:49:18,949 epoch 35 - iter 10/107 - loss 0.04353378 - samples/sec: 111.33 - lr: 0.003125
2022-05-23 18:49:21,844 epoch 35 - iter 20/107 - loss 0.04582754 - samples/sec: 110.55 - lr: 0.003125
2022-05-23 18:49:24,827 epoch 35 - iter 30/107 - loss 0.04558410 - samples/sec: 107.32 - lr: 0.003125
2022-05-23 18:49:27,700 epoch 35 - iter 40/107 - loss 0.04649403 - samples/sec: 111.44 - lr: 0.003125
2022-05-23 18:49:30,660 epoch 35 - iter 50/107 - loss 0.04515105 - samples/sec: 108.11 - lr: 0.003125
2022-05-23 18:49:33,452 epoch 35 - iter 60/107 - loss 0.04572315 - samples/sec: 114.67 - lr: 0.003125
2022-05-23 18:49:36,361 epoch 35 - iter 70/107 - loss 0.04561227 - samples/sec: 110.02 - lr: 0.003125
2022-05-23 18:49:39,235 epoch 35 - iter 80/107 - loss 0.04457967 - samples/sec: 111.41 - lr: 0.003125
2022-05-23 18:49:42,220 epoch 35 - iter 90/107 - loss 0.04360034 - samples/sec: 107.22 - lr: 0.003125
2022-05-23 18:49:45,138 epoch 35 - iter 100/107 - loss 0.04403922 - samples/sec: 109.70 - lr: 0.003125
2022-05-23 18:49:46,830 ----------------------------------------------------------------------------------------------------
2022-05-23 18:49:46,830 EPOCH 35 done: loss 0.0439 - lr 0.003125
2022-05-23 18:49:55,734 Evaluating as a multi-label problem: False
2022-05-23 18:49:55,745 DEV : loss 0.21257933974266052 - f1-score (micro avg)  0.5283
2022-05-23 18:49:55,831 Epoch    35: reducing learning rate of group 0 to 1.5625e-03.
2022-05-23 18:49:55,831 BAD EPOCHS (no improvement): 4
2022-05-23 18:49:55,834 ----------------------------------------------------------------------------------------------------
2022-05-23 18:49:58,776 epoch 36 - iter 10/107 - loss 0.04019361 - samples/sec: 108.81 - lr: 0.001563
2022-05-23 18:50:01,643 epoch 36 - iter 20/107 - loss 0.03730870 - samples/sec: 111.68 - lr: 0.001563
2022-05-23 18:50:04,586 epoch 36 - iter 30/107 - loss 0.03860234 - samples/sec: 108.76 - lr: 0.001563
2022-05-23 18:50:07,392 epoch 36 - iter 40/107 - loss 0.03842630 - samples/sec: 114.08 - lr: 0.001563
2022-05-23 18:50:10,279 epoch 36 - iter 50/107 - loss 0.03864565 - samples/sec: 110.88 - lr: 0.001563
2022-05-23 18:50:13,073 epoch 36 - iter 60/107 - loss 0.03892777 - samples/sec: 114.58 - lr: 0.001563
2022-05-23 18:50:16,082 epoch 36 - iter 70/107 - loss 0.03893388 - samples/sec: 106.36 - lr: 0.001563
2022-05-23 18:50:18,968 epoch 36 - iter 80/107 - loss 0.04019422 - samples/sec: 110.90 - lr: 0.001563
2022-05-23 18:50:21,957 epoch 36 - iter 90/107 - loss 0.04097477 - samples/sec: 107.10 - lr: 0.001563
2022-05-23 18:50:24,737 epoch 36 - iter 100/107 - loss 0.04144603 - samples/sec: 115.16 - lr: 0.001563
2022-05-23 18:50:26,527 ----------------------------------------------------------------------------------------------------
2022-05-23 18:50:26,527 EPOCH 36 done: loss 0.0415 - lr 0.001563
2022-05-23 18:50:35,416 Evaluating as a multi-label problem: False
2022-05-23 18:50:35,427 DEV : loss 0.21092642843723297 - f1-score (micro avg)  0.5263
2022-05-23 18:50:35,512 BAD EPOCHS (no improvement): 1
2022-05-23 18:50:35,515 ----------------------------------------------------------------------------------------------------
2022-05-23 18:50:38,315 epoch 37 - iter 10/107 - loss 0.03647589 - samples/sec: 114.36 - lr: 0.001563
2022-05-23 18:50:41,130 epoch 37 - iter 20/107 - loss 0.03971407 - samples/sec: 113.72 - lr: 0.001563
2022-05-23 18:50:44,012 epoch 37 - iter 30/107 - loss 0.03906633 - samples/sec: 111.08 - lr: 0.001563
2022-05-23 18:50:46,960 epoch 37 - iter 40/107 - loss 0.04152045 - samples/sec: 108.56 - lr: 0.001563
2022-05-23 18:50:49,791 epoch 37 - iter 50/107 - loss 0.03916301 - samples/sec: 113.10 - lr: 0.001563
2022-05-23 18:50:52,653 epoch 37 - iter 60/107 - loss 0.04054053 - samples/sec: 111.86 - lr: 0.001563
2022-05-23 18:50:55,526 epoch 37 - iter 70/107 - loss 0.04156305 - samples/sec: 111.39 - lr: 0.001563
2022-05-23 18:50:58,472 epoch 37 - iter 80/107 - loss 0.04181311 - samples/sec: 108.66 - lr: 0.001563
2022-05-23 18:51:01,391 epoch 37 - iter 90/107 - loss 0.04214354 - samples/sec: 109.68 - lr: 0.001563
2022-05-23 18:51:04,135 epoch 37 - iter 100/107 - loss 0.04236902 - samples/sec: 116.64 - lr: 0.001563
2022-05-23 18:51:05,808 ----------------------------------------------------------------------------------------------------
2022-05-23 18:51:05,808 EPOCH 37 done: loss 0.0421 - lr 0.001563
2022-05-23 18:51:14,721 Evaluating as a multi-label problem: False
2022-05-23 18:51:14,732 DEV : loss 0.2121431976556778 - f1-score (micro avg)  0.5321
2022-05-23 18:51:14,818 BAD EPOCHS (no improvement): 2
2022-05-23 18:51:14,821 ----------------------------------------------------------------------------------------------------
2022-05-23 18:51:17,619 epoch 38 - iter 10/107 - loss 0.03699867 - samples/sec: 114.38 - lr: 0.001563
2022-05-23 18:51:20,524 epoch 38 - iter 20/107 - loss 0.03789971 - samples/sec: 110.21 - lr: 0.001563
2022-05-23 18:51:23,446 epoch 38 - iter 30/107 - loss 0.04004441 - samples/sec: 109.53 - lr: 0.001563
2022-05-23 18:51:26,382 epoch 38 - iter 40/107 - loss 0.03959081 - samples/sec: 109.03 - lr: 0.001563
2022-05-23 18:51:29,290 epoch 38 - iter 50/107 - loss 0.04156253 - samples/sec: 110.08 - lr: 0.001563
2022-05-23 18:51:32,227 epoch 38 - iter 60/107 - loss 0.04110980 - samples/sec: 108.99 - lr: 0.001563
2022-05-23 18:51:35,067 epoch 38 - iter 70/107 - loss 0.04163278 - samples/sec: 112.71 - lr: 0.001563
2022-05-23 18:51:37,978 epoch 38 - iter 80/107 - loss 0.04069535 - samples/sec: 109.96 - lr: 0.001563
2022-05-23 18:51:40,903 epoch 38 - iter 90/107 - loss 0.04063072 - samples/sec: 109.45 - lr: 0.001563
2022-05-23 18:51:43,879 epoch 38 - iter 100/107 - loss 0.04098480 - samples/sec: 107.55 - lr: 0.001563
2022-05-23 18:51:45,622 ----------------------------------------------------------------------------------------------------
2022-05-23 18:51:45,622 EPOCH 38 done: loss 0.0417 - lr 0.001563
2022-05-23 18:51:54,603 Evaluating as a multi-label problem: False
2022-05-23 18:51:54,614 DEV : loss 0.21257555484771729 - f1-score (micro avg)  0.531
2022-05-23 18:51:54,703 BAD EPOCHS (no improvement): 3
2022-05-23 18:51:54,705 ----------------------------------------------------------------------------------------------------
2022-05-23 18:51:57,718 epoch 39 - iter 10/107 - loss 0.06436444 - samples/sec: 106.25 - lr: 0.001563
2022-05-23 18:52:00,674 epoch 39 - iter 20/107 - loss 0.05324177 - samples/sec: 108.29 - lr: 0.001563
2022-05-23 18:52:03,593 epoch 39 - iter 30/107 - loss 0.04798406 - samples/sec: 109.68 - lr: 0.001563
2022-05-23 18:52:06,467 epoch 39 - iter 40/107 - loss 0.04603395 - samples/sec: 111.38 - lr: 0.001563
2022-05-23 18:52:09,456 epoch 39 - iter 50/107 - loss 0.04434883 - samples/sec: 107.10 - lr: 0.001563
2022-05-23 18:52:12,328 epoch 39 - iter 60/107 - loss 0.04367380 - samples/sec: 111.45 - lr: 0.001563
2022-05-23 18:52:15,099 epoch 39 - iter 70/107 - loss 0.04385019 - samples/sec: 115.54 - lr: 0.001563
2022-05-23 18:52:17,977 epoch 39 - iter 80/107 - loss 0.04431522 - samples/sec: 111.20 - lr: 0.001563
2022-05-23 18:52:20,851 epoch 39 - iter 90/107 - loss 0.04317478 - samples/sec: 111.37 - lr: 0.001563
2022-05-23 18:52:23,716 epoch 39 - iter 100/107 - loss 0.04303109 - samples/sec: 111.76 - lr: 0.001563
2022-05-23 18:52:25,568 ----------------------------------------------------------------------------------------------------
2022-05-23 18:52:25,568 EPOCH 39 done: loss 0.0436 - lr 0.001563
2022-05-23 18:52:34,458 Evaluating as a multi-label problem: False
2022-05-23 18:52:34,469 DEV : loss 0.2121453583240509 - f1-score (micro avg)  0.5332
2022-05-23 18:52:34,557 Epoch    39: reducing learning rate of group 0 to 7.8125e-04.
2022-05-23 18:52:34,557 BAD EPOCHS (no improvement): 4
2022-05-23 18:52:34,560 ----------------------------------------------------------------------------------------------------
2022-05-23 18:52:37,510 epoch 40 - iter 10/107 - loss 0.03638964 - samples/sec: 108.56 - lr: 0.000781
2022-05-23 18:52:40,369 epoch 40 - iter 20/107 - loss 0.03923472 - samples/sec: 111.95 - lr: 0.000781
2022-05-23 18:52:43,280 epoch 40 - iter 30/107 - loss 0.03888617 - samples/sec: 109.97 - lr: 0.000781
2022-05-23 18:52:46,106 epoch 40 - iter 40/107 - loss 0.03730176 - samples/sec: 113.27 - lr: 0.000781
2022-05-23 18:52:48,994 epoch 40 - iter 50/107 - loss 0.03871773 - samples/sec: 110.85 - lr: 0.000781
2022-05-23 18:52:51,899 epoch 40 - iter 60/107 - loss 0.04093390 - samples/sec: 110.18 - lr: 0.000781
2022-05-23 18:52:54,702 epoch 40 - iter 70/107 - loss 0.04240640 - samples/sec: 114.19 - lr: 0.000781
2022-05-23 18:52:57,756 epoch 40 - iter 80/107 - loss 0.04279601 - samples/sec: 104.83 - lr: 0.000781
2022-05-23 18:53:00,709 epoch 40 - iter 90/107 - loss 0.04357050 - samples/sec: 108.42 - lr: 0.000781
2022-05-23 18:53:03,663 epoch 40 - iter 100/107 - loss 0.04341619 - samples/sec: 108.37 - lr: 0.000781
2022-05-23 18:53:05,480 ----------------------------------------------------------------------------------------------------
2022-05-23 18:53:05,480 EPOCH 40 done: loss 0.0438 - lr 0.000781
2022-05-23 18:53:14,403 Evaluating as a multi-label problem: False
2022-05-23 18:53:14,414 DEV : loss 0.21036159992218018 - f1-score (micro avg)  0.5324
2022-05-23 18:53:14,500 BAD EPOCHS (no improvement): 1
2022-05-23 18:53:14,504 ----------------------------------------------------------------------------------------------------
2022-05-23 18:53:17,389 epoch 41 - iter 10/107 - loss 0.03909039 - samples/sec: 110.95 - lr: 0.000781
2022-05-23 18:53:20,340 epoch 41 - iter 20/107 - loss 0.03717069 - samples/sec: 108.46 - lr: 0.000781
2022-05-23 18:53:23,258 epoch 41 - iter 30/107 - loss 0.03904458 - samples/sec: 109.72 - lr: 0.000781
2022-05-23 18:53:26,080 epoch 41 - iter 40/107 - loss 0.03968864 - samples/sec: 113.42 - lr: 0.000781
2022-05-23 18:53:28,950 epoch 41 - iter 50/107 - loss 0.03856587 - samples/sec: 111.55 - lr: 0.000781
2022-05-23 18:53:31,831 epoch 41 - iter 60/107 - loss 0.04196006 - samples/sec: 111.09 - lr: 0.000781
2022-05-23 18:53:34,711 epoch 41 - iter 70/107 - loss 0.04125124 - samples/sec: 111.18 - lr: 0.000781
2022-05-23 18:53:37,593 epoch 41 - iter 80/107 - loss 0.04122691 - samples/sec: 111.07 - lr: 0.000781
2022-05-23 18:53:40,494 epoch 41 - iter 90/107 - loss 0.04114966 - samples/sec: 110.33 - lr: 0.000781
2022-05-23 18:53:43,563 epoch 41 - iter 100/107 - loss 0.04024291 - samples/sec: 104.30 - lr: 0.000781
2022-05-23 18:53:45,321 ----------------------------------------------------------------------------------------------------
2022-05-23 18:53:45,321 EPOCH 41 done: loss 0.0410 - lr 0.000781
2022-05-23 18:53:54,232 Evaluating as a multi-label problem: False
2022-05-23 18:53:54,243 DEV : loss 0.21003618836402893 - f1-score (micro avg)  0.532
2022-05-23 18:53:54,330 BAD EPOCHS (no improvement): 2
2022-05-23 18:53:54,333 ----------------------------------------------------------------------------------------------------
2022-05-23 18:53:57,198 epoch 42 - iter 10/107 - loss 0.04305796 - samples/sec: 111.76 - lr: 0.000781
2022-05-23 18:54:00,102 epoch 42 - iter 20/107 - loss 0.03859385 - samples/sec: 110.22 - lr: 0.000781
2022-05-23 18:54:03,083 epoch 42 - iter 30/107 - loss 0.04055219 - samples/sec: 107.37 - lr: 0.000781
2022-05-23 18:54:05,964 epoch 42 - iter 40/107 - loss 0.04211687 - samples/sec: 111.11 - lr: 0.000781
2022-05-23 18:54:08,849 epoch 42 - iter 50/107 - loss 0.04253696 - samples/sec: 110.96 - lr: 0.000781
2022-05-23 18:54:11,812 epoch 42 - iter 60/107 - loss 0.04106928 - samples/sec: 108.03 - lr: 0.000781
2022-05-23 18:54:14,621 epoch 42 - iter 70/107 - loss 0.04059049 - samples/sec: 113.95 - lr: 0.000781
2022-05-23 18:54:17,506 epoch 42 - iter 80/107 - loss 0.04085654 - samples/sec: 110.96 - lr: 0.000781
2022-05-23 18:54:20,420 epoch 42 - iter 90/107 - loss 0.04062181 - samples/sec: 109.85 - lr: 0.000781
2022-05-23 18:54:23,334 epoch 42 - iter 100/107 - loss 0.04204775 - samples/sec: 109.83 - lr: 0.000781
2022-05-23 18:54:25,037 ----------------------------------------------------------------------------------------------------
2022-05-23 18:54:25,038 EPOCH 42 done: loss 0.0420 - lr 0.000781
2022-05-23 18:54:33,925 Evaluating as a multi-label problem: False
2022-05-23 18:54:33,937 DEV : loss 0.21032406389713287 - f1-score (micro avg)  0.5331
2022-05-23 18:54:34,023 BAD EPOCHS (no improvement): 3
2022-05-23 18:54:34,026 ----------------------------------------------------------------------------------------------------
2022-05-23 18:54:36,888 epoch 43 - iter 10/107 - loss 0.03218452 - samples/sec: 111.88 - lr: 0.000781
2022-05-23 18:54:39,904 epoch 43 - iter 20/107 - loss 0.03786190 - samples/sec: 106.12 - lr: 0.000781
2022-05-23 18:54:42,814 epoch 43 - iter 30/107 - loss 0.03848161 - samples/sec: 110.01 - lr: 0.000781
2022-05-23 18:54:45,684 epoch 43 - iter 40/107 - loss 0.03927694 - samples/sec: 111.53 - lr: 0.000781
2022-05-23 18:54:48,603 epoch 43 - iter 50/107 - loss 0.03960650 - samples/sec: 109.67 - lr: 0.000781
2022-05-23 18:54:51,642 epoch 43 - iter 60/107 - loss 0.04011213 - samples/sec: 105.33 - lr: 0.000781
2022-05-23 18:54:54,530 epoch 43 - iter 70/107 - loss 0.04056937 - samples/sec: 110.82 - lr: 0.000781
2022-05-23 18:54:57,228 epoch 43 - iter 80/107 - loss 0.04199623 - samples/sec: 118.64 - lr: 0.000781
2022-05-23 18:55:00,177 epoch 43 - iter 90/107 - loss 0.04169895 - samples/sec: 108.58 - lr: 0.000781
2022-05-23 18:55:03,054 epoch 43 - iter 100/107 - loss 0.04121557 - samples/sec: 111.23 - lr: 0.000781
2022-05-23 18:55:04,888 ----------------------------------------------------------------------------------------------------
2022-05-23 18:55:04,888 EPOCH 43 done: loss 0.0414 - lr 0.000781
2022-05-23 18:55:13,848 Evaluating as a multi-label problem: False
2022-05-23 18:55:13,858 DEV : loss 0.20994386076927185 - f1-score (micro avg)  0.5327
2022-05-23 18:55:13,944 Epoch    43: reducing learning rate of group 0 to 3.9063e-04.
2022-05-23 18:55:13,944 BAD EPOCHS (no improvement): 4
2022-05-23 18:55:13,947 ----------------------------------------------------------------------------------------------------
2022-05-23 18:55:16,703 epoch 44 - iter 10/107 - loss 0.04192666 - samples/sec: 116.13 - lr: 0.000391
2022-05-23 18:55:19,569 epoch 44 - iter 20/107 - loss 0.03772194 - samples/sec: 111.73 - lr: 0.000391
2022-05-23 18:55:22,514 epoch 44 - iter 30/107 - loss 0.04182643 - samples/sec: 108.69 - lr: 0.000391
2022-05-23 18:55:25,212 epoch 44 - iter 40/107 - loss 0.04136113 - samples/sec: 118.67 - lr: 0.000391
2022-05-23 18:55:28,211 epoch 44 - iter 50/107 - loss 0.04096747 - samples/sec: 106.73 - lr: 0.000391
2022-05-23 18:55:31,159 epoch 44 - iter 60/107 - loss 0.04162289 - samples/sec: 108.58 - lr: 0.000391
2022-05-23 18:55:34,136 epoch 44 - iter 70/107 - loss 0.04200676 - samples/sec: 107.53 - lr: 0.000391
2022-05-23 18:55:37,072 epoch 44 - iter 80/107 - loss 0.04215349 - samples/sec: 109.01 - lr: 0.000391
2022-05-23 18:55:39,893 epoch 44 - iter 90/107 - loss 0.04178188 - samples/sec: 113.49 - lr: 0.000391
2022-05-23 18:55:42,736 epoch 44 - iter 100/107 - loss 0.04202738 - samples/sec: 112.59 - lr: 0.000391
2022-05-23 18:55:44,526 ----------------------------------------------------------------------------------------------------
2022-05-23 18:55:44,527 EPOCH 44 done: loss 0.0417 - lr 0.000391
2022-05-23 18:55:53,472 Evaluating as a multi-label problem: False
2022-05-23 18:55:53,483 DEV : loss 0.21036440134048462 - f1-score (micro avg)  0.532
2022-05-23 18:55:53,569 BAD EPOCHS (no improvement): 1
2022-05-23 18:55:53,572 ----------------------------------------------------------------------------------------------------
2022-05-23 18:55:56,482 epoch 45 - iter 10/107 - loss 0.05836014 - samples/sec: 110.04 - lr: 0.000391
2022-05-23 18:55:59,413 epoch 45 - iter 20/107 - loss 0.04490039 - samples/sec: 109.19 - lr: 0.000391
2022-05-23 18:56:02,267 epoch 45 - iter 30/107 - loss 0.04509683 - samples/sec: 112.17 - lr: 0.000391
2022-05-23 18:56:05,092 epoch 45 - iter 40/107 - loss 0.04279925 - samples/sec: 113.30 - lr: 0.000391
2022-05-23 18:56:07,910 epoch 45 - iter 50/107 - loss 0.04260135 - samples/sec: 113.59 - lr: 0.000391
2022-05-23 18:56:10,757 epoch 45 - iter 60/107 - loss 0.04263762 - samples/sec: 112.44 - lr: 0.000391
2022-05-23 18:56:13,781 epoch 45 - iter 70/107 - loss 0.04263599 - samples/sec: 105.87 - lr: 0.000391
2022-05-23 18:56:16,675 epoch 45 - iter 80/107 - loss 0.04123371 - samples/sec: 110.60 - lr: 0.000391
2022-05-23 18:56:19,520 epoch 45 - iter 90/107 - loss 0.04154508 - samples/sec: 112.54 - lr: 0.000391
2022-05-23 18:56:22,384 epoch 45 - iter 100/107 - loss 0.04188073 - samples/sec: 111.78 - lr: 0.000391
2022-05-23 18:56:24,226 ----------------------------------------------------------------------------------------------------
2022-05-23 18:56:24,226 EPOCH 45 done: loss 0.0418 - lr 0.000391
2022-05-23 18:56:33,158 Evaluating as a multi-label problem: False
2022-05-23 18:56:33,170 DEV : loss 0.21102164685726166 - f1-score (micro avg)  0.5328
2022-05-23 18:56:33,258 BAD EPOCHS (no improvement): 2
2022-05-23 18:56:33,261 ----------------------------------------------------------------------------------------------------
2022-05-23 18:56:36,200 epoch 46 - iter 10/107 - loss 0.04237343 - samples/sec: 108.92 - lr: 0.000391
2022-05-23 18:56:38,920 epoch 46 - iter 20/107 - loss 0.04347687 - samples/sec: 117.69 - lr: 0.000391
2022-05-23 18:56:41,725 epoch 46 - iter 30/107 - loss 0.04050996 - samples/sec: 114.15 - lr: 0.000391
2022-05-23 18:56:44,457 epoch 46 - iter 40/107 - loss 0.04170709 - samples/sec: 117.15 - lr: 0.000391
2022-05-23 18:56:47,309 epoch 46 - iter 50/107 - loss 0.04082137 - samples/sec: 112.23 - lr: 0.000391
2022-05-23 18:56:50,193 epoch 46 - iter 60/107 - loss 0.04099770 - samples/sec: 111.02 - lr: 0.000391
2022-05-23 18:56:53,016 epoch 46 - iter 70/107 - loss 0.04061846 - samples/sec: 113.38 - lr: 0.000391
2022-05-23 18:56:55,944 epoch 46 - iter 80/107 - loss 0.04192788 - samples/sec: 109.34 - lr: 0.000391
2022-05-23 18:56:58,800 epoch 46 - iter 90/107 - loss 0.04144507 - samples/sec: 112.06 - lr: 0.000391
2022-05-23 18:57:01,720 epoch 46 - iter 100/107 - loss 0.04120322 - samples/sec: 109.61 - lr: 0.000391
2022-05-23 18:57:03,512 ----------------------------------------------------------------------------------------------------
2022-05-23 18:57:03,512 EPOCH 46 done: loss 0.0413 - lr 0.000391
2022-05-23 18:57:12,431 Evaluating as a multi-label problem: False
2022-05-23 18:57:12,442 DEV : loss 0.2112031728029251 - f1-score (micro avg)  0.532
2022-05-23 18:57:12,529 BAD EPOCHS (no improvement): 3
2022-05-23 18:57:12,561 ----------------------------------------------------------------------------------------------------
2022-05-23 18:57:15,460 epoch 47 - iter 10/107 - loss 0.04290861 - samples/sec: 110.42 - lr: 0.000391
2022-05-23 18:57:18,342 epoch 47 - iter 20/107 - loss 0.03985540 - samples/sec: 111.11 - lr: 0.000391
2022-05-23 18:57:21,337 epoch 47 - iter 30/107 - loss 0.04219463 - samples/sec: 106.88 - lr: 0.000391
2022-05-23 18:57:24,256 epoch 47 - iter 40/107 - loss 0.04308904 - samples/sec: 109.67 - lr: 0.000391
2022-05-23 18:57:27,092 epoch 47 - iter 50/107 - loss 0.04387767 - samples/sec: 112.86 - lr: 0.000391
2022-05-23 18:57:30,002 epoch 47 - iter 60/107 - loss 0.04377150 - samples/sec: 110.00 - lr: 0.000391
2022-05-23 18:57:32,830 epoch 47 - iter 70/107 - loss 0.04425907 - samples/sec: 113.20 - lr: 0.000391
2022-05-23 18:57:35,767 epoch 47 - iter 80/107 - loss 0.04376362 - samples/sec: 108.98 - lr: 0.000391
2022-05-23 18:57:38,615 epoch 47 - iter 90/107 - loss 0.04279287 - samples/sec: 112.38 - lr: 0.000391
2022-05-23 18:57:41,560 epoch 47 - iter 100/107 - loss 0.04280168 - samples/sec: 108.72 - lr: 0.000391
2022-05-23 18:57:43,413 ----------------------------------------------------------------------------------------------------
2022-05-23 18:57:43,413 EPOCH 47 done: loss 0.0427 - lr 0.000391
2022-05-23 18:57:52,380 Evaluating as a multi-label problem: False
2022-05-23 18:57:52,390 DEV : loss 0.2112417370080948 - f1-score (micro avg)  0.532
2022-05-23 18:57:52,476 Epoch    47: reducing learning rate of group 0 to 1.9531e-04.
2022-05-23 18:57:52,476 BAD EPOCHS (no improvement): 4
2022-05-23 18:57:52,479 ----------------------------------------------------------------------------------------------------
2022-05-23 18:57:55,461 epoch 48 - iter 10/107 - loss 0.04481833 - samples/sec: 107.36 - lr: 0.000195
2022-05-23 18:57:58,307 epoch 48 - iter 20/107 - loss 0.04353418 - samples/sec: 112.46 - lr: 0.000195
2022-05-23 18:58:01,247 epoch 48 - iter 30/107 - loss 0.04424954 - samples/sec: 108.88 - lr: 0.000195
2022-05-23 18:58:04,093 epoch 48 - iter 40/107 - loss 0.04588705 - samples/sec: 112.48 - lr: 0.000195
2022-05-23 18:58:06,963 epoch 48 - iter 50/107 - loss 0.04344831 - samples/sec: 111.53 - lr: 0.000195
2022-05-23 18:58:09,878 epoch 48 - iter 60/107 - loss 0.04292844 - samples/sec: 109.84 - lr: 0.000195
2022-05-23 18:58:12,768 epoch 48 - iter 70/107 - loss 0.04316472 - samples/sec: 110.74 - lr: 0.000195
2022-05-23 18:58:15,700 epoch 48 - iter 80/107 - loss 0.04253922 - samples/sec: 109.17 - lr: 0.000195
2022-05-23 18:58:18,591 epoch 48 - iter 90/107 - loss 0.04217809 - samples/sec: 110.75 - lr: 0.000195
2022-05-23 18:58:21,501 epoch 48 - iter 100/107 - loss 0.04167548 - samples/sec: 109.98 - lr: 0.000195
2022-05-23 18:58:23,239 ----------------------------------------------------------------------------------------------------
2022-05-23 18:58:23,239 EPOCH 48 done: loss 0.0410 - lr 0.000195
2022-05-23 18:58:32,189 Evaluating as a multi-label problem: False
2022-05-23 18:58:32,200 DEV : loss 0.21140199899673462 - f1-score (micro avg)  0.5328
2022-05-23 18:58:32,286 BAD EPOCHS (no improvement): 1
2022-05-23 18:58:32,288 ----------------------------------------------------------------------------------------------------
2022-05-23 18:58:35,221 epoch 49 - iter 10/107 - loss 0.04397914 - samples/sec: 109.13 - lr: 0.000195
2022-05-23 18:58:38,130 epoch 49 - iter 20/107 - loss 0.04778042 - samples/sec: 110.05 - lr: 0.000195
2022-05-23 18:58:41,029 epoch 49 - iter 30/107 - loss 0.04274612 - samples/sec: 110.42 - lr: 0.000195
2022-05-23 18:58:43,928 epoch 49 - iter 40/107 - loss 0.04102100 - samples/sec: 110.43 - lr: 0.000195
2022-05-23 18:58:46,748 epoch 49 - iter 50/107 - loss 0.04208092 - samples/sec: 113.50 - lr: 0.000195
2022-05-23 18:58:49,622 epoch 49 - iter 60/107 - loss 0.04208918 - samples/sec: 111.38 - lr: 0.000195
2022-05-23 18:58:52,449 epoch 49 - iter 70/107 - loss 0.04158586 - samples/sec: 113.21 - lr: 0.000195
2022-05-23 18:58:55,303 epoch 49 - iter 80/107 - loss 0.04198426 - samples/sec: 112.17 - lr: 0.000195
2022-05-23 18:58:58,176 epoch 49 - iter 90/107 - loss 0.04115985 - samples/sec: 111.45 - lr: 0.000195
2022-05-23 18:59:01,127 epoch 49 - iter 100/107 - loss 0.04000812 - samples/sec: 108.46 - lr: 0.000195
2022-05-23 18:59:02,933 ----------------------------------------------------------------------------------------------------
2022-05-23 18:59:02,933 EPOCH 49 done: loss 0.0400 - lr 0.000195
2022-05-23 18:59:11,898 Evaluating as a multi-label problem: False
2022-05-23 18:59:11,909 DEV : loss 0.21157041192054749 - f1-score (micro avg)  0.5313
2022-05-23 18:59:11,997 BAD EPOCHS (no improvement): 2
2022-05-23 18:59:12,000 ----------------------------------------------------------------------------------------------------
2022-05-23 18:59:15,000 epoch 50 - iter 10/107 - loss 0.03544732 - samples/sec: 106.69 - lr: 0.000195
2022-05-23 18:59:17,922 epoch 50 - iter 20/107 - loss 0.04354417 - samples/sec: 109.58 - lr: 0.000195
2022-05-23 18:59:20,863 epoch 50 - iter 30/107 - loss 0.04124750 - samples/sec: 108.81 - lr: 0.000195
2022-05-23 18:59:23,704 epoch 50 - iter 40/107 - loss 0.04284631 - samples/sec: 112.69 - lr: 0.000195
2022-05-23 18:59:26,547 epoch 50 - iter 50/107 - loss 0.04335973 - samples/sec: 112.61 - lr: 0.000195
2022-05-23 18:59:29,391 epoch 50 - iter 60/107 - loss 0.04272374 - samples/sec: 112.54 - lr: 0.000195
2022-05-23 18:59:32,227 epoch 50 - iter 70/107 - loss 0.04232613 - samples/sec: 112.88 - lr: 0.000195
2022-05-23 18:59:35,128 epoch 50 - iter 80/107 - loss 0.04209908 - samples/sec: 110.34 - lr: 0.000195
2022-05-23 18:59:38,000 epoch 50 - iter 90/107 - loss 0.04159647 - samples/sec: 111.45 - lr: 0.000195
2022-05-23 18:59:40,812 epoch 50 - iter 100/107 - loss 0.03996418 - samples/sec: 113.83 - lr: 0.000195
2022-05-23 18:59:42,662 ----------------------------------------------------------------------------------------------------
2022-05-23 18:59:42,662 EPOCH 50 done: loss 0.0406 - lr 0.000195
2022-05-23 18:59:51,701 Evaluating as a multi-label problem: False
2022-05-23 18:59:51,712 DEV : loss 0.2119445949792862 - f1-score (micro avg)  0.5317
2022-05-23 18:59:51,801 BAD EPOCHS (no improvement): 3
2022-05-23 18:59:51,839 ----------------------------------------------------------------------------------------------------
2022-05-23 18:59:54,740 epoch 51 - iter 10/107 - loss 0.04574744 - samples/sec: 110.39 - lr: 0.000195
2022-05-23 18:59:57,650 epoch 51 - iter 20/107 - loss 0.04345170 - samples/sec: 109.99 - lr: 0.000195
2022-05-23 19:00:00,618 epoch 51 - iter 30/107 - loss 0.04378233 - samples/sec: 107.85 - lr: 0.000195
2022-05-23 19:00:03,509 epoch 51 - iter 40/107 - loss 0.04366240 - samples/sec: 110.73 - lr: 0.000195
2022-05-23 19:00:06,467 epoch 51 - iter 50/107 - loss 0.04435333 - samples/sec: 108.23 - lr: 0.000195
2022-05-23 19:00:09,297 epoch 51 - iter 60/107 - loss 0.04306428 - samples/sec: 113.13 - lr: 0.000195
2022-05-23 19:00:12,186 epoch 51 - iter 70/107 - loss 0.04267907 - samples/sec: 110.77 - lr: 0.000195
2022-05-23 19:00:14,976 epoch 51 - iter 80/107 - loss 0.04283910 - samples/sec: 114.73 - lr: 0.000195
2022-05-23 19:00:17,953 epoch 51 - iter 90/107 - loss 0.04135205 - samples/sec: 107.52 - lr: 0.000195
2022-05-23 19:00:20,825 epoch 51 - iter 100/107 - loss 0.04149582 - samples/sec: 111.47 - lr: 0.000195
2022-05-23 19:00:22,544 ----------------------------------------------------------------------------------------------------
2022-05-23 19:00:22,545 EPOCH 51 done: loss 0.0416 - lr 0.000195
2022-05-23 19:00:31,393 Evaluating as a multi-label problem: False
2022-05-23 19:00:31,404 DEV : loss 0.21171003580093384 - f1-score (micro avg)  0.5309
2022-05-23 19:00:31,489 Epoch    51: reducing learning rate of group 0 to 9.7656e-05.
2022-05-23 19:00:31,489 BAD EPOCHS (no improvement): 4
2022-05-23 19:00:31,508 ----------------------------------------------------------------------------------------------------
2022-05-23 19:00:31,508 ----------------------------------------------------------------------------------------------------
2022-05-23 19:00:31,508 learning rate too small - quitting training!
2022-05-23 19:00:31,508 ----------------------------------------------------------------------------------------------------
2022-05-23 19:02:10,734 ----------------------------------------------------------------------------------------------------
2022-05-23 19:02:10,735 loading file resources/taggers/model_06_r15_run_4/best-model.pt
2022-05-23 19:03:34,690 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-05-23 19:03:59,072 Evaluating as a multi-label problem: False
2022-05-23 19:03:59,085 0.6347	0.3494	0.4507	0.3063
2022-05-23 19:03:59,085 
Results:
- F-score (micro) 0.4507
- F-score (macro) 0.3534
- Accuracy 0.3063

By class:
               precision    recall  f1-score   support

       person     0.7297    0.5035    0.5959       429
     location     0.5906    0.5867    0.5886       150
        group     0.5102    0.1515    0.2336       165
creative-work     0.5000    0.1197    0.1932       142
      product     0.5238    0.0866    0.1486       127
  corporation     0.4444    0.3030    0.3604        66

    micro avg     0.6347    0.3494    0.4507      1079
    macro avg     0.5498    0.2918    0.3534      1079
 weighted avg     0.6049    0.3494    0.4194      1079

2022-05-23 19:03:59,085 ----------------------------------------------------------------------------------------------------
