2022-03-28 11:10:21,002 ----------------------------------------------------------------------------------------------------
2022-03-28 11:10:21,002 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_3): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4362, out_features=4362, bias=True)
  (rnn): LSTM(4362, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-03-28 11:10:21,002 ----------------------------------------------------------------------------------------------------
2022-03-28 11:10:21,002 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-03-28 11:10:21,003 ----------------------------------------------------------------------------------------------------
2022-03-28 11:10:21,003 Parameters:
2022-03-28 11:10:21,003  - learning_rate: "0.100000"
2022-03-28 11:10:21,003  - mini_batch_size: "32"
2022-03-28 11:10:21,003  - patience: "3"
2022-03-28 11:10:21,003  - anneal_factor: "0.5"
2022-03-28 11:10:21,003  - max_epochs: "150"
2022-03-28 11:10:21,003  - shuffle: "True"
2022-03-28 11:10:21,003  - train_with_dev: "False"
2022-03-28 11:10:21,003  - batch_growth_annealing: "False"
2022-03-28 11:10:21,003 ----------------------------------------------------------------------------------------------------
2022-03-28 11:10:21,003 Model training base path: "resources/taggers/model_07_r5_run_2"
2022-03-28 11:10:21,003 ----------------------------------------------------------------------------------------------------
2022-03-28 11:10:21,003 Device: cuda:1
2022-03-28 11:10:21,003 ----------------------------------------------------------------------------------------------------
2022-03-28 11:10:21,003 Embeddings storage mode: cpu
2022-03-28 11:10:21,003 ----------------------------------------------------------------------------------------------------
2022-03-28 11:10:22,744 epoch 1 - iter 10/107 - loss 1.10504023 - samples/sec: 183.89 - lr: 0.100000
2022-03-28 11:10:24,561 epoch 1 - iter 20/107 - loss 0.69746666 - samples/sec: 176.28 - lr: 0.100000
2022-03-28 11:10:26,441 epoch 1 - iter 30/107 - loss 0.55893108 - samples/sec: 170.24 - lr: 0.100000
2022-03-28 11:10:28,270 epoch 1 - iter 40/107 - loss 0.48243991 - samples/sec: 175.06 - lr: 0.100000
2022-03-28 11:10:30,147 epoch 1 - iter 50/107 - loss 0.42742861 - samples/sec: 170.62 - lr: 0.100000
2022-03-28 11:10:32,033 epoch 1 - iter 60/107 - loss 0.40760749 - samples/sec: 169.72 - lr: 0.100000
2022-03-28 11:10:33,905 epoch 1 - iter 70/107 - loss 0.39122739 - samples/sec: 171.03 - lr: 0.100000
2022-03-28 11:10:35,604 epoch 1 - iter 80/107 - loss 0.38317047 - samples/sec: 188.46 - lr: 0.100000
2022-03-28 11:10:37,087 epoch 1 - iter 90/107 - loss 0.37544633 - samples/sec: 216.00 - lr: 0.100000
2022-03-28 11:10:38,588 epoch 1 - iter 100/107 - loss 0.36658769 - samples/sec: 213.28 - lr: 0.100000
2022-03-28 11:10:39,517 ----------------------------------------------------------------------------------------------------
2022-03-28 11:10:39,517 EPOCH 1 done: loss 0.3594 - lr 0.100000
2022-03-28 11:10:45,632 Evaluating as a multi-label problem: False
2022-03-28 11:10:45,642 DEV : loss 0.47697800397872925 - f1-score (micro avg)  0.0993
2022-03-28 11:10:45,732 BAD EPOCHS (no improvement): 0
2022-03-28 11:10:45,734 saving best model
2022-03-28 11:11:10,393 ----------------------------------------------------------------------------------------------------
2022-03-28 11:11:12,319 epoch 2 - iter 10/107 - loss 0.22610455 - samples/sec: 166.23 - lr: 0.100000
2022-03-28 11:11:14,096 epoch 2 - iter 20/107 - loss 0.17619434 - samples/sec: 180.19 - lr: 0.100000
2022-03-28 11:11:15,869 epoch 2 - iter 30/107 - loss 0.19200531 - samples/sec: 180.62 - lr: 0.100000
2022-03-28 11:11:17,629 epoch 2 - iter 40/107 - loss 0.19588137 - samples/sec: 181.95 - lr: 0.100000
2022-03-28 11:11:19,336 epoch 2 - iter 50/107 - loss 0.20322683 - samples/sec: 187.58 - lr: 0.100000
2022-03-28 11:11:21,116 epoch 2 - iter 60/107 - loss 0.19967931 - samples/sec: 179.87 - lr: 0.100000
2022-03-28 11:11:22,858 epoch 2 - iter 70/107 - loss 0.19838878 - samples/sec: 183.76 - lr: 0.100000
2022-03-28 11:11:24,713 epoch 2 - iter 80/107 - loss 0.19789594 - samples/sec: 172.59 - lr: 0.100000
2022-03-28 11:11:26,412 epoch 2 - iter 90/107 - loss 0.19667145 - samples/sec: 188.53 - lr: 0.100000
2022-03-28 11:11:28,179 epoch 2 - iter 100/107 - loss 0.19229090 - samples/sec: 181.18 - lr: 0.100000
2022-03-28 11:11:29,267 ----------------------------------------------------------------------------------------------------
2022-03-28 11:11:29,267 EPOCH 2 done: loss 0.1939 - lr 0.100000
2022-03-28 11:11:35,358 Evaluating as a multi-label problem: False
2022-03-28 11:11:35,369 DEV : loss 0.2699296176433563 - f1-score (micro avg)  0.4439
2022-03-28 11:11:35,458 BAD EPOCHS (no improvement): 0
2022-03-28 11:11:35,461 saving best model
2022-03-28 11:12:00,210 ----------------------------------------------------------------------------------------------------
2022-03-28 11:12:02,152 epoch 3 - iter 10/107 - loss 0.15718368 - samples/sec: 164.97 - lr: 0.100000
2022-03-28 11:12:03,962 epoch 3 - iter 20/107 - loss 0.15818189 - samples/sec: 176.86 - lr: 0.100000
2022-03-28 11:12:05,792 epoch 3 - iter 30/107 - loss 0.15292171 - samples/sec: 174.91 - lr: 0.100000
2022-03-28 11:12:07,588 epoch 3 - iter 40/107 - loss 0.15629920 - samples/sec: 178.30 - lr: 0.100000
2022-03-28 11:12:09,353 epoch 3 - iter 50/107 - loss 0.15063019 - samples/sec: 181.44 - lr: 0.100000
2022-03-28 11:12:11,150 epoch 3 - iter 60/107 - loss 0.15818908 - samples/sec: 178.16 - lr: 0.100000
2022-03-28 11:12:12,969 epoch 3 - iter 70/107 - loss 0.15801544 - samples/sec: 176.02 - lr: 0.100000
2022-03-28 11:12:14,690 epoch 3 - iter 80/107 - loss 0.16039084 - samples/sec: 186.03 - lr: 0.100000
2022-03-28 11:12:16,404 epoch 3 - iter 90/107 - loss 0.15957059 - samples/sec: 186.81 - lr: 0.100000
2022-03-28 11:12:18,238 epoch 3 - iter 100/107 - loss 0.16071628 - samples/sec: 174.60 - lr: 0.100000
2022-03-28 11:12:19,487 ----------------------------------------------------------------------------------------------------
2022-03-28 11:12:19,488 EPOCH 3 done: loss 0.1603 - lr 0.100000
2022-03-28 11:12:25,723 Evaluating as a multi-label problem: False
2022-03-28 11:12:25,734 DEV : loss 0.29148533940315247 - f1-score (micro avg)  0.4213
2022-03-28 11:12:25,822 BAD EPOCHS (no improvement): 1
2022-03-28 11:12:25,824 ----------------------------------------------------------------------------------------------------
2022-03-28 11:12:27,675 epoch 4 - iter 10/107 - loss 0.12593058 - samples/sec: 173.02 - lr: 0.100000
2022-03-28 11:12:29,586 epoch 4 - iter 20/107 - loss 0.13490371 - samples/sec: 167.58 - lr: 0.100000
2022-03-28 11:12:31,425 epoch 4 - iter 30/107 - loss 0.13618409 - samples/sec: 174.09 - lr: 0.100000
2022-03-28 11:12:33,164 epoch 4 - iter 40/107 - loss 0.13910346 - samples/sec: 184.08 - lr: 0.100000
2022-03-28 11:12:34,892 epoch 4 - iter 50/107 - loss 0.13797571 - samples/sec: 185.23 - lr: 0.100000
2022-03-28 11:12:36,620 epoch 4 - iter 60/107 - loss 0.13278358 - samples/sec: 185.28 - lr: 0.100000
2022-03-28 11:12:38,416 epoch 4 - iter 70/107 - loss 0.13783579 - samples/sec: 178.33 - lr: 0.100000
2022-03-28 11:12:40,213 epoch 4 - iter 80/107 - loss 0.13816672 - samples/sec: 178.17 - lr: 0.100000
2022-03-28 11:12:41,969 epoch 4 - iter 90/107 - loss 0.13813627 - samples/sec: 182.27 - lr: 0.100000
2022-03-28 11:12:43,670 epoch 4 - iter 100/107 - loss 0.13801323 - samples/sec: 188.29 - lr: 0.100000
2022-03-28 11:12:44,703 ----------------------------------------------------------------------------------------------------
2022-03-28 11:12:44,703 EPOCH 4 done: loss 0.1384 - lr 0.100000
2022-03-28 11:12:50,739 Evaluating as a multi-label problem: False
2022-03-28 11:12:50,750 DEV : loss 0.2720603048801422 - f1-score (micro avg)  0.4754
2022-03-28 11:12:50,839 BAD EPOCHS (no improvement): 0
2022-03-28 11:12:50,841 saving best model
2022-03-28 11:13:15,712 ----------------------------------------------------------------------------------------------------
2022-03-28 11:13:17,472 epoch 5 - iter 10/107 - loss 0.10751371 - samples/sec: 181.98 - lr: 0.100000
2022-03-28 11:13:19,150 epoch 5 - iter 20/107 - loss 0.12112918 - samples/sec: 190.86 - lr: 0.100000
2022-03-28 11:13:20,920 epoch 5 - iter 30/107 - loss 0.12185006 - samples/sec: 180.88 - lr: 0.100000
2022-03-28 11:13:22,658 epoch 5 - iter 40/107 - loss 0.12690868 - samples/sec: 184.27 - lr: 0.100000
2022-03-28 11:13:24,412 epoch 5 - iter 50/107 - loss 0.12219355 - samples/sec: 182.47 - lr: 0.100000
2022-03-28 11:13:26,270 epoch 5 - iter 60/107 - loss 0.12564909 - samples/sec: 172.35 - lr: 0.100000
2022-03-28 11:13:28,068 epoch 5 - iter 70/107 - loss 0.12942766 - samples/sec: 178.05 - lr: 0.100000
2022-03-28 11:13:29,786 epoch 5 - iter 80/107 - loss 0.13221194 - samples/sec: 186.41 - lr: 0.100000
2022-03-28 11:13:31,483 epoch 5 - iter 90/107 - loss 0.13324744 - samples/sec: 188.69 - lr: 0.100000
2022-03-28 11:13:33,242 epoch 5 - iter 100/107 - loss 0.13193879 - samples/sec: 181.95 - lr: 0.100000
2022-03-28 11:13:34,381 ----------------------------------------------------------------------------------------------------
2022-03-28 11:13:34,381 EPOCH 5 done: loss 0.1308 - lr 0.100000
2022-03-28 11:13:40,489 Evaluating as a multi-label problem: False
2022-03-28 11:13:40,500 DEV : loss 0.22760987281799316 - f1-score (micro avg)  0.4886
2022-03-28 11:13:40,590 BAD EPOCHS (no improvement): 0
2022-03-28 11:13:40,594 saving best model
2022-03-28 11:14:05,889 ----------------------------------------------------------------------------------------------------
2022-03-28 11:14:07,692 epoch 6 - iter 10/107 - loss 0.10114721 - samples/sec: 177.66 - lr: 0.100000
2022-03-28 11:14:09,347 epoch 6 - iter 20/107 - loss 0.11799041 - samples/sec: 193.43 - lr: 0.100000
2022-03-28 11:14:11,142 epoch 6 - iter 30/107 - loss 0.12099058 - samples/sec: 178.40 - lr: 0.100000
2022-03-28 11:14:12,986 epoch 6 - iter 40/107 - loss 0.11110031 - samples/sec: 173.67 - lr: 0.100000
2022-03-28 11:14:14,851 epoch 6 - iter 50/107 - loss 0.10982773 - samples/sec: 171.60 - lr: 0.100000
2022-03-28 11:14:16,632 epoch 6 - iter 60/107 - loss 0.11314793 - samples/sec: 179.81 - lr: 0.100000
2022-03-28 11:14:18,391 epoch 6 - iter 70/107 - loss 0.11449594 - samples/sec: 181.97 - lr: 0.100000
2022-03-28 11:14:20,128 epoch 6 - iter 80/107 - loss 0.11470685 - samples/sec: 184.37 - lr: 0.100000
2022-03-28 11:14:21,866 epoch 6 - iter 90/107 - loss 0.11678749 - samples/sec: 184.22 - lr: 0.100000
2022-03-28 11:14:23,667 epoch 6 - iter 100/107 - loss 0.11474191 - samples/sec: 177.72 - lr: 0.100000
2022-03-28 11:14:24,705 ----------------------------------------------------------------------------------------------------
2022-03-28 11:14:24,705 EPOCH 6 done: loss 0.1163 - lr 0.100000
2022-03-28 11:14:30,814 Evaluating as a multi-label problem: False
2022-03-28 11:14:30,824 DEV : loss 0.2074843794107437 - f1-score (micro avg)  0.5118
2022-03-28 11:14:30,914 BAD EPOCHS (no improvement): 0
2022-03-28 11:14:30,934 saving best model
2022-03-28 11:14:55,414 ----------------------------------------------------------------------------------------------------
2022-03-28 11:14:57,313 epoch 7 - iter 10/107 - loss 0.09239363 - samples/sec: 168.70 - lr: 0.100000
2022-03-28 11:14:59,152 epoch 7 - iter 20/107 - loss 0.10245259 - samples/sec: 174.12 - lr: 0.100000
2022-03-28 11:15:01,021 epoch 7 - iter 30/107 - loss 0.10798015 - samples/sec: 171.31 - lr: 0.100000
2022-03-28 11:15:02,843 epoch 7 - iter 40/107 - loss 0.10894066 - samples/sec: 175.65 - lr: 0.100000
2022-03-28 11:15:04,586 epoch 7 - iter 50/107 - loss 0.10838876 - samples/sec: 183.74 - lr: 0.100000
2022-03-28 11:15:06,256 epoch 7 - iter 60/107 - loss 0.10751651 - samples/sec: 191.75 - lr: 0.100000
2022-03-28 11:15:07,930 epoch 7 - iter 70/107 - loss 0.10726185 - samples/sec: 191.24 - lr: 0.100000
2022-03-28 11:15:09,655 epoch 7 - iter 80/107 - loss 0.10899081 - samples/sec: 185.62 - lr: 0.100000
2022-03-28 11:15:11,416 epoch 7 - iter 90/107 - loss 0.11170801 - samples/sec: 181.79 - lr: 0.100000
2022-03-28 11:15:13,172 epoch 7 - iter 100/107 - loss 0.11002734 - samples/sec: 182.28 - lr: 0.100000
2022-03-28 11:15:14,337 ----------------------------------------------------------------------------------------------------
2022-03-28 11:15:14,337 EPOCH 7 done: loss 0.1088 - lr 0.100000
2022-03-28 11:15:20,533 Evaluating as a multi-label problem: False
2022-03-28 11:15:20,544 DEV : loss 0.19179753959178925 - f1-score (micro avg)  0.5201
2022-03-28 11:15:20,633 BAD EPOCHS (no improvement): 0
2022-03-28 11:15:20,690 saving best model
2022-03-28 11:15:45,196 ----------------------------------------------------------------------------------------------------
2022-03-28 11:15:47,332 epoch 8 - iter 10/107 - loss 0.11735116 - samples/sec: 149.99 - lr: 0.100000
2022-03-28 11:15:49,354 epoch 8 - iter 20/107 - loss 0.10917336 - samples/sec: 158.38 - lr: 0.100000
2022-03-28 11:15:51,606 epoch 8 - iter 30/107 - loss 0.11134620 - samples/sec: 142.16 - lr: 0.100000
2022-03-28 11:15:53,750 epoch 8 - iter 40/107 - loss 0.10878190 - samples/sec: 149.37 - lr: 0.100000
2022-03-28 11:15:56,048 epoch 8 - iter 50/107 - loss 0.10406616 - samples/sec: 139.34 - lr: 0.100000
2022-03-28 11:15:58,321 epoch 8 - iter 60/107 - loss 0.10443338 - samples/sec: 140.85 - lr: 0.100000
2022-03-28 11:16:00,575 epoch 8 - iter 70/107 - loss 0.10444725 - samples/sec: 142.07 - lr: 0.100000
2022-03-28 11:16:02,784 epoch 8 - iter 80/107 - loss 0.10535222 - samples/sec: 144.91 - lr: 0.100000
2022-03-28 11:16:05,125 epoch 8 - iter 90/107 - loss 0.10249532 - samples/sec: 136.80 - lr: 0.100000
2022-03-28 11:16:07,436 epoch 8 - iter 100/107 - loss 0.10225632 - samples/sec: 138.51 - lr: 0.100000
2022-03-28 11:16:08,757 ----------------------------------------------------------------------------------------------------
2022-03-28 11:16:08,757 EPOCH 8 done: loss 0.1019 - lr 0.100000
2022-03-28 11:16:16,372 Evaluating as a multi-label problem: False
2022-03-28 11:16:16,384 DEV : loss 0.1974801868200302 - f1-score (micro avg)  0.5282
2022-03-28 11:16:16,503 BAD EPOCHS (no improvement): 0
2022-03-28 11:16:16,506 saving best model
2022-03-28 11:16:43,012 ----------------------------------------------------------------------------------------------------
2022-03-28 11:16:45,296 epoch 9 - iter 10/107 - loss 0.08537081 - samples/sec: 140.25 - lr: 0.100000
2022-03-28 11:16:47,562 epoch 9 - iter 20/107 - loss 0.09757061 - samples/sec: 141.27 - lr: 0.100000
2022-03-28 11:16:49,811 epoch 9 - iter 30/107 - loss 0.09836703 - samples/sec: 142.34 - lr: 0.100000
2022-03-28 11:16:52,029 epoch 9 - iter 40/107 - loss 0.09419803 - samples/sec: 144.36 - lr: 0.100000
2022-03-28 11:16:54,300 epoch 9 - iter 50/107 - loss 0.09516154 - samples/sec: 141.03 - lr: 0.100000
2022-03-28 11:16:56,538 epoch 9 - iter 60/107 - loss 0.09777417 - samples/sec: 143.01 - lr: 0.100000
2022-03-28 11:16:58,851 epoch 9 - iter 70/107 - loss 0.09560532 - samples/sec: 138.45 - lr: 0.100000
2022-03-28 11:17:01,111 epoch 9 - iter 80/107 - loss 0.09536763 - samples/sec: 141.68 - lr: 0.100000
2022-03-28 11:17:03,291 epoch 9 - iter 90/107 - loss 0.09556983 - samples/sec: 146.84 - lr: 0.100000
2022-03-28 11:17:05,460 epoch 9 - iter 100/107 - loss 0.09465529 - samples/sec: 147.60 - lr: 0.100000
2022-03-28 11:17:06,864 ----------------------------------------------------------------------------------------------------
2022-03-28 11:17:06,864 EPOCH 9 done: loss 0.0966 - lr 0.100000
2022-03-28 11:17:14,427 Evaluating as a multi-label problem: False
2022-03-28 11:17:14,439 DEV : loss 0.18401296436786652 - f1-score (micro avg)  0.5186
2022-03-28 11:17:14,553 BAD EPOCHS (no improvement): 1
2022-03-28 11:17:14,578 ----------------------------------------------------------------------------------------------------
2022-03-28 11:17:16,770 epoch 10 - iter 10/107 - loss 0.09504733 - samples/sec: 146.11 - lr: 0.100000
2022-03-28 11:17:19,029 epoch 10 - iter 20/107 - loss 0.09004903 - samples/sec: 141.71 - lr: 0.100000
2022-03-28 11:17:21,257 epoch 10 - iter 30/107 - loss 0.08838058 - samples/sec: 143.69 - lr: 0.100000
2022-03-28 11:17:23,415 epoch 10 - iter 40/107 - loss 0.08575262 - samples/sec: 148.38 - lr: 0.100000
2022-03-28 11:17:25,722 epoch 10 - iter 50/107 - loss 0.08469801 - samples/sec: 138.74 - lr: 0.100000
2022-03-28 11:17:27,979 epoch 10 - iter 60/107 - loss 0.08901401 - samples/sec: 141.88 - lr: 0.100000
2022-03-28 11:17:30,222 epoch 10 - iter 70/107 - loss 0.09137138 - samples/sec: 142.71 - lr: 0.100000
2022-03-28 11:17:32,361 epoch 10 - iter 80/107 - loss 0.09300944 - samples/sec: 149.72 - lr: 0.100000
2022-03-28 11:17:34,558 epoch 10 - iter 90/107 - loss 0.09483977 - samples/sec: 145.71 - lr: 0.100000
2022-03-28 11:17:36,795 epoch 10 - iter 100/107 - loss 0.09331611 - samples/sec: 143.12 - lr: 0.100000
2022-03-28 11:17:38,149 ----------------------------------------------------------------------------------------------------
2022-03-28 11:17:38,150 EPOCH 10 done: loss 0.0931 - lr 0.100000
2022-03-28 11:17:45,776 Evaluating as a multi-label problem: False
2022-03-28 11:17:45,788 DEV : loss 0.19629979133605957 - f1-score (micro avg)  0.5269
2022-03-28 11:17:45,905 BAD EPOCHS (no improvement): 2
2022-03-28 11:17:45,907 ----------------------------------------------------------------------------------------------------
2022-03-28 11:17:48,145 epoch 11 - iter 10/107 - loss 0.09986922 - samples/sec: 143.03 - lr: 0.100000
2022-03-28 11:17:50,337 epoch 11 - iter 20/107 - loss 0.08473881 - samples/sec: 146.09 - lr: 0.100000
2022-03-28 11:17:52,605 epoch 11 - iter 30/107 - loss 0.08377329 - samples/sec: 141.13 - lr: 0.100000
2022-03-28 11:17:54,883 epoch 11 - iter 40/107 - loss 0.08060268 - samples/sec: 140.53 - lr: 0.100000
2022-03-28 11:17:57,147 epoch 11 - iter 50/107 - loss 0.08416952 - samples/sec: 141.42 - lr: 0.100000
2022-03-28 11:17:59,400 epoch 11 - iter 60/107 - loss 0.08629561 - samples/sec: 142.14 - lr: 0.100000
2022-03-28 11:18:01,602 epoch 11 - iter 70/107 - loss 0.08744887 - samples/sec: 145.40 - lr: 0.100000
2022-03-28 11:18:03,782 epoch 11 - iter 80/107 - loss 0.08605158 - samples/sec: 146.83 - lr: 0.100000
2022-03-28 11:18:05,967 epoch 11 - iter 90/107 - loss 0.08594222 - samples/sec: 146.53 - lr: 0.100000
2022-03-28 11:18:08,145 epoch 11 - iter 100/107 - loss 0.08646942 - samples/sec: 146.98 - lr: 0.100000
2022-03-28 11:18:09,540 ----------------------------------------------------------------------------------------------------
2022-03-28 11:18:09,540 EPOCH 11 done: loss 0.0870 - lr 0.100000
2022-03-28 11:18:17,138 Evaluating as a multi-label problem: False
2022-03-28 11:18:17,150 DEV : loss 0.20507515966892242 - f1-score (micro avg)  0.4884
2022-03-28 11:18:17,265 BAD EPOCHS (no improvement): 3
2022-03-28 11:18:17,267 ----------------------------------------------------------------------------------------------------
2022-03-28 11:18:19,333 epoch 12 - iter 10/107 - loss 0.07067187 - samples/sec: 154.97 - lr: 0.100000
2022-03-28 11:18:21,555 epoch 12 - iter 20/107 - loss 0.07789059 - samples/sec: 144.08 - lr: 0.100000
2022-03-28 11:18:23,858 epoch 12 - iter 30/107 - loss 0.07690685 - samples/sec: 139.03 - lr: 0.100000
2022-03-28 11:18:25,953 epoch 12 - iter 40/107 - loss 0.07791832 - samples/sec: 152.84 - lr: 0.100000
2022-03-28 11:18:28,195 epoch 12 - iter 50/107 - loss 0.07944619 - samples/sec: 142.80 - lr: 0.100000
2022-03-28 11:18:30,354 epoch 12 - iter 60/107 - loss 0.08216836 - samples/sec: 148.29 - lr: 0.100000
2022-03-28 11:18:32,569 epoch 12 - iter 70/107 - loss 0.08195800 - samples/sec: 144.57 - lr: 0.100000
2022-03-28 11:18:34,833 epoch 12 - iter 80/107 - loss 0.08397353 - samples/sec: 141.43 - lr: 0.100000
2022-03-28 11:18:37,040 epoch 12 - iter 90/107 - loss 0.08157472 - samples/sec: 145.00 - lr: 0.100000
2022-03-28 11:18:39,269 epoch 12 - iter 100/107 - loss 0.08359690 - samples/sec: 143.65 - lr: 0.100000
2022-03-28 11:18:40,612 ----------------------------------------------------------------------------------------------------
2022-03-28 11:18:40,613 EPOCH 12 done: loss 0.0844 - lr 0.100000
2022-03-28 11:18:48,230 Evaluating as a multi-label problem: False
2022-03-28 11:18:48,241 DEV : loss 0.2046191543340683 - f1-score (micro avg)  0.4911
2022-03-28 11:18:48,356 Epoch    12: reducing learning rate of group 0 to 5.0000e-02.
2022-03-28 11:18:48,356 BAD EPOCHS (no improvement): 4
2022-03-28 11:18:48,373 ----------------------------------------------------------------------------------------------------
2022-03-28 11:18:50,604 epoch 13 - iter 10/107 - loss 0.06047769 - samples/sec: 143.49 - lr: 0.050000
2022-03-28 11:18:52,815 epoch 13 - iter 20/107 - loss 0.06601264 - samples/sec: 144.84 - lr: 0.050000
2022-03-28 11:18:55,059 epoch 13 - iter 30/107 - loss 0.06640885 - samples/sec: 142.66 - lr: 0.050000
2022-03-28 11:18:57,326 epoch 13 - iter 40/107 - loss 0.06853308 - samples/sec: 141.20 - lr: 0.050000
2022-03-28 11:18:59,498 epoch 13 - iter 50/107 - loss 0.07097613 - samples/sec: 147.39 - lr: 0.050000
2022-03-28 11:19:01,747 epoch 13 - iter 60/107 - loss 0.07051376 - samples/sec: 142.38 - lr: 0.050000
2022-03-28 11:19:03,862 epoch 13 - iter 70/107 - loss 0.07248674 - samples/sec: 151.37 - lr: 0.050000
2022-03-28 11:19:06,026 epoch 13 - iter 80/107 - loss 0.07182730 - samples/sec: 147.96 - lr: 0.050000
2022-03-28 11:19:08,322 epoch 13 - iter 90/107 - loss 0.07205522 - samples/sec: 139.47 - lr: 0.050000
2022-03-28 11:19:10,548 epoch 13 - iter 100/107 - loss 0.07216240 - samples/sec: 143.78 - lr: 0.050000
2022-03-28 11:19:11,943 ----------------------------------------------------------------------------------------------------
2022-03-28 11:19:11,943 EPOCH 13 done: loss 0.0733 - lr 0.050000
2022-03-28 11:19:19,581 Evaluating as a multi-label problem: False
2022-03-28 11:19:19,592 DEV : loss 0.18264523148536682 - f1-score (micro avg)  0.5073
2022-03-28 11:19:19,710 BAD EPOCHS (no improvement): 1
2022-03-28 11:19:19,713 ----------------------------------------------------------------------------------------------------
2022-03-28 11:19:22,003 epoch 14 - iter 10/107 - loss 0.06703730 - samples/sec: 139.83 - lr: 0.050000
2022-03-28 11:19:24,293 epoch 14 - iter 20/107 - loss 0.07211562 - samples/sec: 139.79 - lr: 0.050000
2022-03-28 11:19:26,492 epoch 14 - iter 30/107 - loss 0.06837404 - samples/sec: 145.59 - lr: 0.050000
2022-03-28 11:19:28,755 epoch 14 - iter 40/107 - loss 0.06858758 - samples/sec: 141.42 - lr: 0.050000
2022-03-28 11:19:31,003 epoch 14 - iter 50/107 - loss 0.07184974 - samples/sec: 142.44 - lr: 0.050000
2022-03-28 11:19:33,201 epoch 14 - iter 60/107 - loss 0.07222752 - samples/sec: 145.65 - lr: 0.050000
2022-03-28 11:19:35,463 epoch 14 - iter 70/107 - loss 0.07156312 - samples/sec: 141.51 - lr: 0.050000
2022-03-28 11:19:37,664 epoch 14 - iter 80/107 - loss 0.07115818 - samples/sec: 145.49 - lr: 0.050000
2022-03-28 11:19:39,860 epoch 14 - iter 90/107 - loss 0.07073650 - samples/sec: 145.76 - lr: 0.050000
2022-03-28 11:19:42,070 epoch 14 - iter 100/107 - loss 0.07033019 - samples/sec: 144.91 - lr: 0.050000
2022-03-28 11:19:43,434 ----------------------------------------------------------------------------------------------------
2022-03-28 11:19:43,434 EPOCH 14 done: loss 0.0713 - lr 0.050000
2022-03-28 11:19:50,980 Evaluating as a multi-label problem: False
2022-03-28 11:19:50,991 DEV : loss 0.18690621852874756 - f1-score (micro avg)  0.5146
2022-03-28 11:19:51,107 BAD EPOCHS (no improvement): 2
2022-03-28 11:19:51,110 ----------------------------------------------------------------------------------------------------
2022-03-28 11:19:53,334 epoch 15 - iter 10/107 - loss 0.06694124 - samples/sec: 143.97 - lr: 0.050000
2022-03-28 11:19:55,516 epoch 15 - iter 20/107 - loss 0.06060175 - samples/sec: 146.70 - lr: 0.050000
2022-03-28 11:19:57,757 epoch 15 - iter 30/107 - loss 0.06563773 - samples/sec: 142.92 - lr: 0.050000
2022-03-28 11:19:59,935 epoch 15 - iter 40/107 - loss 0.06474082 - samples/sec: 146.94 - lr: 0.050000
2022-03-28 11:20:02,086 epoch 15 - iter 50/107 - loss 0.06568740 - samples/sec: 148.88 - lr: 0.050000
2022-03-28 11:20:04,312 epoch 15 - iter 60/107 - loss 0.06719619 - samples/sec: 143.80 - lr: 0.050000
2022-03-28 11:20:06,570 epoch 15 - iter 70/107 - loss 0.06585203 - samples/sec: 141.82 - lr: 0.050000
2022-03-28 11:20:08,867 epoch 15 - iter 80/107 - loss 0.06545116 - samples/sec: 139.33 - lr: 0.050000
2022-03-28 11:20:10,963 epoch 15 - iter 90/107 - loss 0.06650489 - samples/sec: 152.74 - lr: 0.050000
2022-03-28 11:20:13,103 epoch 15 - iter 100/107 - loss 0.06582195 - samples/sec: 149.62 - lr: 0.050000
2022-03-28 11:20:14,363 ----------------------------------------------------------------------------------------------------
2022-03-28 11:20:14,363 EPOCH 15 done: loss 0.0663 - lr 0.050000
2022-03-28 11:20:21,553 Evaluating as a multi-label problem: False
2022-03-28 11:20:21,564 DEV : loss 0.18413323163986206 - f1-score (micro avg)  0.5484
2022-03-28 11:20:21,678 BAD EPOCHS (no improvement): 0
2022-03-28 11:20:21,681 saving best model
2022-03-28 11:20:46,764 ----------------------------------------------------------------------------------------------------
2022-03-28 11:20:48,978 epoch 16 - iter 10/107 - loss 0.06964296 - samples/sec: 144.69 - lr: 0.050000
2022-03-28 11:20:51,172 epoch 16 - iter 20/107 - loss 0.06471101 - samples/sec: 145.94 - lr: 0.050000
2022-03-28 11:20:53,392 epoch 16 - iter 30/107 - loss 0.06873675 - samples/sec: 144.24 - lr: 0.050000
2022-03-28 11:20:55,658 epoch 16 - iter 40/107 - loss 0.06867907 - samples/sec: 141.27 - lr: 0.050000
2022-03-28 11:20:57,938 epoch 16 - iter 50/107 - loss 0.06853267 - samples/sec: 140.40 - lr: 0.050000
2022-03-28 11:21:00,164 epoch 16 - iter 60/107 - loss 0.06838160 - samples/sec: 143.84 - lr: 0.050000
2022-03-28 11:21:02,436 epoch 16 - iter 70/107 - loss 0.06706586 - samples/sec: 140.91 - lr: 0.050000
2022-03-28 11:21:04,566 epoch 16 - iter 80/107 - loss 0.06812483 - samples/sec: 150.30 - lr: 0.050000
2022-03-28 11:21:06,816 epoch 16 - iter 90/107 - loss 0.06753018 - samples/sec: 142.29 - lr: 0.050000
2022-03-28 11:21:09,024 epoch 16 - iter 100/107 - loss 0.06674867 - samples/sec: 144.98 - lr: 0.050000
2022-03-28 11:21:10,371 ----------------------------------------------------------------------------------------------------
2022-03-28 11:21:10,371 EPOCH 16 done: loss 0.0674 - lr 0.050000
2022-03-28 11:21:17,934 Evaluating as a multi-label problem: False
2022-03-28 11:21:17,945 DEV : loss 0.18848776817321777 - f1-score (micro avg)  0.5242
2022-03-28 11:21:18,060 BAD EPOCHS (no improvement): 1
2022-03-28 11:21:18,078 ----------------------------------------------------------------------------------------------------
2022-03-28 11:21:20,301 epoch 17 - iter 10/107 - loss 0.05387804 - samples/sec: 144.03 - lr: 0.050000
2022-03-28 11:21:22,513 epoch 17 - iter 20/107 - loss 0.06625618 - samples/sec: 144.78 - lr: 0.050000
2022-03-28 11:21:24,701 epoch 17 - iter 30/107 - loss 0.06290802 - samples/sec: 146.35 - lr: 0.050000
2022-03-28 11:21:26,903 epoch 17 - iter 40/107 - loss 0.05972900 - samples/sec: 145.38 - lr: 0.050000
2022-03-28 11:21:29,074 epoch 17 - iter 50/107 - loss 0.06302343 - samples/sec: 147.46 - lr: 0.050000
2022-03-28 11:21:31,232 epoch 17 - iter 60/107 - loss 0.06130771 - samples/sec: 148.34 - lr: 0.050000
2022-03-28 11:21:33,508 epoch 17 - iter 70/107 - loss 0.06108282 - samples/sec: 140.67 - lr: 0.050000
2022-03-28 11:21:35,833 epoch 17 - iter 80/107 - loss 0.06179968 - samples/sec: 137.70 - lr: 0.050000
2022-03-28 11:21:38,037 epoch 17 - iter 90/107 - loss 0.06336471 - samples/sec: 145.26 - lr: 0.050000
2022-03-28 11:21:40,226 epoch 17 - iter 100/107 - loss 0.06290915 - samples/sec: 146.28 - lr: 0.050000
2022-03-28 11:21:41,589 ----------------------------------------------------------------------------------------------------
2022-03-28 11:21:41,589 EPOCH 17 done: loss 0.0629 - lr 0.050000
2022-03-28 11:21:49,145 Evaluating as a multi-label problem: False
2022-03-28 11:21:49,156 DEV : loss 0.18463794887065887 - f1-score (micro avg)  0.5004
2022-03-28 11:21:49,271 BAD EPOCHS (no improvement): 2
2022-03-28 11:21:49,274 ----------------------------------------------------------------------------------------------------
2022-03-28 11:21:51,515 epoch 18 - iter 10/107 - loss 0.05829967 - samples/sec: 142.86 - lr: 0.050000
2022-03-28 11:21:53,740 epoch 18 - iter 20/107 - loss 0.06336105 - samples/sec: 143.90 - lr: 0.050000
2022-03-28 11:21:56,001 epoch 18 - iter 30/107 - loss 0.06269430 - samples/sec: 141.57 - lr: 0.050000
2022-03-28 11:21:58,239 epoch 18 - iter 40/107 - loss 0.05990863 - samples/sec: 143.08 - lr: 0.050000
2022-03-28 11:22:00,442 epoch 18 - iter 50/107 - loss 0.06071377 - samples/sec: 145.32 - lr: 0.050000
2022-03-28 11:22:02,637 epoch 18 - iter 60/107 - loss 0.06252484 - samples/sec: 145.86 - lr: 0.050000
2022-03-28 11:22:04,822 epoch 18 - iter 70/107 - loss 0.06268656 - samples/sec: 146.49 - lr: 0.050000
2022-03-28 11:22:06,981 epoch 18 - iter 80/107 - loss 0.06332788 - samples/sec: 148.27 - lr: 0.050000
2022-03-28 11:22:09,242 epoch 18 - iter 90/107 - loss 0.06286359 - samples/sec: 141.61 - lr: 0.050000
2022-03-28 11:22:11,446 epoch 18 - iter 100/107 - loss 0.06264621 - samples/sec: 145.28 - lr: 0.050000
2022-03-28 11:22:12,800 ----------------------------------------------------------------------------------------------------
2022-03-28 11:22:12,801 EPOCH 18 done: loss 0.0625 - lr 0.050000
2022-03-28 11:22:20,316 Evaluating as a multi-label problem: False
2022-03-28 11:22:20,328 DEV : loss 0.19381359219551086 - f1-score (micro avg)  0.5135
2022-03-28 11:22:20,443 BAD EPOCHS (no improvement): 3
2022-03-28 11:22:20,446 ----------------------------------------------------------------------------------------------------
2022-03-28 11:22:22,631 epoch 19 - iter 10/107 - loss 0.07217375 - samples/sec: 146.52 - lr: 0.050000
2022-03-28 11:22:24,847 epoch 19 - iter 20/107 - loss 0.06210863 - samples/sec: 144.48 - lr: 0.050000
2022-03-28 11:22:26,971 epoch 19 - iter 30/107 - loss 0.05887260 - samples/sec: 150.77 - lr: 0.050000
2022-03-28 11:22:29,290 epoch 19 - iter 40/107 - loss 0.06465159 - samples/sec: 138.02 - lr: 0.050000
2022-03-28 11:22:31,573 epoch 19 - iter 50/107 - loss 0.06152916 - samples/sec: 140.21 - lr: 0.050000
2022-03-28 11:22:33,789 epoch 19 - iter 60/107 - loss 0.06174524 - samples/sec: 144.53 - lr: 0.050000
2022-03-28 11:22:36,044 epoch 19 - iter 70/107 - loss 0.06120058 - samples/sec: 141.92 - lr: 0.050000
2022-03-28 11:22:38,206 epoch 19 - iter 80/107 - loss 0.06083665 - samples/sec: 148.14 - lr: 0.050000
2022-03-28 11:22:40,432 epoch 19 - iter 90/107 - loss 0.05946566 - samples/sec: 143.79 - lr: 0.050000
2022-03-28 11:22:42,665 epoch 19 - iter 100/107 - loss 0.05921250 - samples/sec: 143.36 - lr: 0.050000
2022-03-28 11:22:44,009 ----------------------------------------------------------------------------------------------------
2022-03-28 11:22:44,009 EPOCH 19 done: loss 0.0590 - lr 0.050000
2022-03-28 11:22:51,559 Evaluating as a multi-label problem: False
2022-03-28 11:22:51,570 DEV : loss 0.19389185309410095 - f1-score (micro avg)  0.5086
2022-03-28 11:22:51,686 Epoch    19: reducing learning rate of group 0 to 2.5000e-02.
2022-03-28 11:22:51,686 BAD EPOCHS (no improvement): 4
2022-03-28 11:22:51,689 ----------------------------------------------------------------------------------------------------
2022-03-28 11:22:53,933 epoch 20 - iter 10/107 - loss 0.05602306 - samples/sec: 142.70 - lr: 0.025000
2022-03-28 11:22:56,207 epoch 20 - iter 20/107 - loss 0.05469880 - samples/sec: 140.78 - lr: 0.025000
2022-03-28 11:22:58,373 epoch 20 - iter 30/107 - loss 0.05526217 - samples/sec: 147.79 - lr: 0.025000
2022-03-28 11:23:00,616 epoch 20 - iter 40/107 - loss 0.06005849 - samples/sec: 142.75 - lr: 0.025000
2022-03-28 11:23:02,797 epoch 20 - iter 50/107 - loss 0.05943969 - samples/sec: 146.78 - lr: 0.025000
2022-03-28 11:23:04,940 epoch 20 - iter 60/107 - loss 0.05885202 - samples/sec: 149.40 - lr: 0.025000
2022-03-28 11:23:07,210 epoch 20 - iter 70/107 - loss 0.05759918 - samples/sec: 141.05 - lr: 0.025000
2022-03-28 11:23:09,386 epoch 20 - iter 80/107 - loss 0.05659446 - samples/sec: 147.15 - lr: 0.025000
2022-03-28 11:23:11,505 epoch 20 - iter 90/107 - loss 0.05668605 - samples/sec: 151.06 - lr: 0.025000
2022-03-28 11:23:13,743 epoch 20 - iter 100/107 - loss 0.05696445 - samples/sec: 143.04 - lr: 0.025000
2022-03-28 11:23:15,094 ----------------------------------------------------------------------------------------------------
2022-03-28 11:23:15,094 EPOCH 20 done: loss 0.0573 - lr 0.025000
2022-03-28 11:23:24,120 Evaluating as a multi-label problem: False
2022-03-28 11:23:24,131 DEV : loss 0.17567096650600433 - f1-score (micro avg)  0.5382
2022-03-28 11:23:24,246 BAD EPOCHS (no improvement): 1
2022-03-28 11:23:24,248 ----------------------------------------------------------------------------------------------------
2022-03-28 11:23:26,510 epoch 21 - iter 10/107 - loss 0.05582696 - samples/sec: 141.60 - lr: 0.025000
2022-03-28 11:23:28,660 epoch 21 - iter 20/107 - loss 0.05479159 - samples/sec: 148.92 - lr: 0.025000
2022-03-28 11:23:30,928 epoch 21 - iter 30/107 - loss 0.05538437 - samples/sec: 141.10 - lr: 0.025000
2022-03-28 11:23:33,167 epoch 21 - iter 40/107 - loss 0.05368776 - samples/sec: 143.01 - lr: 0.025000
2022-03-28 11:23:35,414 epoch 21 - iter 50/107 - loss 0.05460538 - samples/sec: 142.45 - lr: 0.025000
2022-03-28 11:23:37,643 epoch 21 - iter 60/107 - loss 0.05392447 - samples/sec: 143.67 - lr: 0.025000
2022-03-28 11:23:39,830 epoch 21 - iter 70/107 - loss 0.05419176 - samples/sec: 146.39 - lr: 0.025000
2022-03-28 11:23:42,098 epoch 21 - iter 80/107 - loss 0.05320452 - samples/sec: 141.15 - lr: 0.025000
2022-03-28 11:23:44,254 epoch 21 - iter 90/107 - loss 0.05410673 - samples/sec: 148.47 - lr: 0.025000
2022-03-28 11:23:46,522 epoch 21 - iter 100/107 - loss 0.05413322 - samples/sec: 141.15 - lr: 0.025000
2022-03-28 11:23:47,865 ----------------------------------------------------------------------------------------------------
2022-03-28 11:23:47,865 EPOCH 21 done: loss 0.0538 - lr 0.025000
2022-03-28 11:23:55,398 Evaluating as a multi-label problem: False
2022-03-28 11:23:55,409 DEV : loss 0.19503101706504822 - f1-score (micro avg)  0.5093
2022-03-28 11:23:55,523 BAD EPOCHS (no improvement): 2
2022-03-28 11:23:55,526 ----------------------------------------------------------------------------------------------------
2022-03-28 11:23:57,724 epoch 22 - iter 10/107 - loss 0.05249403 - samples/sec: 145.68 - lr: 0.025000
2022-03-28 11:23:59,944 epoch 22 - iter 20/107 - loss 0.05511848 - samples/sec: 144.22 - lr: 0.025000
2022-03-28 11:24:02,085 epoch 22 - iter 30/107 - loss 0.05394760 - samples/sec: 149.53 - lr: 0.025000
2022-03-28 11:24:04,234 epoch 22 - iter 40/107 - loss 0.04977418 - samples/sec: 148.97 - lr: 0.025000
2022-03-28 11:24:06,451 epoch 22 - iter 50/107 - loss 0.05003243 - samples/sec: 144.42 - lr: 0.025000
2022-03-28 11:24:08,768 epoch 22 - iter 60/107 - loss 0.05040154 - samples/sec: 138.16 - lr: 0.025000
2022-03-28 11:24:11,026 epoch 22 - iter 70/107 - loss 0.05076254 - samples/sec: 141.82 - lr: 0.025000
2022-03-28 11:24:13,278 epoch 22 - iter 80/107 - loss 0.05084734 - samples/sec: 142.15 - lr: 0.025000
2022-03-28 11:24:15,529 epoch 22 - iter 90/107 - loss 0.05264916 - samples/sec: 142.20 - lr: 0.025000
2022-03-28 11:24:17,778 epoch 22 - iter 100/107 - loss 0.05371470 - samples/sec: 142.36 - lr: 0.025000
2022-03-28 11:24:19,143 ----------------------------------------------------------------------------------------------------
2022-03-28 11:24:19,143 EPOCH 22 done: loss 0.0531 - lr 0.025000
2022-03-28 11:24:26,706 Evaluating as a multi-label problem: False
2022-03-28 11:24:26,717 DEV : loss 0.19831621646881104 - f1-score (micro avg)  0.5051
2022-03-28 11:24:26,833 BAD EPOCHS (no improvement): 3
2022-03-28 11:24:26,835 ----------------------------------------------------------------------------------------------------
2022-03-28 11:24:29,031 epoch 23 - iter 10/107 - loss 0.04465876 - samples/sec: 145.81 - lr: 0.025000
2022-03-28 11:24:31,210 epoch 23 - iter 20/107 - loss 0.04966108 - samples/sec: 146.93 - lr: 0.025000
2022-03-28 11:24:33,470 epoch 23 - iter 30/107 - loss 0.04911444 - samples/sec: 141.61 - lr: 0.025000
2022-03-28 11:24:35,657 epoch 23 - iter 40/107 - loss 0.05126662 - samples/sec: 146.44 - lr: 0.025000
2022-03-28 11:24:37,861 epoch 23 - iter 50/107 - loss 0.05106484 - samples/sec: 145.24 - lr: 0.025000
2022-03-28 11:24:40,063 epoch 23 - iter 60/107 - loss 0.04994880 - samples/sec: 145.42 - lr: 0.025000
2022-03-28 11:24:42,302 epoch 23 - iter 70/107 - loss 0.05067561 - samples/sec: 143.03 - lr: 0.025000
2022-03-28 11:24:44,567 epoch 23 - iter 80/107 - loss 0.05127851 - samples/sec: 141.35 - lr: 0.025000
2022-03-28 11:24:46,697 epoch 23 - iter 90/107 - loss 0.05194449 - samples/sec: 150.27 - lr: 0.025000
2022-03-28 11:24:48,954 epoch 23 - iter 100/107 - loss 0.05114518 - samples/sec: 141.86 - lr: 0.025000
2022-03-28 11:24:50,295 ----------------------------------------------------------------------------------------------------
2022-03-28 11:24:50,295 EPOCH 23 done: loss 0.0515 - lr 0.025000
2022-03-28 11:24:57,886 Evaluating as a multi-label problem: False
2022-03-28 11:24:57,897 DEV : loss 0.19201259315013885 - f1-score (micro avg)  0.5162
2022-03-28 11:24:58,014 Epoch    23: reducing learning rate of group 0 to 1.2500e-02.
2022-03-28 11:24:58,014 BAD EPOCHS (no improvement): 4
2022-03-28 11:24:58,017 ----------------------------------------------------------------------------------------------------
2022-03-28 11:25:00,256 epoch 24 - iter 10/107 - loss 0.04723259 - samples/sec: 142.97 - lr: 0.012500
2022-03-28 11:25:02,569 epoch 24 - iter 20/107 - loss 0.05035156 - samples/sec: 138.42 - lr: 0.012500
2022-03-28 11:25:04,752 epoch 24 - iter 30/107 - loss 0.05151902 - samples/sec: 146.63 - lr: 0.012500
2022-03-28 11:25:07,040 epoch 24 - iter 40/107 - loss 0.05350869 - samples/sec: 139.91 - lr: 0.012500
2022-03-28 11:25:09,235 epoch 24 - iter 50/107 - loss 0.05298009 - samples/sec: 145.87 - lr: 0.012500
2022-03-28 11:25:11,429 epoch 24 - iter 60/107 - loss 0.05295204 - samples/sec: 145.94 - lr: 0.012500
2022-03-28 11:25:13,645 epoch 24 - iter 70/107 - loss 0.05108259 - samples/sec: 144.46 - lr: 0.012500
2022-03-28 11:25:15,816 epoch 24 - iter 80/107 - loss 0.04973581 - samples/sec: 147.48 - lr: 0.012500
2022-03-28 11:25:18,093 epoch 24 - iter 90/107 - loss 0.05030227 - samples/sec: 140.60 - lr: 0.012500
2022-03-28 11:25:20,242 epoch 24 - iter 100/107 - loss 0.04951047 - samples/sec: 148.96 - lr: 0.012500
2022-03-28 11:25:21,636 ----------------------------------------------------------------------------------------------------
2022-03-28 11:25:21,636 EPOCH 24 done: loss 0.0500 - lr 0.012500
2022-03-28 11:25:29,277 Evaluating as a multi-label problem: False
2022-03-28 11:25:29,289 DEV : loss 0.1893698126077652 - f1-score (micro avg)  0.5233
2022-03-28 11:25:29,403 BAD EPOCHS (no improvement): 1
2022-03-28 11:25:29,470 ----------------------------------------------------------------------------------------------------
2022-03-28 11:25:31,728 epoch 25 - iter 10/107 - loss 0.04415943 - samples/sec: 141.84 - lr: 0.012500
2022-03-28 11:25:33,941 epoch 25 - iter 20/107 - loss 0.04658433 - samples/sec: 144.64 - lr: 0.012500
2022-03-28 11:25:36,095 epoch 25 - iter 30/107 - loss 0.05214985 - samples/sec: 148.70 - lr: 0.012500
2022-03-28 11:25:38,384 epoch 25 - iter 40/107 - loss 0.04988382 - samples/sec: 139.84 - lr: 0.012500
2022-03-28 11:25:40,536 epoch 25 - iter 50/107 - loss 0.04986762 - samples/sec: 148.78 - lr: 0.012500
2022-03-28 11:25:42,845 epoch 25 - iter 60/107 - loss 0.04814008 - samples/sec: 138.61 - lr: 0.012500
2022-03-28 11:25:45,118 epoch 25 - iter 70/107 - loss 0.04929300 - samples/sec: 140.88 - lr: 0.012500
2022-03-28 11:25:47,417 epoch 25 - iter 80/107 - loss 0.04976746 - samples/sec: 139.27 - lr: 0.012500
2022-03-28 11:25:49,590 epoch 25 - iter 90/107 - loss 0.04895382 - samples/sec: 147.27 - lr: 0.012500
2022-03-28 11:25:51,827 epoch 25 - iter 100/107 - loss 0.04814731 - samples/sec: 143.12 - lr: 0.012500
2022-03-28 11:25:53,165 ----------------------------------------------------------------------------------------------------
2022-03-28 11:25:53,165 EPOCH 25 done: loss 0.0484 - lr 0.012500
2022-03-28 11:26:00,746 Evaluating as a multi-label problem: False
2022-03-28 11:26:00,757 DEV : loss 0.19186286628246307 - f1-score (micro avg)  0.5184
2022-03-28 11:26:00,873 BAD EPOCHS (no improvement): 2
2022-03-28 11:26:00,876 ----------------------------------------------------------------------------------------------------
2022-03-28 11:26:03,145 epoch 26 - iter 10/107 - loss 0.05248228 - samples/sec: 141.05 - lr: 0.012500
2022-03-28 11:26:05,310 epoch 26 - iter 20/107 - loss 0.05070357 - samples/sec: 147.90 - lr: 0.012500
2022-03-28 11:26:07,544 epoch 26 - iter 30/107 - loss 0.04740227 - samples/sec: 143.29 - lr: 0.012500
2022-03-28 11:26:09,738 epoch 26 - iter 40/107 - loss 0.04629412 - samples/sec: 145.93 - lr: 0.012500
2022-03-28 11:26:11,953 epoch 26 - iter 50/107 - loss 0.04642502 - samples/sec: 144.59 - lr: 0.012500
2022-03-28 11:26:14,207 epoch 26 - iter 60/107 - loss 0.04664486 - samples/sec: 142.04 - lr: 0.012500
2022-03-28 11:26:16,274 epoch 26 - iter 70/107 - loss 0.04700358 - samples/sec: 154.87 - lr: 0.012500
2022-03-28 11:26:18,379 epoch 26 - iter 80/107 - loss 0.04769651 - samples/sec: 152.12 - lr: 0.012500
2022-03-28 11:26:20,443 epoch 26 - iter 90/107 - loss 0.04865859 - samples/sec: 155.15 - lr: 0.012500
2022-03-28 11:26:22,489 epoch 26 - iter 100/107 - loss 0.04801006 - samples/sec: 156.43 - lr: 0.012500
2022-03-28 11:26:23,667 ----------------------------------------------------------------------------------------------------
2022-03-28 11:26:23,667 EPOCH 26 done: loss 0.0480 - lr 0.012500
2022-03-28 11:26:30,944 Evaluating as a multi-label problem: False
2022-03-28 11:26:30,956 DEV : loss 0.18919624388217926 - f1-score (micro avg)  0.5282
2022-03-28 11:26:31,073 BAD EPOCHS (no improvement): 3
2022-03-28 11:26:31,076 ----------------------------------------------------------------------------------------------------
2022-03-28 11:26:33,317 epoch 27 - iter 10/107 - loss 0.05076062 - samples/sec: 142.85 - lr: 0.012500
2022-03-28 11:26:35,570 epoch 27 - iter 20/107 - loss 0.04473843 - samples/sec: 142.08 - lr: 0.012500
2022-03-28 11:26:37,766 epoch 27 - iter 30/107 - loss 0.04630930 - samples/sec: 145.79 - lr: 0.012500
2022-03-28 11:26:40,005 epoch 27 - iter 40/107 - loss 0.04419551 - samples/sec: 143.02 - lr: 0.012500
2022-03-28 11:26:42,214 epoch 27 - iter 50/107 - loss 0.04553802 - samples/sec: 144.87 - lr: 0.012500
2022-03-28 11:26:44,418 epoch 27 - iter 60/107 - loss 0.04716492 - samples/sec: 145.30 - lr: 0.012500
2022-03-28 11:26:46,630 epoch 27 - iter 70/107 - loss 0.04776936 - samples/sec: 144.74 - lr: 0.012500
2022-03-28 11:26:48,791 epoch 27 - iter 80/107 - loss 0.04745335 - samples/sec: 148.12 - lr: 0.012500
2022-03-28 11:26:51,008 epoch 27 - iter 90/107 - loss 0.04712551 - samples/sec: 144.40 - lr: 0.012500
2022-03-28 11:26:53,252 epoch 27 - iter 100/107 - loss 0.04687991 - samples/sec: 142.70 - lr: 0.012500
2022-03-28 11:26:54,637 ----------------------------------------------------------------------------------------------------
2022-03-28 11:26:54,637 EPOCH 27 done: loss 0.0460 - lr 0.012500
2022-03-28 11:27:02,175 Evaluating as a multi-label problem: False
2022-03-28 11:27:02,187 DEV : loss 0.19591021537780762 - f1-score (micro avg)  0.5229
2022-03-28 11:27:02,302 Epoch    27: reducing learning rate of group 0 to 6.2500e-03.
2022-03-28 11:27:02,302 BAD EPOCHS (no improvement): 4
2022-03-28 11:27:02,311 ----------------------------------------------------------------------------------------------------
2022-03-28 11:27:04,532 epoch 28 - iter 10/107 - loss 0.05779063 - samples/sec: 144.21 - lr: 0.006250
2022-03-28 11:27:06,723 epoch 28 - iter 20/107 - loss 0.05094082 - samples/sec: 146.17 - lr: 0.006250
2022-03-28 11:27:08,882 epoch 28 - iter 30/107 - loss 0.04659603 - samples/sec: 148.24 - lr: 0.006250
2022-03-28 11:27:11,110 epoch 28 - iter 40/107 - loss 0.04536099 - samples/sec: 143.69 - lr: 0.006250
2022-03-28 11:27:13,339 epoch 28 - iter 50/107 - loss 0.04488635 - samples/sec: 143.68 - lr: 0.006250
2022-03-28 11:27:15,583 epoch 28 - iter 60/107 - loss 0.04454599 - samples/sec: 142.66 - lr: 0.006250
2022-03-28 11:27:17,912 epoch 28 - iter 70/107 - loss 0.04485778 - samples/sec: 137.45 - lr: 0.006250
2022-03-28 11:27:20,104 epoch 28 - iter 80/107 - loss 0.04500413 - samples/sec: 146.01 - lr: 0.006250
2022-03-28 11:27:22,257 epoch 28 - iter 90/107 - loss 0.04634644 - samples/sec: 148.72 - lr: 0.006250
2022-03-28 11:27:24,465 epoch 28 - iter 100/107 - loss 0.04715811 - samples/sec: 144.99 - lr: 0.006250
2022-03-28 11:27:25,819 ----------------------------------------------------------------------------------------------------
2022-03-28 11:27:25,819 EPOCH 28 done: loss 0.0467 - lr 0.006250
2022-03-28 11:27:33,361 Evaluating as a multi-label problem: False
2022-03-28 11:27:33,372 DEV : loss 0.1927650272846222 - f1-score (micro avg)  0.5252
2022-03-28 11:27:33,487 BAD EPOCHS (no improvement): 1
2022-03-28 11:27:33,490 ----------------------------------------------------------------------------------------------------
2022-03-28 11:27:35,718 epoch 29 - iter 10/107 - loss 0.04586990 - samples/sec: 143.68 - lr: 0.006250
2022-03-28 11:27:37,982 epoch 29 - iter 20/107 - loss 0.04442932 - samples/sec: 141.41 - lr: 0.006250
2022-03-28 11:27:40,236 epoch 29 - iter 30/107 - loss 0.04412892 - samples/sec: 142.05 - lr: 0.006250
2022-03-28 11:27:42,548 epoch 29 - iter 40/107 - loss 0.04507539 - samples/sec: 138.44 - lr: 0.006250
2022-03-28 11:27:44,692 epoch 29 - iter 50/107 - loss 0.04723481 - samples/sec: 149.35 - lr: 0.006250
2022-03-28 11:27:46,923 epoch 29 - iter 60/107 - loss 0.04692673 - samples/sec: 143.55 - lr: 0.006250
2022-03-28 11:27:49,047 epoch 29 - iter 70/107 - loss 0.04681243 - samples/sec: 150.75 - lr: 0.006250
2022-03-28 11:27:51,258 epoch 29 - iter 80/107 - loss 0.04688833 - samples/sec: 144.75 - lr: 0.006250
2022-03-28 11:27:53,463 epoch 29 - iter 90/107 - loss 0.04619797 - samples/sec: 145.21 - lr: 0.006250
2022-03-28 11:27:55,548 epoch 29 - iter 100/107 - loss 0.04643071 - samples/sec: 153.53 - lr: 0.006250
2022-03-28 11:27:56,909 ----------------------------------------------------------------------------------------------------
2022-03-28 11:27:56,909 EPOCH 29 done: loss 0.0474 - lr 0.006250
2022-03-28 11:28:04,435 Evaluating as a multi-label problem: False
2022-03-28 11:28:04,446 DEV : loss 0.1934322863817215 - f1-score (micro avg)  0.5279
2022-03-28 11:28:04,566 BAD EPOCHS (no improvement): 2
2022-03-28 11:28:04,569 ----------------------------------------------------------------------------------------------------
2022-03-28 11:28:06,823 epoch 30 - iter 10/107 - loss 0.05033460 - samples/sec: 142.03 - lr: 0.006250
2022-03-28 11:28:09,045 epoch 30 - iter 20/107 - loss 0.05006856 - samples/sec: 144.07 - lr: 0.006250
2022-03-28 11:28:11,195 epoch 30 - iter 30/107 - loss 0.04787380 - samples/sec: 148.92 - lr: 0.006250
2022-03-28 11:28:13,446 epoch 30 - iter 40/107 - loss 0.04362467 - samples/sec: 142.23 - lr: 0.006250
2022-03-28 11:28:15,767 epoch 30 - iter 50/107 - loss 0.04432820 - samples/sec: 137.92 - lr: 0.006250
2022-03-28 11:28:17,928 epoch 30 - iter 60/107 - loss 0.04251064 - samples/sec: 148.11 - lr: 0.006250
2022-03-28 11:28:19,955 epoch 30 - iter 70/107 - loss 0.04355542 - samples/sec: 157.94 - lr: 0.006250
2022-03-28 11:28:22,011 epoch 30 - iter 80/107 - loss 0.04308766 - samples/sec: 155.74 - lr: 0.006250
2022-03-28 11:28:24,155 epoch 30 - iter 90/107 - loss 0.04349791 - samples/sec: 149.33 - lr: 0.006250
2022-03-28 11:28:26,344 epoch 30 - iter 100/107 - loss 0.04359023 - samples/sec: 146.27 - lr: 0.006250
2022-03-28 11:28:27,734 ----------------------------------------------------------------------------------------------------
2022-03-28 11:28:27,734 EPOCH 30 done: loss 0.0439 - lr 0.006250
2022-03-28 11:28:35,289 Evaluating as a multi-label problem: False
2022-03-28 11:28:35,300 DEV : loss 0.1942579746246338 - f1-score (micro avg)  0.5268
2022-03-28 11:28:35,418 BAD EPOCHS (no improvement): 3
2022-03-28 11:28:35,420 ----------------------------------------------------------------------------------------------------
2022-03-28 11:28:37,646 epoch 31 - iter 10/107 - loss 0.04698006 - samples/sec: 143.88 - lr: 0.006250
2022-03-28 11:28:39,903 epoch 31 - iter 20/107 - loss 0.04816180 - samples/sec: 141.82 - lr: 0.006250
2022-03-28 11:28:42,108 epoch 31 - iter 30/107 - loss 0.04661966 - samples/sec: 145.20 - lr: 0.006250
2022-03-28 11:28:44,257 epoch 31 - iter 40/107 - loss 0.04675898 - samples/sec: 149.01 - lr: 0.006250
2022-03-28 11:28:46,417 epoch 31 - iter 50/107 - loss 0.04521085 - samples/sec: 148.18 - lr: 0.006250
2022-03-28 11:28:48,661 epoch 31 - iter 60/107 - loss 0.04426171 - samples/sec: 142.70 - lr: 0.006250
2022-03-28 11:28:50,802 epoch 31 - iter 70/107 - loss 0.04463999 - samples/sec: 149.51 - lr: 0.006250
2022-03-28 11:28:53,028 epoch 31 - iter 80/107 - loss 0.04436690 - samples/sec: 143.83 - lr: 0.006250
2022-03-28 11:28:55,277 epoch 31 - iter 90/107 - loss 0.04503715 - samples/sec: 142.33 - lr: 0.006250
2022-03-28 11:28:57,447 epoch 31 - iter 100/107 - loss 0.04535909 - samples/sec: 147.55 - lr: 0.006250
2022-03-28 11:28:58,850 ----------------------------------------------------------------------------------------------------
2022-03-28 11:28:58,850 EPOCH 31 done: loss 0.0452 - lr 0.006250
2022-03-28 11:29:06,361 Evaluating as a multi-label problem: False
2022-03-28 11:29:06,372 DEV : loss 0.20074355602264404 - f1-score (micro avg)  0.5124
2022-03-28 11:29:06,487 Epoch    31: reducing learning rate of group 0 to 3.1250e-03.
2022-03-28 11:29:06,487 BAD EPOCHS (no improvement): 4
2022-03-28 11:29:06,490 ----------------------------------------------------------------------------------------------------
2022-03-28 11:29:08,646 epoch 32 - iter 10/107 - loss 0.04057360 - samples/sec: 148.52 - lr: 0.003125
2022-03-28 11:29:10,933 epoch 32 - iter 20/107 - loss 0.04145794 - samples/sec: 139.96 - lr: 0.003125
2022-03-28 11:29:13,158 epoch 32 - iter 30/107 - loss 0.04249892 - samples/sec: 143.88 - lr: 0.003125
2022-03-28 11:29:15,336 epoch 32 - iter 40/107 - loss 0.04541155 - samples/sec: 147.00 - lr: 0.003125
2022-03-28 11:29:17,600 epoch 32 - iter 50/107 - loss 0.04497877 - samples/sec: 141.43 - lr: 0.003125
2022-03-28 11:29:19,891 epoch 32 - iter 60/107 - loss 0.04382954 - samples/sec: 139.73 - lr: 0.003125
2022-03-28 11:29:22,086 epoch 32 - iter 70/107 - loss 0.04479040 - samples/sec: 145.83 - lr: 0.003125
2022-03-28 11:29:24,211 epoch 32 - iter 80/107 - loss 0.04501547 - samples/sec: 150.70 - lr: 0.003125
2022-03-28 11:29:26,438 epoch 32 - iter 90/107 - loss 0.04534637 - samples/sec: 143.78 - lr: 0.003125
2022-03-28 11:29:28,615 epoch 32 - iter 100/107 - loss 0.04510698 - samples/sec: 147.08 - lr: 0.003125
2022-03-28 11:29:29,936 ----------------------------------------------------------------------------------------------------
2022-03-28 11:29:29,936 EPOCH 32 done: loss 0.0445 - lr 0.003125
2022-03-28 11:29:37,448 Evaluating as a multi-label problem: False
2022-03-28 11:29:37,459 DEV : loss 0.20100119709968567 - f1-score (micro avg)  0.514
2022-03-28 11:29:37,573 BAD EPOCHS (no improvement): 1
2022-03-28 11:29:37,575 ----------------------------------------------------------------------------------------------------
2022-03-28 11:29:39,859 epoch 33 - iter 10/107 - loss 0.04329012 - samples/sec: 140.21 - lr: 0.003125
2022-03-28 11:29:42,062 epoch 33 - iter 20/107 - loss 0.04354174 - samples/sec: 145.33 - lr: 0.003125
2022-03-28 11:29:44,327 epoch 33 - iter 30/107 - loss 0.04585604 - samples/sec: 141.35 - lr: 0.003125
2022-03-28 11:29:46,552 epoch 33 - iter 40/107 - loss 0.04633023 - samples/sec: 143.83 - lr: 0.003125
2022-03-28 11:29:48,808 epoch 33 - iter 50/107 - loss 0.04507281 - samples/sec: 141.91 - lr: 0.003125
2022-03-28 11:29:50,991 epoch 33 - iter 60/107 - loss 0.04516379 - samples/sec: 146.66 - lr: 0.003125
2022-03-28 11:29:53,195 epoch 33 - iter 70/107 - loss 0.04503871 - samples/sec: 145.30 - lr: 0.003125
2022-03-28 11:29:55,374 epoch 33 - iter 80/107 - loss 0.04485444 - samples/sec: 146.90 - lr: 0.003125
2022-03-28 11:29:57,551 epoch 33 - iter 90/107 - loss 0.04415864 - samples/sec: 147.08 - lr: 0.003125
2022-03-28 11:29:59,701 epoch 33 - iter 100/107 - loss 0.04428298 - samples/sec: 148.86 - lr: 0.003125
2022-03-28 11:30:01,139 ----------------------------------------------------------------------------------------------------
2022-03-28 11:30:01,139 EPOCH 33 done: loss 0.0438 - lr 0.003125
2022-03-28 11:30:08,686 Evaluating as a multi-label problem: False
2022-03-28 11:30:08,697 DEV : loss 0.19857443869113922 - f1-score (micro avg)  0.5174
2022-03-28 11:30:08,812 BAD EPOCHS (no improvement): 2
2022-03-28 11:30:08,815 ----------------------------------------------------------------------------------------------------
2022-03-28 11:30:11,052 epoch 34 - iter 10/107 - loss 0.04361371 - samples/sec: 143.17 - lr: 0.003125
2022-03-28 11:30:13,318 epoch 34 - iter 20/107 - loss 0.04296141 - samples/sec: 141.32 - lr: 0.003125
2022-03-28 11:30:15,600 epoch 34 - iter 30/107 - loss 0.04825881 - samples/sec: 140.30 - lr: 0.003125
2022-03-28 11:30:17,796 epoch 34 - iter 40/107 - loss 0.04571628 - samples/sec: 145.81 - lr: 0.003125
2022-03-28 11:30:19,954 epoch 34 - iter 50/107 - loss 0.04832681 - samples/sec: 148.32 - lr: 0.003125
2022-03-28 11:30:22,098 epoch 34 - iter 60/107 - loss 0.04760859 - samples/sec: 149.35 - lr: 0.003125
2022-03-28 11:30:24,365 epoch 34 - iter 70/107 - loss 0.04694111 - samples/sec: 141.19 - lr: 0.003125
2022-03-28 11:30:26,531 epoch 34 - iter 80/107 - loss 0.04601750 - samples/sec: 147.84 - lr: 0.003125
2022-03-28 11:30:28,757 epoch 34 - iter 90/107 - loss 0.04561900 - samples/sec: 143.80 - lr: 0.003125
2022-03-28 11:30:31,000 epoch 34 - iter 100/107 - loss 0.04560635 - samples/sec: 142.71 - lr: 0.003125
2022-03-28 11:30:32,364 ----------------------------------------------------------------------------------------------------
2022-03-28 11:30:32,364 EPOCH 34 done: loss 0.0447 - lr 0.003125
2022-03-28 11:30:41,455 Evaluating as a multi-label problem: False
2022-03-28 11:30:41,466 DEV : loss 0.200600266456604 - f1-score (micro avg)  0.5139
2022-03-28 11:30:41,580 BAD EPOCHS (no improvement): 3
2022-03-28 11:30:41,582 ----------------------------------------------------------------------------------------------------
2022-03-28 11:30:43,746 epoch 35 - iter 10/107 - loss 0.04806161 - samples/sec: 148.02 - lr: 0.003125
2022-03-28 11:30:45,984 epoch 35 - iter 20/107 - loss 0.04981872 - samples/sec: 143.02 - lr: 0.003125
2022-03-28 11:30:48,194 epoch 35 - iter 30/107 - loss 0.04808715 - samples/sec: 144.84 - lr: 0.003125
2022-03-28 11:30:50,465 epoch 35 - iter 40/107 - loss 0.04521534 - samples/sec: 140.99 - lr: 0.003125
2022-03-28 11:30:52,705 epoch 35 - iter 50/107 - loss 0.04231553 - samples/sec: 142.90 - lr: 0.003125
2022-03-28 11:30:54,874 epoch 35 - iter 60/107 - loss 0.04418971 - samples/sec: 147.62 - lr: 0.003125
2022-03-28 11:30:57,160 epoch 35 - iter 70/107 - loss 0.04428776 - samples/sec: 140.01 - lr: 0.003125
2022-03-28 11:30:59,240 epoch 35 - iter 80/107 - loss 0.04497112 - samples/sec: 153.96 - lr: 0.003125
2022-03-28 11:31:01,513 epoch 35 - iter 90/107 - loss 0.04508151 - samples/sec: 140.88 - lr: 0.003125
2022-03-28 11:31:03,642 epoch 35 - iter 100/107 - loss 0.04540865 - samples/sec: 150.39 - lr: 0.003125
2022-03-28 11:31:05,048 ----------------------------------------------------------------------------------------------------
2022-03-28 11:31:05,048 EPOCH 35 done: loss 0.0445 - lr 0.003125
2022-03-28 11:31:12,576 Evaluating as a multi-label problem: False
2022-03-28 11:31:12,588 DEV : loss 0.19878007471561432 - f1-score (micro avg)  0.5181
2022-03-28 11:31:12,701 Epoch    35: reducing learning rate of group 0 to 1.5625e-03.
2022-03-28 11:31:12,701 BAD EPOCHS (no improvement): 4
2022-03-28 11:31:12,704 ----------------------------------------------------------------------------------------------------
2022-03-28 11:31:14,916 epoch 36 - iter 10/107 - loss 0.04733049 - samples/sec: 144.76 - lr: 0.001563
2022-03-28 11:31:17,154 epoch 36 - iter 20/107 - loss 0.04518240 - samples/sec: 143.05 - lr: 0.001563
2022-03-28 11:31:19,382 epoch 36 - iter 30/107 - loss 0.04324804 - samples/sec: 143.73 - lr: 0.001563
2022-03-28 11:31:21,660 epoch 36 - iter 40/107 - loss 0.04253196 - samples/sec: 140.51 - lr: 0.001563
2022-03-28 11:31:23,891 epoch 36 - iter 50/107 - loss 0.04399740 - samples/sec: 143.51 - lr: 0.001563
2022-03-28 11:31:26,131 epoch 36 - iter 60/107 - loss 0.04275055 - samples/sec: 142.88 - lr: 0.001563
2022-03-28 11:31:28,406 epoch 36 - iter 70/107 - loss 0.04186317 - samples/sec: 140.74 - lr: 0.001563
2022-03-28 11:31:30,542 epoch 36 - iter 80/107 - loss 0.04283699 - samples/sec: 149.86 - lr: 0.001563
2022-03-28 11:31:32,804 epoch 36 - iter 90/107 - loss 0.04216408 - samples/sec: 141.56 - lr: 0.001563
2022-03-28 11:31:35,024 epoch 36 - iter 100/107 - loss 0.04279920 - samples/sec: 144.23 - lr: 0.001563
2022-03-28 11:31:36,365 ----------------------------------------------------------------------------------------------------
2022-03-28 11:31:36,365 EPOCH 36 done: loss 0.0434 - lr 0.001563
2022-03-28 11:31:43,693 Evaluating as a multi-label problem: False
2022-03-28 11:31:43,704 DEV : loss 0.1972503513097763 - f1-score (micro avg)  0.5195
2022-03-28 11:31:43,819 BAD EPOCHS (no improvement): 1
2022-03-28 11:31:43,822 ----------------------------------------------------------------------------------------------------
2022-03-28 11:31:45,960 epoch 37 - iter 10/107 - loss 0.03838713 - samples/sec: 149.74 - lr: 0.001563
2022-03-28 11:31:48,038 epoch 37 - iter 20/107 - loss 0.04336156 - samples/sec: 154.15 - lr: 0.001563
2022-03-28 11:31:49,959 epoch 37 - iter 30/107 - loss 0.04546167 - samples/sec: 166.62 - lr: 0.001563
2022-03-28 11:31:52,051 epoch 37 - iter 40/107 - loss 0.04496961 - samples/sec: 153.05 - lr: 0.001563
2022-03-28 11:31:54,082 epoch 37 - iter 50/107 - loss 0.04169809 - samples/sec: 157.66 - lr: 0.001563
2022-03-28 11:31:56,162 epoch 37 - iter 60/107 - loss 0.04166684 - samples/sec: 153.92 - lr: 0.001563
2022-03-28 11:31:58,305 epoch 37 - iter 70/107 - loss 0.04296778 - samples/sec: 149.39 - lr: 0.001563
2022-03-28 11:32:00,348 epoch 37 - iter 80/107 - loss 0.04257493 - samples/sec: 156.74 - lr: 0.001563
2022-03-28 11:32:02,501 epoch 37 - iter 90/107 - loss 0.04290058 - samples/sec: 148.66 - lr: 0.001563
2022-03-28 11:32:04,754 epoch 37 - iter 100/107 - loss 0.04305891 - samples/sec: 142.11 - lr: 0.001563
2022-03-28 11:32:06,171 ----------------------------------------------------------------------------------------------------
2022-03-28 11:32:06,171 EPOCH 37 done: loss 0.0435 - lr 0.001563
2022-03-28 11:32:13,693 Evaluating as a multi-label problem: False
2022-03-28 11:32:13,704 DEV : loss 0.19838853180408478 - f1-score (micro avg)  0.5192
2022-03-28 11:32:13,819 BAD EPOCHS (no improvement): 2
2022-03-28 11:32:13,822 ----------------------------------------------------------------------------------------------------
2022-03-28 11:32:15,935 epoch 38 - iter 10/107 - loss 0.04030890 - samples/sec: 151.50 - lr: 0.001563
2022-03-28 11:32:17,818 epoch 38 - iter 20/107 - loss 0.04404157 - samples/sec: 170.09 - lr: 0.001563
2022-03-28 11:32:19,656 epoch 38 - iter 30/107 - loss 0.04366094 - samples/sec: 174.12 - lr: 0.001563
2022-03-28 11:32:21,482 epoch 38 - iter 40/107 - loss 0.04369810 - samples/sec: 175.39 - lr: 0.001563
2022-03-28 11:32:23,349 epoch 38 - iter 50/107 - loss 0.04363641 - samples/sec: 171.46 - lr: 0.001563
2022-03-28 11:32:25,239 epoch 38 - iter 60/107 - loss 0.04204757 - samples/sec: 169.41 - lr: 0.001563
2022-03-28 11:32:27,117 epoch 38 - iter 70/107 - loss 0.04327935 - samples/sec: 170.44 - lr: 0.001563
2022-03-28 11:32:28,919 epoch 38 - iter 80/107 - loss 0.04516295 - samples/sec: 177.73 - lr: 0.001563
2022-03-28 11:32:30,708 epoch 38 - iter 90/107 - loss 0.04422480 - samples/sec: 178.95 - lr: 0.001563
2022-03-28 11:32:32,484 epoch 38 - iter 100/107 - loss 0.04442819 - samples/sec: 180.29 - lr: 0.001563
2022-03-28 11:32:33,629 ----------------------------------------------------------------------------------------------------
2022-03-28 11:32:33,629 EPOCH 38 done: loss 0.0443 - lr 0.001563
2022-03-28 11:32:39,728 Evaluating as a multi-label problem: False
2022-03-28 11:32:39,739 DEV : loss 0.1962522268295288 - f1-score (micro avg)  0.5245
2022-03-28 11:32:39,828 BAD EPOCHS (no improvement): 3
2022-03-28 11:32:39,831 ----------------------------------------------------------------------------------------------------
2022-03-28 11:32:41,731 epoch 39 - iter 10/107 - loss 0.04582302 - samples/sec: 168.54 - lr: 0.001563
2022-03-28 11:32:43,581 epoch 39 - iter 20/107 - loss 0.04236533 - samples/sec: 173.10 - lr: 0.001563
2022-03-28 11:32:45,382 epoch 39 - iter 30/107 - loss 0.04044572 - samples/sec: 177.78 - lr: 0.001563
2022-03-28 11:32:47,162 epoch 39 - iter 40/107 - loss 0.04377364 - samples/sec: 179.87 - lr: 0.001563
2022-03-28 11:32:48,980 epoch 39 - iter 50/107 - loss 0.04342281 - samples/sec: 176.10 - lr: 0.001563
2022-03-28 11:32:50,745 epoch 39 - iter 60/107 - loss 0.04332995 - samples/sec: 181.42 - lr: 0.001563
2022-03-28 11:32:52,513 epoch 39 - iter 70/107 - loss 0.04162782 - samples/sec: 181.15 - lr: 0.001563
2022-03-28 11:32:54,325 epoch 39 - iter 80/107 - loss 0.04144763 - samples/sec: 176.61 - lr: 0.001563
2022-03-28 11:32:56,257 epoch 39 - iter 90/107 - loss 0.04293651 - samples/sec: 165.78 - lr: 0.001563
2022-03-28 11:32:58,129 epoch 39 - iter 100/107 - loss 0.04362642 - samples/sec: 171.00 - lr: 0.001563
2022-03-28 11:32:59,313 ----------------------------------------------------------------------------------------------------
2022-03-28 11:32:59,314 EPOCH 39 done: loss 0.0436 - lr 0.001563
2022-03-28 11:33:05,443 Evaluating as a multi-label problem: False
2022-03-28 11:33:05,453 DEV : loss 0.19874024391174316 - f1-score (micro avg)  0.5208
2022-03-28 11:33:05,542 Epoch    39: reducing learning rate of group 0 to 7.8125e-04.
2022-03-28 11:33:05,542 BAD EPOCHS (no improvement): 4
2022-03-28 11:33:05,545 ----------------------------------------------------------------------------------------------------
2022-03-28 11:33:07,510 epoch 40 - iter 10/107 - loss 0.04098038 - samples/sec: 162.93 - lr: 0.000781
2022-03-28 11:33:09,344 epoch 40 - iter 20/107 - loss 0.04667779 - samples/sec: 174.53 - lr: 0.000781
2022-03-28 11:33:11,208 epoch 40 - iter 30/107 - loss 0.04335817 - samples/sec: 171.78 - lr: 0.000781
2022-03-28 11:33:13,053 epoch 40 - iter 40/107 - loss 0.04230627 - samples/sec: 173.51 - lr: 0.000781
2022-03-28 11:33:14,885 epoch 40 - iter 50/107 - loss 0.04205490 - samples/sec: 174.74 - lr: 0.000781
2022-03-28 11:33:16,755 epoch 40 - iter 60/107 - loss 0.04127850 - samples/sec: 171.24 - lr: 0.000781
2022-03-28 11:33:18,445 epoch 40 - iter 70/107 - loss 0.04203987 - samples/sec: 189.41 - lr: 0.000781
2022-03-28 11:33:20,180 epoch 40 - iter 80/107 - loss 0.04247529 - samples/sec: 184.57 - lr: 0.000781
2022-03-28 11:33:22,007 epoch 40 - iter 90/107 - loss 0.04278009 - samples/sec: 175.26 - lr: 0.000781
2022-03-28 11:33:23,776 epoch 40 - iter 100/107 - loss 0.04241951 - samples/sec: 181.03 - lr: 0.000781
2022-03-28 11:33:24,865 ----------------------------------------------------------------------------------------------------
2022-03-28 11:33:24,865 EPOCH 40 done: loss 0.0428 - lr 0.000781
2022-03-28 11:33:30,952 Evaluating as a multi-label problem: False
2022-03-28 11:33:30,963 DEV : loss 0.19964203238487244 - f1-score (micro avg)  0.5178
2022-03-28 11:33:31,052 BAD EPOCHS (no improvement): 1
2022-03-28 11:33:31,055 ----------------------------------------------------------------------------------------------------
2022-03-28 11:33:32,948 epoch 41 - iter 10/107 - loss 0.05650555 - samples/sec: 169.19 - lr: 0.000781
2022-03-28 11:33:34,783 epoch 41 - iter 20/107 - loss 0.04884712 - samples/sec: 174.46 - lr: 0.000781
2022-03-28 11:33:36,588 epoch 41 - iter 30/107 - loss 0.04782170 - samples/sec: 177.36 - lr: 0.000781
2022-03-28 11:33:38,379 epoch 41 - iter 40/107 - loss 0.04650374 - samples/sec: 178.80 - lr: 0.000781
2022-03-28 11:33:40,197 epoch 41 - iter 50/107 - loss 0.04601734 - samples/sec: 176.13 - lr: 0.000781
2022-03-28 11:33:42,021 epoch 41 - iter 60/107 - loss 0.04513117 - samples/sec: 175.49 - lr: 0.000781
2022-03-28 11:33:43,846 epoch 41 - iter 70/107 - loss 0.04577998 - samples/sec: 175.42 - lr: 0.000781
2022-03-28 11:33:45,712 epoch 41 - iter 80/107 - loss 0.04550616 - samples/sec: 171.58 - lr: 0.000781
2022-03-28 11:33:47,530 epoch 41 - iter 90/107 - loss 0.04488082 - samples/sec: 176.10 - lr: 0.000781
2022-03-28 11:33:49,386 epoch 41 - iter 100/107 - loss 0.04573511 - samples/sec: 172.51 - lr: 0.000781
2022-03-28 11:33:50,615 ----------------------------------------------------------------------------------------------------
2022-03-28 11:33:50,615 EPOCH 41 done: loss 0.0451 - lr 0.000781
2022-03-28 11:33:56,738 Evaluating as a multi-label problem: False
2022-03-28 11:33:56,749 DEV : loss 0.19844387471675873 - f1-score (micro avg)  0.5185
2022-03-28 11:33:56,837 BAD EPOCHS (no improvement): 2
2022-03-28 11:33:56,840 ----------------------------------------------------------------------------------------------------
2022-03-28 11:33:58,846 epoch 42 - iter 10/107 - loss 0.04660045 - samples/sec: 159.57 - lr: 0.000781
2022-03-28 11:34:00,655 epoch 42 - iter 20/107 - loss 0.04795172 - samples/sec: 177.05 - lr: 0.000781
2022-03-28 11:34:02,497 epoch 42 - iter 30/107 - loss 0.04568212 - samples/sec: 173.81 - lr: 0.000781
2022-03-28 11:34:04,358 epoch 42 - iter 40/107 - loss 0.04372285 - samples/sec: 171.98 - lr: 0.000781
2022-03-28 11:34:06,204 epoch 42 - iter 50/107 - loss 0.04443254 - samples/sec: 173.44 - lr: 0.000781
2022-03-28 11:34:08,013 epoch 42 - iter 60/107 - loss 0.04597116 - samples/sec: 176.97 - lr: 0.000781
2022-03-28 11:34:09,868 epoch 42 - iter 70/107 - loss 0.04606625 - samples/sec: 172.62 - lr: 0.000781
2022-03-28 11:34:11,632 epoch 42 - iter 80/107 - loss 0.04679447 - samples/sec: 181.52 - lr: 0.000781
2022-03-28 11:34:13,366 epoch 42 - iter 90/107 - loss 0.04659399 - samples/sec: 184.61 - lr: 0.000781
2022-03-28 11:34:15,185 epoch 42 - iter 100/107 - loss 0.04537271 - samples/sec: 176.02 - lr: 0.000781
2022-03-28 11:34:16,411 ----------------------------------------------------------------------------------------------------
2022-03-28 11:34:16,412 EPOCH 42 done: loss 0.0445 - lr 0.000781
2022-03-28 11:34:22,606 Evaluating as a multi-label problem: False
2022-03-28 11:34:22,617 DEV : loss 0.1983174979686737 - f1-score (micro avg)  0.5208
2022-03-28 11:34:22,705 BAD EPOCHS (no improvement): 3
2022-03-28 11:34:22,708 ----------------------------------------------------------------------------------------------------
2022-03-28 11:34:24,642 epoch 43 - iter 10/107 - loss 0.05262726 - samples/sec: 165.57 - lr: 0.000781
2022-03-28 11:34:26,577 epoch 43 - iter 20/107 - loss 0.04768672 - samples/sec: 165.43 - lr: 0.000781
2022-03-28 11:34:28,449 epoch 43 - iter 30/107 - loss 0.04523990 - samples/sec: 171.01 - lr: 0.000781
2022-03-28 11:34:30,198 epoch 43 - iter 40/107 - loss 0.04679315 - samples/sec: 183.09 - lr: 0.000781
2022-03-28 11:34:31,929 epoch 43 - iter 50/107 - loss 0.04687427 - samples/sec: 184.99 - lr: 0.000781
2022-03-28 11:34:33,788 epoch 43 - iter 60/107 - loss 0.04577597 - samples/sec: 172.23 - lr: 0.000781
2022-03-28 11:34:35,629 epoch 43 - iter 70/107 - loss 0.04530977 - samples/sec: 173.88 - lr: 0.000781
2022-03-28 11:34:37,484 epoch 43 - iter 80/107 - loss 0.04595306 - samples/sec: 172.60 - lr: 0.000781
2022-03-28 11:34:39,359 epoch 43 - iter 90/107 - loss 0.04515513 - samples/sec: 170.70 - lr: 0.000781
2022-03-28 11:34:41,254 epoch 43 - iter 100/107 - loss 0.04530948 - samples/sec: 169.01 - lr: 0.000781
2022-03-28 11:34:42,394 ----------------------------------------------------------------------------------------------------
2022-03-28 11:34:42,394 EPOCH 43 done: loss 0.0455 - lr 0.000781
2022-03-28 11:34:48,518 Evaluating as a multi-label problem: False
2022-03-28 11:34:48,528 DEV : loss 0.19837333261966705 - f1-score (micro avg)  0.5205
2022-03-28 11:34:48,617 Epoch    43: reducing learning rate of group 0 to 3.9063e-04.
2022-03-28 11:34:48,617 BAD EPOCHS (no improvement): 4
2022-03-28 11:34:48,620 ----------------------------------------------------------------------------------------------------
2022-03-28 11:34:50,461 epoch 44 - iter 10/107 - loss 0.04827221 - samples/sec: 173.99 - lr: 0.000391
2022-03-28 11:34:52,276 epoch 44 - iter 20/107 - loss 0.04551375 - samples/sec: 176.40 - lr: 0.000391
2022-03-28 11:34:54,121 epoch 44 - iter 30/107 - loss 0.04323897 - samples/sec: 173.48 - lr: 0.000391
2022-03-28 11:34:55,970 epoch 44 - iter 40/107 - loss 0.04131021 - samples/sec: 173.20 - lr: 0.000391
2022-03-28 11:34:57,761 epoch 44 - iter 50/107 - loss 0.04173508 - samples/sec: 178.71 - lr: 0.000391
2022-03-28 11:34:59,540 epoch 44 - iter 60/107 - loss 0.04276846 - samples/sec: 180.00 - lr: 0.000391
2022-03-28 11:35:01,331 epoch 44 - iter 70/107 - loss 0.04250920 - samples/sec: 178.77 - lr: 0.000391
2022-03-28 11:35:03,265 epoch 44 - iter 80/107 - loss 0.04313072 - samples/sec: 165.50 - lr: 0.000391
2022-03-28 11:35:05,029 epoch 44 - iter 90/107 - loss 0.04230019 - samples/sec: 181.62 - lr: 0.000391
2022-03-28 11:35:06,844 epoch 44 - iter 100/107 - loss 0.04166239 - samples/sec: 176.35 - lr: 0.000391
2022-03-28 11:35:08,020 ----------------------------------------------------------------------------------------------------
2022-03-28 11:35:08,020 EPOCH 44 done: loss 0.0418 - lr 0.000391
2022-03-28 11:35:14,127 Evaluating as a multi-label problem: False
2022-03-28 11:35:14,138 DEV : loss 0.19901752471923828 - f1-score (micro avg)  0.5201
2022-03-28 11:35:14,225 BAD EPOCHS (no improvement): 1
2022-03-28 11:35:14,228 ----------------------------------------------------------------------------------------------------
2022-03-28 11:35:16,065 epoch 45 - iter 10/107 - loss 0.03653530 - samples/sec: 174.35 - lr: 0.000391
2022-03-28 11:35:17,862 epoch 45 - iter 20/107 - loss 0.03854619 - samples/sec: 178.13 - lr: 0.000391
2022-03-28 11:35:19,713 epoch 45 - iter 30/107 - loss 0.04092638 - samples/sec: 172.97 - lr: 0.000391
2022-03-28 11:35:21,516 epoch 45 - iter 40/107 - loss 0.03926477 - samples/sec: 177.60 - lr: 0.000391
2022-03-28 11:35:23,385 epoch 45 - iter 50/107 - loss 0.03922521 - samples/sec: 171.31 - lr: 0.000391
2022-03-28 11:35:25,240 epoch 45 - iter 60/107 - loss 0.04000915 - samples/sec: 172.61 - lr: 0.000391
2022-03-28 11:35:27,048 epoch 45 - iter 70/107 - loss 0.04182753 - samples/sec: 177.09 - lr: 0.000391
2022-03-28 11:35:28,824 epoch 45 - iter 80/107 - loss 0.04249091 - samples/sec: 180.25 - lr: 0.000391
2022-03-28 11:35:30,620 epoch 45 - iter 90/107 - loss 0.04202035 - samples/sec: 178.24 - lr: 0.000391
2022-03-28 11:35:32,542 epoch 45 - iter 100/107 - loss 0.04197788 - samples/sec: 166.60 - lr: 0.000391
2022-03-28 11:35:33,650 ----------------------------------------------------------------------------------------------------
2022-03-28 11:35:33,650 EPOCH 45 done: loss 0.0422 - lr 0.000391
2022-03-28 11:35:39,761 Evaluating as a multi-label problem: False
2022-03-28 11:35:39,771 DEV : loss 0.1984233558177948 - f1-score (micro avg)  0.5209
2022-03-28 11:35:39,860 BAD EPOCHS (no improvement): 2
2022-03-28 11:35:39,863 ----------------------------------------------------------------------------------------------------
2022-03-28 11:35:41,717 epoch 46 - iter 10/107 - loss 0.04549260 - samples/sec: 172.65 - lr: 0.000391
2022-03-28 11:35:43,629 epoch 46 - iter 20/107 - loss 0.04135926 - samples/sec: 167.48 - lr: 0.000391
2022-03-28 11:35:45,443 epoch 46 - iter 30/107 - loss 0.03981236 - samples/sec: 176.48 - lr: 0.000391
2022-03-28 11:35:47,248 epoch 46 - iter 40/107 - loss 0.04039076 - samples/sec: 177.33 - lr: 0.000391
2022-03-28 11:35:49,052 epoch 46 - iter 50/107 - loss 0.04216284 - samples/sec: 177.50 - lr: 0.000391
2022-03-28 11:35:50,884 epoch 46 - iter 60/107 - loss 0.04238704 - samples/sec: 174.75 - lr: 0.000391
2022-03-28 11:35:52,852 epoch 46 - iter 70/107 - loss 0.04281920 - samples/sec: 162.70 - lr: 0.000391
2022-03-28 11:35:54,711 epoch 46 - iter 80/107 - loss 0.04334570 - samples/sec: 172.27 - lr: 0.000391
2022-03-28 11:35:56,603 epoch 46 - iter 90/107 - loss 0.04353323 - samples/sec: 169.20 - lr: 0.000391
2022-03-28 11:35:58,364 epoch 46 - iter 100/107 - loss 0.04402506 - samples/sec: 181.83 - lr: 0.000391
2022-03-28 11:35:59,460 ----------------------------------------------------------------------------------------------------
2022-03-28 11:35:59,460 EPOCH 46 done: loss 0.0440 - lr 0.000391
2022-03-28 11:36:05,593 Evaluating as a multi-label problem: False
2022-03-28 11:36:05,604 DEV : loss 0.19823776185512543 - f1-score (micro avg)  0.5193
2022-03-28 11:36:05,694 BAD EPOCHS (no improvement): 3
2022-03-28 11:36:05,697 ----------------------------------------------------------------------------------------------------
2022-03-28 11:36:07,610 epoch 47 - iter 10/107 - loss 0.05793629 - samples/sec: 167.41 - lr: 0.000391
2022-03-28 11:36:09,473 epoch 47 - iter 20/107 - loss 0.04736585 - samples/sec: 171.80 - lr: 0.000391
2022-03-28 11:36:11,300 epoch 47 - iter 30/107 - loss 0.04899401 - samples/sec: 175.27 - lr: 0.000391
2022-03-28 11:36:13,146 epoch 47 - iter 40/107 - loss 0.04686056 - samples/sec: 173.44 - lr: 0.000391
2022-03-28 11:36:14,917 epoch 47 - iter 50/107 - loss 0.04553435 - samples/sec: 180.78 - lr: 0.000391
2022-03-28 11:36:16,684 epoch 47 - iter 60/107 - loss 0.04554442 - samples/sec: 181.15 - lr: 0.000391
2022-03-28 11:36:18,409 epoch 47 - iter 70/107 - loss 0.04536303 - samples/sec: 185.62 - lr: 0.000391
2022-03-28 11:36:20,225 epoch 47 - iter 80/107 - loss 0.04517417 - samples/sec: 176.31 - lr: 0.000391
2022-03-28 11:36:22,003 epoch 47 - iter 90/107 - loss 0.04488237 - samples/sec: 180.11 - lr: 0.000391
2022-03-28 11:36:23,770 epoch 47 - iter 100/107 - loss 0.04492308 - samples/sec: 181.19 - lr: 0.000391
2022-03-28 11:36:24,820 ----------------------------------------------------------------------------------------------------
2022-03-28 11:36:24,820 EPOCH 47 done: loss 0.0448 - lr 0.000391
2022-03-28 11:36:30,844 Evaluating as a multi-label problem: False
2022-03-28 11:36:30,855 DEV : loss 0.19809924066066742 - f1-score (micro avg)  0.5205
2022-03-28 11:36:30,943 Epoch    47: reducing learning rate of group 0 to 1.9531e-04.
2022-03-28 11:36:30,943 BAD EPOCHS (no improvement): 4
2022-03-28 11:36:30,946 ----------------------------------------------------------------------------------------------------
2022-03-28 11:36:32,856 epoch 48 - iter 10/107 - loss 0.04147407 - samples/sec: 167.63 - lr: 0.000195
2022-03-28 11:36:34,680 epoch 48 - iter 20/107 - loss 0.04581396 - samples/sec: 175.49 - lr: 0.000195
2022-03-28 11:36:36,489 epoch 48 - iter 30/107 - loss 0.04308477 - samples/sec: 176.96 - lr: 0.000195
2022-03-28 11:36:38,274 epoch 48 - iter 40/107 - loss 0.04594695 - samples/sec: 179.42 - lr: 0.000195
2022-03-28 11:36:40,136 epoch 48 - iter 50/107 - loss 0.04599934 - samples/sec: 171.98 - lr: 0.000195
2022-03-28 11:36:41,995 epoch 48 - iter 60/107 - loss 0.04522739 - samples/sec: 172.21 - lr: 0.000195
2022-03-28 11:36:43,888 epoch 48 - iter 70/107 - loss 0.04649349 - samples/sec: 169.08 - lr: 0.000195
2022-03-28 11:36:45,696 epoch 48 - iter 80/107 - loss 0.04505888 - samples/sec: 177.18 - lr: 0.000195
2022-03-28 11:36:47,427 epoch 48 - iter 90/107 - loss 0.04448724 - samples/sec: 184.96 - lr: 0.000195
2022-03-28 11:36:49,162 epoch 48 - iter 100/107 - loss 0.04355824 - samples/sec: 184.58 - lr: 0.000195
2022-03-28 11:36:50,348 ----------------------------------------------------------------------------------------------------
2022-03-28 11:36:50,348 EPOCH 48 done: loss 0.0434 - lr 0.000195
2022-03-28 11:36:57,964 Evaluating as a multi-label problem: False
2022-03-28 11:36:57,975 DEV : loss 0.1980971097946167 - f1-score (micro avg)  0.5205
2022-03-28 11:36:58,063 BAD EPOCHS (no improvement): 1
2022-03-28 11:36:58,066 ----------------------------------------------------------------------------------------------------
2022-03-28 11:36:59,944 epoch 49 - iter 10/107 - loss 0.04321975 - samples/sec: 170.49 - lr: 0.000195
2022-03-28 11:37:01,730 epoch 49 - iter 20/107 - loss 0.03685008 - samples/sec: 179.22 - lr: 0.000195
2022-03-28 11:37:03,731 epoch 49 - iter 30/107 - loss 0.03992855 - samples/sec: 160.00 - lr: 0.000195
2022-03-28 11:37:05,592 epoch 49 - iter 40/107 - loss 0.04090035 - samples/sec: 172.06 - lr: 0.000195
2022-03-28 11:37:07,458 epoch 49 - iter 50/107 - loss 0.04040612 - samples/sec: 171.58 - lr: 0.000195
2022-03-28 11:37:09,285 epoch 49 - iter 60/107 - loss 0.04201781 - samples/sec: 175.29 - lr: 0.000195
2022-03-28 11:37:11,152 epoch 49 - iter 70/107 - loss 0.04222219 - samples/sec: 171.44 - lr: 0.000195
2022-03-28 11:37:12,955 epoch 49 - iter 80/107 - loss 0.04228593 - samples/sec: 177.60 - lr: 0.000195
2022-03-28 11:37:14,761 epoch 49 - iter 90/107 - loss 0.04375297 - samples/sec: 177.30 - lr: 0.000195
2022-03-28 11:37:16,656 epoch 49 - iter 100/107 - loss 0.04414322 - samples/sec: 168.91 - lr: 0.000195
2022-03-28 11:37:17,824 ----------------------------------------------------------------------------------------------------
2022-03-28 11:37:17,824 EPOCH 49 done: loss 0.0441 - lr 0.000195
2022-03-28 11:37:23,930 Evaluating as a multi-label problem: False
2022-03-28 11:37:23,940 DEV : loss 0.19800320267677307 - f1-score (micro avg)  0.5216
2022-03-28 11:37:24,030 BAD EPOCHS (no improvement): 2
2022-03-28 11:37:24,033 ----------------------------------------------------------------------------------------------------
2022-03-28 11:37:25,879 epoch 50 - iter 10/107 - loss 0.03438087 - samples/sec: 173.41 - lr: 0.000195
2022-03-28 11:37:27,731 epoch 50 - iter 20/107 - loss 0.04039852 - samples/sec: 172.85 - lr: 0.000195
2022-03-28 11:37:29,588 epoch 50 - iter 30/107 - loss 0.04121964 - samples/sec: 172.40 - lr: 0.000195
2022-03-28 11:37:31,387 epoch 50 - iter 40/107 - loss 0.04316465 - samples/sec: 178.05 - lr: 0.000195
2022-03-28 11:37:33,165 epoch 50 - iter 50/107 - loss 0.04435620 - samples/sec: 180.06 - lr: 0.000195
2022-03-28 11:37:34,970 epoch 50 - iter 60/107 - loss 0.04264221 - samples/sec: 177.39 - lr: 0.000195
2022-03-28 11:37:36,748 epoch 50 - iter 70/107 - loss 0.04343806 - samples/sec: 180.08 - lr: 0.000195
2022-03-28 11:37:38,536 epoch 50 - iter 80/107 - loss 0.04282895 - samples/sec: 179.14 - lr: 0.000195
2022-03-28 11:37:40,396 epoch 50 - iter 90/107 - loss 0.04317968 - samples/sec: 172.06 - lr: 0.000195
2022-03-28 11:37:42,297 epoch 50 - iter 100/107 - loss 0.04354930 - samples/sec: 168.43 - lr: 0.000195
2022-03-28 11:37:43,394 ----------------------------------------------------------------------------------------------------
2022-03-28 11:37:43,394 EPOCH 50 done: loss 0.0434 - lr 0.000195
2022-03-28 11:37:49,514 Evaluating as a multi-label problem: False
2022-03-28 11:37:49,525 DEV : loss 0.19806894659996033 - f1-score (micro avg)  0.5216
2022-03-28 11:37:49,613 BAD EPOCHS (no improvement): 3
2022-03-28 11:37:49,616 ----------------------------------------------------------------------------------------------------
2022-03-28 11:37:51,636 epoch 51 - iter 10/107 - loss 0.05005504 - samples/sec: 158.52 - lr: 0.000195
2022-03-28 11:37:53,518 epoch 51 - iter 20/107 - loss 0.04797607 - samples/sec: 170.09 - lr: 0.000195
2022-03-28 11:37:55,377 epoch 51 - iter 30/107 - loss 0.04755833 - samples/sec: 172.27 - lr: 0.000195
2022-03-28 11:37:57,224 epoch 51 - iter 40/107 - loss 0.04603499 - samples/sec: 173.31 - lr: 0.000195
2022-03-28 11:37:59,078 epoch 51 - iter 50/107 - loss 0.04429481 - samples/sec: 172.73 - lr: 0.000195
2022-03-28 11:38:00,901 epoch 51 - iter 60/107 - loss 0.04592631 - samples/sec: 175.61 - lr: 0.000195
2022-03-28 11:38:02,781 epoch 51 - iter 70/107 - loss 0.04757783 - samples/sec: 170.31 - lr: 0.000195
2022-03-28 11:38:04,662 epoch 51 - iter 80/107 - loss 0.04599137 - samples/sec: 170.22 - lr: 0.000195
2022-03-28 11:38:06,460 epoch 51 - iter 90/107 - loss 0.04535527 - samples/sec: 178.06 - lr: 0.000195
2022-03-28 11:38:08,185 epoch 51 - iter 100/107 - loss 0.04468262 - samples/sec: 185.59 - lr: 0.000195
2022-03-28 11:38:09,241 ----------------------------------------------------------------------------------------------------
2022-03-28 11:38:09,241 EPOCH 51 done: loss 0.0444 - lr 0.000195
2022-03-28 11:38:15,376 Evaluating as a multi-label problem: False
2022-03-28 11:38:15,386 DEV : loss 0.1982576996088028 - f1-score (micro avg)  0.5216
2022-03-28 11:38:15,476 Epoch    51: reducing learning rate of group 0 to 9.7656e-05.
2022-03-28 11:38:15,476 BAD EPOCHS (no improvement): 4
2022-03-28 11:38:15,478 ----------------------------------------------------------------------------------------------------
2022-03-28 11:38:15,478 ----------------------------------------------------------------------------------------------------
2022-03-28 11:38:15,479 learning rate too small - quitting training!
2022-03-28 11:38:15,479 ----------------------------------------------------------------------------------------------------
2022-03-28 11:38:40,095 ----------------------------------------------------------------------------------------------------
2022-03-28 11:38:40,096 loading file resources/taggers/model_07_r5_run_2/best-model.pt
2022-03-28 11:38:55,276 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-03-28 11:39:14,038 Evaluating as a multi-label problem: False
2022-03-28 11:39:14,051 0.6431	0.3457	0.4497	0.3075
2022-03-28 11:39:14,051 
Results:
- F-score (micro) 0.4497
- F-score (macro) 0.3394
- Accuracy 0.3075

By class:
               precision    recall  f1-score   support

       person     0.7587    0.5058    0.6070       429
     location     0.5918    0.5800    0.5859       150
        group     0.5800    0.1758    0.2698       165
creative-work     0.5000    0.1127    0.1839       142
      product     0.4762    0.0787    0.1351       127
  corporation     0.3182    0.2121    0.2545        66

    micro avg     0.6431    0.3457    0.4497      1079
    macro avg     0.5375    0.2775    0.3394      1079
 weighted avg     0.6139    0.3457    0.4197      1079

2022-03-28 11:39:14,051 ----------------------------------------------------------------------------------------------------
