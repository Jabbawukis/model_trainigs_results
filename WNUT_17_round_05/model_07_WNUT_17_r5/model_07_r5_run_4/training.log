2022-03-28 10:47:08,816 ----------------------------------------------------------------------------------------------------
2022-03-28 10:47:08,817 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_3): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4362, out_features=4362, bias=True)
  (rnn): LSTM(4362, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-03-28 10:47:08,818 ----------------------------------------------------------------------------------------------------
2022-03-28 10:47:08,818 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-03-28 10:47:08,818 ----------------------------------------------------------------------------------------------------
2022-03-28 10:47:08,818 Parameters:
2022-03-28 10:47:08,820  - learning_rate: "0.100000"
2022-03-28 10:47:08,820  - mini_batch_size: "32"
2022-03-28 10:47:08,820  - patience: "3"
2022-03-28 10:47:08,820  - anneal_factor: "0.5"
2022-03-28 10:47:08,820  - max_epochs: "150"
2022-03-28 10:47:08,820  - shuffle: "True"
2022-03-28 10:47:08,820  - train_with_dev: "False"
2022-03-28 10:47:08,820  - batch_growth_annealing: "False"
2022-03-28 10:47:08,822 ----------------------------------------------------------------------------------------------------
2022-03-28 10:47:08,822 Model training base path: "resources/taggers/model_07_r5_run_1"
2022-03-28 10:47:08,822 ----------------------------------------------------------------------------------------------------
2022-03-28 10:47:08,822 Device: cuda:1
2022-03-28 10:47:08,822 ----------------------------------------------------------------------------------------------------
2022-03-28 10:47:08,822 Embeddings storage mode: cpu
2022-03-28 10:47:08,822 ----------------------------------------------------------------------------------------------------
2022-03-28 10:47:11,780 epoch 1 - iter 10/107 - loss 0.65267718 - samples/sec: 108.23 - lr: 0.100000
2022-03-28 10:47:14,805 epoch 1 - iter 20/107 - loss 0.47961110 - samples/sec: 105.82 - lr: 0.100000
2022-03-28 10:47:17,846 epoch 1 - iter 30/107 - loss 0.42170838 - samples/sec: 105.25 - lr: 0.100000
2022-03-28 10:47:20,841 epoch 1 - iter 40/107 - loss 0.38627057 - samples/sec: 106.88 - lr: 0.100000
2022-03-28 10:47:23,857 epoch 1 - iter 50/107 - loss 0.35397967 - samples/sec: 106.14 - lr: 0.100000
2022-03-28 10:47:26,899 epoch 1 - iter 60/107 - loss 0.34585074 - samples/sec: 105.23 - lr: 0.100000
2022-03-28 10:47:29,963 epoch 1 - iter 70/107 - loss 0.33695888 - samples/sec: 104.47 - lr: 0.100000
2022-03-28 10:47:32,858 epoch 1 - iter 80/107 - loss 0.33269159 - samples/sec: 110.57 - lr: 0.100000
2022-03-28 10:47:35,577 epoch 1 - iter 90/107 - loss 0.32860843 - samples/sec: 117.76 - lr: 0.100000
2022-03-28 10:47:38,337 epoch 1 - iter 100/107 - loss 0.32445915 - samples/sec: 116.00 - lr: 0.100000
2022-03-28 10:47:40,054 ----------------------------------------------------------------------------------------------------
2022-03-28 10:47:40,054 EPOCH 1 done: loss 0.3191 - lr 0.100000
2022-03-28 10:47:52,615 Evaluating as a multi-label problem: False
2022-03-28 10:47:52,626 DEV : loss 0.43273240327835083 - f1-score (micro avg)  0.2085
2022-03-28 10:47:52,710 BAD EPOCHS (no improvement): 0
2022-03-28 10:47:52,714 saving best model
2022-03-28 10:48:16,469 ----------------------------------------------------------------------------------------------------
2022-03-28 10:48:22,476 epoch 2 - iter 10/107 - loss 0.21343607 - samples/sec: 53.29 - lr: 0.100000
2022-03-28 10:48:24,174 epoch 2 - iter 20/107 - loss 0.23552617 - samples/sec: 188.58 - lr: 0.100000
2022-03-28 10:48:25,877 epoch 2 - iter 30/107 - loss 0.21839314 - samples/sec: 187.96 - lr: 0.100000
2022-03-28 10:48:27,570 epoch 2 - iter 40/107 - loss 0.21256371 - samples/sec: 189.19 - lr: 0.100000
2022-03-28 10:48:29,373 epoch 2 - iter 50/107 - loss 0.20531680 - samples/sec: 177.59 - lr: 0.100000
2022-03-28 10:48:31,075 epoch 2 - iter 60/107 - loss 0.20316385 - samples/sec: 188.13 - lr: 0.100000
2022-03-28 10:48:32,806 epoch 2 - iter 70/107 - loss 0.19905055 - samples/sec: 184.97 - lr: 0.100000
2022-03-28 10:48:34,481 epoch 2 - iter 80/107 - loss 0.19418473 - samples/sec: 191.11 - lr: 0.100000
2022-03-28 10:48:36,174 epoch 2 - iter 90/107 - loss 0.19463853 - samples/sec: 189.18 - lr: 0.100000
2022-03-28 10:48:37,858 epoch 2 - iter 100/107 - loss 0.19281407 - samples/sec: 190.06 - lr: 0.100000
2022-03-28 10:48:38,873 ----------------------------------------------------------------------------------------------------
2022-03-28 10:48:38,874 EPOCH 2 done: loss 0.1929 - lr 0.100000
2022-03-28 10:48:44,864 Evaluating as a multi-label problem: False
2022-03-28 10:48:44,874 DEV : loss 0.32900264859199524 - f1-score (micro avg)  0.3151
2022-03-28 10:48:44,958 BAD EPOCHS (no improvement): 0
2022-03-28 10:48:44,961 saving best model
2022-03-28 10:49:09,510 ----------------------------------------------------------------------------------------------------
2022-03-28 10:49:11,430 epoch 3 - iter 10/107 - loss 0.17591952 - samples/sec: 166.80 - lr: 0.100000
2022-03-28 10:49:13,304 epoch 3 - iter 20/107 - loss 0.15228144 - samples/sec: 170.90 - lr: 0.100000
2022-03-28 10:49:15,251 epoch 3 - iter 30/107 - loss 0.15604759 - samples/sec: 164.43 - lr: 0.100000
2022-03-28 10:49:16,976 epoch 3 - iter 40/107 - loss 0.15316446 - samples/sec: 185.54 - lr: 0.100000
2022-03-28 10:49:18,692 epoch 3 - iter 50/107 - loss 0.15868404 - samples/sec: 186.67 - lr: 0.100000
2022-03-28 10:49:20,513 epoch 3 - iter 60/107 - loss 0.16225948 - samples/sec: 175.82 - lr: 0.100000
2022-03-28 10:49:22,349 epoch 3 - iter 70/107 - loss 0.16535880 - samples/sec: 174.31 - lr: 0.100000
2022-03-28 10:49:24,145 epoch 3 - iter 80/107 - loss 0.16199952 - samples/sec: 178.38 - lr: 0.100000
2022-03-28 10:49:25,957 epoch 3 - iter 90/107 - loss 0.16220807 - samples/sec: 176.67 - lr: 0.100000
2022-03-28 10:49:27,748 epoch 3 - iter 100/107 - loss 0.15908754 - samples/sec: 178.77 - lr: 0.100000
2022-03-28 10:49:28,878 ----------------------------------------------------------------------------------------------------
2022-03-28 10:49:28,878 EPOCH 3 done: loss 0.1609 - lr 0.100000
2022-03-28 10:49:34,905 Evaluating as a multi-label problem: False
2022-03-28 10:49:34,915 DEV : loss 0.26986226439476013 - f1-score (micro avg)  0.4329
2022-03-28 10:49:35,001 BAD EPOCHS (no improvement): 0
2022-03-28 10:49:35,004 saving best model
2022-03-28 10:49:59,152 ----------------------------------------------------------------------------------------------------
2022-03-28 10:50:01,173 epoch 4 - iter 10/107 - loss 0.15063034 - samples/sec: 158.49 - lr: 0.100000
2022-03-28 10:50:02,957 epoch 4 - iter 20/107 - loss 0.15635822 - samples/sec: 179.47 - lr: 0.100000
2022-03-28 10:50:04,782 epoch 4 - iter 30/107 - loss 0.14892311 - samples/sec: 175.47 - lr: 0.100000
2022-03-28 10:50:06,535 epoch 4 - iter 40/107 - loss 0.14935279 - samples/sec: 182.64 - lr: 0.100000
2022-03-28 10:50:08,221 epoch 4 - iter 50/107 - loss 0.14506755 - samples/sec: 189.83 - lr: 0.100000
2022-03-28 10:50:10,009 epoch 4 - iter 60/107 - loss 0.14365268 - samples/sec: 179.09 - lr: 0.100000
2022-03-28 10:50:11,720 epoch 4 - iter 70/107 - loss 0.14161751 - samples/sec: 187.18 - lr: 0.100000
2022-03-28 10:50:13,528 epoch 4 - iter 80/107 - loss 0.14167007 - samples/sec: 177.09 - lr: 0.100000
2022-03-28 10:50:15,312 epoch 4 - iter 90/107 - loss 0.14044749 - samples/sec: 179.40 - lr: 0.100000
2022-03-28 10:50:16,967 epoch 4 - iter 100/107 - loss 0.14011413 - samples/sec: 193.52 - lr: 0.100000
2022-03-28 10:50:17,984 ----------------------------------------------------------------------------------------------------
2022-03-28 10:50:17,985 EPOCH 4 done: loss 0.1404 - lr 0.100000
2022-03-28 10:50:23,932 Evaluating as a multi-label problem: False
2022-03-28 10:50:23,943 DEV : loss 0.20924220979213715 - f1-score (micro avg)  0.532
2022-03-28 10:50:24,030 BAD EPOCHS (no improvement): 0
2022-03-28 10:50:24,047 saving best model
2022-03-28 10:50:48,441 ----------------------------------------------------------------------------------------------------
2022-03-28 10:50:50,727 epoch 5 - iter 10/107 - loss 0.11889990 - samples/sec: 140.12 - lr: 0.100000
2022-03-28 10:50:53,039 epoch 5 - iter 20/107 - loss 0.12372560 - samples/sec: 138.50 - lr: 0.100000
2022-03-28 10:50:55,325 epoch 5 - iter 30/107 - loss 0.12847273 - samples/sec: 140.02 - lr: 0.100000
2022-03-28 10:50:57,645 epoch 5 - iter 40/107 - loss 0.12333352 - samples/sec: 138.00 - lr: 0.100000
2022-03-28 10:50:59,840 epoch 5 - iter 50/107 - loss 0.12930966 - samples/sec: 145.93 - lr: 0.100000
2022-03-28 10:51:02,217 epoch 5 - iter 60/107 - loss 0.12965654 - samples/sec: 134.68 - lr: 0.100000
2022-03-28 10:51:04,509 epoch 5 - iter 70/107 - loss 0.12831534 - samples/sec: 139.69 - lr: 0.100000
2022-03-28 10:51:06,805 epoch 5 - iter 80/107 - loss 0.12862947 - samples/sec: 139.46 - lr: 0.100000
2022-03-28 10:51:09,198 epoch 5 - iter 90/107 - loss 0.12644180 - samples/sec: 133.79 - lr: 0.100000
2022-03-28 10:51:11,596 epoch 5 - iter 100/107 - loss 0.12608890 - samples/sec: 133.52 - lr: 0.100000
2022-03-28 10:51:12,964 ----------------------------------------------------------------------------------------------------
2022-03-28 10:51:12,964 EPOCH 5 done: loss 0.1254 - lr 0.100000
2022-03-28 10:51:20,536 Evaluating as a multi-label problem: False
2022-03-28 10:51:20,548 DEV : loss 0.22790662944316864 - f1-score (micro avg)  0.4642
2022-03-28 10:51:20,665 BAD EPOCHS (no improvement): 1
2022-03-28 10:51:20,701 ----------------------------------------------------------------------------------------------------
2022-03-28 10:51:23,005 epoch 6 - iter 10/107 - loss 0.16375980 - samples/sec: 138.97 - lr: 0.100000
2022-03-28 10:51:25,372 epoch 6 - iter 20/107 - loss 0.13364310 - samples/sec: 135.29 - lr: 0.100000
2022-03-28 10:51:27,586 epoch 6 - iter 30/107 - loss 0.12462864 - samples/sec: 144.62 - lr: 0.100000
2022-03-28 10:51:29,814 epoch 6 - iter 40/107 - loss 0.12158089 - samples/sec: 143.66 - lr: 0.100000
2022-03-28 10:51:32,159 epoch 6 - iter 50/107 - loss 0.11917449 - samples/sec: 136.56 - lr: 0.100000
2022-03-28 10:51:34,421 epoch 6 - iter 60/107 - loss 0.11914031 - samples/sec: 141.54 - lr: 0.100000
2022-03-28 10:51:36,663 epoch 6 - iter 70/107 - loss 0.11420143 - samples/sec: 142.79 - lr: 0.100000
2022-03-28 10:51:38,947 epoch 6 - iter 80/107 - loss 0.11274068 - samples/sec: 140.22 - lr: 0.100000
2022-03-28 10:51:41,283 epoch 6 - iter 90/107 - loss 0.11347222 - samples/sec: 137.00 - lr: 0.100000
2022-03-28 10:51:43,469 epoch 6 - iter 100/107 - loss 0.11307871 - samples/sec: 146.52 - lr: 0.100000
2022-03-28 10:51:44,861 ----------------------------------------------------------------------------------------------------
2022-03-28 10:51:44,862 EPOCH 6 done: loss 0.1138 - lr 0.100000
2022-03-28 10:51:52,523 Evaluating as a multi-label problem: False
2022-03-28 10:51:52,534 DEV : loss 0.2514066994190216 - f1-score (micro avg)  0.454
2022-03-28 10:51:52,648 BAD EPOCHS (no improvement): 2
2022-03-28 10:51:52,650 ----------------------------------------------------------------------------------------------------
2022-03-28 10:51:54,922 epoch 7 - iter 10/107 - loss 0.12289305 - samples/sec: 140.93 - lr: 0.100000
2022-03-28 10:51:57,118 epoch 7 - iter 20/107 - loss 0.11696038 - samples/sec: 145.83 - lr: 0.100000
2022-03-28 10:51:59,305 epoch 7 - iter 30/107 - loss 0.12095801 - samples/sec: 146.43 - lr: 0.100000
2022-03-28 10:52:01,561 epoch 7 - iter 40/107 - loss 0.12090472 - samples/sec: 141.88 - lr: 0.100000
2022-03-28 10:52:03,806 epoch 7 - iter 50/107 - loss 0.11836975 - samples/sec: 142.63 - lr: 0.100000
2022-03-28 10:52:06,201 epoch 7 - iter 60/107 - loss 0.11309005 - samples/sec: 133.66 - lr: 0.100000
2022-03-28 10:52:08,498 epoch 7 - iter 70/107 - loss 0.11147844 - samples/sec: 139.40 - lr: 0.100000
2022-03-28 10:52:10,720 epoch 7 - iter 80/107 - loss 0.11310718 - samples/sec: 144.09 - lr: 0.100000
2022-03-28 10:52:13,024 epoch 7 - iter 90/107 - loss 0.11104867 - samples/sec: 138.94 - lr: 0.100000
2022-03-28 10:52:15,291 epoch 7 - iter 100/107 - loss 0.10899122 - samples/sec: 141.21 - lr: 0.100000
2022-03-28 10:52:16,716 ----------------------------------------------------------------------------------------------------
2022-03-28 10:52:16,716 EPOCH 7 done: loss 0.1086 - lr 0.100000
2022-03-28 10:52:24,312 Evaluating as a multi-label problem: False
2022-03-28 10:52:24,323 DEV : loss 0.21159307658672333 - f1-score (micro avg)  0.474
2022-03-28 10:52:24,441 BAD EPOCHS (no improvement): 3
2022-03-28 10:52:24,443 ----------------------------------------------------------------------------------------------------
2022-03-28 10:52:26,681 epoch 8 - iter 10/107 - loss 0.09991642 - samples/sec: 143.14 - lr: 0.100000
2022-03-28 10:52:28,904 epoch 8 - iter 20/107 - loss 0.09728316 - samples/sec: 144.00 - lr: 0.100000
2022-03-28 10:52:31,200 epoch 8 - iter 30/107 - loss 0.09112908 - samples/sec: 139.40 - lr: 0.100000
2022-03-28 10:52:33,430 epoch 8 - iter 40/107 - loss 0.09553799 - samples/sec: 143.59 - lr: 0.100000
2022-03-28 10:52:35,728 epoch 8 - iter 50/107 - loss 0.09658974 - samples/sec: 139.30 - lr: 0.100000
2022-03-28 10:52:38,016 epoch 8 - iter 60/107 - loss 0.09764115 - samples/sec: 139.99 - lr: 0.100000
2022-03-28 10:52:40,297 epoch 8 - iter 70/107 - loss 0.10049100 - samples/sec: 140.32 - lr: 0.100000
2022-03-28 10:52:42,487 epoch 8 - iter 80/107 - loss 0.10182015 - samples/sec: 146.21 - lr: 0.100000
2022-03-28 10:52:44,810 epoch 8 - iter 90/107 - loss 0.10332068 - samples/sec: 137.83 - lr: 0.100000
2022-03-28 10:52:47,040 epoch 8 - iter 100/107 - loss 0.10251982 - samples/sec: 143.58 - lr: 0.100000
2022-03-28 10:52:48,515 ----------------------------------------------------------------------------------------------------
2022-03-28 10:52:48,515 EPOCH 8 done: loss 0.1025 - lr 0.100000
2022-03-28 10:52:56,086 Evaluating as a multi-label problem: False
2022-03-28 10:52:56,097 DEV : loss 0.20585303008556366 - f1-score (micro avg)  0.506
2022-03-28 10:52:56,209 Epoch     8: reducing learning rate of group 0 to 5.0000e-02.
2022-03-28 10:52:56,209 BAD EPOCHS (no improvement): 4
2022-03-28 10:52:56,212 ----------------------------------------------------------------------------------------------------
2022-03-28 10:52:58,416 epoch 9 - iter 10/107 - loss 0.09533598 - samples/sec: 145.26 - lr: 0.050000
2022-03-28 10:53:00,659 epoch 9 - iter 20/107 - loss 0.09672680 - samples/sec: 142.78 - lr: 0.050000
2022-03-28 10:53:02,867 epoch 9 - iter 30/107 - loss 0.09083199 - samples/sec: 144.99 - lr: 0.050000
2022-03-28 10:53:05,118 epoch 9 - iter 40/107 - loss 0.09222708 - samples/sec: 142.24 - lr: 0.050000
2022-03-28 10:53:07,364 epoch 9 - iter 50/107 - loss 0.09201962 - samples/sec: 142.57 - lr: 0.050000
2022-03-28 10:53:09,650 epoch 9 - iter 60/107 - loss 0.09267694 - samples/sec: 140.05 - lr: 0.050000
2022-03-28 10:53:11,926 epoch 9 - iter 70/107 - loss 0.09186625 - samples/sec: 140.63 - lr: 0.050000
2022-03-28 10:53:14,213 epoch 9 - iter 80/107 - loss 0.09482540 - samples/sec: 139.99 - lr: 0.050000
2022-03-28 10:53:16,573 epoch 9 - iter 90/107 - loss 0.09354962 - samples/sec: 135.66 - lr: 0.050000
2022-03-28 10:53:18,668 epoch 9 - iter 100/107 - loss 0.09223149 - samples/sec: 152.84 - lr: 0.050000
2022-03-28 10:53:19,973 ----------------------------------------------------------------------------------------------------
2022-03-28 10:53:19,973 EPOCH 9 done: loss 0.0916 - lr 0.050000
2022-03-28 10:53:26,374 Evaluating as a multi-label problem: False
2022-03-28 10:53:26,384 DEV : loss 0.19357673823833466 - f1-score (micro avg)  0.5101
2022-03-28 10:53:26,471 BAD EPOCHS (no improvement): 1
2022-03-28 10:53:26,474 ----------------------------------------------------------------------------------------------------
2022-03-28 10:53:28,384 epoch 10 - iter 10/107 - loss 0.08729109 - samples/sec: 167.69 - lr: 0.050000
2022-03-28 10:53:30,205 epoch 10 - iter 20/107 - loss 0.08177250 - samples/sec: 175.76 - lr: 0.050000
2022-03-28 10:53:32,000 epoch 10 - iter 30/107 - loss 0.08153556 - samples/sec: 178.38 - lr: 0.050000
2022-03-28 10:53:33,906 epoch 10 - iter 40/107 - loss 0.08116482 - samples/sec: 168.04 - lr: 0.050000
2022-03-28 10:53:35,686 epoch 10 - iter 50/107 - loss 0.08649854 - samples/sec: 179.85 - lr: 0.050000
2022-03-28 10:53:37,452 epoch 10 - iter 60/107 - loss 0.08442519 - samples/sec: 181.35 - lr: 0.050000
2022-03-28 10:53:39,292 epoch 10 - iter 70/107 - loss 0.08353124 - samples/sec: 174.03 - lr: 0.050000
2022-03-28 10:53:41,077 epoch 10 - iter 80/107 - loss 0.08350732 - samples/sec: 179.33 - lr: 0.050000
2022-03-28 10:53:42,922 epoch 10 - iter 90/107 - loss 0.08351715 - samples/sec: 173.53 - lr: 0.050000
2022-03-28 10:53:44,699 epoch 10 - iter 100/107 - loss 0.08543116 - samples/sec: 180.23 - lr: 0.050000
2022-03-28 10:53:45,795 ----------------------------------------------------------------------------------------------------
2022-03-28 10:53:45,795 EPOCH 10 done: loss 0.0849 - lr 0.050000
2022-03-28 10:53:51,956 Evaluating as a multi-label problem: False
2022-03-28 10:53:51,967 DEV : loss 0.19943732023239136 - f1-score (micro avg)  0.4952
2022-03-28 10:53:52,054 BAD EPOCHS (no improvement): 2
2022-03-28 10:53:52,057 ----------------------------------------------------------------------------------------------------
2022-03-28 10:53:53,967 epoch 11 - iter 10/107 - loss 0.08237566 - samples/sec: 167.69 - lr: 0.050000
2022-03-28 10:53:55,821 epoch 11 - iter 20/107 - loss 0.07106593 - samples/sec: 172.65 - lr: 0.050000
2022-03-28 10:53:57,679 epoch 11 - iter 30/107 - loss 0.07820897 - samples/sec: 172.31 - lr: 0.050000
2022-03-28 10:53:59,441 epoch 11 - iter 40/107 - loss 0.07861002 - samples/sec: 181.66 - lr: 0.050000
2022-03-28 10:54:01,210 epoch 11 - iter 50/107 - loss 0.08130334 - samples/sec: 181.02 - lr: 0.050000
2022-03-28 10:54:03,031 epoch 11 - iter 60/107 - loss 0.08286184 - samples/sec: 175.82 - lr: 0.050000
2022-03-28 10:54:04,821 epoch 11 - iter 70/107 - loss 0.08374576 - samples/sec: 178.87 - lr: 0.050000
2022-03-28 10:54:06,686 epoch 11 - iter 80/107 - loss 0.08209141 - samples/sec: 171.65 - lr: 0.050000
2022-03-28 10:54:08,481 epoch 11 - iter 90/107 - loss 0.08201028 - samples/sec: 178.40 - lr: 0.050000
2022-03-28 10:54:10,343 epoch 11 - iter 100/107 - loss 0.08233517 - samples/sec: 171.96 - lr: 0.050000
2022-03-28 10:54:11,485 ----------------------------------------------------------------------------------------------------
2022-03-28 10:54:11,485 EPOCH 11 done: loss 0.0816 - lr 0.050000
2022-03-28 10:54:17,629 Evaluating as a multi-label problem: False
2022-03-28 10:54:17,640 DEV : loss 0.21750858426094055 - f1-score (micro avg)  0.4857
2022-03-28 10:54:17,726 BAD EPOCHS (no improvement): 3
2022-03-28 10:54:17,728 ----------------------------------------------------------------------------------------------------
2022-03-28 10:54:19,560 epoch 12 - iter 10/107 - loss 0.07737025 - samples/sec: 174.82 - lr: 0.050000
2022-03-28 10:54:21,421 epoch 12 - iter 20/107 - loss 0.07142343 - samples/sec: 172.12 - lr: 0.050000
2022-03-28 10:54:23,180 epoch 12 - iter 30/107 - loss 0.06883721 - samples/sec: 182.00 - lr: 0.050000
2022-03-28 10:54:24,960 epoch 12 - iter 40/107 - loss 0.06809609 - samples/sec: 179.89 - lr: 0.050000
2022-03-28 10:54:26,838 epoch 12 - iter 50/107 - loss 0.06958037 - samples/sec: 170.44 - lr: 0.050000
2022-03-28 10:54:28,685 epoch 12 - iter 60/107 - loss 0.07123188 - samples/sec: 173.31 - lr: 0.050000
2022-03-28 10:54:30,588 epoch 12 - iter 70/107 - loss 0.07585721 - samples/sec: 168.28 - lr: 0.050000
2022-03-28 10:54:32,458 epoch 12 - iter 80/107 - loss 0.07636469 - samples/sec: 171.25 - lr: 0.050000
2022-03-28 10:54:34,261 epoch 12 - iter 90/107 - loss 0.07712264 - samples/sec: 177.50 - lr: 0.050000
2022-03-28 10:54:36,036 epoch 12 - iter 100/107 - loss 0.07695295 - samples/sec: 180.37 - lr: 0.050000
2022-03-28 10:54:37,121 ----------------------------------------------------------------------------------------------------
2022-03-28 10:54:37,121 EPOCH 12 done: loss 0.0786 - lr 0.050000
2022-03-28 10:54:43,261 Evaluating as a multi-label problem: False
2022-03-28 10:54:43,271 DEV : loss 0.20085345208644867 - f1-score (micro avg)  0.488
2022-03-28 10:54:43,358 Epoch    12: reducing learning rate of group 0 to 2.5000e-02.
2022-03-28 10:54:43,358 BAD EPOCHS (no improvement): 4
2022-03-28 10:54:43,361 ----------------------------------------------------------------------------------------------------
2022-03-28 10:54:45,301 epoch 13 - iter 10/107 - loss 0.07295982 - samples/sec: 165.03 - lr: 0.025000
2022-03-28 10:54:47,105 epoch 13 - iter 20/107 - loss 0.07815199 - samples/sec: 177.48 - lr: 0.025000
2022-03-28 10:54:48,909 epoch 13 - iter 30/107 - loss 0.07629014 - samples/sec: 177.51 - lr: 0.025000
2022-03-28 10:54:50,744 epoch 13 - iter 40/107 - loss 0.07575239 - samples/sec: 174.49 - lr: 0.025000
2022-03-28 10:54:52,511 epoch 13 - iter 50/107 - loss 0.07402960 - samples/sec: 181.19 - lr: 0.025000
2022-03-28 10:54:54,276 epoch 13 - iter 60/107 - loss 0.07622255 - samples/sec: 181.37 - lr: 0.025000
2022-03-28 10:54:56,159 epoch 13 - iter 70/107 - loss 0.07532459 - samples/sec: 170.04 - lr: 0.025000
2022-03-28 10:54:58,008 epoch 13 - iter 80/107 - loss 0.07424918 - samples/sec: 173.18 - lr: 0.025000
2022-03-28 10:54:59,806 epoch 13 - iter 90/107 - loss 0.07482763 - samples/sec: 178.13 - lr: 0.025000
2022-03-28 10:55:01,596 epoch 13 - iter 100/107 - loss 0.07550939 - samples/sec: 178.87 - lr: 0.025000
2022-03-28 10:55:02,654 ----------------------------------------------------------------------------------------------------
2022-03-28 10:55:02,654 EPOCH 13 done: loss 0.0761 - lr 0.025000
2022-03-28 10:55:08,571 Evaluating as a multi-label problem: False
2022-03-28 10:55:08,582 DEV : loss 0.18908926844596863 - f1-score (micro avg)  0.5188
2022-03-28 10:55:08,668 BAD EPOCHS (no improvement): 1
2022-03-28 10:55:08,671 ----------------------------------------------------------------------------------------------------
2022-03-28 10:55:10,398 epoch 14 - iter 10/107 - loss 0.07562284 - samples/sec: 185.39 - lr: 0.025000
2022-03-28 10:55:12,132 epoch 14 - iter 20/107 - loss 0.07358065 - samples/sec: 184.68 - lr: 0.025000
2022-03-28 10:55:13,869 epoch 14 - iter 30/107 - loss 0.06851408 - samples/sec: 184.36 - lr: 0.025000
2022-03-28 10:55:15,633 epoch 14 - iter 40/107 - loss 0.07068703 - samples/sec: 181.46 - lr: 0.025000
2022-03-28 10:55:17,363 epoch 14 - iter 50/107 - loss 0.07078274 - samples/sec: 185.13 - lr: 0.025000
2022-03-28 10:55:19,070 epoch 14 - iter 60/107 - loss 0.07117022 - samples/sec: 187.58 - lr: 0.025000
2022-03-28 10:55:20,830 epoch 14 - iter 70/107 - loss 0.07198425 - samples/sec: 181.89 - lr: 0.025000
2022-03-28 10:55:22,593 epoch 14 - iter 80/107 - loss 0.07344326 - samples/sec: 181.59 - lr: 0.025000
2022-03-28 10:55:24,339 epoch 14 - iter 90/107 - loss 0.07282716 - samples/sec: 183.35 - lr: 0.025000
2022-03-28 10:55:26,177 epoch 14 - iter 100/107 - loss 0.07227676 - samples/sec: 174.24 - lr: 0.025000
2022-03-28 10:55:27,250 ----------------------------------------------------------------------------------------------------
2022-03-28 10:55:27,250 EPOCH 14 done: loss 0.0718 - lr 0.025000
2022-03-28 10:55:33,348 Evaluating as a multi-label problem: False
2022-03-28 10:55:33,359 DEV : loss 0.19301365315914154 - f1-score (micro avg)  0.5332
2022-03-28 10:55:33,447 BAD EPOCHS (no improvement): 0
2022-03-28 10:55:33,449 saving best model
2022-03-28 10:55:58,256 ----------------------------------------------------------------------------------------------------
2022-03-28 10:56:00,085 epoch 15 - iter 10/107 - loss 0.08507375 - samples/sec: 175.11 - lr: 0.025000
2022-03-28 10:56:01,871 epoch 15 - iter 20/107 - loss 0.07930327 - samples/sec: 179.30 - lr: 0.025000
2022-03-28 10:56:03,733 epoch 15 - iter 30/107 - loss 0.07355284 - samples/sec: 171.93 - lr: 0.025000
2022-03-28 10:56:05,567 epoch 15 - iter 40/107 - loss 0.07005041 - samples/sec: 174.57 - lr: 0.025000
2022-03-28 10:56:08,717 epoch 15 - iter 50/107 - loss 0.06989005 - samples/sec: 101.63 - lr: 0.025000
2022-03-28 10:56:10,582 epoch 15 - iter 60/107 - loss 0.07107936 - samples/sec: 171.65 - lr: 0.025000
2022-03-28 10:56:12,347 epoch 15 - iter 70/107 - loss 0.07075680 - samples/sec: 181.39 - lr: 0.025000
2022-03-28 10:56:14,203 epoch 15 - iter 80/107 - loss 0.07055822 - samples/sec: 172.56 - lr: 0.025000
2022-03-28 10:56:15,991 epoch 15 - iter 90/107 - loss 0.07064603 - samples/sec: 178.99 - lr: 0.025000
2022-03-28 10:56:17,788 epoch 15 - iter 100/107 - loss 0.07161535 - samples/sec: 178.22 - lr: 0.025000
2022-03-28 10:56:18,822 ----------------------------------------------------------------------------------------------------
2022-03-28 10:56:18,822 EPOCH 15 done: loss 0.0713 - lr 0.025000
2022-03-28 10:56:24,941 Evaluating as a multi-label problem: False
2022-03-28 10:56:24,952 DEV : loss 0.19403934478759766 - f1-score (micro avg)  0.5152
2022-03-28 10:56:25,040 BAD EPOCHS (no improvement): 1
2022-03-28 10:56:25,043 ----------------------------------------------------------------------------------------------------
2022-03-28 10:56:26,877 epoch 16 - iter 10/107 - loss 0.07274934 - samples/sec: 174.53 - lr: 0.025000
2022-03-28 10:56:28,698 epoch 16 - iter 20/107 - loss 0.06640155 - samples/sec: 175.84 - lr: 0.025000
2022-03-28 10:56:30,522 epoch 16 - iter 30/107 - loss 0.06861147 - samples/sec: 175.52 - lr: 0.025000
2022-03-28 10:56:32,251 epoch 16 - iter 40/107 - loss 0.07043538 - samples/sec: 185.27 - lr: 0.025000
2022-03-28 10:56:33,969 epoch 16 - iter 50/107 - loss 0.06894785 - samples/sec: 186.37 - lr: 0.025000
2022-03-28 10:56:35,781 epoch 16 - iter 60/107 - loss 0.07088831 - samples/sec: 176.69 - lr: 0.025000
2022-03-28 10:56:37,559 epoch 16 - iter 70/107 - loss 0.07029998 - samples/sec: 180.06 - lr: 0.025000
2022-03-28 10:56:39,326 epoch 16 - iter 80/107 - loss 0.07017464 - samples/sec: 181.26 - lr: 0.025000
2022-03-28 10:56:41,078 epoch 16 - iter 90/107 - loss 0.07066479 - samples/sec: 182.71 - lr: 0.025000
2022-03-28 10:56:42,839 epoch 16 - iter 100/107 - loss 0.07046633 - samples/sec: 181.81 - lr: 0.025000
2022-03-28 10:56:43,916 ----------------------------------------------------------------------------------------------------
2022-03-28 10:56:43,916 EPOCH 16 done: loss 0.0701 - lr 0.025000
2022-03-28 10:56:50,013 Evaluating as a multi-label problem: False
2022-03-28 10:56:50,024 DEV : loss 0.18739750981330872 - f1-score (micro avg)  0.5251
2022-03-28 10:56:50,111 BAD EPOCHS (no improvement): 2
2022-03-28 10:56:50,114 ----------------------------------------------------------------------------------------------------
2022-03-28 10:56:52,052 epoch 17 - iter 10/107 - loss 0.06345485 - samples/sec: 165.20 - lr: 0.025000
2022-03-28 10:56:53,887 epoch 17 - iter 20/107 - loss 0.07168077 - samples/sec: 174.46 - lr: 0.025000
2022-03-28 10:56:55,712 epoch 17 - iter 30/107 - loss 0.07028210 - samples/sec: 175.49 - lr: 0.025000
2022-03-28 10:56:57,487 epoch 17 - iter 40/107 - loss 0.06644307 - samples/sec: 180.34 - lr: 0.025000
2022-03-28 10:56:59,333 epoch 17 - iter 50/107 - loss 0.06402781 - samples/sec: 173.40 - lr: 0.025000
2022-03-28 10:57:01,139 epoch 17 - iter 60/107 - loss 0.06189996 - samples/sec: 177.30 - lr: 0.025000
2022-03-28 10:57:02,964 epoch 17 - iter 70/107 - loss 0.06301339 - samples/sec: 175.40 - lr: 0.025000
2022-03-28 10:57:04,715 epoch 17 - iter 80/107 - loss 0.06384944 - samples/sec: 182.89 - lr: 0.025000
2022-03-28 10:57:06,507 epoch 17 - iter 90/107 - loss 0.06586180 - samples/sec: 178.66 - lr: 0.025000
2022-03-28 10:57:08,265 epoch 17 - iter 100/107 - loss 0.06656986 - samples/sec: 182.14 - lr: 0.025000
2022-03-28 10:57:09,272 ----------------------------------------------------------------------------------------------------
2022-03-28 10:57:09,272 EPOCH 17 done: loss 0.0668 - lr 0.025000
2022-03-28 10:57:15,362 Evaluating as a multi-label problem: False
2022-03-28 10:57:15,373 DEV : loss 0.19436253607273102 - f1-score (micro avg)  0.5089
2022-03-28 10:57:15,460 BAD EPOCHS (no improvement): 3
2022-03-28 10:57:15,462 ----------------------------------------------------------------------------------------------------
2022-03-28 10:57:17,332 epoch 18 - iter 10/107 - loss 0.06421245 - samples/sec: 171.32 - lr: 0.025000
2022-03-28 10:57:19,197 epoch 18 - iter 20/107 - loss 0.06651864 - samples/sec: 171.63 - lr: 0.025000
2022-03-28 10:57:21,052 epoch 18 - iter 30/107 - loss 0.06948072 - samples/sec: 172.66 - lr: 0.025000
2022-03-28 10:57:22,818 epoch 18 - iter 40/107 - loss 0.07173944 - samples/sec: 181.28 - lr: 0.025000
2022-03-28 10:57:24,457 epoch 18 - iter 50/107 - loss 0.06914138 - samples/sec: 195.43 - lr: 0.025000
2022-03-28 10:57:26,131 epoch 18 - iter 60/107 - loss 0.06621379 - samples/sec: 191.19 - lr: 0.025000
2022-03-28 10:57:27,900 epoch 18 - iter 70/107 - loss 0.06539364 - samples/sec: 181.04 - lr: 0.025000
2022-03-28 10:57:29,631 epoch 18 - iter 80/107 - loss 0.06707955 - samples/sec: 184.94 - lr: 0.025000
2022-03-28 10:57:31,418 epoch 18 - iter 90/107 - loss 0.06706498 - samples/sec: 179.19 - lr: 0.025000
2022-03-28 10:57:33,174 epoch 18 - iter 100/107 - loss 0.06684528 - samples/sec: 182.26 - lr: 0.025000
2022-03-28 10:57:34,268 ----------------------------------------------------------------------------------------------------
2022-03-28 10:57:34,268 EPOCH 18 done: loss 0.0668 - lr 0.025000
2022-03-28 10:57:40,394 Evaluating as a multi-label problem: False
2022-03-28 10:57:40,405 DEV : loss 0.19272881746292114 - f1-score (micro avg)  0.5326
2022-03-28 10:57:40,496 Epoch    18: reducing learning rate of group 0 to 1.2500e-02.
2022-03-28 10:57:40,496 BAD EPOCHS (no improvement): 4
2022-03-28 10:57:40,499 ----------------------------------------------------------------------------------------------------
2022-03-28 10:57:42,486 epoch 19 - iter 10/107 - loss 0.05553241 - samples/sec: 161.09 - lr: 0.012500
2022-03-28 10:57:44,329 epoch 19 - iter 20/107 - loss 0.06248955 - samples/sec: 173.76 - lr: 0.012500
2022-03-28 10:57:46,097 epoch 19 - iter 30/107 - loss 0.06265650 - samples/sec: 181.13 - lr: 0.012500
2022-03-28 10:57:47,855 epoch 19 - iter 40/107 - loss 0.06417451 - samples/sec: 182.12 - lr: 0.012500
2022-03-28 10:57:49,581 epoch 19 - iter 50/107 - loss 0.06428540 - samples/sec: 185.48 - lr: 0.012500
2022-03-28 10:57:51,374 epoch 19 - iter 60/107 - loss 0.06449608 - samples/sec: 178.49 - lr: 0.012500
2022-03-28 10:57:53,081 epoch 19 - iter 70/107 - loss 0.06413612 - samples/sec: 187.61 - lr: 0.012500
2022-03-28 10:57:54,874 epoch 19 - iter 80/107 - loss 0.06285966 - samples/sec: 178.60 - lr: 0.012500
2022-03-28 10:57:56,644 epoch 19 - iter 90/107 - loss 0.06271173 - samples/sec: 180.89 - lr: 0.012500
2022-03-28 10:57:58,425 epoch 19 - iter 100/107 - loss 0.06370111 - samples/sec: 179.72 - lr: 0.012500
2022-03-28 10:57:59,536 ----------------------------------------------------------------------------------------------------
2022-03-28 10:57:59,536 EPOCH 19 done: loss 0.0647 - lr 0.012500
2022-03-28 10:58:05,639 Evaluating as a multi-label problem: False
2022-03-28 10:58:05,650 DEV : loss 0.19672131538391113 - f1-score (micro avg)  0.5172
2022-03-28 10:58:05,736 BAD EPOCHS (no improvement): 1
2022-03-28 10:58:05,739 ----------------------------------------------------------------------------------------------------
2022-03-28 10:58:07,622 epoch 20 - iter 10/107 - loss 0.06347665 - samples/sec: 170.07 - lr: 0.012500
2022-03-28 10:58:09,490 epoch 20 - iter 20/107 - loss 0.05776907 - samples/sec: 171.42 - lr: 0.012500
2022-03-28 10:58:11,292 epoch 20 - iter 30/107 - loss 0.05844193 - samples/sec: 177.61 - lr: 0.012500
2022-03-28 10:58:13,027 epoch 20 - iter 40/107 - loss 0.06056644 - samples/sec: 184.63 - lr: 0.012500
2022-03-28 10:58:14,730 epoch 20 - iter 50/107 - loss 0.05968057 - samples/sec: 188.01 - lr: 0.012500
2022-03-28 10:58:16,457 epoch 20 - iter 60/107 - loss 0.06204885 - samples/sec: 185.40 - lr: 0.012500
2022-03-28 10:58:18,123 epoch 20 - iter 70/107 - loss 0.06161432 - samples/sec: 192.14 - lr: 0.012500
2022-03-28 10:58:19,813 epoch 20 - iter 80/107 - loss 0.06035765 - samples/sec: 189.44 - lr: 0.012500
2022-03-28 10:58:21,584 epoch 20 - iter 90/107 - loss 0.06162651 - samples/sec: 180.75 - lr: 0.012500
2022-03-28 10:58:23,288 epoch 20 - iter 100/107 - loss 0.06334454 - samples/sec: 187.93 - lr: 0.012500
2022-03-28 10:58:24,391 ----------------------------------------------------------------------------------------------------
2022-03-28 10:58:24,391 EPOCH 20 done: loss 0.0629 - lr 0.012500
2022-03-28 10:58:30,538 Evaluating as a multi-label problem: False
2022-03-28 10:58:30,549 DEV : loss 0.18807648122310638 - f1-score (micro avg)  0.5223
2022-03-28 10:58:30,638 BAD EPOCHS (no improvement): 2
2022-03-28 10:58:30,641 ----------------------------------------------------------------------------------------------------
2022-03-28 10:58:32,517 epoch 21 - iter 10/107 - loss 0.06360018 - samples/sec: 170.61 - lr: 0.012500
2022-03-28 10:58:34,329 epoch 21 - iter 20/107 - loss 0.06240855 - samples/sec: 176.76 - lr: 0.012500
2022-03-28 10:58:36,085 epoch 21 - iter 30/107 - loss 0.06223463 - samples/sec: 182.28 - lr: 0.012500
2022-03-28 10:58:37,806 epoch 21 - iter 40/107 - loss 0.05937401 - samples/sec: 186.09 - lr: 0.012500
2022-03-28 10:58:39,572 epoch 21 - iter 50/107 - loss 0.05960742 - samples/sec: 181.24 - lr: 0.012500
2022-03-28 10:58:41,346 epoch 21 - iter 60/107 - loss 0.05763954 - samples/sec: 180.52 - lr: 0.012500
2022-03-28 10:58:43,191 epoch 21 - iter 70/107 - loss 0.05814384 - samples/sec: 173.54 - lr: 0.012500
2022-03-28 10:58:45,017 epoch 21 - iter 80/107 - loss 0.05945760 - samples/sec: 175.30 - lr: 0.012500
2022-03-28 10:58:46,708 epoch 21 - iter 90/107 - loss 0.06035667 - samples/sec: 189.37 - lr: 0.012500
2022-03-28 10:58:48,454 epoch 21 - iter 100/107 - loss 0.06165535 - samples/sec: 183.30 - lr: 0.012500
2022-03-28 10:58:49,565 ----------------------------------------------------------------------------------------------------
2022-03-28 10:58:49,565 EPOCH 21 done: loss 0.0622 - lr 0.012500
2022-03-28 10:58:55,642 Evaluating as a multi-label problem: False
2022-03-28 10:58:55,653 DEV : loss 0.18399840593338013 - f1-score (micro avg)  0.5319
2022-03-28 10:58:55,743 BAD EPOCHS (no improvement): 3
2022-03-28 10:58:55,746 ----------------------------------------------------------------------------------------------------
2022-03-28 10:58:57,634 epoch 22 - iter 10/107 - loss 0.06586176 - samples/sec: 169.63 - lr: 0.012500
2022-03-28 10:58:59,425 epoch 22 - iter 20/107 - loss 0.06296001 - samples/sec: 178.81 - lr: 0.012500
2022-03-28 10:59:01,193 epoch 22 - iter 30/107 - loss 0.05867018 - samples/sec: 181.07 - lr: 0.012500
2022-03-28 10:59:02,904 epoch 22 - iter 40/107 - loss 0.05753208 - samples/sec: 187.19 - lr: 0.012500
2022-03-28 10:59:04,657 epoch 22 - iter 50/107 - loss 0.06406936 - samples/sec: 182.64 - lr: 0.012500
2022-03-28 10:59:06,410 epoch 22 - iter 60/107 - loss 0.06317192 - samples/sec: 182.62 - lr: 0.012500
2022-03-28 10:59:08,166 epoch 22 - iter 70/107 - loss 0.06404646 - samples/sec: 182.34 - lr: 0.012500
2022-03-28 10:59:09,924 epoch 22 - iter 80/107 - loss 0.06267397 - samples/sec: 182.11 - lr: 0.012500
2022-03-28 10:59:11,640 epoch 22 - iter 90/107 - loss 0.06288276 - samples/sec: 186.52 - lr: 0.012500
2022-03-28 10:59:13,401 epoch 22 - iter 100/107 - loss 0.06253187 - samples/sec: 181.87 - lr: 0.012500
2022-03-28 10:59:14,451 ----------------------------------------------------------------------------------------------------
2022-03-28 10:59:14,451 EPOCH 22 done: loss 0.0615 - lr 0.012500
2022-03-28 10:59:20,561 Evaluating as a multi-label problem: False
2022-03-28 10:59:20,571 DEV : loss 0.20814713835716248 - f1-score (micro avg)  0.5192
2022-03-28 10:59:20,659 Epoch    22: reducing learning rate of group 0 to 6.2500e-03.
2022-03-28 10:59:20,660 BAD EPOCHS (no improvement): 4
2022-03-28 10:59:20,662 ----------------------------------------------------------------------------------------------------
2022-03-28 10:59:22,529 epoch 23 - iter 10/107 - loss 0.05076915 - samples/sec: 171.57 - lr: 0.006250
2022-03-28 10:59:24,419 epoch 23 - iter 20/107 - loss 0.05417752 - samples/sec: 169.33 - lr: 0.006250
2022-03-28 10:59:26,157 epoch 23 - iter 30/107 - loss 0.05602676 - samples/sec: 184.27 - lr: 0.006250
2022-03-28 10:59:27,886 epoch 23 - iter 40/107 - loss 0.05643568 - samples/sec: 185.16 - lr: 0.006250
2022-03-28 10:59:29,636 epoch 23 - iter 50/107 - loss 0.05635781 - samples/sec: 182.95 - lr: 0.006250
2022-03-28 10:59:31,398 epoch 23 - iter 60/107 - loss 0.05785201 - samples/sec: 181.67 - lr: 0.006250
2022-03-28 10:59:33,170 epoch 23 - iter 70/107 - loss 0.05801518 - samples/sec: 180.66 - lr: 0.006250
2022-03-28 10:59:34,923 epoch 23 - iter 80/107 - loss 0.05957406 - samples/sec: 182.68 - lr: 0.006250
2022-03-28 10:59:36,620 epoch 23 - iter 90/107 - loss 0.05832836 - samples/sec: 188.66 - lr: 0.006250
2022-03-28 10:59:38,370 epoch 23 - iter 100/107 - loss 0.05876765 - samples/sec: 183.00 - lr: 0.006250
2022-03-28 10:59:39,393 ----------------------------------------------------------------------------------------------------
2022-03-28 10:59:39,393 EPOCH 23 done: loss 0.0603 - lr 0.006250
2022-03-28 10:59:45,452 Evaluating as a multi-label problem: False
2022-03-28 10:59:45,462 DEV : loss 0.19267791509628296 - f1-score (micro avg)  0.5283
2022-03-28 10:59:45,552 BAD EPOCHS (no improvement): 1
2022-03-28 10:59:45,555 ----------------------------------------------------------------------------------------------------
2022-03-28 10:59:47,442 epoch 24 - iter 10/107 - loss 0.05452095 - samples/sec: 169.68 - lr: 0.006250
2022-03-28 10:59:49,161 epoch 24 - iter 20/107 - loss 0.05472884 - samples/sec: 186.34 - lr: 0.006250
2022-03-28 10:59:50,946 epoch 24 - iter 30/107 - loss 0.05748981 - samples/sec: 179.38 - lr: 0.006250
2022-03-28 10:59:52,649 epoch 24 - iter 40/107 - loss 0.05901681 - samples/sec: 188.02 - lr: 0.006250
2022-03-28 10:59:54,423 epoch 24 - iter 50/107 - loss 0.05628628 - samples/sec: 180.43 - lr: 0.006250
2022-03-28 10:59:56,249 epoch 24 - iter 60/107 - loss 0.05816847 - samples/sec: 175.31 - lr: 0.006250
2022-03-28 10:59:57,967 epoch 24 - iter 70/107 - loss 0.05784582 - samples/sec: 186.37 - lr: 0.006250
2022-03-28 10:59:59,765 epoch 24 - iter 80/107 - loss 0.05802524 - samples/sec: 178.06 - lr: 0.006250
2022-03-28 11:00:01,482 epoch 24 - iter 90/107 - loss 0.05978083 - samples/sec: 186.53 - lr: 0.006250
2022-03-28 11:00:03,217 epoch 24 - iter 100/107 - loss 0.06126942 - samples/sec: 184.55 - lr: 0.006250
2022-03-28 11:00:04,319 ----------------------------------------------------------------------------------------------------
2022-03-28 11:00:04,320 EPOCH 24 done: loss 0.0609 - lr 0.006250
2022-03-28 11:00:10,444 Evaluating as a multi-label problem: False
2022-03-28 11:00:10,455 DEV : loss 0.1892106682062149 - f1-score (micro avg)  0.5313
2022-03-28 11:00:10,543 BAD EPOCHS (no improvement): 2
2022-03-28 11:00:10,545 ----------------------------------------------------------------------------------------------------
2022-03-28 11:00:12,419 epoch 25 - iter 10/107 - loss 0.07423199 - samples/sec: 170.95 - lr: 0.006250
2022-03-28 11:00:14,264 epoch 25 - iter 20/107 - loss 0.06782826 - samples/sec: 173.48 - lr: 0.006250
2022-03-28 11:00:16,079 epoch 25 - iter 30/107 - loss 0.06020999 - samples/sec: 176.42 - lr: 0.006250
2022-03-28 11:00:17,897 epoch 25 - iter 40/107 - loss 0.06016571 - samples/sec: 176.12 - lr: 0.006250
2022-03-28 11:00:19,615 epoch 25 - iter 50/107 - loss 0.06031002 - samples/sec: 186.34 - lr: 0.006250
2022-03-28 11:00:21,384 epoch 25 - iter 60/107 - loss 0.05866913 - samples/sec: 181.01 - lr: 0.006250
2022-03-28 11:00:23,139 epoch 25 - iter 70/107 - loss 0.05824479 - samples/sec: 182.44 - lr: 0.006250
2022-03-28 11:00:24,883 epoch 25 - iter 80/107 - loss 0.05874639 - samples/sec: 183.56 - lr: 0.006250
2022-03-28 11:00:26,622 epoch 25 - iter 90/107 - loss 0.05923148 - samples/sec: 184.05 - lr: 0.006250
2022-03-28 11:00:28,392 epoch 25 - iter 100/107 - loss 0.05949698 - samples/sec: 180.91 - lr: 0.006250
2022-03-28 11:00:29,468 ----------------------------------------------------------------------------------------------------
2022-03-28 11:00:29,468 EPOCH 25 done: loss 0.0596 - lr 0.006250
2022-03-28 11:00:35,532 Evaluating as a multi-label problem: False
2022-03-28 11:00:35,543 DEV : loss 0.1932441145181656 - f1-score (micro avg)  0.52
2022-03-28 11:00:35,632 BAD EPOCHS (no improvement): 3
2022-03-28 11:00:35,635 ----------------------------------------------------------------------------------------------------
2022-03-28 11:00:37,425 epoch 26 - iter 10/107 - loss 0.08662244 - samples/sec: 178.87 - lr: 0.006250
2022-03-28 11:00:39,205 epoch 26 - iter 20/107 - loss 0.07124170 - samples/sec: 179.95 - lr: 0.006250
2022-03-28 11:00:40,992 epoch 26 - iter 30/107 - loss 0.06600160 - samples/sec: 179.11 - lr: 0.006250
2022-03-28 11:00:42,663 epoch 26 - iter 40/107 - loss 0.06325712 - samples/sec: 191.66 - lr: 0.006250
2022-03-28 11:00:44,337 epoch 26 - iter 50/107 - loss 0.06082084 - samples/sec: 191.30 - lr: 0.006250
2022-03-28 11:00:46,080 epoch 26 - iter 60/107 - loss 0.06051266 - samples/sec: 183.62 - lr: 0.006250
2022-03-28 11:00:47,810 epoch 26 - iter 70/107 - loss 0.06224025 - samples/sec: 185.06 - lr: 0.006250
2022-03-28 11:00:49,520 epoch 26 - iter 80/107 - loss 0.06191912 - samples/sec: 187.27 - lr: 0.006250
2022-03-28 11:00:51,287 epoch 26 - iter 90/107 - loss 0.06112639 - samples/sec: 181.20 - lr: 0.006250
2022-03-28 11:00:53,101 epoch 26 - iter 100/107 - loss 0.06052738 - samples/sec: 176.48 - lr: 0.006250
2022-03-28 11:00:54,206 ----------------------------------------------------------------------------------------------------
2022-03-28 11:00:54,206 EPOCH 26 done: loss 0.0604 - lr 0.006250
2022-03-28 11:01:00,339 Evaluating as a multi-label problem: False
2022-03-28 11:01:00,349 DEV : loss 0.19839324057102203 - f1-score (micro avg)  0.5102
2022-03-28 11:01:00,436 Epoch    26: reducing learning rate of group 0 to 3.1250e-03.
2022-03-28 11:01:00,436 BAD EPOCHS (no improvement): 4
2022-03-28 11:01:00,439 ----------------------------------------------------------------------------------------------------
2022-03-28 11:01:02,280 epoch 27 - iter 10/107 - loss 0.04656958 - samples/sec: 173.90 - lr: 0.003125
2022-03-28 11:01:03,995 epoch 27 - iter 20/107 - loss 0.05324075 - samples/sec: 186.64 - lr: 0.003125
2022-03-28 11:01:05,669 epoch 27 - iter 30/107 - loss 0.05292536 - samples/sec: 191.35 - lr: 0.003125
2022-03-28 11:01:07,398 epoch 27 - iter 40/107 - loss 0.05490045 - samples/sec: 185.16 - lr: 0.003125
2022-03-28 11:01:09,200 epoch 27 - iter 50/107 - loss 0.05408060 - samples/sec: 177.63 - lr: 0.003125
2022-03-28 11:01:11,037 epoch 27 - iter 60/107 - loss 0.05509704 - samples/sec: 174.28 - lr: 0.003125
2022-03-28 11:01:12,827 epoch 27 - iter 70/107 - loss 0.05802869 - samples/sec: 178.90 - lr: 0.003125
2022-03-28 11:01:14,664 epoch 27 - iter 80/107 - loss 0.05813395 - samples/sec: 174.28 - lr: 0.003125
2022-03-28 11:01:16,477 epoch 27 - iter 90/107 - loss 0.05735686 - samples/sec: 176.58 - lr: 0.003125
2022-03-28 11:01:18,227 epoch 27 - iter 100/107 - loss 0.05717043 - samples/sec: 182.95 - lr: 0.003125
2022-03-28 11:01:19,348 ----------------------------------------------------------------------------------------------------
2022-03-28 11:01:19,348 EPOCH 27 done: loss 0.0579 - lr 0.003125
2022-03-28 11:01:25,442 Evaluating as a multi-label problem: False
2022-03-28 11:01:25,453 DEV : loss 0.19252043962478638 - f1-score (micro avg)  0.5203
2022-03-28 11:01:25,543 BAD EPOCHS (no improvement): 1
2022-03-28 11:01:25,547 ----------------------------------------------------------------------------------------------------
2022-03-28 11:01:27,439 epoch 28 - iter 10/107 - loss 0.05810988 - samples/sec: 169.25 - lr: 0.003125
2022-03-28 11:01:29,177 epoch 28 - iter 20/107 - loss 0.05715631 - samples/sec: 184.24 - lr: 0.003125
2022-03-28 11:01:30,923 epoch 28 - iter 30/107 - loss 0.05412684 - samples/sec: 183.43 - lr: 0.003125
2022-03-28 11:01:32,587 epoch 28 - iter 40/107 - loss 0.05374337 - samples/sec: 192.41 - lr: 0.003125
2022-03-28 11:01:34,235 epoch 28 - iter 50/107 - loss 0.05850092 - samples/sec: 194.23 - lr: 0.003125
2022-03-28 11:01:35,923 epoch 28 - iter 60/107 - loss 0.05824824 - samples/sec: 189.69 - lr: 0.003125
2022-03-28 11:01:37,582 epoch 28 - iter 70/107 - loss 0.05971641 - samples/sec: 193.07 - lr: 0.003125
2022-03-28 11:01:39,310 epoch 28 - iter 80/107 - loss 0.05941665 - samples/sec: 185.29 - lr: 0.003125
2022-03-28 11:01:40,992 epoch 28 - iter 90/107 - loss 0.05773099 - samples/sec: 190.35 - lr: 0.003125
2022-03-28 11:01:42,682 epoch 28 - iter 100/107 - loss 0.05879821 - samples/sec: 189.41 - lr: 0.003125
2022-03-28 11:01:43,791 ----------------------------------------------------------------------------------------------------
2022-03-28 11:01:43,792 EPOCH 28 done: loss 0.0583 - lr 0.003125
2022-03-28 11:01:49,614 Evaluating as a multi-label problem: False
2022-03-28 11:01:49,624 DEV : loss 0.1903970092535019 - f1-score (micro avg)  0.5157
2022-03-28 11:01:49,714 BAD EPOCHS (no improvement): 2
2022-03-28 11:01:49,717 ----------------------------------------------------------------------------------------------------
2022-03-28 11:01:53,050 epoch 29 - iter 10/107 - loss 0.05634247 - samples/sec: 96.03 - lr: 0.003125
2022-03-28 11:01:54,854 epoch 29 - iter 20/107 - loss 0.05354877 - samples/sec: 177.55 - lr: 0.003125
2022-03-28 11:01:56,616 epoch 29 - iter 30/107 - loss 0.05638825 - samples/sec: 181.71 - lr: 0.003125
2022-03-28 11:01:58,347 epoch 29 - iter 40/107 - loss 0.05659112 - samples/sec: 184.89 - lr: 0.003125
2022-03-28 11:02:00,108 epoch 29 - iter 50/107 - loss 0.05868137 - samples/sec: 181.85 - lr: 0.003125
2022-03-28 11:02:01,864 epoch 29 - iter 60/107 - loss 0.05926638 - samples/sec: 182.31 - lr: 0.003125
2022-03-28 11:02:03,549 epoch 29 - iter 70/107 - loss 0.05943379 - samples/sec: 190.06 - lr: 0.003125
2022-03-28 11:02:05,246 epoch 29 - iter 80/107 - loss 0.05951664 - samples/sec: 188.59 - lr: 0.003125
2022-03-28 11:02:07,012 epoch 29 - iter 90/107 - loss 0.05856202 - samples/sec: 181.37 - lr: 0.003125
2022-03-28 11:02:08,813 epoch 29 - iter 100/107 - loss 0.05781944 - samples/sec: 177.76 - lr: 0.003125
2022-03-28 11:02:09,904 ----------------------------------------------------------------------------------------------------
2022-03-28 11:02:09,904 EPOCH 29 done: loss 0.0584 - lr 0.003125
2022-03-28 11:02:15,936 Evaluating as a multi-label problem: False
2022-03-28 11:02:15,948 DEV : loss 0.1938176453113556 - f1-score (micro avg)  0.5223
2022-03-28 11:02:16,035 BAD EPOCHS (no improvement): 3
2022-03-28 11:02:16,038 ----------------------------------------------------------------------------------------------------
2022-03-28 11:02:17,732 epoch 30 - iter 10/107 - loss 0.04660101 - samples/sec: 189.05 - lr: 0.003125
2022-03-28 11:02:19,557 epoch 30 - iter 20/107 - loss 0.05052226 - samples/sec: 175.40 - lr: 0.003125
2022-03-28 11:02:21,344 epoch 30 - iter 30/107 - loss 0.05412828 - samples/sec: 179.19 - lr: 0.003125
2022-03-28 11:02:23,051 epoch 30 - iter 40/107 - loss 0.05693722 - samples/sec: 187.61 - lr: 0.003125
2022-03-28 11:02:24,759 epoch 30 - iter 50/107 - loss 0.06012008 - samples/sec: 187.47 - lr: 0.003125
2022-03-28 11:02:26,602 epoch 30 - iter 60/107 - loss 0.05726694 - samples/sec: 173.66 - lr: 0.003125
2022-03-28 11:02:28,425 epoch 30 - iter 70/107 - loss 0.05638601 - samples/sec: 175.65 - lr: 0.003125
2022-03-28 11:02:30,237 epoch 30 - iter 80/107 - loss 0.05499419 - samples/sec: 176.73 - lr: 0.003125
2022-03-28 11:02:31,999 epoch 30 - iter 90/107 - loss 0.05699877 - samples/sec: 181.65 - lr: 0.003125
2022-03-28 11:02:33,783 epoch 30 - iter 100/107 - loss 0.05683174 - samples/sec: 179.46 - lr: 0.003125
2022-03-28 11:02:34,831 ----------------------------------------------------------------------------------------------------
2022-03-28 11:02:34,831 EPOCH 30 done: loss 0.0569 - lr 0.003125
2022-03-28 11:02:40,914 Evaluating as a multi-label problem: False
2022-03-28 11:02:40,925 DEV : loss 0.19292548298835754 - f1-score (micro avg)  0.5257
2022-03-28 11:02:41,011 Epoch    30: reducing learning rate of group 0 to 1.5625e-03.
2022-03-28 11:02:41,011 BAD EPOCHS (no improvement): 4
2022-03-28 11:02:41,014 ----------------------------------------------------------------------------------------------------
2022-03-28 11:02:43,003 epoch 31 - iter 10/107 - loss 0.05612931 - samples/sec: 160.96 - lr: 0.001563
2022-03-28 11:02:44,770 epoch 31 - iter 20/107 - loss 0.05317722 - samples/sec: 181.26 - lr: 0.001563
2022-03-28 11:02:46,522 epoch 31 - iter 30/107 - loss 0.05436302 - samples/sec: 182.77 - lr: 0.001563
2022-03-28 11:02:48,219 epoch 31 - iter 40/107 - loss 0.05321899 - samples/sec: 188.60 - lr: 0.001563
2022-03-28 11:02:49,947 epoch 31 - iter 50/107 - loss 0.05278814 - samples/sec: 185.33 - lr: 0.001563
2022-03-28 11:02:51,694 epoch 31 - iter 60/107 - loss 0.05388616 - samples/sec: 183.23 - lr: 0.001563
2022-03-28 11:02:53,360 epoch 31 - iter 70/107 - loss 0.05476394 - samples/sec: 192.16 - lr: 0.001563
2022-03-28 11:02:55,127 epoch 31 - iter 80/107 - loss 0.05596281 - samples/sec: 181.24 - lr: 0.001563
2022-03-28 11:02:56,881 epoch 31 - iter 90/107 - loss 0.05761773 - samples/sec: 182.53 - lr: 0.001563
2022-03-28 11:02:58,695 epoch 31 - iter 100/107 - loss 0.05736691 - samples/sec: 176.51 - lr: 0.001563
2022-03-28 11:02:59,774 ----------------------------------------------------------------------------------------------------
2022-03-28 11:02:59,774 EPOCH 31 done: loss 0.0563 - lr 0.001563
2022-03-28 11:03:05,845 Evaluating as a multi-label problem: False
2022-03-28 11:03:05,856 DEV : loss 0.19390873610973358 - f1-score (micro avg)  0.5261
2022-03-28 11:03:05,943 BAD EPOCHS (no improvement): 1
2022-03-28 11:03:05,946 ----------------------------------------------------------------------------------------------------
2022-03-28 11:03:07,709 epoch 32 - iter 10/107 - loss 0.05791356 - samples/sec: 181.67 - lr: 0.001563
2022-03-28 11:03:09,460 epoch 32 - iter 20/107 - loss 0.05340325 - samples/sec: 182.88 - lr: 0.001563
2022-03-28 11:03:11,336 epoch 32 - iter 30/107 - loss 0.05320137 - samples/sec: 170.62 - lr: 0.001563
2022-03-28 11:03:13,125 epoch 32 - iter 40/107 - loss 0.05381433 - samples/sec: 179.01 - lr: 0.001563
2022-03-28 11:03:14,831 epoch 32 - iter 50/107 - loss 0.05541475 - samples/sec: 187.67 - lr: 0.001563
2022-03-28 11:03:16,569 epoch 32 - iter 60/107 - loss 0.05597325 - samples/sec: 184.24 - lr: 0.001563
2022-03-28 11:03:18,320 epoch 32 - iter 70/107 - loss 0.05573811 - samples/sec: 182.82 - lr: 0.001563
2022-03-28 11:03:20,016 epoch 32 - iter 80/107 - loss 0.05674063 - samples/sec: 188.82 - lr: 0.001563
2022-03-28 11:03:21,832 epoch 32 - iter 90/107 - loss 0.05726275 - samples/sec: 176.28 - lr: 0.001563
2022-03-28 11:03:23,561 epoch 32 - iter 100/107 - loss 0.05653172 - samples/sec: 185.14 - lr: 0.001563
2022-03-28 11:03:24,668 ----------------------------------------------------------------------------------------------------
2022-03-28 11:03:24,668 EPOCH 32 done: loss 0.0559 - lr 0.001563
2022-03-28 11:03:30,785 Evaluating as a multi-label problem: False
2022-03-28 11:03:30,795 DEV : loss 0.19553440809249878 - f1-score (micro avg)  0.5212
2022-03-28 11:03:30,883 BAD EPOCHS (no improvement): 2
2022-03-28 11:03:30,886 ----------------------------------------------------------------------------------------------------
2022-03-28 11:03:32,746 epoch 33 - iter 10/107 - loss 0.05736595 - samples/sec: 172.16 - lr: 0.001563
2022-03-28 11:03:34,550 epoch 33 - iter 20/107 - loss 0.06270130 - samples/sec: 177.43 - lr: 0.001563
2022-03-28 11:03:36,265 epoch 33 - iter 30/107 - loss 0.05763633 - samples/sec: 186.70 - lr: 0.001563
2022-03-28 11:03:37,993 epoch 33 - iter 40/107 - loss 0.05669504 - samples/sec: 185.32 - lr: 0.001563
2022-03-28 11:03:39,730 epoch 33 - iter 50/107 - loss 0.05591219 - samples/sec: 184.32 - lr: 0.001563
2022-03-28 11:03:41,451 epoch 33 - iter 60/107 - loss 0.05616002 - samples/sec: 186.06 - lr: 0.001563
2022-03-28 11:03:43,154 epoch 33 - iter 70/107 - loss 0.05509497 - samples/sec: 187.96 - lr: 0.001563
2022-03-28 11:03:44,910 epoch 33 - iter 80/107 - loss 0.05554051 - samples/sec: 182.39 - lr: 0.001563
2022-03-28 11:03:46,692 epoch 33 - iter 90/107 - loss 0.05565853 - samples/sec: 179.64 - lr: 0.001563
2022-03-28 11:03:48,455 epoch 33 - iter 100/107 - loss 0.05630516 - samples/sec: 181.59 - lr: 0.001563
2022-03-28 11:03:49,551 ----------------------------------------------------------------------------------------------------
2022-03-28 11:03:49,551 EPOCH 33 done: loss 0.0563 - lr 0.001563
2022-03-28 11:03:55,604 Evaluating as a multi-label problem: False
2022-03-28 11:03:55,615 DEV : loss 0.1959075629711151 - f1-score (micro avg)  0.5227
2022-03-28 11:03:55,702 BAD EPOCHS (no improvement): 3
2022-03-28 11:03:55,705 ----------------------------------------------------------------------------------------------------
2022-03-28 11:03:57,540 epoch 34 - iter 10/107 - loss 0.04793975 - samples/sec: 174.55 - lr: 0.001563
2022-03-28 11:03:59,223 epoch 34 - iter 20/107 - loss 0.05394279 - samples/sec: 190.24 - lr: 0.001563
2022-03-28 11:04:00,949 epoch 34 - iter 30/107 - loss 0.05324612 - samples/sec: 185.50 - lr: 0.001563
2022-03-28 11:04:02,609 epoch 34 - iter 40/107 - loss 0.05369156 - samples/sec: 192.83 - lr: 0.001563
2022-03-28 11:04:04,317 epoch 34 - iter 50/107 - loss 0.05576056 - samples/sec: 187.53 - lr: 0.001563
2022-03-28 11:04:06,097 epoch 34 - iter 60/107 - loss 0.05582095 - samples/sec: 179.85 - lr: 0.001563
2022-03-28 11:04:07,970 epoch 34 - iter 70/107 - loss 0.05549792 - samples/sec: 170.89 - lr: 0.001563
2022-03-28 11:04:09,858 epoch 34 - iter 80/107 - loss 0.05595780 - samples/sec: 169.66 - lr: 0.001563
2022-03-28 11:04:11,730 epoch 34 - iter 90/107 - loss 0.05550617 - samples/sec: 170.96 - lr: 0.001563
2022-03-28 11:04:13,513 epoch 34 - iter 100/107 - loss 0.05716329 - samples/sec: 179.54 - lr: 0.001563
2022-03-28 11:04:14,561 ----------------------------------------------------------------------------------------------------
2022-03-28 11:04:14,561 EPOCH 34 done: loss 0.0567 - lr 0.001563
2022-03-28 11:04:20,670 Evaluating as a multi-label problem: False
2022-03-28 11:04:20,681 DEV : loss 0.19595371186733246 - f1-score (micro avg)  0.5224
2022-03-28 11:04:20,767 Epoch    34: reducing learning rate of group 0 to 7.8125e-04.
2022-03-28 11:04:20,768 BAD EPOCHS (no improvement): 4
2022-03-28 11:04:20,774 ----------------------------------------------------------------------------------------------------
2022-03-28 11:04:22,629 epoch 35 - iter 10/107 - loss 0.06003410 - samples/sec: 172.56 - lr: 0.000781
2022-03-28 11:04:24,365 epoch 35 - iter 20/107 - loss 0.05759005 - samples/sec: 184.49 - lr: 0.000781
2022-03-28 11:04:26,170 epoch 35 - iter 30/107 - loss 0.06195560 - samples/sec: 177.34 - lr: 0.000781
2022-03-28 11:04:27,871 epoch 35 - iter 40/107 - loss 0.05980070 - samples/sec: 188.19 - lr: 0.000781
2022-03-28 11:04:29,689 epoch 35 - iter 50/107 - loss 0.05978274 - samples/sec: 176.18 - lr: 0.000781
2022-03-28 11:04:31,477 epoch 35 - iter 60/107 - loss 0.05759170 - samples/sec: 178.99 - lr: 0.000781
2022-03-28 11:04:33,231 epoch 35 - iter 70/107 - loss 0.05635269 - samples/sec: 182.57 - lr: 0.000781
2022-03-28 11:04:35,017 epoch 35 - iter 80/107 - loss 0.05681444 - samples/sec: 179.24 - lr: 0.000781
2022-03-28 11:04:36,808 epoch 35 - iter 90/107 - loss 0.05550174 - samples/sec: 178.84 - lr: 0.000781
2022-03-28 11:04:38,537 epoch 35 - iter 100/107 - loss 0.05541782 - samples/sec: 185.16 - lr: 0.000781
2022-03-28 11:04:39,596 ----------------------------------------------------------------------------------------------------
2022-03-28 11:04:39,596 EPOCH 35 done: loss 0.0565 - lr 0.000781
2022-03-28 11:04:45,650 Evaluating as a multi-label problem: False
2022-03-28 11:04:45,661 DEV : loss 0.19491258263587952 - f1-score (micro avg)  0.5227
2022-03-28 11:04:45,749 BAD EPOCHS (no improvement): 1
2022-03-28 11:04:45,752 ----------------------------------------------------------------------------------------------------
2022-03-28 11:04:47,644 epoch 36 - iter 10/107 - loss 0.05360126 - samples/sec: 169.21 - lr: 0.000781
2022-03-28 11:04:49,410 epoch 36 - iter 20/107 - loss 0.05461773 - samples/sec: 181.37 - lr: 0.000781
2022-03-28 11:04:51,084 epoch 36 - iter 30/107 - loss 0.05780927 - samples/sec: 191.28 - lr: 0.000781
2022-03-28 11:04:52,794 epoch 36 - iter 40/107 - loss 0.05764257 - samples/sec: 187.24 - lr: 0.000781
2022-03-28 11:04:54,611 epoch 36 - iter 50/107 - loss 0.05733795 - samples/sec: 176.19 - lr: 0.000781
2022-03-28 11:04:56,395 epoch 36 - iter 60/107 - loss 0.05897886 - samples/sec: 179.46 - lr: 0.000781
2022-03-28 11:04:58,274 epoch 36 - iter 70/107 - loss 0.05778327 - samples/sec: 170.37 - lr: 0.000781
2022-03-28 11:05:00,018 epoch 36 - iter 80/107 - loss 0.05686257 - samples/sec: 183.54 - lr: 0.000781
2022-03-28 11:05:01,823 epoch 36 - iter 90/107 - loss 0.05613565 - samples/sec: 177.44 - lr: 0.000781
2022-03-28 11:05:03,531 epoch 36 - iter 100/107 - loss 0.05606539 - samples/sec: 187.47 - lr: 0.000781
2022-03-28 11:05:04,687 ----------------------------------------------------------------------------------------------------
2022-03-28 11:05:04,687 EPOCH 36 done: loss 0.0554 - lr 0.000781
2022-03-28 11:05:10,647 Evaluating as a multi-label problem: False
2022-03-28 11:05:10,658 DEV : loss 0.19564422965049744 - f1-score (micro avg)  0.5227
2022-03-28 11:05:10,744 BAD EPOCHS (no improvement): 2
2022-03-28 11:05:10,747 ----------------------------------------------------------------------------------------------------
2022-03-28 11:05:12,585 epoch 37 - iter 10/107 - loss 0.04504701 - samples/sec: 174.24 - lr: 0.000781
2022-03-28 11:05:14,260 epoch 37 - iter 20/107 - loss 0.05032764 - samples/sec: 191.13 - lr: 0.000781
2022-03-28 11:05:15,933 epoch 37 - iter 30/107 - loss 0.05696686 - samples/sec: 191.36 - lr: 0.000781
2022-03-28 11:05:17,715 epoch 37 - iter 40/107 - loss 0.05622008 - samples/sec: 179.74 - lr: 0.000781
2022-03-28 11:05:19,443 epoch 37 - iter 50/107 - loss 0.05630891 - samples/sec: 185.21 - lr: 0.000781
2022-03-28 11:05:21,127 epoch 37 - iter 60/107 - loss 0.05511178 - samples/sec: 190.20 - lr: 0.000781
2022-03-28 11:05:22,835 epoch 37 - iter 70/107 - loss 0.05653603 - samples/sec: 187.45 - lr: 0.000781
2022-03-28 11:05:24,552 epoch 37 - iter 80/107 - loss 0.05756622 - samples/sec: 186.48 - lr: 0.000781
2022-03-28 11:05:26,272 epoch 37 - iter 90/107 - loss 0.05696837 - samples/sec: 186.17 - lr: 0.000781
2022-03-28 11:05:28,004 epoch 37 - iter 100/107 - loss 0.05660919 - samples/sec: 184.82 - lr: 0.000781
2022-03-28 11:05:29,066 ----------------------------------------------------------------------------------------------------
2022-03-28 11:05:29,066 EPOCH 37 done: loss 0.0564 - lr 0.000781
2022-03-28 11:05:35,092 Evaluating as a multi-label problem: False
2022-03-28 11:05:35,103 DEV : loss 0.1965542435646057 - f1-score (micro avg)  0.5205
2022-03-28 11:05:35,190 BAD EPOCHS (no improvement): 3
2022-03-28 11:05:35,193 ----------------------------------------------------------------------------------------------------
2022-03-28 11:05:37,085 epoch 38 - iter 10/107 - loss 0.07698795 - samples/sec: 169.26 - lr: 0.000781
2022-03-28 11:05:38,782 epoch 38 - iter 20/107 - loss 0.07538927 - samples/sec: 188.72 - lr: 0.000781
2022-03-28 11:05:40,525 epoch 38 - iter 30/107 - loss 0.07013926 - samples/sec: 183.64 - lr: 0.000781
2022-03-28 11:05:42,376 epoch 38 - iter 40/107 - loss 0.06463213 - samples/sec: 172.94 - lr: 0.000781
2022-03-28 11:05:44,093 epoch 38 - iter 50/107 - loss 0.06246529 - samples/sec: 186.48 - lr: 0.000781
2022-03-28 11:05:45,895 epoch 38 - iter 60/107 - loss 0.06051624 - samples/sec: 177.70 - lr: 0.000781
2022-03-28 11:05:47,710 epoch 38 - iter 70/107 - loss 0.05936681 - samples/sec: 176.43 - lr: 0.000781
2022-03-28 11:05:49,507 epoch 38 - iter 80/107 - loss 0.05790715 - samples/sec: 178.11 - lr: 0.000781
2022-03-28 11:05:51,219 epoch 38 - iter 90/107 - loss 0.05682415 - samples/sec: 187.05 - lr: 0.000781
2022-03-28 11:05:53,022 epoch 38 - iter 100/107 - loss 0.05713911 - samples/sec: 177.62 - lr: 0.000781
2022-03-28 11:05:54,145 ----------------------------------------------------------------------------------------------------
2022-03-28 11:05:54,145 EPOCH 38 done: loss 0.0573 - lr 0.000781
2022-03-28 11:06:00,322 Evaluating as a multi-label problem: False
2022-03-28 11:06:00,333 DEV : loss 0.19548210501670837 - f1-score (micro avg)  0.5212
2022-03-28 11:06:00,421 Epoch    38: reducing learning rate of group 0 to 3.9063e-04.
2022-03-28 11:06:00,421 BAD EPOCHS (no improvement): 4
2022-03-28 11:06:00,425 ----------------------------------------------------------------------------------------------------
2022-03-28 11:06:02,383 epoch 39 - iter 10/107 - loss 0.05642270 - samples/sec: 163.53 - lr: 0.000391
2022-03-28 11:06:04,193 epoch 39 - iter 20/107 - loss 0.05987800 - samples/sec: 176.83 - lr: 0.000391
2022-03-28 11:06:05,965 epoch 39 - iter 30/107 - loss 0.05982138 - samples/sec: 180.76 - lr: 0.000391
2022-03-28 11:06:07,761 epoch 39 - iter 40/107 - loss 0.05773575 - samples/sec: 178.22 - lr: 0.000391
2022-03-28 11:06:09,506 epoch 39 - iter 50/107 - loss 0.05746393 - samples/sec: 183.51 - lr: 0.000391
2022-03-28 11:06:11,265 epoch 39 - iter 60/107 - loss 0.05555252 - samples/sec: 181.95 - lr: 0.000391
2022-03-28 11:06:13,001 epoch 39 - iter 70/107 - loss 0.05604531 - samples/sec: 184.56 - lr: 0.000391
2022-03-28 11:06:14,723 epoch 39 - iter 80/107 - loss 0.05724656 - samples/sec: 185.95 - lr: 0.000391
2022-03-28 11:06:16,446 epoch 39 - iter 90/107 - loss 0.05703928 - samples/sec: 185.78 - lr: 0.000391
2022-03-28 11:06:18,295 epoch 39 - iter 100/107 - loss 0.05755016 - samples/sec: 173.16 - lr: 0.000391
2022-03-28 11:06:19,375 ----------------------------------------------------------------------------------------------------
2022-03-28 11:06:19,375 EPOCH 39 done: loss 0.0569 - lr 0.000391
2022-03-28 11:06:25,414 Evaluating as a multi-label problem: False
2022-03-28 11:06:25,424 DEV : loss 0.195101797580719 - f1-score (micro avg)  0.5208
2022-03-28 11:06:25,512 BAD EPOCHS (no improvement): 1
2022-03-28 11:06:25,515 ----------------------------------------------------------------------------------------------------
2022-03-28 11:06:27,340 epoch 40 - iter 10/107 - loss 0.05355985 - samples/sec: 175.40 - lr: 0.000391
2022-03-28 11:06:29,191 epoch 40 - iter 20/107 - loss 0.05681702 - samples/sec: 173.02 - lr: 0.000391
2022-03-28 11:06:31,015 epoch 40 - iter 30/107 - loss 0.05750308 - samples/sec: 175.49 - lr: 0.000391
2022-03-28 11:06:32,889 epoch 40 - iter 40/107 - loss 0.05617067 - samples/sec: 170.83 - lr: 0.000391
2022-03-28 11:06:34,755 epoch 40 - iter 50/107 - loss 0.05480175 - samples/sec: 171.57 - lr: 0.000391
2022-03-28 11:06:36,528 epoch 40 - iter 60/107 - loss 0.05534868 - samples/sec: 180.63 - lr: 0.000391
2022-03-28 11:06:38,204 epoch 40 - iter 70/107 - loss 0.05557956 - samples/sec: 191.09 - lr: 0.000391
2022-03-28 11:06:39,920 epoch 40 - iter 80/107 - loss 0.05589041 - samples/sec: 186.78 - lr: 0.000391
2022-03-28 11:06:41,727 epoch 40 - iter 90/107 - loss 0.05614777 - samples/sec: 177.20 - lr: 0.000391
2022-03-28 11:06:43,432 epoch 40 - iter 100/107 - loss 0.05569655 - samples/sec: 187.76 - lr: 0.000391
2022-03-28 11:06:44,515 ----------------------------------------------------------------------------------------------------
2022-03-28 11:06:44,515 EPOCH 40 done: loss 0.0565 - lr 0.000391
2022-03-28 11:06:50,622 Evaluating as a multi-label problem: False
2022-03-28 11:06:50,632 DEV : loss 0.19528061151504517 - f1-score (micro avg)  0.5212
2022-03-28 11:06:50,721 BAD EPOCHS (no improvement): 2
2022-03-28 11:06:50,725 ----------------------------------------------------------------------------------------------------
2022-03-28 11:06:52,648 epoch 41 - iter 10/107 - loss 0.06205390 - samples/sec: 166.52 - lr: 0.000391
2022-03-28 11:06:54,460 epoch 41 - iter 20/107 - loss 0.06242585 - samples/sec: 176.62 - lr: 0.000391
2022-03-28 11:06:56,145 epoch 41 - iter 30/107 - loss 0.06502400 - samples/sec: 190.08 - lr: 0.000391
2022-03-28 11:06:57,831 epoch 41 - iter 40/107 - loss 0.06404321 - samples/sec: 189.87 - lr: 0.000391
2022-03-28 11:06:59,523 epoch 41 - iter 50/107 - loss 0.06206774 - samples/sec: 189.20 - lr: 0.000391
2022-03-28 11:07:01,226 epoch 41 - iter 60/107 - loss 0.06106368 - samples/sec: 188.10 - lr: 0.000391
2022-03-28 11:07:03,057 epoch 41 - iter 70/107 - loss 0.06029012 - samples/sec: 174.86 - lr: 0.000391
2022-03-28 11:07:04,875 epoch 41 - iter 80/107 - loss 0.06038436 - samples/sec: 176.15 - lr: 0.000391
2022-03-28 11:07:06,651 epoch 41 - iter 90/107 - loss 0.05793828 - samples/sec: 180.30 - lr: 0.000391
2022-03-28 11:07:08,492 epoch 41 - iter 100/107 - loss 0.05870552 - samples/sec: 173.90 - lr: 0.000391
2022-03-28 11:07:09,570 ----------------------------------------------------------------------------------------------------
2022-03-28 11:07:09,570 EPOCH 41 done: loss 0.0584 - lr 0.000391
2022-03-28 11:07:15,654 Evaluating as a multi-label problem: False
2022-03-28 11:07:15,665 DEV : loss 0.19524338841438293 - f1-score (micro avg)  0.5193
2022-03-28 11:07:15,753 BAD EPOCHS (no improvement): 3
2022-03-28 11:07:15,756 ----------------------------------------------------------------------------------------------------
2022-03-28 11:07:17,548 epoch 42 - iter 10/107 - loss 0.04853683 - samples/sec: 178.77 - lr: 0.000391
2022-03-28 11:07:19,455 epoch 42 - iter 20/107 - loss 0.04955032 - samples/sec: 167.83 - lr: 0.000391
2022-03-28 11:07:21,384 epoch 42 - iter 30/107 - loss 0.05018121 - samples/sec: 165.96 - lr: 0.000391
2022-03-28 11:07:23,149 epoch 42 - iter 40/107 - loss 0.05056790 - samples/sec: 181.49 - lr: 0.000391
2022-03-28 11:07:24,918 epoch 42 - iter 50/107 - loss 0.05360246 - samples/sec: 180.96 - lr: 0.000391
2022-03-28 11:07:26,714 epoch 42 - iter 60/107 - loss 0.05479032 - samples/sec: 178.24 - lr: 0.000391
2022-03-28 11:07:28,466 epoch 42 - iter 70/107 - loss 0.05602090 - samples/sec: 182.73 - lr: 0.000391
2022-03-28 11:07:30,159 epoch 42 - iter 80/107 - loss 0.05607295 - samples/sec: 189.15 - lr: 0.000391
2022-03-28 11:07:31,902 epoch 42 - iter 90/107 - loss 0.05585757 - samples/sec: 183.67 - lr: 0.000391
2022-03-28 11:07:33,630 epoch 42 - iter 100/107 - loss 0.05556654 - samples/sec: 185.28 - lr: 0.000391
2022-03-28 11:07:34,717 ----------------------------------------------------------------------------------------------------
2022-03-28 11:07:34,717 EPOCH 42 done: loss 0.0547 - lr 0.000391
2022-03-28 11:07:42,341 Evaluating as a multi-label problem: False
2022-03-28 11:07:42,351 DEV : loss 0.19521762430667877 - f1-score (micro avg)  0.5193
2022-03-28 11:07:42,440 Epoch    42: reducing learning rate of group 0 to 1.9531e-04.
2022-03-28 11:07:42,440 BAD EPOCHS (no improvement): 4
2022-03-28 11:07:42,444 ----------------------------------------------------------------------------------------------------
2022-03-28 11:07:44,307 epoch 43 - iter 10/107 - loss 0.05295747 - samples/sec: 171.82 - lr: 0.000195
2022-03-28 11:07:46,072 epoch 43 - iter 20/107 - loss 0.05054843 - samples/sec: 181.40 - lr: 0.000195
2022-03-28 11:07:47,848 epoch 43 - iter 30/107 - loss 0.05283323 - samples/sec: 180.27 - lr: 0.000195
2022-03-28 11:07:49,659 epoch 43 - iter 40/107 - loss 0.05302762 - samples/sec: 176.88 - lr: 0.000195
2022-03-28 11:07:51,465 epoch 43 - iter 50/107 - loss 0.05323101 - samples/sec: 177.20 - lr: 0.000195
2022-03-28 11:07:53,213 epoch 43 - iter 60/107 - loss 0.05369585 - samples/sec: 183.28 - lr: 0.000195
2022-03-28 11:07:54,950 epoch 43 - iter 70/107 - loss 0.05278153 - samples/sec: 184.29 - lr: 0.000195
2022-03-28 11:07:56,600 epoch 43 - iter 80/107 - loss 0.05522788 - samples/sec: 194.05 - lr: 0.000195
2022-03-28 11:07:58,434 epoch 43 - iter 90/107 - loss 0.05486508 - samples/sec: 174.57 - lr: 0.000195
2022-03-28 11:08:00,168 epoch 43 - iter 100/107 - loss 0.05473101 - samples/sec: 184.61 - lr: 0.000195
2022-03-28 11:08:01,201 ----------------------------------------------------------------------------------------------------
2022-03-28 11:08:01,201 EPOCH 43 done: loss 0.0545 - lr 0.000195
2022-03-28 11:08:07,247 Evaluating as a multi-label problem: False
2022-03-28 11:08:07,258 DEV : loss 0.1952841430902481 - f1-score (micro avg)  0.5197
2022-03-28 11:08:07,346 BAD EPOCHS (no improvement): 1
2022-03-28 11:08:07,349 ----------------------------------------------------------------------------------------------------
2022-03-28 11:08:09,302 epoch 44 - iter 10/107 - loss 0.04920230 - samples/sec: 163.96 - lr: 0.000195
2022-03-28 11:08:11,201 epoch 44 - iter 20/107 - loss 0.05278517 - samples/sec: 168.53 - lr: 0.000195
2022-03-28 11:08:13,017 epoch 44 - iter 30/107 - loss 0.05441381 - samples/sec: 176.37 - lr: 0.000195
2022-03-28 11:08:14,812 epoch 44 - iter 40/107 - loss 0.05601276 - samples/sec: 178.37 - lr: 0.000195
2022-03-28 11:08:16,535 epoch 44 - iter 50/107 - loss 0.05775925 - samples/sec: 185.77 - lr: 0.000195
2022-03-28 11:08:18,294 epoch 44 - iter 60/107 - loss 0.05767247 - samples/sec: 181.98 - lr: 0.000195
2022-03-28 11:08:19,978 epoch 44 - iter 70/107 - loss 0.05811272 - samples/sec: 190.19 - lr: 0.000195
2022-03-28 11:08:21,714 epoch 44 - iter 80/107 - loss 0.05651391 - samples/sec: 184.37 - lr: 0.000195
2022-03-28 11:08:23,447 epoch 44 - iter 90/107 - loss 0.05543398 - samples/sec: 184.82 - lr: 0.000195
2022-03-28 11:08:25,249 epoch 44 - iter 100/107 - loss 0.05458455 - samples/sec: 177.62 - lr: 0.000195
2022-03-28 11:08:26,298 ----------------------------------------------------------------------------------------------------
2022-03-28 11:08:26,298 EPOCH 44 done: loss 0.0550 - lr 0.000195
2022-03-28 11:08:32,438 Evaluating as a multi-label problem: False
2022-03-28 11:08:32,448 DEV : loss 0.1953229159116745 - f1-score (micro avg)  0.5197
2022-03-28 11:08:32,536 BAD EPOCHS (no improvement): 2
2022-03-28 11:08:32,539 ----------------------------------------------------------------------------------------------------
2022-03-28 11:08:34,442 epoch 45 - iter 10/107 - loss 0.06489225 - samples/sec: 168.26 - lr: 0.000195
2022-03-28 11:08:36,267 epoch 45 - iter 20/107 - loss 0.06063283 - samples/sec: 175.52 - lr: 0.000195
2022-03-28 11:08:37,982 epoch 45 - iter 30/107 - loss 0.06064928 - samples/sec: 186.65 - lr: 0.000195
2022-03-28 11:08:39,775 epoch 45 - iter 40/107 - loss 0.06125774 - samples/sec: 178.63 - lr: 0.000195
2022-03-28 11:08:41,555 epoch 45 - iter 50/107 - loss 0.05955503 - samples/sec: 179.91 - lr: 0.000195
2022-03-28 11:08:43,335 epoch 45 - iter 60/107 - loss 0.06003773 - samples/sec: 179.84 - lr: 0.000195
2022-03-28 11:08:45,102 epoch 45 - iter 70/107 - loss 0.05975844 - samples/sec: 181.19 - lr: 0.000195
2022-03-28 11:08:46,865 epoch 45 - iter 80/107 - loss 0.06041258 - samples/sec: 181.57 - lr: 0.000195
2022-03-28 11:08:48,570 epoch 45 - iter 90/107 - loss 0.05829833 - samples/sec: 187.79 - lr: 0.000195
2022-03-28 11:08:50,291 epoch 45 - iter 100/107 - loss 0.05780552 - samples/sec: 186.03 - lr: 0.000195
2022-03-28 11:08:51,399 ----------------------------------------------------------------------------------------------------
2022-03-28 11:08:51,399 EPOCH 45 done: loss 0.0576 - lr 0.000195
2022-03-28 11:08:57,473 Evaluating as a multi-label problem: False
2022-03-28 11:08:57,484 DEV : loss 0.19515861570835114 - f1-score (micro avg)  0.5197
2022-03-28 11:08:57,578 BAD EPOCHS (no improvement): 3
2022-03-28 11:08:57,581 ----------------------------------------------------------------------------------------------------
2022-03-28 11:08:59,413 epoch 46 - iter 10/107 - loss 0.05225613 - samples/sec: 174.80 - lr: 0.000195
2022-03-28 11:09:01,223 epoch 46 - iter 20/107 - loss 0.05180833 - samples/sec: 176.85 - lr: 0.000195
2022-03-28 11:09:02,982 epoch 46 - iter 30/107 - loss 0.05345819 - samples/sec: 182.00 - lr: 0.000195
2022-03-28 11:09:04,747 epoch 46 - iter 40/107 - loss 0.05323699 - samples/sec: 181.42 - lr: 0.000195
2022-03-28 11:09:06,523 epoch 46 - iter 50/107 - loss 0.05458604 - samples/sec: 180.26 - lr: 0.000195
2022-03-28 11:09:08,293 epoch 46 - iter 60/107 - loss 0.05512952 - samples/sec: 180.90 - lr: 0.000195
2022-03-28 11:09:10,035 epoch 46 - iter 70/107 - loss 0.05429674 - samples/sec: 183.83 - lr: 0.000195
2022-03-28 11:09:11,784 epoch 46 - iter 80/107 - loss 0.05583405 - samples/sec: 183.03 - lr: 0.000195
2022-03-28 11:09:13,576 epoch 46 - iter 90/107 - loss 0.05598628 - samples/sec: 178.67 - lr: 0.000195
2022-03-28 11:09:15,332 epoch 46 - iter 100/107 - loss 0.05611910 - samples/sec: 182.32 - lr: 0.000195
2022-03-28 11:09:16,426 ----------------------------------------------------------------------------------------------------
2022-03-28 11:09:16,426 EPOCH 46 done: loss 0.0567 - lr 0.000195
2022-03-28 11:09:22,536 Evaluating as a multi-label problem: False
2022-03-28 11:09:22,547 DEV : loss 0.1951683759689331 - f1-score (micro avg)  0.5197
2022-03-28 11:09:22,634 Epoch    46: reducing learning rate of group 0 to 9.7656e-05.
2022-03-28 11:09:22,634 BAD EPOCHS (no improvement): 4
2022-03-28 11:09:22,637 ----------------------------------------------------------------------------------------------------
2022-03-28 11:09:22,637 ----------------------------------------------------------------------------------------------------
2022-03-28 11:09:22,637 learning rate too small - quitting training!
2022-03-28 11:09:22,637 ----------------------------------------------------------------------------------------------------
2022-03-28 11:09:46,937 ----------------------------------------------------------------------------------------------------
2022-03-28 11:09:46,938 loading file resources/taggers/model_07_r5_run_1/best-model.pt
2022-03-28 11:10:02,105 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-03-28 11:10:20,791 Evaluating as a multi-label problem: False
2022-03-28 11:10:20,803 0.6845	0.3197	0.4359	0.2939
2022-03-28 11:10:20,803 
Results:
- F-score (micro) 0.4359
- F-score (macro) 0.3271
- Accuracy 0.2939

By class:
               precision    recall  f1-score   support

       person     0.7923    0.4802    0.5980       429
     location     0.6341    0.5200    0.5714       150
        group     0.6429    0.1636    0.2609       165
creative-work     0.5000    0.0915    0.1548       142
      product     0.3529    0.0472    0.0833       127
  corporation     0.4167    0.2273    0.2941        66

    micro avg     0.6845    0.3197    0.4359      1079
    macro avg     0.5565    0.2550    0.3271      1079
 weighted avg     0.6343    0.3197    0.4052      1079

2022-03-28 11:10:20,803 ----------------------------------------------------------------------------------------------------
