2022-03-27 23:59:31,692 ----------------------------------------------------------------------------------------------------
2022-03-27 23:59:31,692 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4757, out_features=4757, bias=True)
  (rnn): LSTM(4757, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-03-27 23:59:31,692 ----------------------------------------------------------------------------------------------------
2022-03-27 23:59:31,692 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-03-27 23:59:31,692 ----------------------------------------------------------------------------------------------------
2022-03-27 23:59:31,692 Parameters:
2022-03-27 23:59:31,692  - learning_rate: "0.100000"
2022-03-27 23:59:31,692  - mini_batch_size: "32"
2022-03-27 23:59:31,692  - patience: "3"
2022-03-27 23:59:31,692  - anneal_factor: "0.5"
2022-03-27 23:59:31,692  - max_epochs: "150"
2022-03-27 23:59:31,692  - shuffle: "True"
2022-03-27 23:59:31,692  - train_with_dev: "False"
2022-03-27 23:59:31,692  - batch_growth_annealing: "False"
2022-03-27 23:59:31,693 ----------------------------------------------------------------------------------------------------
2022-03-27 23:59:31,693 Model training base path: "resources/taggers/model_05_r5_run_3"
2022-03-27 23:59:31,693 ----------------------------------------------------------------------------------------------------
2022-03-27 23:59:31,693 Device: cuda:2
2022-03-27 23:59:31,693 ----------------------------------------------------------------------------------------------------
2022-03-27 23:59:31,693 Embeddings storage mode: cpu
2022-03-27 23:59:31,693 ----------------------------------------------------------------------------------------------------
2022-03-27 23:59:34,530 epoch 1 - iter 10/107 - loss 0.82637357 - samples/sec: 112.84 - lr: 0.100000
2022-03-27 23:59:37,359 epoch 1 - iter 20/107 - loss 0.55409366 - samples/sec: 113.11 - lr: 0.100000
2022-03-27 23:59:40,297 epoch 1 - iter 30/107 - loss 0.46027318 - samples/sec: 108.98 - lr: 0.100000
2022-03-27 23:59:42,953 epoch 1 - iter 40/107 - loss 0.40714439 - samples/sec: 120.52 - lr: 0.100000
2022-03-27 23:59:45,864 epoch 1 - iter 50/107 - loss 0.36752272 - samples/sec: 109.97 - lr: 0.100000
2022-03-27 23:59:48,697 epoch 1 - iter 60/107 - loss 0.35118390 - samples/sec: 112.98 - lr: 0.100000
2022-03-27 23:59:51,515 epoch 1 - iter 70/107 - loss 0.33899169 - samples/sec: 113.60 - lr: 0.100000
2022-03-27 23:59:54,247 epoch 1 - iter 80/107 - loss 0.33464204 - samples/sec: 117.20 - lr: 0.100000
2022-03-27 23:59:56,605 epoch 1 - iter 90/107 - loss 0.33160322 - samples/sec: 135.76 - lr: 0.100000
2022-03-27 23:59:59,067 epoch 1 - iter 100/107 - loss 0.32539854 - samples/sec: 130.04 - lr: 0.100000
2022-03-28 00:00:00,535 ----------------------------------------------------------------------------------------------------
2022-03-28 00:00:00,535 EPOCH 1 done: loss 0.3200 - lr 0.100000
2022-03-28 00:00:08,696 Evaluating as a multi-label problem: False
2022-03-28 00:00:08,707 DEV : loss 0.4085533320903778 - f1-score (micro avg)  0.1389
2022-03-28 00:00:08,782 BAD EPOCHS (no improvement): 0
2022-03-28 00:00:08,785 saving best model
2022-03-28 00:00:22,988 ----------------------------------------------------------------------------------------------------
2022-03-28 00:00:25,716 epoch 2 - iter 10/107 - loss 0.19027700 - samples/sec: 117.37 - lr: 0.100000
2022-03-28 00:00:28,412 epoch 2 - iter 20/107 - loss 0.19300232 - samples/sec: 118.74 - lr: 0.100000
2022-03-28 00:00:31,117 epoch 2 - iter 30/107 - loss 0.18952003 - samples/sec: 118.37 - lr: 0.100000
2022-03-28 00:00:33,661 epoch 2 - iter 40/107 - loss 0.18839889 - samples/sec: 125.84 - lr: 0.100000
2022-03-28 00:00:36,459 epoch 2 - iter 50/107 - loss 0.19457275 - samples/sec: 114.39 - lr: 0.100000
2022-03-28 00:00:39,078 epoch 2 - iter 60/107 - loss 0.19362186 - samples/sec: 122.24 - lr: 0.100000
2022-03-28 00:00:41,840 epoch 2 - iter 70/107 - loss 0.19214899 - samples/sec: 115.92 - lr: 0.100000
2022-03-28 00:00:44,703 epoch 2 - iter 80/107 - loss 0.19203034 - samples/sec: 111.79 - lr: 0.100000
2022-03-28 00:00:47,517 epoch 2 - iter 90/107 - loss 0.18894021 - samples/sec: 113.77 - lr: 0.100000
2022-03-28 00:00:50,299 epoch 2 - iter 100/107 - loss 0.18684178 - samples/sec: 115.08 - lr: 0.100000
2022-03-28 00:00:51,809 ----------------------------------------------------------------------------------------------------
2022-03-28 00:00:51,809 EPOCH 2 done: loss 0.1859 - lr 0.100000
2022-03-28 00:00:59,306 Evaluating as a multi-label problem: False
2022-03-28 00:00:59,317 DEV : loss 0.2764355540275574 - f1-score (micro avg)  0.4133
2022-03-28 00:00:59,393 BAD EPOCHS (no improvement): 0
2022-03-28 00:00:59,396 saving best model
2022-03-28 00:01:13,869 ----------------------------------------------------------------------------------------------------
2022-03-28 00:01:15,797 epoch 3 - iter 10/107 - loss 0.17686671 - samples/sec: 166.17 - lr: 0.100000
2022-03-28 00:01:17,658 epoch 3 - iter 20/107 - loss 0.15683261 - samples/sec: 171.97 - lr: 0.100000
2022-03-28 00:01:19,471 epoch 3 - iter 30/107 - loss 0.16274717 - samples/sec: 176.60 - lr: 0.100000
2022-03-28 00:01:21,361 epoch 3 - iter 40/107 - loss 0.16761364 - samples/sec: 169.40 - lr: 0.100000
2022-03-28 00:01:23,161 epoch 3 - iter 50/107 - loss 0.16120635 - samples/sec: 177.88 - lr: 0.100000
2022-03-28 00:01:24,891 epoch 3 - iter 60/107 - loss 0.16649021 - samples/sec: 185.17 - lr: 0.100000
2022-03-28 00:01:26,631 epoch 3 - iter 70/107 - loss 0.16729095 - samples/sec: 184.01 - lr: 0.100000
2022-03-28 00:01:28,474 epoch 3 - iter 80/107 - loss 0.16539093 - samples/sec: 173.68 - lr: 0.100000
2022-03-28 00:01:30,265 epoch 3 - iter 90/107 - loss 0.16292172 - samples/sec: 178.80 - lr: 0.100000
2022-03-28 00:01:32,149 epoch 3 - iter 100/107 - loss 0.15914328 - samples/sec: 169.97 - lr: 0.100000
2022-03-28 00:01:33,350 ----------------------------------------------------------------------------------------------------
2022-03-28 00:01:33,350 EPOCH 3 done: loss 0.1581 - lr 0.100000
2022-03-28 00:01:39,479 Evaluating as a multi-label problem: False
2022-03-28 00:01:39,489 DEV : loss 0.2653048634529114 - f1-score (micro avg)  0.4363
2022-03-28 00:01:39,561 BAD EPOCHS (no improvement): 0
2022-03-28 00:01:39,565 saving best model
2022-03-28 00:01:53,424 ----------------------------------------------------------------------------------------------------
2022-03-28 00:01:56,290 epoch 4 - iter 10/107 - loss 0.15563784 - samples/sec: 111.71 - lr: 0.100000
2022-03-28 00:01:59,084 epoch 4 - iter 20/107 - loss 0.13028148 - samples/sec: 114.59 - lr: 0.100000
2022-03-28 00:02:01,861 epoch 4 - iter 30/107 - loss 0.13589624 - samples/sec: 115.27 - lr: 0.100000
2022-03-28 00:02:04,642 epoch 4 - iter 40/107 - loss 0.13810556 - samples/sec: 115.08 - lr: 0.100000
2022-03-28 00:02:07,311 epoch 4 - iter 50/107 - loss 0.14004068 - samples/sec: 119.96 - lr: 0.100000
2022-03-28 00:02:10,093 epoch 4 - iter 60/107 - loss 0.14539081 - samples/sec: 115.07 - lr: 0.100000
2022-03-28 00:02:12,564 epoch 4 - iter 70/107 - loss 0.14125255 - samples/sec: 129.56 - lr: 0.100000
2022-03-28 00:02:15,270 epoch 4 - iter 80/107 - loss 0.13796795 - samples/sec: 118.33 - lr: 0.100000
2022-03-28 00:02:17,768 epoch 4 - iter 90/107 - loss 0.13773213 - samples/sec: 128.13 - lr: 0.100000
2022-03-28 00:02:20,353 epoch 4 - iter 100/107 - loss 0.13896756 - samples/sec: 123.87 - lr: 0.100000
2022-03-28 00:02:21,747 ----------------------------------------------------------------------------------------------------
2022-03-28 00:02:21,747 EPOCH 4 done: loss 0.1394 - lr 0.100000
2022-03-28 00:02:29,153 Evaluating as a multi-label problem: False
2022-03-28 00:02:29,164 DEV : loss 0.24826911091804504 - f1-score (micro avg)  0.4444
2022-03-28 00:02:29,238 BAD EPOCHS (no improvement): 0
2022-03-28 00:02:29,241 saving best model
2022-03-28 00:02:43,105 ----------------------------------------------------------------------------------------------------
2022-03-28 00:02:45,695 epoch 5 - iter 10/107 - loss 0.12629986 - samples/sec: 123.61 - lr: 0.100000
2022-03-28 00:02:48,426 epoch 5 - iter 20/107 - loss 0.11944675 - samples/sec: 117.23 - lr: 0.100000
2022-03-28 00:02:51,172 epoch 5 - iter 30/107 - loss 0.13122282 - samples/sec: 116.59 - lr: 0.100000
2022-03-28 00:02:53,760 epoch 5 - iter 40/107 - loss 0.13301730 - samples/sec: 123.70 - lr: 0.100000
2022-03-28 00:02:56,420 epoch 5 - iter 50/107 - loss 0.13244289 - samples/sec: 120.35 - lr: 0.100000
2022-03-28 00:02:59,235 epoch 5 - iter 60/107 - loss 0.13414477 - samples/sec: 113.71 - lr: 0.100000
2022-03-28 00:03:01,838 epoch 5 - iter 70/107 - loss 0.13119698 - samples/sec: 122.97 - lr: 0.100000
2022-03-28 00:03:04,468 epoch 5 - iter 80/107 - loss 0.12944195 - samples/sec: 121.75 - lr: 0.100000
2022-03-28 00:03:07,015 epoch 5 - iter 90/107 - loss 0.12714271 - samples/sec: 125.67 - lr: 0.100000
2022-03-28 00:03:09,214 epoch 5 - iter 100/107 - loss 0.12792309 - samples/sec: 145.63 - lr: 0.100000
2022-03-28 00:03:10,642 ----------------------------------------------------------------------------------------------------
2022-03-28 00:03:10,642 EPOCH 5 done: loss 0.1280 - lr 0.100000
2022-03-28 00:03:18,163 Evaluating as a multi-label problem: False
2022-03-28 00:03:18,173 DEV : loss 0.2354304939508438 - f1-score (micro avg)  0.4437
2022-03-28 00:03:18,247 BAD EPOCHS (no improvement): 1
2022-03-28 00:03:18,250 ----------------------------------------------------------------------------------------------------
2022-03-28 00:03:21,008 epoch 6 - iter 10/107 - loss 0.10718451 - samples/sec: 116.10 - lr: 0.100000
2022-03-28 00:03:23,729 epoch 6 - iter 20/107 - loss 0.11376446 - samples/sec: 117.62 - lr: 0.100000
2022-03-28 00:03:26,656 epoch 6 - iter 30/107 - loss 0.11208458 - samples/sec: 109.37 - lr: 0.100000
2022-03-28 00:03:29,208 epoch 6 - iter 40/107 - loss 0.10927674 - samples/sec: 125.43 - lr: 0.100000
2022-03-28 00:03:31,920 epoch 6 - iter 50/107 - loss 0.11131603 - samples/sec: 118.03 - lr: 0.100000
2022-03-28 00:03:34,454 epoch 6 - iter 60/107 - loss 0.11536149 - samples/sec: 126.34 - lr: 0.100000
2022-03-28 00:03:37,251 epoch 6 - iter 70/107 - loss 0.11529011 - samples/sec: 114.46 - lr: 0.100000
2022-03-28 00:03:39,851 epoch 6 - iter 80/107 - loss 0.11546655 - samples/sec: 123.13 - lr: 0.100000
2022-03-28 00:03:42,557 epoch 6 - iter 90/107 - loss 0.11586870 - samples/sec: 118.28 - lr: 0.100000
2022-03-28 00:03:45,365 epoch 6 - iter 100/107 - loss 0.11534407 - samples/sec: 114.00 - lr: 0.100000
2022-03-28 00:03:47,177 ----------------------------------------------------------------------------------------------------
2022-03-28 00:03:47,177 EPOCH 6 done: loss 0.1159 - lr 0.100000
2022-03-28 00:03:55,531 Evaluating as a multi-label problem: False
2022-03-28 00:03:55,543 DEV : loss 0.20627397298812866 - f1-score (micro avg)  0.4908
2022-03-28 00:03:55,616 BAD EPOCHS (no improvement): 0
2022-03-28 00:03:55,619 saving best model
2022-03-28 00:04:09,559 ----------------------------------------------------------------------------------------------------
2022-03-28 00:04:12,328 epoch 7 - iter 10/107 - loss 0.11650158 - samples/sec: 115.61 - lr: 0.100000
2022-03-28 00:04:15,046 epoch 7 - iter 20/107 - loss 0.10524674 - samples/sec: 117.81 - lr: 0.100000
2022-03-28 00:04:17,781 epoch 7 - iter 30/107 - loss 0.10341242 - samples/sec: 117.02 - lr: 0.100000
2022-03-28 00:04:20,497 epoch 7 - iter 40/107 - loss 0.11319668 - samples/sec: 117.89 - lr: 0.100000
2022-03-28 00:04:23,224 epoch 7 - iter 50/107 - loss 0.11382035 - samples/sec: 117.38 - lr: 0.100000
2022-03-28 00:04:25,843 epoch 7 - iter 60/107 - loss 0.11438473 - samples/sec: 122.20 - lr: 0.100000
2022-03-28 00:04:28,508 epoch 7 - iter 70/107 - loss 0.11385402 - samples/sec: 120.15 - lr: 0.100000
2022-03-28 00:04:31,295 epoch 7 - iter 80/107 - loss 0.11270928 - samples/sec: 114.86 - lr: 0.100000
2022-03-28 00:04:34,090 epoch 7 - iter 90/107 - loss 0.11154514 - samples/sec: 114.52 - lr: 0.100000
2022-03-28 00:04:36,659 epoch 7 - iter 100/107 - loss 0.11022302 - samples/sec: 124.62 - lr: 0.100000
2022-03-28 00:04:38,352 ----------------------------------------------------------------------------------------------------
2022-03-28 00:04:38,353 EPOCH 7 done: loss 0.1099 - lr 0.100000
2022-03-28 00:04:46,359 Evaluating as a multi-label problem: False
2022-03-28 00:04:46,370 DEV : loss 0.19361287355422974 - f1-score (micro avg)  0.5074
2022-03-28 00:04:46,443 BAD EPOCHS (no improvement): 0
2022-03-28 00:04:46,447 saving best model
2022-03-28 00:05:00,180 ----------------------------------------------------------------------------------------------------
2022-03-28 00:05:03,071 epoch 8 - iter 10/107 - loss 0.09568880 - samples/sec: 110.77 - lr: 0.100000
2022-03-28 00:05:05,762 epoch 8 - iter 20/107 - loss 0.10179102 - samples/sec: 118.97 - lr: 0.100000
2022-03-28 00:05:08,522 epoch 8 - iter 30/107 - loss 0.10073435 - samples/sec: 115.97 - lr: 0.100000
2022-03-28 00:05:11,226 epoch 8 - iter 40/107 - loss 0.09997884 - samples/sec: 118.40 - lr: 0.100000
2022-03-28 00:05:13,968 epoch 8 - iter 50/107 - loss 0.10056166 - samples/sec: 116.71 - lr: 0.100000
2022-03-28 00:05:16,605 epoch 8 - iter 60/107 - loss 0.10199284 - samples/sec: 121.38 - lr: 0.100000
2022-03-28 00:05:19,437 epoch 8 - iter 70/107 - loss 0.10341697 - samples/sec: 113.05 - lr: 0.100000
2022-03-28 00:05:21,976 epoch 8 - iter 80/107 - loss 0.10272294 - samples/sec: 126.09 - lr: 0.100000
2022-03-28 00:05:24,631 epoch 8 - iter 90/107 - loss 0.10371662 - samples/sec: 120.59 - lr: 0.100000
2022-03-28 00:05:27,408 epoch 8 - iter 100/107 - loss 0.10316397 - samples/sec: 115.27 - lr: 0.100000
2022-03-28 00:05:30,332 ----------------------------------------------------------------------------------------------------
2022-03-28 00:05:30,332 EPOCH 8 done: loss 0.1020 - lr 0.100000
2022-03-28 00:05:38,046 Evaluating as a multi-label problem: False
2022-03-28 00:05:38,056 DEV : loss 0.19627727568149567 - f1-score (micro avg)  0.4984
2022-03-28 00:05:38,129 BAD EPOCHS (no improvement): 1
2022-03-28 00:05:38,132 ----------------------------------------------------------------------------------------------------
2022-03-28 00:05:40,737 epoch 9 - iter 10/107 - loss 0.09237596 - samples/sec: 122.89 - lr: 0.100000
2022-03-28 00:05:43,296 epoch 9 - iter 20/107 - loss 0.09784062 - samples/sec: 125.10 - lr: 0.100000
2022-03-28 00:05:46,066 epoch 9 - iter 30/107 - loss 0.10092722 - samples/sec: 115.56 - lr: 0.100000
2022-03-28 00:05:48,763 epoch 9 - iter 40/107 - loss 0.09678551 - samples/sec: 118.72 - lr: 0.100000
2022-03-28 00:05:51,336 epoch 9 - iter 50/107 - loss 0.09549586 - samples/sec: 124.42 - lr: 0.100000
2022-03-28 00:05:53,958 epoch 9 - iter 60/107 - loss 0.09514280 - samples/sec: 122.06 - lr: 0.100000
2022-03-28 00:05:56,711 epoch 9 - iter 70/107 - loss 0.09744005 - samples/sec: 116.30 - lr: 0.100000
2022-03-28 00:05:59,389 epoch 9 - iter 80/107 - loss 0.09630513 - samples/sec: 119.50 - lr: 0.100000
2022-03-28 00:06:02,087 epoch 9 - iter 90/107 - loss 0.09757221 - samples/sec: 118.64 - lr: 0.100000
2022-03-28 00:06:04,834 epoch 9 - iter 100/107 - loss 0.09822585 - samples/sec: 116.57 - lr: 0.100000
2022-03-28 00:06:06,629 ----------------------------------------------------------------------------------------------------
2022-03-28 00:06:06,629 EPOCH 9 done: loss 0.0973 - lr 0.100000
2022-03-28 00:06:15,256 Evaluating as a multi-label problem: False
2022-03-28 00:06:15,267 DEV : loss 0.22779184579849243 - f1-score (micro avg)  0.4787
2022-03-28 00:06:15,340 BAD EPOCHS (no improvement): 2
2022-03-28 00:06:15,346 ----------------------------------------------------------------------------------------------------
2022-03-28 00:06:18,257 epoch 10 - iter 10/107 - loss 0.08694846 - samples/sec: 109.95 - lr: 0.100000
2022-03-28 00:06:21,021 epoch 10 - iter 20/107 - loss 0.08426195 - samples/sec: 115.85 - lr: 0.100000
2022-03-28 00:06:23,339 epoch 10 - iter 30/107 - loss 0.08073439 - samples/sec: 138.09 - lr: 0.100000
2022-03-28 00:06:25,914 epoch 10 - iter 40/107 - loss 0.08766781 - samples/sec: 124.31 - lr: 0.100000
2022-03-28 00:06:28,459 epoch 10 - iter 50/107 - loss 0.09355397 - samples/sec: 125.81 - lr: 0.100000
2022-03-28 00:06:31,020 epoch 10 - iter 60/107 - loss 0.09257745 - samples/sec: 124.97 - lr: 0.100000
2022-03-28 00:06:33,399 epoch 10 - iter 70/107 - loss 0.09074561 - samples/sec: 134.57 - lr: 0.100000
2022-03-28 00:06:35,998 epoch 10 - iter 80/107 - loss 0.08869864 - samples/sec: 123.18 - lr: 0.100000
2022-03-28 00:06:38,657 epoch 10 - iter 90/107 - loss 0.09012035 - samples/sec: 120.41 - lr: 0.100000
2022-03-28 00:06:41,381 epoch 10 - iter 100/107 - loss 0.08996975 - samples/sec: 117.51 - lr: 0.100000
2022-03-28 00:06:43,086 ----------------------------------------------------------------------------------------------------
2022-03-28 00:06:43,086 EPOCH 10 done: loss 0.0911 - lr 0.100000
2022-03-28 00:06:51,642 Evaluating as a multi-label problem: False
2022-03-28 00:06:51,653 DEV : loss 0.21593473851680756 - f1-score (micro avg)  0.4772
2022-03-28 00:06:51,727 BAD EPOCHS (no improvement): 3
2022-03-28 00:06:51,730 ----------------------------------------------------------------------------------------------------
2022-03-28 00:06:54,446 epoch 11 - iter 10/107 - loss 0.09088662 - samples/sec: 117.87 - lr: 0.100000
2022-03-28 00:06:57,192 epoch 11 - iter 20/107 - loss 0.08600974 - samples/sec: 116.59 - lr: 0.100000
2022-03-28 00:06:59,845 epoch 11 - iter 30/107 - loss 0.08582396 - samples/sec: 120.66 - lr: 0.100000
2022-03-28 00:07:02,490 epoch 11 - iter 40/107 - loss 0.08551976 - samples/sec: 121.05 - lr: 0.100000
2022-03-28 00:07:05,079 epoch 11 - iter 50/107 - loss 0.08502029 - samples/sec: 123.64 - lr: 0.100000
2022-03-28 00:07:07,779 epoch 11 - iter 60/107 - loss 0.08446259 - samples/sec: 118.55 - lr: 0.100000
2022-03-28 00:07:10,429 epoch 11 - iter 70/107 - loss 0.08459957 - samples/sec: 120.80 - lr: 0.100000
2022-03-28 00:07:13,193 epoch 11 - iter 80/107 - loss 0.08268622 - samples/sec: 115.82 - lr: 0.100000
2022-03-28 00:07:15,840 epoch 11 - iter 90/107 - loss 0.08445389 - samples/sec: 120.91 - lr: 0.100000
2022-03-28 00:07:18,121 epoch 11 - iter 100/107 - loss 0.08418026 - samples/sec: 140.40 - lr: 0.100000
2022-03-28 00:07:19,456 ----------------------------------------------------------------------------------------------------
2022-03-28 00:07:19,456 EPOCH 11 done: loss 0.0850 - lr 0.100000
2022-03-28 00:07:27,147 Evaluating as a multi-label problem: False
2022-03-28 00:07:27,157 DEV : loss 0.19134850800037384 - f1-score (micro avg)  0.496
2022-03-28 00:07:27,230 Epoch    11: reducing learning rate of group 0 to 5.0000e-02.
2022-03-28 00:07:27,230 BAD EPOCHS (no improvement): 4
2022-03-28 00:07:27,232 ----------------------------------------------------------------------------------------------------
2022-03-28 00:07:29,929 epoch 12 - iter 10/107 - loss 0.07121954 - samples/sec: 118.70 - lr: 0.050000
2022-03-28 00:07:32,531 epoch 12 - iter 20/107 - loss 0.07213134 - samples/sec: 123.04 - lr: 0.050000
2022-03-28 00:07:35,045 epoch 12 - iter 30/107 - loss 0.07129146 - samples/sec: 127.30 - lr: 0.050000
2022-03-28 00:07:37,841 epoch 12 - iter 40/107 - loss 0.07103364 - samples/sec: 114.51 - lr: 0.050000
2022-03-28 00:07:40,581 epoch 12 - iter 50/107 - loss 0.07347111 - samples/sec: 116.83 - lr: 0.050000
2022-03-28 00:07:43,373 epoch 12 - iter 60/107 - loss 0.07414174 - samples/sec: 114.66 - lr: 0.050000
2022-03-28 00:07:46,053 epoch 12 - iter 70/107 - loss 0.07504974 - samples/sec: 119.46 - lr: 0.050000
2022-03-28 00:07:48,793 epoch 12 - iter 80/107 - loss 0.07656477 - samples/sec: 116.81 - lr: 0.050000
2022-03-28 00:07:51,457 epoch 12 - iter 90/107 - loss 0.07520859 - samples/sec: 120.16 - lr: 0.050000
2022-03-28 00:07:54,238 epoch 12 - iter 100/107 - loss 0.07434648 - samples/sec: 115.12 - lr: 0.050000
2022-03-28 00:07:55,978 ----------------------------------------------------------------------------------------------------
2022-03-28 00:07:55,978 EPOCH 12 done: loss 0.0749 - lr 0.050000
2022-03-28 00:08:04,907 Evaluating as a multi-label problem: False
2022-03-28 00:08:04,919 DEV : loss 0.2173689305782318 - f1-score (micro avg)  0.4838
2022-03-28 00:08:04,991 BAD EPOCHS (no improvement): 1
2022-03-28 00:08:05,070 ----------------------------------------------------------------------------------------------------
2022-03-28 00:08:07,445 epoch 13 - iter 10/107 - loss 0.06743353 - samples/sec: 134.82 - lr: 0.050000
2022-03-28 00:08:09,780 epoch 13 - iter 20/107 - loss 0.06654214 - samples/sec: 137.10 - lr: 0.050000
2022-03-28 00:08:12,212 epoch 13 - iter 30/107 - loss 0.07675549 - samples/sec: 131.65 - lr: 0.050000
2022-03-28 00:08:14,768 epoch 13 - iter 40/107 - loss 0.07095049 - samples/sec: 125.21 - lr: 0.050000
2022-03-28 00:08:17,072 epoch 13 - iter 50/107 - loss 0.07151731 - samples/sec: 138.95 - lr: 0.050000
2022-03-28 00:08:19,750 epoch 13 - iter 60/107 - loss 0.07036570 - samples/sec: 119.57 - lr: 0.050000
2022-03-28 00:08:22,488 epoch 13 - iter 70/107 - loss 0.07042632 - samples/sec: 116.91 - lr: 0.050000
2022-03-28 00:08:25,238 epoch 13 - iter 80/107 - loss 0.07198431 - samples/sec: 116.42 - lr: 0.050000
2022-03-28 00:08:28,001 epoch 13 - iter 90/107 - loss 0.07140099 - samples/sec: 115.87 - lr: 0.050000
2022-03-28 00:08:30,718 epoch 13 - iter 100/107 - loss 0.07019408 - samples/sec: 117.80 - lr: 0.050000
2022-03-28 00:08:32,318 ----------------------------------------------------------------------------------------------------
2022-03-28 00:08:32,319 EPOCH 13 done: loss 0.0708 - lr 0.050000
2022-03-28 00:08:40,841 Evaluating as a multi-label problem: False
2022-03-28 00:08:40,853 DEV : loss 0.19274376332759857 - f1-score (micro avg)  0.5097
2022-03-28 00:08:40,927 BAD EPOCHS (no improvement): 0
2022-03-28 00:08:40,929 saving best model
2022-03-28 00:08:55,331 ----------------------------------------------------------------------------------------------------
2022-03-28 00:08:58,046 epoch 14 - iter 10/107 - loss 0.07399692 - samples/sec: 117.91 - lr: 0.050000
2022-03-28 00:09:00,552 epoch 14 - iter 20/107 - loss 0.07657614 - samples/sec: 127.74 - lr: 0.050000
2022-03-28 00:09:02,933 epoch 14 - iter 30/107 - loss 0.07435957 - samples/sec: 134.48 - lr: 0.050000
2022-03-28 00:09:05,540 epoch 14 - iter 40/107 - loss 0.07196043 - samples/sec: 122.78 - lr: 0.050000
2022-03-28 00:09:08,086 epoch 14 - iter 50/107 - loss 0.07198687 - samples/sec: 125.74 - lr: 0.050000
2022-03-28 00:09:10,344 epoch 14 - iter 60/107 - loss 0.07154907 - samples/sec: 141.77 - lr: 0.050000
2022-03-28 00:09:13,073 epoch 14 - iter 70/107 - loss 0.06884853 - samples/sec: 117.30 - lr: 0.050000
2022-03-28 00:09:15,864 epoch 14 - iter 80/107 - loss 0.06827645 - samples/sec: 114.73 - lr: 0.050000
2022-03-28 00:09:18,684 epoch 14 - iter 90/107 - loss 0.06796466 - samples/sec: 113.52 - lr: 0.050000
2022-03-28 00:09:21,308 epoch 14 - iter 100/107 - loss 0.06832876 - samples/sec: 121.98 - lr: 0.050000
2022-03-28 00:09:22,963 ----------------------------------------------------------------------------------------------------
2022-03-28 00:09:22,963 EPOCH 14 done: loss 0.0684 - lr 0.050000
2022-03-28 00:09:31,253 Evaluating as a multi-label problem: False
2022-03-28 00:09:31,264 DEV : loss 0.21854566037654877 - f1-score (micro avg)  0.4706
2022-03-28 00:09:31,336 BAD EPOCHS (no improvement): 1
2022-03-28 00:09:31,339 ----------------------------------------------------------------------------------------------------
2022-03-28 00:09:35,417 epoch 15 - iter 10/107 - loss 0.06554832 - samples/sec: 78.49 - lr: 0.050000
2022-03-28 00:09:38,174 epoch 15 - iter 20/107 - loss 0.06635351 - samples/sec: 116.11 - lr: 0.050000
2022-03-28 00:09:40,947 epoch 15 - iter 30/107 - loss 0.06540946 - samples/sec: 115.44 - lr: 0.050000
2022-03-28 00:09:43,474 epoch 15 - iter 40/107 - loss 0.06570814 - samples/sec: 126.67 - lr: 0.050000
2022-03-28 00:09:46,237 epoch 15 - iter 50/107 - loss 0.06302546 - samples/sec: 115.88 - lr: 0.050000
2022-03-28 00:09:48,918 epoch 15 - iter 60/107 - loss 0.06205381 - samples/sec: 119.41 - lr: 0.050000
2022-03-28 00:09:51,427 epoch 15 - iter 70/107 - loss 0.06263582 - samples/sec: 127.57 - lr: 0.050000
2022-03-28 00:09:53,977 epoch 15 - iter 80/107 - loss 0.06410298 - samples/sec: 125.56 - lr: 0.050000
2022-03-28 00:09:56,365 epoch 15 - iter 90/107 - loss 0.06428816 - samples/sec: 134.04 - lr: 0.050000
2022-03-28 00:09:58,879 epoch 15 - iter 100/107 - loss 0.06442385 - samples/sec: 127.35 - lr: 0.050000
2022-03-28 00:10:00,360 ----------------------------------------------------------------------------------------------------
2022-03-28 00:10:00,361 EPOCH 15 done: loss 0.0651 - lr 0.050000
2022-03-28 00:10:08,495 Evaluating as a multi-label problem: False
2022-03-28 00:10:08,506 DEV : loss 0.2131134420633316 - f1-score (micro avg)  0.4683
2022-03-28 00:10:08,579 BAD EPOCHS (no improvement): 2
2022-03-28 00:10:08,582 ----------------------------------------------------------------------------------------------------
2022-03-28 00:10:11,152 epoch 16 - iter 10/107 - loss 0.06512711 - samples/sec: 124.58 - lr: 0.050000
2022-03-28 00:10:13,882 epoch 16 - iter 20/107 - loss 0.06363499 - samples/sec: 117.28 - lr: 0.050000
2022-03-28 00:10:16,618 epoch 16 - iter 30/107 - loss 0.06387098 - samples/sec: 116.97 - lr: 0.050000
2022-03-28 00:10:19,304 epoch 16 - iter 40/107 - loss 0.06538326 - samples/sec: 119.21 - lr: 0.050000
2022-03-28 00:10:21,988 epoch 16 - iter 50/107 - loss 0.06479011 - samples/sec: 119.28 - lr: 0.050000
2022-03-28 00:10:24,748 epoch 16 - iter 60/107 - loss 0.06535356 - samples/sec: 115.96 - lr: 0.050000
2022-03-28 00:10:27,484 epoch 16 - iter 70/107 - loss 0.06498538 - samples/sec: 117.01 - lr: 0.050000
2022-03-28 00:10:30,220 epoch 16 - iter 80/107 - loss 0.06491847 - samples/sec: 116.99 - lr: 0.050000
2022-03-28 00:10:32,900 epoch 16 - iter 90/107 - loss 0.06391206 - samples/sec: 119.45 - lr: 0.050000
2022-03-28 00:10:35,649 epoch 16 - iter 100/107 - loss 0.06446467 - samples/sec: 116.46 - lr: 0.050000
2022-03-28 00:10:37,253 ----------------------------------------------------------------------------------------------------
2022-03-28 00:10:37,253 EPOCH 16 done: loss 0.0649 - lr 0.050000
2022-03-28 00:10:45,286 Evaluating as a multi-label problem: False
2022-03-28 00:10:45,297 DEV : loss 0.22149522602558136 - f1-score (micro avg)  0.4736
2022-03-28 00:10:45,372 BAD EPOCHS (no improvement): 3
2022-03-28 00:10:45,375 ----------------------------------------------------------------------------------------------------
2022-03-28 00:10:47,847 epoch 17 - iter 10/107 - loss 0.06296244 - samples/sec: 129.54 - lr: 0.050000
2022-03-28 00:10:50,175 epoch 17 - iter 20/107 - loss 0.06245269 - samples/sec: 137.51 - lr: 0.050000
2022-03-28 00:10:52,654 epoch 17 - iter 30/107 - loss 0.06031036 - samples/sec: 129.13 - lr: 0.050000
2022-03-28 00:10:55,494 epoch 17 - iter 40/107 - loss 0.05659737 - samples/sec: 112.70 - lr: 0.050000
2022-03-28 00:10:58,112 epoch 17 - iter 50/107 - loss 0.05902043 - samples/sec: 122.31 - lr: 0.050000
2022-03-28 00:11:00,915 epoch 17 - iter 60/107 - loss 0.05992208 - samples/sec: 114.18 - lr: 0.050000
2022-03-28 00:11:03,728 epoch 17 - iter 70/107 - loss 0.06016906 - samples/sec: 113.81 - lr: 0.050000
2022-03-28 00:11:06,534 epoch 17 - iter 80/107 - loss 0.05981792 - samples/sec: 114.07 - lr: 0.050000
2022-03-28 00:11:09,268 epoch 17 - iter 90/107 - loss 0.06094910 - samples/sec: 117.08 - lr: 0.050000
2022-03-28 00:11:12,008 epoch 17 - iter 100/107 - loss 0.06179019 - samples/sec: 116.83 - lr: 0.050000
2022-03-28 00:11:13,653 ----------------------------------------------------------------------------------------------------
2022-03-28 00:11:13,654 EPOCH 17 done: loss 0.0616 - lr 0.050000
2022-03-28 00:11:22,049 Evaluating as a multi-label problem: False
2022-03-28 00:11:22,060 DEV : loss 0.21440382301807404 - f1-score (micro avg)  0.4911
2022-03-28 00:11:22,132 Epoch    17: reducing learning rate of group 0 to 2.5000e-02.
2022-03-28 00:11:22,133 BAD EPOCHS (no improvement): 4
2022-03-28 00:11:22,135 ----------------------------------------------------------------------------------------------------
2022-03-28 00:11:24,979 epoch 18 - iter 10/107 - loss 0.05149026 - samples/sec: 112.56 - lr: 0.025000
2022-03-28 00:11:27,628 epoch 18 - iter 20/107 - loss 0.05689981 - samples/sec: 120.86 - lr: 0.025000
2022-03-28 00:11:30,328 epoch 18 - iter 30/107 - loss 0.06135650 - samples/sec: 118.56 - lr: 0.025000
2022-03-28 00:11:33,001 epoch 18 - iter 40/107 - loss 0.06183749 - samples/sec: 119.78 - lr: 0.025000
2022-03-28 00:11:35,540 epoch 18 - iter 50/107 - loss 0.06122657 - samples/sec: 126.07 - lr: 0.025000
2022-03-28 00:11:37,995 epoch 18 - iter 60/107 - loss 0.05869895 - samples/sec: 130.43 - lr: 0.025000
2022-03-28 00:11:40,430 epoch 18 - iter 70/107 - loss 0.05778454 - samples/sec: 131.44 - lr: 0.025000
2022-03-28 00:11:42,787 epoch 18 - iter 80/107 - loss 0.05716790 - samples/sec: 135.83 - lr: 0.025000
2022-03-28 00:11:45,251 epoch 18 - iter 90/107 - loss 0.05566127 - samples/sec: 129.94 - lr: 0.025000
2022-03-28 00:11:47,878 epoch 18 - iter 100/107 - loss 0.05517305 - samples/sec: 121.85 - lr: 0.025000
2022-03-28 00:11:49,732 ----------------------------------------------------------------------------------------------------
2022-03-28 00:11:49,732 EPOCH 18 done: loss 0.0556 - lr 0.025000
2022-03-28 00:11:58,244 Evaluating as a multi-label problem: False
2022-03-28 00:11:58,255 DEV : loss 0.20360660552978516 - f1-score (micro avg)  0.5036
2022-03-28 00:11:58,328 BAD EPOCHS (no improvement): 1
2022-03-28 00:11:58,388 ----------------------------------------------------------------------------------------------------
2022-03-28 00:12:01,090 epoch 19 - iter 10/107 - loss 0.04687137 - samples/sec: 118.49 - lr: 0.025000
2022-03-28 00:12:03,754 epoch 19 - iter 20/107 - loss 0.05014543 - samples/sec: 120.19 - lr: 0.025000
2022-03-28 00:12:06,530 epoch 19 - iter 30/107 - loss 0.05202130 - samples/sec: 115.32 - lr: 0.025000
2022-03-28 00:12:09,245 epoch 19 - iter 40/107 - loss 0.05569723 - samples/sec: 117.90 - lr: 0.025000
2022-03-28 00:12:12,011 epoch 19 - iter 50/107 - loss 0.05416111 - samples/sec: 115.74 - lr: 0.025000
2022-03-28 00:12:14,668 epoch 19 - iter 60/107 - loss 0.05402515 - samples/sec: 120.46 - lr: 0.025000
2022-03-28 00:12:17,521 epoch 19 - iter 70/107 - loss 0.05340376 - samples/sec: 112.25 - lr: 0.025000
2022-03-28 00:12:20,273 epoch 19 - iter 80/107 - loss 0.05343905 - samples/sec: 116.32 - lr: 0.025000
2022-03-28 00:12:22,942 epoch 19 - iter 90/107 - loss 0.05445253 - samples/sec: 119.95 - lr: 0.025000
2022-03-28 00:12:25,688 epoch 19 - iter 100/107 - loss 0.05440695 - samples/sec: 116.57 - lr: 0.025000
2022-03-28 00:12:27,240 ----------------------------------------------------------------------------------------------------
2022-03-28 00:12:27,241 EPOCH 19 done: loss 0.0547 - lr 0.025000
2022-03-28 00:12:34,935 Evaluating as a multi-label problem: False
2022-03-28 00:12:34,947 DEV : loss 0.1973544806241989 - f1-score (micro avg)  0.5205
2022-03-28 00:12:35,022 BAD EPOCHS (no improvement): 0
2022-03-28 00:12:35,025 saving best model
2022-03-28 00:12:48,598 ----------------------------------------------------------------------------------------------------
2022-03-28 00:12:51,401 epoch 20 - iter 10/107 - loss 0.06058976 - samples/sec: 114.22 - lr: 0.025000
2022-03-28 00:12:54,152 epoch 20 - iter 20/107 - loss 0.05492855 - samples/sec: 116.36 - lr: 0.025000
2022-03-28 00:12:56,869 epoch 20 - iter 30/107 - loss 0.05132271 - samples/sec: 117.81 - lr: 0.025000
2022-03-28 00:12:59,713 epoch 20 - iter 40/107 - loss 0.04931600 - samples/sec: 112.57 - lr: 0.025000
2022-03-28 00:13:02,494 epoch 20 - iter 50/107 - loss 0.04935969 - samples/sec: 115.10 - lr: 0.025000
2022-03-28 00:13:05,133 epoch 20 - iter 60/107 - loss 0.04899118 - samples/sec: 121.28 - lr: 0.025000
2022-03-28 00:13:07,836 epoch 20 - iter 70/107 - loss 0.04981043 - samples/sec: 118.47 - lr: 0.025000
2022-03-28 00:13:10,532 epoch 20 - iter 80/107 - loss 0.05111658 - samples/sec: 118.72 - lr: 0.025000
2022-03-28 00:13:13,233 epoch 20 - iter 90/107 - loss 0.05173762 - samples/sec: 118.53 - lr: 0.025000
2022-03-28 00:13:15,663 epoch 20 - iter 100/107 - loss 0.05227431 - samples/sec: 131.73 - lr: 0.025000
2022-03-28 00:13:17,279 ----------------------------------------------------------------------------------------------------
2022-03-28 00:13:17,279 EPOCH 20 done: loss 0.0526 - lr 0.025000
2022-03-28 00:13:24,849 Evaluating as a multi-label problem: False
2022-03-28 00:13:24,860 DEV : loss 0.19287109375 - f1-score (micro avg)  0.5205
2022-03-28 00:13:24,933 BAD EPOCHS (no improvement): 1
2022-03-28 00:13:24,937 ----------------------------------------------------------------------------------------------------
2022-03-28 00:13:27,665 epoch 21 - iter 10/107 - loss 0.05687573 - samples/sec: 117.32 - lr: 0.025000
2022-03-28 00:13:30,351 epoch 21 - iter 20/107 - loss 0.05130803 - samples/sec: 119.20 - lr: 0.025000
2022-03-28 00:13:33,158 epoch 21 - iter 30/107 - loss 0.05310583 - samples/sec: 114.02 - lr: 0.025000
2022-03-28 00:13:35,951 epoch 21 - iter 40/107 - loss 0.05541847 - samples/sec: 114.63 - lr: 0.025000
2022-03-28 00:13:38,719 epoch 21 - iter 50/107 - loss 0.05211216 - samples/sec: 115.66 - lr: 0.025000
2022-03-28 00:13:41,395 epoch 21 - iter 60/107 - loss 0.05198304 - samples/sec: 119.61 - lr: 0.025000
2022-03-28 00:13:44,211 epoch 21 - iter 70/107 - loss 0.05253930 - samples/sec: 113.68 - lr: 0.025000
2022-03-28 00:13:46,708 epoch 21 - iter 80/107 - loss 0.05314153 - samples/sec: 128.19 - lr: 0.025000
2022-03-28 00:13:49,613 epoch 21 - iter 90/107 - loss 0.05420089 - samples/sec: 110.20 - lr: 0.025000
2022-03-28 00:13:52,237 epoch 21 - iter 100/107 - loss 0.05357567 - samples/sec: 122.02 - lr: 0.025000
2022-03-28 00:13:53,900 ----------------------------------------------------------------------------------------------------
2022-03-28 00:13:53,900 EPOCH 21 done: loss 0.0537 - lr 0.025000
2022-03-28 00:14:03,565 Evaluating as a multi-label problem: False
2022-03-28 00:14:03,576 DEV : loss 0.1975761502981186 - f1-score (micro avg)  0.5168
2022-03-28 00:14:03,648 BAD EPOCHS (no improvement): 2
2022-03-28 00:14:03,650 ----------------------------------------------------------------------------------------------------
2022-03-28 00:14:06,126 epoch 22 - iter 10/107 - loss 0.06105254 - samples/sec: 129.33 - lr: 0.025000
2022-03-28 00:14:08,403 epoch 22 - iter 20/107 - loss 0.05506920 - samples/sec: 140.61 - lr: 0.025000
2022-03-28 00:14:10,888 epoch 22 - iter 30/107 - loss 0.05534709 - samples/sec: 128.82 - lr: 0.025000
2022-03-28 00:14:13,527 epoch 22 - iter 40/107 - loss 0.05502848 - samples/sec: 121.29 - lr: 0.025000
2022-03-28 00:14:16,224 epoch 22 - iter 50/107 - loss 0.05453179 - samples/sec: 118.68 - lr: 0.025000
2022-03-28 00:14:18,936 epoch 22 - iter 60/107 - loss 0.05396469 - samples/sec: 118.02 - lr: 0.025000
2022-03-28 00:14:21,706 epoch 22 - iter 70/107 - loss 0.05347971 - samples/sec: 115.58 - lr: 0.025000
2022-03-28 00:14:24,462 epoch 22 - iter 80/107 - loss 0.05272759 - samples/sec: 116.16 - lr: 0.025000
2022-03-28 00:14:27,071 epoch 22 - iter 90/107 - loss 0.05141900 - samples/sec: 122.71 - lr: 0.025000
2022-03-28 00:14:29,734 epoch 22 - iter 100/107 - loss 0.05106321 - samples/sec: 120.21 - lr: 0.025000
2022-03-28 00:14:31,453 ----------------------------------------------------------------------------------------------------
2022-03-28 00:14:31,453 EPOCH 22 done: loss 0.0511 - lr 0.025000
2022-03-28 00:14:39,922 Evaluating as a multi-label problem: False
2022-03-28 00:14:39,933 DEV : loss 0.21241755783557892 - f1-score (micro avg)  0.4909
2022-03-28 00:14:40,005 BAD EPOCHS (no improvement): 3
2022-03-28 00:14:40,008 ----------------------------------------------------------------------------------------------------
2022-03-28 00:14:42,607 epoch 23 - iter 10/107 - loss 0.04887455 - samples/sec: 123.22 - lr: 0.025000
2022-03-28 00:14:45,318 epoch 23 - iter 20/107 - loss 0.04493562 - samples/sec: 118.10 - lr: 0.025000
2022-03-28 00:14:48,013 epoch 23 - iter 30/107 - loss 0.04643271 - samples/sec: 118.76 - lr: 0.025000
2022-03-28 00:14:50,729 epoch 23 - iter 40/107 - loss 0.04833653 - samples/sec: 117.88 - lr: 0.025000
2022-03-28 00:14:53,561 epoch 23 - iter 50/107 - loss 0.04676469 - samples/sec: 113.01 - lr: 0.025000
2022-03-28 00:14:56,205 epoch 23 - iter 60/107 - loss 0.04836339 - samples/sec: 121.12 - lr: 0.025000
2022-03-28 00:14:58,664 epoch 23 - iter 70/107 - loss 0.04989830 - samples/sec: 130.17 - lr: 0.025000
2022-03-28 00:15:01,224 epoch 23 - iter 80/107 - loss 0.05026862 - samples/sec: 125.03 - lr: 0.025000
2022-03-28 00:15:03,626 epoch 23 - iter 90/107 - loss 0.04981502 - samples/sec: 133.28 - lr: 0.025000
2022-03-28 00:15:06,188 epoch 23 - iter 100/107 - loss 0.05048946 - samples/sec: 124.97 - lr: 0.025000
2022-03-28 00:15:07,708 ----------------------------------------------------------------------------------------------------
2022-03-28 00:15:07,708 EPOCH 23 done: loss 0.0504 - lr 0.025000
2022-03-28 00:15:16,210 Evaluating as a multi-label problem: False
2022-03-28 00:15:16,220 DEV : loss 0.20024476945400238 - f1-score (micro avg)  0.5123
2022-03-28 00:15:16,293 Epoch    23: reducing learning rate of group 0 to 1.2500e-02.
2022-03-28 00:15:16,293 BAD EPOCHS (no improvement): 4
2022-03-28 00:15:16,296 ----------------------------------------------------------------------------------------------------
2022-03-28 00:15:18,937 epoch 24 - iter 10/107 - loss 0.05526992 - samples/sec: 121.21 - lr: 0.012500
2022-03-28 00:15:21,864 epoch 24 - iter 20/107 - loss 0.04525307 - samples/sec: 109.38 - lr: 0.012500
2022-03-28 00:15:24,419 epoch 24 - iter 30/107 - loss 0.04643608 - samples/sec: 125.30 - lr: 0.012500
2022-03-28 00:15:27,156 epoch 24 - iter 40/107 - loss 0.04664056 - samples/sec: 116.97 - lr: 0.012500
2022-03-28 00:15:29,792 epoch 24 - iter 50/107 - loss 0.04713157 - samples/sec: 121.46 - lr: 0.012500
2022-03-28 00:15:32,591 epoch 24 - iter 60/107 - loss 0.04654705 - samples/sec: 114.35 - lr: 0.012500
2022-03-28 00:15:35,362 epoch 24 - iter 70/107 - loss 0.04471842 - samples/sec: 115.53 - lr: 0.012500
2022-03-28 00:15:37,971 epoch 24 - iter 80/107 - loss 0.04429475 - samples/sec: 122.67 - lr: 0.012500
2022-03-28 00:15:40,662 epoch 24 - iter 90/107 - loss 0.04518111 - samples/sec: 118.98 - lr: 0.012500
2022-03-28 00:15:43,342 epoch 24 - iter 100/107 - loss 0.04635575 - samples/sec: 119.43 - lr: 0.012500
2022-03-28 00:15:45,003 ----------------------------------------------------------------------------------------------------
2022-03-28 00:15:45,003 EPOCH 24 done: loss 0.0462 - lr 0.012500
2022-03-28 00:15:52,719 Evaluating as a multi-label problem: False
2022-03-28 00:15:52,731 DEV : loss 0.20257246494293213 - f1-score (micro avg)  0.5112
2022-03-28 00:15:52,805 BAD EPOCHS (no improvement): 1
2022-03-28 00:15:52,808 ----------------------------------------------------------------------------------------------------
2022-03-28 00:15:55,287 epoch 25 - iter 10/107 - loss 0.04168998 - samples/sec: 129.17 - lr: 0.012500
2022-03-28 00:15:57,772 epoch 25 - iter 20/107 - loss 0.04247790 - samples/sec: 128.83 - lr: 0.012500
2022-03-28 00:16:00,345 epoch 25 - iter 30/107 - loss 0.04414448 - samples/sec: 124.40 - lr: 0.012500
2022-03-28 00:16:03,121 epoch 25 - iter 40/107 - loss 0.04386254 - samples/sec: 115.32 - lr: 0.012500
2022-03-28 00:16:05,801 epoch 25 - iter 50/107 - loss 0.04234792 - samples/sec: 119.45 - lr: 0.012500
2022-03-28 00:16:08,470 epoch 25 - iter 60/107 - loss 0.04383823 - samples/sec: 119.97 - lr: 0.012500
2022-03-28 00:16:11,128 epoch 25 - iter 70/107 - loss 0.04520704 - samples/sec: 120.43 - lr: 0.012500
2022-03-28 00:16:13,779 epoch 25 - iter 80/107 - loss 0.04578366 - samples/sec: 120.74 - lr: 0.012500
2022-03-28 00:16:16,587 epoch 25 - iter 90/107 - loss 0.04626165 - samples/sec: 114.03 - lr: 0.012500
2022-03-28 00:16:19,191 epoch 25 - iter 100/107 - loss 0.04681609 - samples/sec: 122.94 - lr: 0.012500
2022-03-28 00:16:20,932 ----------------------------------------------------------------------------------------------------
2022-03-28 00:16:20,932 EPOCH 25 done: loss 0.0464 - lr 0.012500
2022-03-28 00:16:29,363 Evaluating as a multi-label problem: False
2022-03-28 00:16:29,374 DEV : loss 0.19972658157348633 - f1-score (micro avg)  0.5143
2022-03-28 00:16:29,451 BAD EPOCHS (no improvement): 2
2022-03-28 00:16:29,508 ----------------------------------------------------------------------------------------------------
2022-03-28 00:16:32,281 epoch 26 - iter 10/107 - loss 0.04383797 - samples/sec: 115.45 - lr: 0.012500
2022-03-28 00:16:35,072 epoch 26 - iter 20/107 - loss 0.04296312 - samples/sec: 114.70 - lr: 0.012500
2022-03-28 00:16:37,687 epoch 26 - iter 30/107 - loss 0.04730072 - samples/sec: 122.41 - lr: 0.012500
2022-03-28 00:16:40,311 epoch 26 - iter 40/107 - loss 0.04504554 - samples/sec: 121.99 - lr: 0.012500
2022-03-28 00:16:42,796 epoch 26 - iter 50/107 - loss 0.04520870 - samples/sec: 128.83 - lr: 0.012500
2022-03-28 00:16:45,195 epoch 26 - iter 60/107 - loss 0.04555041 - samples/sec: 133.46 - lr: 0.012500
2022-03-28 00:16:47,816 epoch 26 - iter 70/107 - loss 0.04460599 - samples/sec: 122.12 - lr: 0.012500
2022-03-28 00:16:50,288 epoch 26 - iter 80/107 - loss 0.04414899 - samples/sec: 129.54 - lr: 0.012500
2022-03-28 00:16:52,935 epoch 26 - iter 90/107 - loss 0.04528844 - samples/sec: 120.94 - lr: 0.012500
2022-03-28 00:16:55,662 epoch 26 - iter 100/107 - loss 0.04607823 - samples/sec: 117.38 - lr: 0.012500
2022-03-28 00:16:57,293 ----------------------------------------------------------------------------------------------------
2022-03-28 00:16:57,293 EPOCH 26 done: loss 0.0455 - lr 0.012500
2022-03-28 00:17:05,747 Evaluating as a multi-label problem: False
2022-03-28 00:17:05,760 DEV : loss 0.21241948008537292 - f1-score (micro avg)  0.4988
2022-03-28 00:17:05,833 BAD EPOCHS (no improvement): 3
2022-03-28 00:17:05,836 ----------------------------------------------------------------------------------------------------
2022-03-28 00:17:08,619 epoch 27 - iter 10/107 - loss 0.04700239 - samples/sec: 115.03 - lr: 0.012500
2022-03-28 00:17:11,199 epoch 27 - iter 20/107 - loss 0.04541184 - samples/sec: 124.10 - lr: 0.012500
2022-03-28 00:17:14,052 epoch 27 - iter 30/107 - loss 0.04604143 - samples/sec: 112.19 - lr: 0.012500
2022-03-28 00:17:16,891 epoch 27 - iter 40/107 - loss 0.04581735 - samples/sec: 112.77 - lr: 0.012500
2022-03-28 00:17:19,637 epoch 27 - iter 50/107 - loss 0.04594532 - samples/sec: 116.55 - lr: 0.012500
2022-03-28 00:17:22,293 epoch 27 - iter 60/107 - loss 0.04685142 - samples/sec: 120.56 - lr: 0.012500
2022-03-28 00:17:24,935 epoch 27 - iter 70/107 - loss 0.04740789 - samples/sec: 121.12 - lr: 0.012500
2022-03-28 00:17:27,689 epoch 27 - iter 80/107 - loss 0.04651192 - samples/sec: 116.27 - lr: 0.012500
2022-03-28 00:17:30,350 epoch 27 - iter 90/107 - loss 0.04542256 - samples/sec: 120.30 - lr: 0.012500
2022-03-28 00:17:32,735 epoch 27 - iter 100/107 - loss 0.04609344 - samples/sec: 134.19 - lr: 0.012500
2022-03-28 00:17:34,257 ----------------------------------------------------------------------------------------------------
2022-03-28 00:17:34,258 EPOCH 27 done: loss 0.0456 - lr 0.012500
2022-03-28 00:17:41,913 Evaluating as a multi-label problem: False
2022-03-28 00:17:41,924 DEV : loss 0.20570598542690277 - f1-score (micro avg)  0.5097
2022-03-28 00:17:41,997 Epoch    27: reducing learning rate of group 0 to 6.2500e-03.
2022-03-28 00:17:41,997 BAD EPOCHS (no improvement): 4
2022-03-28 00:17:42,000 ----------------------------------------------------------------------------------------------------
2022-03-28 00:17:44,743 epoch 28 - iter 10/107 - loss 0.04693139 - samples/sec: 116.72 - lr: 0.006250
2022-03-28 00:17:47,401 epoch 28 - iter 20/107 - loss 0.04569351 - samples/sec: 120.44 - lr: 0.006250
2022-03-28 00:17:50,112 epoch 28 - iter 30/107 - loss 0.04606192 - samples/sec: 118.07 - lr: 0.006250
2022-03-28 00:17:52,732 epoch 28 - iter 40/107 - loss 0.04482682 - samples/sec: 122.16 - lr: 0.006250
2022-03-28 00:17:55,442 epoch 28 - iter 50/107 - loss 0.04509299 - samples/sec: 118.15 - lr: 0.006250
2022-03-28 00:17:58,177 epoch 28 - iter 60/107 - loss 0.04550039 - samples/sec: 117.04 - lr: 0.006250
2022-03-28 00:18:00,928 epoch 28 - iter 70/107 - loss 0.04501580 - samples/sec: 116.38 - lr: 0.006250
2022-03-28 00:18:03,578 epoch 28 - iter 80/107 - loss 0.04592510 - samples/sec: 120.76 - lr: 0.006250
2022-03-28 00:18:07,568 epoch 28 - iter 90/107 - loss 0.04503055 - samples/sec: 80.22 - lr: 0.006250
2022-03-28 00:18:10,152 epoch 28 - iter 100/107 - loss 0.04493402 - samples/sec: 123.90 - lr: 0.006250
2022-03-28 00:18:11,811 ----------------------------------------------------------------------------------------------------
2022-03-28 00:18:11,811 EPOCH 28 done: loss 0.0445 - lr 0.006250
2022-03-28 00:18:20,284 Evaluating as a multi-label problem: False
2022-03-28 00:18:20,295 DEV : loss 0.20573914051055908 - f1-score (micro avg)  0.5074
2022-03-28 00:18:20,369 BAD EPOCHS (no improvement): 1
2022-03-28 00:18:20,372 ----------------------------------------------------------------------------------------------------
2022-03-28 00:18:22,851 epoch 29 - iter 10/107 - loss 0.04851687 - samples/sec: 129.18 - lr: 0.006250
2022-03-28 00:18:25,371 epoch 29 - iter 20/107 - loss 0.04575611 - samples/sec: 127.06 - lr: 0.006250
2022-03-28 00:18:27,732 epoch 29 - iter 30/107 - loss 0.04589785 - samples/sec: 135.62 - lr: 0.006250
2022-03-28 00:18:30,156 epoch 29 - iter 40/107 - loss 0.04564570 - samples/sec: 132.05 - lr: 0.006250
2022-03-28 00:18:32,693 epoch 29 - iter 50/107 - loss 0.04542558 - samples/sec: 126.19 - lr: 0.006250
2022-03-28 00:18:35,312 epoch 29 - iter 60/107 - loss 0.04528267 - samples/sec: 122.20 - lr: 0.006250
2022-03-28 00:18:37,995 epoch 29 - iter 70/107 - loss 0.04496087 - samples/sec: 119.31 - lr: 0.006250
2022-03-28 00:18:40,728 epoch 29 - iter 80/107 - loss 0.04493744 - samples/sec: 117.15 - lr: 0.006250
2022-03-28 00:18:43,499 epoch 29 - iter 90/107 - loss 0.04472522 - samples/sec: 115.50 - lr: 0.006250
2022-03-28 00:18:46,327 epoch 29 - iter 100/107 - loss 0.04484389 - samples/sec: 113.20 - lr: 0.006250
2022-03-28 00:18:48,095 ----------------------------------------------------------------------------------------------------
2022-03-28 00:18:48,095 EPOCH 29 done: loss 0.0442 - lr 0.006250
2022-03-28 00:18:56,637 Evaluating as a multi-label problem: False
2022-03-28 00:18:56,647 DEV : loss 0.21316805481910706 - f1-score (micro avg)  0.5047
2022-03-28 00:18:56,719 BAD EPOCHS (no improvement): 2
2022-03-28 00:18:56,722 ----------------------------------------------------------------------------------------------------
2022-03-28 00:18:59,349 epoch 30 - iter 10/107 - loss 0.04261042 - samples/sec: 121.87 - lr: 0.006250
2022-03-28 00:19:01,969 epoch 30 - iter 20/107 - loss 0.04619547 - samples/sec: 122.17 - lr: 0.006250
2022-03-28 00:19:04,706 epoch 30 - iter 30/107 - loss 0.04239008 - samples/sec: 116.96 - lr: 0.006250
2022-03-28 00:19:07,431 epoch 30 - iter 40/107 - loss 0.04391513 - samples/sec: 117.50 - lr: 0.006250
2022-03-28 00:19:10,231 epoch 30 - iter 50/107 - loss 0.04324352 - samples/sec: 114.35 - lr: 0.006250
2022-03-28 00:19:13,093 epoch 30 - iter 60/107 - loss 0.04364051 - samples/sec: 111.85 - lr: 0.006250
2022-03-28 00:19:15,654 epoch 30 - iter 70/107 - loss 0.04381912 - samples/sec: 124.97 - lr: 0.006250
2022-03-28 00:19:18,053 epoch 30 - iter 80/107 - loss 0.04309521 - samples/sec: 133.47 - lr: 0.006250
2022-03-28 00:19:20,419 epoch 30 - iter 90/107 - loss 0.04365861 - samples/sec: 135.27 - lr: 0.006250
2022-03-28 00:19:22,904 epoch 30 - iter 100/107 - loss 0.04309283 - samples/sec: 128.84 - lr: 0.006250
2022-03-28 00:19:24,637 ----------------------------------------------------------------------------------------------------
2022-03-28 00:19:24,637 EPOCH 30 done: loss 0.0430 - lr 0.006250
2022-03-28 00:19:33,103 Evaluating as a multi-label problem: False
2022-03-28 00:19:33,114 DEV : loss 0.21272484958171844 - f1-score (micro avg)  0.5086
2022-03-28 00:19:33,188 BAD EPOCHS (no improvement): 3
2022-03-28 00:19:33,190 ----------------------------------------------------------------------------------------------------
2022-03-28 00:19:35,772 epoch 31 - iter 10/107 - loss 0.03659557 - samples/sec: 123.99 - lr: 0.006250
2022-03-28 00:19:38,545 epoch 31 - iter 20/107 - loss 0.03777335 - samples/sec: 115.45 - lr: 0.006250
2022-03-28 00:19:41,184 epoch 31 - iter 30/107 - loss 0.03969347 - samples/sec: 121.29 - lr: 0.006250
2022-03-28 00:19:43,958 epoch 31 - iter 40/107 - loss 0.04014687 - samples/sec: 115.42 - lr: 0.006250
2022-03-28 00:19:46,680 epoch 31 - iter 50/107 - loss 0.04002919 - samples/sec: 117.57 - lr: 0.006250
2022-03-28 00:19:49,237 epoch 31 - iter 60/107 - loss 0.04141630 - samples/sec: 125.21 - lr: 0.006250
2022-03-28 00:19:51,872 epoch 31 - iter 70/107 - loss 0.04256735 - samples/sec: 121.49 - lr: 0.006250
2022-03-28 00:19:54,936 epoch 31 - iter 80/107 - loss 0.04220876 - samples/sec: 104.51 - lr: 0.006250
2022-03-28 00:19:57,586 epoch 31 - iter 90/107 - loss 0.04245547 - samples/sec: 120.78 - lr: 0.006250
2022-03-28 00:20:00,302 epoch 31 - iter 100/107 - loss 0.04276056 - samples/sec: 117.90 - lr: 0.006250
2022-03-28 00:20:02,045 ----------------------------------------------------------------------------------------------------
2022-03-28 00:20:02,045 EPOCH 31 done: loss 0.0431 - lr 0.006250
2022-03-28 00:20:09,877 Evaluating as a multi-label problem: False
2022-03-28 00:20:09,888 DEV : loss 0.2066158801317215 - f1-score (micro avg)  0.5143
2022-03-28 00:20:09,965 Epoch    31: reducing learning rate of group 0 to 3.1250e-03.
2022-03-28 00:20:09,965 BAD EPOCHS (no improvement): 4
2022-03-28 00:20:09,968 ----------------------------------------------------------------------------------------------------
2022-03-28 00:20:12,536 epoch 32 - iter 10/107 - loss 0.04145034 - samples/sec: 124.65 - lr: 0.003125
2022-03-28 00:20:15,062 epoch 32 - iter 20/107 - loss 0.03980452 - samples/sec: 126.75 - lr: 0.003125
2022-03-28 00:20:17,612 epoch 32 - iter 30/107 - loss 0.04096467 - samples/sec: 125.51 - lr: 0.003125
2022-03-28 00:20:20,474 epoch 32 - iter 40/107 - loss 0.03959037 - samples/sec: 111.85 - lr: 0.003125
2022-03-28 00:20:23,230 epoch 32 - iter 50/107 - loss 0.03968622 - samples/sec: 116.15 - lr: 0.003125
2022-03-28 00:20:25,854 epoch 32 - iter 60/107 - loss 0.04053511 - samples/sec: 122.01 - lr: 0.003125
2022-03-28 00:20:28,472 epoch 32 - iter 70/107 - loss 0.04092180 - samples/sec: 122.28 - lr: 0.003125
2022-03-28 00:20:31,193 epoch 32 - iter 80/107 - loss 0.04019698 - samples/sec: 117.66 - lr: 0.003125
2022-03-28 00:20:33,769 epoch 32 - iter 90/107 - loss 0.04018698 - samples/sec: 124.25 - lr: 0.003125
2022-03-28 00:20:36,402 epoch 32 - iter 100/107 - loss 0.04113356 - samples/sec: 121.62 - lr: 0.003125
2022-03-28 00:20:38,004 ----------------------------------------------------------------------------------------------------
2022-03-28 00:20:38,004 EPOCH 32 done: loss 0.0422 - lr 0.003125
2022-03-28 00:20:46,563 Evaluating as a multi-label problem: False
2022-03-28 00:20:46,574 DEV : loss 0.20712251961231232 - f1-score (micro avg)  0.5136
2022-03-28 00:20:46,646 BAD EPOCHS (no improvement): 1
2022-03-28 00:20:46,648 ----------------------------------------------------------------------------------------------------
2022-03-28 00:20:49,286 epoch 33 - iter 10/107 - loss 0.05220571 - samples/sec: 121.36 - lr: 0.003125
2022-03-28 00:20:51,977 epoch 33 - iter 20/107 - loss 0.04162378 - samples/sec: 118.94 - lr: 0.003125
2022-03-28 00:20:54,631 epoch 33 - iter 30/107 - loss 0.04201829 - samples/sec: 120.63 - lr: 0.003125
2022-03-28 00:20:57,492 epoch 33 - iter 40/107 - loss 0.04427975 - samples/sec: 111.88 - lr: 0.003125
2022-03-28 00:21:00,006 epoch 33 - iter 50/107 - loss 0.04494259 - samples/sec: 127.36 - lr: 0.003125
2022-03-28 00:21:02,514 epoch 33 - iter 60/107 - loss 0.04470671 - samples/sec: 127.62 - lr: 0.003125
2022-03-28 00:21:04,864 epoch 33 - iter 70/107 - loss 0.04596031 - samples/sec: 136.25 - lr: 0.003125
2022-03-28 00:21:07,324 epoch 33 - iter 80/107 - loss 0.04476204 - samples/sec: 130.12 - lr: 0.003125
2022-03-28 00:21:09,777 epoch 33 - iter 90/107 - loss 0.04491732 - samples/sec: 130.53 - lr: 0.003125
2022-03-28 00:21:12,551 epoch 33 - iter 100/107 - loss 0.04392100 - samples/sec: 115.37 - lr: 0.003125
2022-03-28 00:21:14,234 ----------------------------------------------------------------------------------------------------
2022-03-28 00:21:14,234 EPOCH 33 done: loss 0.0437 - lr 0.003125
2022-03-28 00:21:22,780 Evaluating as a multi-label problem: False
2022-03-28 00:21:22,792 DEV : loss 0.20778758823871613 - f1-score (micro avg)  0.516
2022-03-28 00:21:22,866 BAD EPOCHS (no improvement): 2
2022-03-28 00:21:22,869 ----------------------------------------------------------------------------------------------------
2022-03-28 00:21:25,653 epoch 34 - iter 10/107 - loss 0.04666097 - samples/sec: 114.98 - lr: 0.003125
2022-03-28 00:21:28,406 epoch 34 - iter 20/107 - loss 0.04134101 - samples/sec: 116.32 - lr: 0.003125
2022-03-28 00:21:31,115 epoch 34 - iter 30/107 - loss 0.04327952 - samples/sec: 118.15 - lr: 0.003125
2022-03-28 00:21:33,888 epoch 34 - iter 40/107 - loss 0.04350287 - samples/sec: 115.46 - lr: 0.003125
2022-03-28 00:21:36,553 epoch 34 - iter 50/107 - loss 0.04348674 - samples/sec: 120.11 - lr: 0.003125
2022-03-28 00:21:39,137 epoch 34 - iter 60/107 - loss 0.04244323 - samples/sec: 123.90 - lr: 0.003125
2022-03-28 00:21:41,801 epoch 34 - iter 70/107 - loss 0.04199563 - samples/sec: 120.14 - lr: 0.003125
2022-03-28 00:21:44,564 epoch 34 - iter 80/107 - loss 0.04174832 - samples/sec: 115.85 - lr: 0.003125
2022-03-28 00:21:47,247 epoch 34 - iter 90/107 - loss 0.04210769 - samples/sec: 119.34 - lr: 0.003125
2022-03-28 00:21:50,039 epoch 34 - iter 100/107 - loss 0.04133854 - samples/sec: 114.64 - lr: 0.003125
2022-03-28 00:21:51,560 ----------------------------------------------------------------------------------------------------
2022-03-28 00:21:51,560 EPOCH 34 done: loss 0.0421 - lr 0.003125
2022-03-28 00:22:00,393 Evaluating as a multi-label problem: False
2022-03-28 00:22:00,404 DEV : loss 0.20895320177078247 - f1-score (micro avg)  0.5124
2022-03-28 00:22:00,475 BAD EPOCHS (no improvement): 3
2022-03-28 00:22:00,478 ----------------------------------------------------------------------------------------------------
2022-03-28 00:22:03,237 epoch 35 - iter 10/107 - loss 0.04129298 - samples/sec: 116.06 - lr: 0.003125
2022-03-28 00:22:05,897 epoch 35 - iter 20/107 - loss 0.04429677 - samples/sec: 120.38 - lr: 0.003125
2022-03-28 00:22:08,697 epoch 35 - iter 30/107 - loss 0.04268547 - samples/sec: 114.30 - lr: 0.003125
2022-03-28 00:22:11,239 epoch 35 - iter 40/107 - loss 0.04302568 - samples/sec: 125.98 - lr: 0.003125
2022-03-28 00:22:13,983 epoch 35 - iter 50/107 - loss 0.04208706 - samples/sec: 116.66 - lr: 0.003125
2022-03-28 00:22:16,680 epoch 35 - iter 60/107 - loss 0.04210306 - samples/sec: 118.67 - lr: 0.003125
2022-03-28 00:22:19,391 epoch 35 - iter 70/107 - loss 0.04229949 - samples/sec: 118.11 - lr: 0.003125
2022-03-28 00:22:22,123 epoch 35 - iter 80/107 - loss 0.04206116 - samples/sec: 117.14 - lr: 0.003125
2022-03-28 00:22:24,877 epoch 35 - iter 90/107 - loss 0.04173386 - samples/sec: 116.26 - lr: 0.003125
2022-03-28 00:22:27,680 epoch 35 - iter 100/107 - loss 0.04080010 - samples/sec: 114.18 - lr: 0.003125
2022-03-28 00:22:29,413 ----------------------------------------------------------------------------------------------------
2022-03-28 00:22:29,413 EPOCH 35 done: loss 0.0412 - lr 0.003125
2022-03-28 00:22:37,946 Evaluating as a multi-label problem: False
2022-03-28 00:22:37,957 DEV : loss 0.20901191234588623 - f1-score (micro avg)  0.5121
2022-03-28 00:22:38,031 Epoch    35: reducing learning rate of group 0 to 1.5625e-03.
2022-03-28 00:22:38,031 BAD EPOCHS (no improvement): 4
2022-03-28 00:22:38,035 ----------------------------------------------------------------------------------------------------
2022-03-28 00:22:40,632 epoch 36 - iter 10/107 - loss 0.04233613 - samples/sec: 123.29 - lr: 0.001563
2022-03-28 00:22:43,149 epoch 36 - iter 20/107 - loss 0.04516261 - samples/sec: 127.19 - lr: 0.001563
2022-03-28 00:22:45,656 epoch 36 - iter 30/107 - loss 0.04342008 - samples/sec: 127.65 - lr: 0.001563
2022-03-28 00:22:47,994 epoch 36 - iter 40/107 - loss 0.04084026 - samples/sec: 136.98 - lr: 0.001563
2022-03-28 00:22:50,375 epoch 36 - iter 50/107 - loss 0.03978684 - samples/sec: 134.45 - lr: 0.001563
2022-03-28 00:22:52,887 epoch 36 - iter 60/107 - loss 0.04036112 - samples/sec: 127.45 - lr: 0.001563
2022-03-28 00:22:55,721 epoch 36 - iter 70/107 - loss 0.04046934 - samples/sec: 112.98 - lr: 0.001563
2022-03-28 00:22:58,434 epoch 36 - iter 80/107 - loss 0.03990331 - samples/sec: 117.98 - lr: 0.001563
2022-03-28 00:23:01,151 epoch 36 - iter 90/107 - loss 0.04079389 - samples/sec: 117.81 - lr: 0.001563
2022-03-28 00:23:03,973 epoch 36 - iter 100/107 - loss 0.04052004 - samples/sec: 113.43 - lr: 0.001563
2022-03-28 00:23:05,635 ----------------------------------------------------------------------------------------------------
2022-03-28 00:23:05,635 EPOCH 36 done: loss 0.0405 - lr 0.001563
2022-03-28 00:23:14,315 Evaluating as a multi-label problem: False
2022-03-28 00:23:14,326 DEV : loss 0.21029582619667053 - f1-score (micro avg)  0.5113
2022-03-28 00:23:14,403 BAD EPOCHS (no improvement): 1
2022-03-28 00:23:14,406 ----------------------------------------------------------------------------------------------------
2022-03-28 00:23:17,223 epoch 37 - iter 10/107 - loss 0.04330328 - samples/sec: 113.65 - lr: 0.001563
2022-03-28 00:23:19,993 epoch 37 - iter 20/107 - loss 0.04248931 - samples/sec: 115.55 - lr: 0.001563
2022-03-28 00:23:22,754 epoch 37 - iter 30/107 - loss 0.04311167 - samples/sec: 115.93 - lr: 0.001563
2022-03-28 00:23:25,336 epoch 37 - iter 40/107 - loss 0.04230753 - samples/sec: 123.99 - lr: 0.001563
2022-03-28 00:23:27,978 epoch 37 - iter 50/107 - loss 0.04126150 - samples/sec: 121.18 - lr: 0.001563
2022-03-28 00:23:30,704 epoch 37 - iter 60/107 - loss 0.04138981 - samples/sec: 117.42 - lr: 0.001563
2022-03-28 00:23:33,319 epoch 37 - iter 70/107 - loss 0.04153933 - samples/sec: 122.44 - lr: 0.001563
2022-03-28 00:23:35,889 epoch 37 - iter 80/107 - loss 0.04107345 - samples/sec: 124.54 - lr: 0.001563
2022-03-28 00:23:38,477 epoch 37 - iter 90/107 - loss 0.04141379 - samples/sec: 123.74 - lr: 0.001563
2022-03-28 00:23:40,975 epoch 37 - iter 100/107 - loss 0.04152071 - samples/sec: 128.15 - lr: 0.001563
2022-03-28 00:23:42,419 ----------------------------------------------------------------------------------------------------
2022-03-28 00:23:42,419 EPOCH 37 done: loss 0.0419 - lr 0.001563
2022-03-28 00:23:50,632 Evaluating as a multi-label problem: False
2022-03-28 00:23:50,643 DEV : loss 0.2070474773645401 - f1-score (micro avg)  0.5132
2022-03-28 00:23:50,716 BAD EPOCHS (no improvement): 2
2022-03-28 00:23:50,719 ----------------------------------------------------------------------------------------------------
2022-03-28 00:23:53,436 epoch 38 - iter 10/107 - loss 0.04417791 - samples/sec: 117.85 - lr: 0.001563
2022-03-28 00:23:56,136 epoch 38 - iter 20/107 - loss 0.04354031 - samples/sec: 118.55 - lr: 0.001563
2022-03-28 00:23:58,904 epoch 38 - iter 30/107 - loss 0.04475762 - samples/sec: 115.65 - lr: 0.001563
2022-03-28 00:24:01,755 epoch 38 - iter 40/107 - loss 0.04214966 - samples/sec: 112.30 - lr: 0.001563
2022-03-28 00:24:04,387 epoch 38 - iter 50/107 - loss 0.04016178 - samples/sec: 121.60 - lr: 0.001563
2022-03-28 00:24:07,015 epoch 38 - iter 60/107 - loss 0.04053933 - samples/sec: 121.84 - lr: 0.001563
2022-03-28 00:24:09,776 epoch 38 - iter 70/107 - loss 0.04027898 - samples/sec: 115.91 - lr: 0.001563
2022-03-28 00:24:12,469 epoch 38 - iter 80/107 - loss 0.04018974 - samples/sec: 118.91 - lr: 0.001563
2022-03-28 00:24:15,246 epoch 38 - iter 90/107 - loss 0.04043549 - samples/sec: 115.26 - lr: 0.001563
2022-03-28 00:24:18,120 epoch 38 - iter 100/107 - loss 0.04140287 - samples/sec: 111.37 - lr: 0.001563
2022-03-28 00:24:19,842 ----------------------------------------------------------------------------------------------------
2022-03-28 00:24:19,842 EPOCH 38 done: loss 0.0411 - lr 0.001563
2022-03-28 00:24:27,883 Evaluating as a multi-label problem: False
2022-03-28 00:24:27,894 DEV : loss 0.20814573764801025 - f1-score (micro avg)  0.5136
2022-03-28 00:24:27,968 BAD EPOCHS (no improvement): 3
2022-03-28 00:24:27,971 ----------------------------------------------------------------------------------------------------
2022-03-28 00:24:30,354 epoch 39 - iter 10/107 - loss 0.04279372 - samples/sec: 134.36 - lr: 0.001563
2022-03-28 00:24:32,697 epoch 39 - iter 20/107 - loss 0.03794348 - samples/sec: 136.63 - lr: 0.001563
2022-03-28 00:24:35,195 epoch 39 - iter 30/107 - loss 0.04007061 - samples/sec: 128.16 - lr: 0.001563
2022-03-28 00:24:37,432 epoch 39 - iter 40/107 - loss 0.04076532 - samples/sec: 143.13 - lr: 0.001563
2022-03-28 00:24:39,199 epoch 39 - iter 50/107 - loss 0.04024091 - samples/sec: 181.15 - lr: 0.001563
2022-03-28 00:24:41,055 epoch 39 - iter 60/107 - loss 0.04045385 - samples/sec: 172.55 - lr: 0.001563
2022-03-28 00:24:43,197 epoch 39 - iter 70/107 - loss 0.04129560 - samples/sec: 149.45 - lr: 0.001563
2022-03-28 00:24:45,972 epoch 39 - iter 80/107 - loss 0.04180894 - samples/sec: 115.37 - lr: 0.001563
2022-03-28 00:24:48,726 epoch 39 - iter 90/107 - loss 0.04144854 - samples/sec: 116.24 - lr: 0.001563
2022-03-28 00:24:51,627 epoch 39 - iter 100/107 - loss 0.04139541 - samples/sec: 110.34 - lr: 0.001563
2022-03-28 00:24:53,306 ----------------------------------------------------------------------------------------------------
2022-03-28 00:24:53,306 EPOCH 39 done: loss 0.0413 - lr 0.001563
2022-03-28 00:25:01,804 Evaluating as a multi-label problem: False
2022-03-28 00:25:01,815 DEV : loss 0.2098938226699829 - f1-score (micro avg)  0.5121
2022-03-28 00:25:01,888 Epoch    39: reducing learning rate of group 0 to 7.8125e-04.
2022-03-28 00:25:01,888 BAD EPOCHS (no improvement): 4
2022-03-28 00:25:01,890 ----------------------------------------------------------------------------------------------------
2022-03-28 00:25:04,588 epoch 40 - iter 10/107 - loss 0.04430676 - samples/sec: 118.68 - lr: 0.000781
2022-03-28 00:25:07,273 epoch 40 - iter 20/107 - loss 0.03956360 - samples/sec: 119.24 - lr: 0.000781
2022-03-28 00:25:10,081 epoch 40 - iter 30/107 - loss 0.04013263 - samples/sec: 113.99 - lr: 0.000781
2022-03-28 00:25:12,792 epoch 40 - iter 40/107 - loss 0.03933250 - samples/sec: 118.08 - lr: 0.000781
2022-03-28 00:25:15,540 epoch 40 - iter 50/107 - loss 0.03950398 - samples/sec: 116.50 - lr: 0.000781
2022-03-28 00:25:18,336 epoch 40 - iter 60/107 - loss 0.04035140 - samples/sec: 114.50 - lr: 0.000781
2022-03-28 00:25:21,057 epoch 40 - iter 70/107 - loss 0.04033417 - samples/sec: 117.66 - lr: 0.000781
2022-03-28 00:25:23,300 epoch 40 - iter 80/107 - loss 0.04029867 - samples/sec: 142.69 - lr: 0.000781
2022-03-28 00:25:25,910 epoch 40 - iter 90/107 - loss 0.03974758 - samples/sec: 122.68 - lr: 0.000781
2022-03-28 00:25:28,305 epoch 40 - iter 100/107 - loss 0.04039663 - samples/sec: 133.62 - lr: 0.000781
2022-03-28 00:25:29,942 ----------------------------------------------------------------------------------------------------
2022-03-28 00:25:29,942 EPOCH 40 done: loss 0.0407 - lr 0.000781
2022-03-28 00:25:38,019 Evaluating as a multi-label problem: False
2022-03-28 00:25:38,030 DEV : loss 0.20951494574546814 - f1-score (micro avg)  0.5121
2022-03-28 00:25:38,103 BAD EPOCHS (no improvement): 1
2022-03-28 00:25:38,169 ----------------------------------------------------------------------------------------------------
2022-03-28 00:25:40,874 epoch 41 - iter 10/107 - loss 0.03242598 - samples/sec: 118.34 - lr: 0.000781
2022-03-28 00:25:43,538 epoch 41 - iter 20/107 - loss 0.03709954 - samples/sec: 120.15 - lr: 0.000781
2022-03-28 00:25:46,262 epoch 41 - iter 30/107 - loss 0.04126191 - samples/sec: 117.51 - lr: 0.000781
2022-03-28 00:25:49,010 epoch 41 - iter 40/107 - loss 0.04129861 - samples/sec: 116.51 - lr: 0.000781
2022-03-28 00:25:51,670 epoch 41 - iter 50/107 - loss 0.04240305 - samples/sec: 120.36 - lr: 0.000781
2022-03-28 00:25:54,544 epoch 41 - iter 60/107 - loss 0.04329148 - samples/sec: 111.37 - lr: 0.000781
2022-03-28 00:25:57,192 epoch 41 - iter 70/107 - loss 0.04305848 - samples/sec: 120.93 - lr: 0.000781
2022-03-28 00:26:00,088 epoch 41 - iter 80/107 - loss 0.04295262 - samples/sec: 110.54 - lr: 0.000781
2022-03-28 00:26:02,728 epoch 41 - iter 90/107 - loss 0.04306712 - samples/sec: 121.25 - lr: 0.000781
2022-03-28 00:26:05,532 epoch 41 - iter 100/107 - loss 0.04256491 - samples/sec: 114.18 - lr: 0.000781
2022-03-28 00:26:07,246 ----------------------------------------------------------------------------------------------------
2022-03-28 00:26:07,246 EPOCH 41 done: loss 0.0428 - lr 0.000781
2022-03-28 00:26:16,797 Evaluating as a multi-label problem: False
2022-03-28 00:26:16,807 DEV : loss 0.2078719586133957 - f1-score (micro avg)  0.5144
2022-03-28 00:26:16,881 BAD EPOCHS (no improvement): 2
2022-03-28 00:26:16,883 ----------------------------------------------------------------------------------------------------
2022-03-28 00:26:19,325 epoch 42 - iter 10/107 - loss 0.04399142 - samples/sec: 131.14 - lr: 0.000781
2022-03-28 00:26:21,824 epoch 42 - iter 20/107 - loss 0.04398224 - samples/sec: 128.07 - lr: 0.000781
2022-03-28 00:26:24,198 epoch 42 - iter 30/107 - loss 0.04295562 - samples/sec: 134.87 - lr: 0.000781
2022-03-28 00:26:26,781 epoch 42 - iter 40/107 - loss 0.04515470 - samples/sec: 123.91 - lr: 0.000781
2022-03-28 00:26:29,594 epoch 42 - iter 50/107 - loss 0.04515577 - samples/sec: 113.83 - lr: 0.000781
2022-03-28 00:26:32,301 epoch 42 - iter 60/107 - loss 0.04266764 - samples/sec: 118.22 - lr: 0.000781
2022-03-28 00:26:35,016 epoch 42 - iter 70/107 - loss 0.04184325 - samples/sec: 117.96 - lr: 0.000781
2022-03-28 00:26:37,731 epoch 42 - iter 80/107 - loss 0.04182119 - samples/sec: 117.91 - lr: 0.000781
2022-03-28 00:26:40,500 epoch 42 - iter 90/107 - loss 0.04209526 - samples/sec: 115.62 - lr: 0.000781
2022-03-28 00:26:43,284 epoch 42 - iter 100/107 - loss 0.04096830 - samples/sec: 114.95 - lr: 0.000781
2022-03-28 00:26:45,068 ----------------------------------------------------------------------------------------------------
2022-03-28 00:26:45,068 EPOCH 42 done: loss 0.0407 - lr 0.000781
2022-03-28 00:26:53,663 Evaluating as a multi-label problem: False
2022-03-28 00:26:53,674 DEV : loss 0.20881663262844086 - f1-score (micro avg)  0.5124
2022-03-28 00:26:53,747 BAD EPOCHS (no improvement): 3
2022-03-28 00:26:53,750 ----------------------------------------------------------------------------------------------------
2022-03-28 00:26:56,511 epoch 43 - iter 10/107 - loss 0.03394265 - samples/sec: 115.95 - lr: 0.000781
2022-03-28 00:26:59,245 epoch 43 - iter 20/107 - loss 0.03667503 - samples/sec: 117.08 - lr: 0.000781
2022-03-28 00:27:02,093 epoch 43 - iter 30/107 - loss 0.03813232 - samples/sec: 112.40 - lr: 0.000781
2022-03-28 00:27:04,832 epoch 43 - iter 40/107 - loss 0.04068505 - samples/sec: 116.86 - lr: 0.000781
2022-03-28 00:27:07,372 epoch 43 - iter 50/107 - loss 0.03912753 - samples/sec: 126.03 - lr: 0.000781
2022-03-28 00:27:09,963 epoch 43 - iter 60/107 - loss 0.03919183 - samples/sec: 123.55 - lr: 0.000781
2022-03-28 00:27:12,418 epoch 43 - iter 70/107 - loss 0.03997361 - samples/sec: 130.38 - lr: 0.000781
2022-03-28 00:27:14,927 epoch 43 - iter 80/107 - loss 0.04072999 - samples/sec: 127.60 - lr: 0.000781
2022-03-28 00:27:17,447 epoch 43 - iter 90/107 - loss 0.04170273 - samples/sec: 127.04 - lr: 0.000781
2022-03-28 00:27:19,980 epoch 43 - iter 100/107 - loss 0.04178766 - samples/sec: 126.39 - lr: 0.000781
2022-03-28 00:27:21,707 ----------------------------------------------------------------------------------------------------
2022-03-28 00:27:21,707 EPOCH 43 done: loss 0.0418 - lr 0.000781
2022-03-28 00:27:30,339 Evaluating as a multi-label problem: False
2022-03-28 00:27:30,350 DEV : loss 0.20670457184314728 - f1-score (micro avg)  0.5155
2022-03-28 00:27:30,424 Epoch    43: reducing learning rate of group 0 to 3.9063e-04.
2022-03-28 00:27:30,424 BAD EPOCHS (no improvement): 4
2022-03-28 00:27:30,427 ----------------------------------------------------------------------------------------------------
2022-03-28 00:27:33,151 epoch 44 - iter 10/107 - loss 0.04591970 - samples/sec: 117.57 - lr: 0.000391
2022-03-28 00:27:35,823 epoch 44 - iter 20/107 - loss 0.04439564 - samples/sec: 119.80 - lr: 0.000391
2022-03-28 00:27:38,624 epoch 44 - iter 30/107 - loss 0.04110084 - samples/sec: 114.26 - lr: 0.000391
2022-03-28 00:27:41,426 epoch 44 - iter 40/107 - loss 0.04166598 - samples/sec: 114.24 - lr: 0.000391
2022-03-28 00:27:44,269 epoch 44 - iter 50/107 - loss 0.04290919 - samples/sec: 112.63 - lr: 0.000391
2022-03-28 00:27:47,127 epoch 44 - iter 60/107 - loss 0.04122956 - samples/sec: 111.98 - lr: 0.000391
2022-03-28 00:27:49,754 epoch 44 - iter 70/107 - loss 0.04066333 - samples/sec: 121.87 - lr: 0.000391
2022-03-28 00:27:52,453 epoch 44 - iter 80/107 - loss 0.04207624 - samples/sec: 118.62 - lr: 0.000391
2022-03-28 00:27:55,049 epoch 44 - iter 90/107 - loss 0.04206394 - samples/sec: 123.31 - lr: 0.000391
2022-03-28 00:27:57,807 epoch 44 - iter 100/107 - loss 0.04228542 - samples/sec: 116.05 - lr: 0.000391
2022-03-28 00:27:59,467 ----------------------------------------------------------------------------------------------------
2022-03-28 00:27:59,467 EPOCH 44 done: loss 0.0418 - lr 0.000391
2022-03-28 00:28:06,879 Evaluating as a multi-label problem: False
2022-03-28 00:28:06,890 DEV : loss 0.20755644142627716 - f1-score (micro avg)  0.5136
2022-03-28 00:28:06,964 BAD EPOCHS (no improvement): 1
2022-03-28 00:28:06,967 ----------------------------------------------------------------------------------------------------
2022-03-28 00:28:09,431 epoch 45 - iter 10/107 - loss 0.04162903 - samples/sec: 129.97 - lr: 0.000391
2022-03-28 00:28:11,853 epoch 45 - iter 20/107 - loss 0.03992233 - samples/sec: 132.16 - lr: 0.000391
2022-03-28 00:28:14,735 epoch 45 - iter 30/107 - loss 0.04028461 - samples/sec: 111.09 - lr: 0.000391
2022-03-28 00:28:17,371 epoch 45 - iter 40/107 - loss 0.04031745 - samples/sec: 121.44 - lr: 0.000391
2022-03-28 00:28:20,062 epoch 45 - iter 50/107 - loss 0.04110521 - samples/sec: 118.96 - lr: 0.000391
2022-03-28 00:28:22,731 epoch 45 - iter 60/107 - loss 0.03940285 - samples/sec: 119.94 - lr: 0.000391
2022-03-28 00:28:25,462 epoch 45 - iter 70/107 - loss 0.04046787 - samples/sec: 117.23 - lr: 0.000391
2022-03-28 00:28:28,098 epoch 45 - iter 80/107 - loss 0.04083343 - samples/sec: 121.45 - lr: 0.000391
2022-03-28 00:28:30,768 epoch 45 - iter 90/107 - loss 0.04125725 - samples/sec: 119.85 - lr: 0.000391
2022-03-28 00:28:33,399 epoch 45 - iter 100/107 - loss 0.04067416 - samples/sec: 121.71 - lr: 0.000391
2022-03-28 00:28:35,021 ----------------------------------------------------------------------------------------------------
2022-03-28 00:28:35,021 EPOCH 45 done: loss 0.0403 - lr 0.000391
2022-03-28 00:28:43,513 Evaluating as a multi-label problem: False
2022-03-28 00:28:43,523 DEV : loss 0.20814646780490875 - f1-score (micro avg)  0.514
2022-03-28 00:28:43,597 BAD EPOCHS (no improvement): 2
2022-03-28 00:28:43,657 ----------------------------------------------------------------------------------------------------
2022-03-28 00:28:46,394 epoch 46 - iter 10/107 - loss 0.03916868 - samples/sec: 116.95 - lr: 0.000391
2022-03-28 00:28:49,052 epoch 46 - iter 20/107 - loss 0.03757168 - samples/sec: 120.43 - lr: 0.000391
2022-03-28 00:28:51,675 epoch 46 - iter 30/107 - loss 0.04058414 - samples/sec: 122.02 - lr: 0.000391
2022-03-28 00:28:54,136 epoch 46 - iter 40/107 - loss 0.04183255 - samples/sec: 130.11 - lr: 0.000391
2022-03-28 00:28:56,554 epoch 46 - iter 50/107 - loss 0.04083002 - samples/sec: 132.42 - lr: 0.000391
2022-03-28 00:28:58,867 epoch 46 - iter 60/107 - loss 0.04049954 - samples/sec: 138.42 - lr: 0.000391
2022-03-28 00:29:01,376 epoch 46 - iter 70/107 - loss 0.04133766 - samples/sec: 127.60 - lr: 0.000391
2022-03-28 00:29:03,909 epoch 46 - iter 80/107 - loss 0.04128634 - samples/sec: 126.37 - lr: 0.000391
2022-03-28 00:29:06,577 epoch 46 - iter 90/107 - loss 0.04003448 - samples/sec: 119.99 - lr: 0.000391
2022-03-28 00:29:09,594 epoch 46 - iter 100/107 - loss 0.03971103 - samples/sec: 106.11 - lr: 0.000391
2022-03-28 00:29:11,202 ----------------------------------------------------------------------------------------------------
2022-03-28 00:29:11,202 EPOCH 46 done: loss 0.0399 - lr 0.000391
2022-03-28 00:29:19,814 Evaluating as a multi-label problem: False
2022-03-28 00:29:19,825 DEV : loss 0.20835170149803162 - f1-score (micro avg)  0.514
2022-03-28 00:29:19,898 BAD EPOCHS (no improvement): 3
2022-03-28 00:29:19,901 ----------------------------------------------------------------------------------------------------
2022-03-28 00:29:22,644 epoch 47 - iter 10/107 - loss 0.03744990 - samples/sec: 116.72 - lr: 0.000391
2022-03-28 00:29:25,328 epoch 47 - iter 20/107 - loss 0.03928473 - samples/sec: 119.25 - lr: 0.000391
2022-03-28 00:29:28,201 epoch 47 - iter 30/107 - loss 0.04010823 - samples/sec: 111.42 - lr: 0.000391
2022-03-28 00:29:30,858 epoch 47 - iter 40/107 - loss 0.04081205 - samples/sec: 120.50 - lr: 0.000391
2022-03-28 00:29:33,581 epoch 47 - iter 50/107 - loss 0.03994131 - samples/sec: 117.55 - lr: 0.000391
2022-03-28 00:29:36,360 epoch 47 - iter 60/107 - loss 0.04119042 - samples/sec: 115.20 - lr: 0.000391
2022-03-28 00:29:38,825 epoch 47 - iter 70/107 - loss 0.04012635 - samples/sec: 129.84 - lr: 0.000391
2022-03-28 00:29:41,486 epoch 47 - iter 80/107 - loss 0.04083999 - samples/sec: 120.33 - lr: 0.000391
2022-03-28 00:29:44,336 epoch 47 - iter 90/107 - loss 0.04063177 - samples/sec: 112.33 - lr: 0.000391
2022-03-28 00:29:46,756 epoch 47 - iter 100/107 - loss 0.04085857 - samples/sec: 132.24 - lr: 0.000391
2022-03-28 00:29:48,252 ----------------------------------------------------------------------------------------------------
2022-03-28 00:29:48,253 EPOCH 47 done: loss 0.0407 - lr 0.000391
2022-03-28 00:29:55,586 Evaluating as a multi-label problem: False
2022-03-28 00:29:55,597 DEV : loss 0.2093004584312439 - f1-score (micro avg)  0.5136
2022-03-28 00:29:55,670 Epoch    47: reducing learning rate of group 0 to 1.9531e-04.
2022-03-28 00:29:55,670 BAD EPOCHS (no improvement): 4
2022-03-28 00:29:55,724 ----------------------------------------------------------------------------------------------------
2022-03-28 00:29:58,332 epoch 48 - iter 10/107 - loss 0.03844556 - samples/sec: 122.77 - lr: 0.000195
2022-03-28 00:30:01,060 epoch 48 - iter 20/107 - loss 0.04236391 - samples/sec: 117.32 - lr: 0.000195
2022-03-28 00:30:03,808 epoch 48 - iter 30/107 - loss 0.04024600 - samples/sec: 116.51 - lr: 0.000195
2022-03-28 00:30:06,531 epoch 48 - iter 40/107 - loss 0.04170131 - samples/sec: 117.54 - lr: 0.000195
2022-03-28 00:30:09,227 epoch 48 - iter 50/107 - loss 0.04021705 - samples/sec: 118.73 - lr: 0.000195
2022-03-28 00:30:13,011 epoch 48 - iter 60/107 - loss 0.04120633 - samples/sec: 84.59 - lr: 0.000195
2022-03-28 00:30:15,713 epoch 48 - iter 70/107 - loss 0.04024872 - samples/sec: 118.49 - lr: 0.000195
2022-03-28 00:30:18,444 epoch 48 - iter 80/107 - loss 0.04117131 - samples/sec: 117.20 - lr: 0.000195
2022-03-28 00:30:21,085 epoch 48 - iter 90/107 - loss 0.04150638 - samples/sec: 121.23 - lr: 0.000195
2022-03-28 00:30:23,858 epoch 48 - iter 100/107 - loss 0.04022423 - samples/sec: 115.43 - lr: 0.000195
2022-03-28 00:30:25,591 ----------------------------------------------------------------------------------------------------
2022-03-28 00:30:25,591 EPOCH 48 done: loss 0.0404 - lr 0.000195
2022-03-28 00:30:33,989 Evaluating as a multi-label problem: False
2022-03-28 00:30:34,000 DEV : loss 0.20914310216903687 - f1-score (micro avg)  0.5148
2022-03-28 00:30:34,072 BAD EPOCHS (no improvement): 1
2022-03-28 00:30:34,075 ----------------------------------------------------------------------------------------------------
2022-03-28 00:30:36,657 epoch 49 - iter 10/107 - loss 0.04070111 - samples/sec: 123.98 - lr: 0.000195
2022-03-28 00:30:39,231 epoch 49 - iter 20/107 - loss 0.03974041 - samples/sec: 124.38 - lr: 0.000195
2022-03-28 00:30:41,639 epoch 49 - iter 30/107 - loss 0.03809043 - samples/sec: 132.97 - lr: 0.000195
2022-03-28 00:30:44,040 epoch 49 - iter 40/107 - loss 0.03785871 - samples/sec: 133.33 - lr: 0.000195
2022-03-28 00:30:46,591 epoch 49 - iter 50/107 - loss 0.03864765 - samples/sec: 125.46 - lr: 0.000195
2022-03-28 00:30:49,290 epoch 49 - iter 60/107 - loss 0.03757243 - samples/sec: 118.60 - lr: 0.000195
2022-03-28 00:30:51,948 epoch 49 - iter 70/107 - loss 0.03684135 - samples/sec: 120.47 - lr: 0.000195
2022-03-28 00:30:54,542 epoch 49 - iter 80/107 - loss 0.03798293 - samples/sec: 123.41 - lr: 0.000195
2022-03-28 00:30:57,211 epoch 49 - iter 90/107 - loss 0.03969273 - samples/sec: 119.94 - lr: 0.000195
2022-03-28 00:30:59,994 epoch 49 - iter 100/107 - loss 0.03961471 - samples/sec: 115.01 - lr: 0.000195
2022-03-28 00:31:01,600 ----------------------------------------------------------------------------------------------------
2022-03-28 00:31:01,600 EPOCH 49 done: loss 0.0397 - lr 0.000195
2022-03-28 00:31:10,206 Evaluating as a multi-label problem: False
2022-03-28 00:31:10,217 DEV : loss 0.20928414165973663 - f1-score (micro avg)  0.5148
2022-03-28 00:31:10,292 BAD EPOCHS (no improvement): 2
2022-03-28 00:31:10,294 ----------------------------------------------------------------------------------------------------
2022-03-28 00:31:12,907 epoch 50 - iter 10/107 - loss 0.03610471 - samples/sec: 122.53 - lr: 0.000195
2022-03-28 00:31:15,750 epoch 50 - iter 20/107 - loss 0.03635440 - samples/sec: 112.62 - lr: 0.000195
2022-03-28 00:31:18,613 epoch 50 - iter 30/107 - loss 0.03638027 - samples/sec: 111.83 - lr: 0.000195
2022-03-28 00:31:21,351 epoch 50 - iter 40/107 - loss 0.03808952 - samples/sec: 116.90 - lr: 0.000195
2022-03-28 00:31:23,951 epoch 50 - iter 50/107 - loss 0.03974624 - samples/sec: 123.13 - lr: 0.000195
2022-03-28 00:31:26,667 epoch 50 - iter 60/107 - loss 0.03987040 - samples/sec: 117.87 - lr: 0.000195
2022-03-28 00:31:29,285 epoch 50 - iter 70/107 - loss 0.04214765 - samples/sec: 122.28 - lr: 0.000195
2022-03-28 00:31:31,947 epoch 50 - iter 80/107 - loss 0.04241740 - samples/sec: 120.24 - lr: 0.000195
2022-03-28 00:31:34,288 epoch 50 - iter 90/107 - loss 0.04311041 - samples/sec: 136.74 - lr: 0.000195
2022-03-28 00:31:36,793 epoch 50 - iter 100/107 - loss 0.04244169 - samples/sec: 127.82 - lr: 0.000195
2022-03-28 00:31:38,333 ----------------------------------------------------------------------------------------------------
2022-03-28 00:31:38,333 EPOCH 50 done: loss 0.0418 - lr 0.000195
2022-03-28 00:31:46,494 Evaluating as a multi-label problem: False
2022-03-28 00:31:46,505 DEV : loss 0.20906516909599304 - f1-score (micro avg)  0.5148
2022-03-28 00:31:46,579 BAD EPOCHS (no improvement): 3
2022-03-28 00:31:46,581 ----------------------------------------------------------------------------------------------------
2022-03-28 00:31:49,147 epoch 51 - iter 10/107 - loss 0.05267380 - samples/sec: 124.81 - lr: 0.000195
2022-03-28 00:31:52,006 epoch 51 - iter 20/107 - loss 0.04437478 - samples/sec: 111.95 - lr: 0.000195
2022-03-28 00:31:54,801 epoch 51 - iter 30/107 - loss 0.04409243 - samples/sec: 114.52 - lr: 0.000195
2022-03-28 00:31:57,607 epoch 51 - iter 40/107 - loss 0.04220477 - samples/sec: 114.08 - lr: 0.000195
2022-03-28 00:32:00,271 epoch 51 - iter 50/107 - loss 0.04036700 - samples/sec: 120.19 - lr: 0.000195
2022-03-28 00:32:03,007 epoch 51 - iter 60/107 - loss 0.04055530 - samples/sec: 116.99 - lr: 0.000195
2022-03-28 00:32:05,788 epoch 51 - iter 70/107 - loss 0.04087168 - samples/sec: 115.14 - lr: 0.000195
2022-03-28 00:32:08,488 epoch 51 - iter 80/107 - loss 0.04178600 - samples/sec: 118.56 - lr: 0.000195
2022-03-28 00:32:11,124 epoch 51 - iter 90/107 - loss 0.04197589 - samples/sec: 121.43 - lr: 0.000195
2022-03-28 00:32:13,842 epoch 51 - iter 100/107 - loss 0.04170962 - samples/sec: 117.80 - lr: 0.000195
2022-03-28 00:32:15,500 ----------------------------------------------------------------------------------------------------
2022-03-28 00:32:15,500 EPOCH 51 done: loss 0.0415 - lr 0.000195
2022-03-28 00:32:23,459 Evaluating as a multi-label problem: False
2022-03-28 00:32:23,471 DEV : loss 0.208711177110672 - f1-score (micro avg)  0.5136
2022-03-28 00:32:23,545 Epoch    51: reducing learning rate of group 0 to 9.7656e-05.
2022-03-28 00:32:23,545 BAD EPOCHS (no improvement): 4
2022-03-28 00:32:23,548 ----------------------------------------------------------------------------------------------------
2022-03-28 00:32:23,548 ----------------------------------------------------------------------------------------------------
2022-03-28 00:32:23,548 learning rate too small - quitting training!
2022-03-28 00:32:23,548 ----------------------------------------------------------------------------------------------------
2022-03-28 00:32:37,852 ----------------------------------------------------------------------------------------------------
2022-03-28 00:32:37,860 loading file resources/taggers/model_05_r5_run_3/best-model.pt
2022-03-28 00:32:52,769 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-03-28 00:33:09,719 Evaluating as a multi-label problem: False
2022-03-28 00:33:09,731 0.6627	0.3077	0.4203	0.2818
2022-03-28 00:33:09,731 
Results:
- F-score (micro) 0.4203
- F-score (macro) 0.2985
- Accuracy 0.2818

By class:
               precision    recall  f1-score   support

       person     0.7743    0.4639    0.5802       429
     location     0.6090    0.5400    0.5724       150
        group     0.5000    0.1636    0.2466       165
creative-work     0.5357    0.1056    0.1765       142
      product     0.2222    0.0157    0.0294       127
  corporation     0.4000    0.1212    0.1860        66

    micro avg     0.6627    0.3077    0.4203      1079
    macro avg     0.5069    0.2350    0.2985      1079
 weighted avg     0.5901    0.3077    0.3860      1079

2022-03-28 00:33:09,732 ----------------------------------------------------------------------------------------------------
