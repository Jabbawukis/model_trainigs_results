2022-03-26 23:08:02,046 ----------------------------------------------------------------------------------------------------
2022-03-26 23:08:02,046 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4262, out_features=4262, bias=True)
  (rnn): LSTM(4262, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-03-26 23:08:02,046 ----------------------------------------------------------------------------------------------------
2022-03-26 23:08:02,046 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-03-26 23:08:02,046 ----------------------------------------------------------------------------------------------------
2022-03-26 23:08:02,046 Parameters:
2022-03-26 23:08:02,047  - learning_rate: "0.100000"
2022-03-26 23:08:02,047  - mini_batch_size: "32"
2022-03-26 23:08:02,047  - patience: "3"
2022-03-26 23:08:02,047  - anneal_factor: "0.5"
2022-03-26 23:08:02,047  - max_epochs: "150"
2022-03-26 23:08:02,047  - shuffle: "True"
2022-03-26 23:08:02,047  - train_with_dev: "False"
2022-03-26 23:08:02,047  - batch_growth_annealing: "False"
2022-03-26 23:08:02,047 ----------------------------------------------------------------------------------------------------
2022-03-26 23:08:02,047 Model training base path: "resources/taggers/model_04_r5_run_3"
2022-03-26 23:08:02,047 ----------------------------------------------------------------------------------------------------
2022-03-26 23:08:02,047 Device: cuda:0
2022-03-26 23:08:02,047 ----------------------------------------------------------------------------------------------------
2022-03-26 23:08:02,047 Embeddings storage mode: cpu
2022-03-26 23:08:02,047 ----------------------------------------------------------------------------------------------------
2022-03-26 23:08:03,610 epoch 1 - iter 10/107 - loss 0.63032186 - samples/sec: 204.89 - lr: 0.100000
2022-03-26 23:08:05,244 epoch 1 - iter 20/107 - loss 0.45037273 - samples/sec: 196.00 - lr: 0.100000
2022-03-26 23:08:06,927 epoch 1 - iter 30/107 - loss 0.39095247 - samples/sec: 190.25 - lr: 0.100000
2022-03-26 23:08:08,581 epoch 1 - iter 40/107 - loss 0.35475350 - samples/sec: 193.52 - lr: 0.100000
2022-03-26 23:08:10,253 epoch 1 - iter 50/107 - loss 0.32580782 - samples/sec: 191.52 - lr: 0.100000
2022-03-26 23:08:11,892 epoch 1 - iter 60/107 - loss 0.31877231 - samples/sec: 195.33 - lr: 0.100000
2022-03-26 23:08:13,535 epoch 1 - iter 70/107 - loss 0.31093136 - samples/sec: 194.95 - lr: 0.100000
2022-03-26 23:08:15,022 epoch 1 - iter 80/107 - loss 0.30986382 - samples/sec: 215.30 - lr: 0.100000
2022-03-26 23:08:16,320 epoch 1 - iter 90/107 - loss 0.30888454 - samples/sec: 246.70 - lr: 0.100000
2022-03-26 23:08:17,643 epoch 1 - iter 100/107 - loss 0.30575110 - samples/sec: 242.11 - lr: 0.100000
2022-03-26 23:08:18,467 ----------------------------------------------------------------------------------------------------
2022-03-26 23:08:18,467 EPOCH 1 done: loss 0.3010 - lr 0.100000
2022-03-26 23:08:24,009 Evaluating as a multi-label problem: False
2022-03-26 23:08:24,019 DEV : loss 0.43891316652297974 - f1-score (micro avg)  0.1789
2022-03-26 23:08:24,094 BAD EPOCHS (no improvement): 0
2022-03-26 23:08:24,097 saving best model
2022-03-26 23:08:48,283 ----------------------------------------------------------------------------------------------------
2022-03-26 23:08:50,092 epoch 2 - iter 10/107 - loss 0.18370959 - samples/sec: 177.04 - lr: 0.100000
2022-03-26 23:08:51,758 epoch 2 - iter 20/107 - loss 0.18882127 - samples/sec: 192.20 - lr: 0.100000
2022-03-26 23:08:53,309 epoch 2 - iter 30/107 - loss 0.19247502 - samples/sec: 206.51 - lr: 0.100000
2022-03-26 23:08:54,857 epoch 2 - iter 40/107 - loss 0.20038054 - samples/sec: 206.78 - lr: 0.100000
2022-03-26 23:08:56,415 epoch 2 - iter 50/107 - loss 0.19365144 - samples/sec: 205.56 - lr: 0.100000
2022-03-26 23:08:57,978 epoch 2 - iter 60/107 - loss 0.19853310 - samples/sec: 204.80 - lr: 0.100000
2022-03-26 23:08:59,515 epoch 2 - iter 70/107 - loss 0.19718549 - samples/sec: 208.43 - lr: 0.100000
2022-03-26 23:09:01,080 epoch 2 - iter 80/107 - loss 0.19565432 - samples/sec: 204.58 - lr: 0.100000
2022-03-26 23:09:02,667 epoch 2 - iter 90/107 - loss 0.19387662 - samples/sec: 201.74 - lr: 0.100000
2022-03-26 23:09:04,264 epoch 2 - iter 100/107 - loss 0.19176473 - samples/sec: 200.43 - lr: 0.100000
2022-03-26 23:09:05,200 ----------------------------------------------------------------------------------------------------
2022-03-26 23:09:05,200 EPOCH 2 done: loss 0.1914 - lr 0.100000
2022-03-26 23:09:10,825 Evaluating as a multi-label problem: False
2022-03-26 23:09:10,836 DEV : loss 0.28679245710372925 - f1-score (micro avg)  0.3993
2022-03-26 23:09:10,918 BAD EPOCHS (no improvement): 0
2022-03-26 23:09:10,921 saving best model
2022-03-26 23:09:34,720 ----------------------------------------------------------------------------------------------------
2022-03-26 23:09:36,511 epoch 3 - iter 10/107 - loss 0.14910924 - samples/sec: 178.81 - lr: 0.100000
2022-03-26 23:09:38,212 epoch 3 - iter 20/107 - loss 0.16510876 - samples/sec: 188.30 - lr: 0.100000
2022-03-26 23:09:39,716 epoch 3 - iter 30/107 - loss 0.16015096 - samples/sec: 212.92 - lr: 0.100000
2022-03-26 23:09:41,304 epoch 3 - iter 40/107 - loss 0.15550801 - samples/sec: 201.61 - lr: 0.100000
2022-03-26 23:09:42,860 epoch 3 - iter 50/107 - loss 0.16132742 - samples/sec: 205.76 - lr: 0.100000
2022-03-26 23:09:44,461 epoch 3 - iter 60/107 - loss 0.16226179 - samples/sec: 200.01 - lr: 0.100000
2022-03-26 23:09:46,101 epoch 3 - iter 70/107 - loss 0.16221113 - samples/sec: 195.29 - lr: 0.100000
2022-03-26 23:09:47,668 epoch 3 - iter 80/107 - loss 0.15956310 - samples/sec: 204.33 - lr: 0.100000
2022-03-26 23:09:49,248 epoch 3 - iter 90/107 - loss 0.15974941 - samples/sec: 202.56 - lr: 0.100000
2022-03-26 23:09:50,864 epoch 3 - iter 100/107 - loss 0.16117070 - samples/sec: 198.15 - lr: 0.100000
2022-03-26 23:09:51,811 ----------------------------------------------------------------------------------------------------
2022-03-26 23:09:51,811 EPOCH 3 done: loss 0.1624 - lr 0.100000
2022-03-26 23:09:57,357 Evaluating as a multi-label problem: False
2022-03-26 23:09:57,368 DEV : loss 0.24250490963459015 - f1-score (micro avg)  0.5288
2022-03-26 23:09:57,441 BAD EPOCHS (no improvement): 0
2022-03-26 23:09:57,444 saving best model
2022-03-26 23:10:21,112 ----------------------------------------------------------------------------------------------------
2022-03-26 23:10:22,883 epoch 4 - iter 10/107 - loss 0.16512655 - samples/sec: 180.82 - lr: 0.100000
2022-03-26 23:10:24,453 epoch 4 - iter 20/107 - loss 0.16180258 - samples/sec: 203.96 - lr: 0.100000
2022-03-26 23:10:26,078 epoch 4 - iter 30/107 - loss 0.15990944 - samples/sec: 197.04 - lr: 0.100000
2022-03-26 23:10:27,714 epoch 4 - iter 40/107 - loss 0.15494289 - samples/sec: 195.79 - lr: 0.100000
2022-03-26 23:10:29,220 epoch 4 - iter 50/107 - loss 0.15187646 - samples/sec: 212.56 - lr: 0.100000
2022-03-26 23:10:30,840 epoch 4 - iter 60/107 - loss 0.14692429 - samples/sec: 197.72 - lr: 0.100000
2022-03-26 23:10:32,450 epoch 4 - iter 70/107 - loss 0.14438081 - samples/sec: 198.91 - lr: 0.100000
2022-03-26 23:10:34,042 epoch 4 - iter 80/107 - loss 0.14847150 - samples/sec: 201.08 - lr: 0.100000
2022-03-26 23:10:35,570 epoch 4 - iter 90/107 - loss 0.14566387 - samples/sec: 209.54 - lr: 0.100000
2022-03-26 23:10:37,130 epoch 4 - iter 100/107 - loss 0.14371133 - samples/sec: 205.32 - lr: 0.100000
2022-03-26 23:10:38,071 ----------------------------------------------------------------------------------------------------
2022-03-26 23:10:38,071 EPOCH 4 done: loss 0.1435 - lr 0.100000
2022-03-26 23:10:43,453 Evaluating as a multi-label problem: False
2022-03-26 23:10:43,466 DEV : loss 0.2626514434814453 - f1-score (micro avg)  0.4462
2022-03-26 23:10:43,541 BAD EPOCHS (no improvement): 1
2022-03-26 23:10:43,545 ----------------------------------------------------------------------------------------------------
2022-03-26 23:10:45,363 epoch 5 - iter 10/107 - loss 0.13753831 - samples/sec: 176.08 - lr: 0.100000
2022-03-26 23:10:46,931 epoch 5 - iter 20/107 - loss 0.12945272 - samples/sec: 204.22 - lr: 0.100000
2022-03-26 23:10:48,497 epoch 5 - iter 30/107 - loss 0.12589024 - samples/sec: 204.51 - lr: 0.100000
2022-03-26 23:10:50,094 epoch 5 - iter 40/107 - loss 0.12972976 - samples/sec: 200.50 - lr: 0.100000
2022-03-26 23:10:51,771 epoch 5 - iter 50/107 - loss 0.13261148 - samples/sec: 190.96 - lr: 0.100000
2022-03-26 23:10:53,446 epoch 5 - iter 60/107 - loss 0.13217734 - samples/sec: 191.12 - lr: 0.100000
2022-03-26 23:10:55,085 epoch 5 - iter 70/107 - loss 0.13092773 - samples/sec: 195.28 - lr: 0.100000
2022-03-26 23:10:56,650 epoch 5 - iter 80/107 - loss 0.13153709 - samples/sec: 204.63 - lr: 0.100000
2022-03-26 23:10:58,231 epoch 5 - iter 90/107 - loss 0.13092127 - samples/sec: 202.51 - lr: 0.100000
2022-03-26 23:10:59,734 epoch 5 - iter 100/107 - loss 0.12999324 - samples/sec: 213.05 - lr: 0.100000
2022-03-26 23:11:00,656 ----------------------------------------------------------------------------------------------------
2022-03-26 23:11:00,656 EPOCH 5 done: loss 0.1303 - lr 0.100000
2022-03-26 23:11:06,292 Evaluating as a multi-label problem: False
2022-03-26 23:11:06,303 DEV : loss 0.22984367609024048 - f1-score (micro avg)  0.4739
2022-03-26 23:11:06,377 BAD EPOCHS (no improvement): 2
2022-03-26 23:11:06,379 ----------------------------------------------------------------------------------------------------
2022-03-26 23:11:08,049 epoch 6 - iter 10/107 - loss 0.13919137 - samples/sec: 191.78 - lr: 0.100000
2022-03-26 23:11:09,606 epoch 6 - iter 20/107 - loss 0.12440290 - samples/sec: 205.63 - lr: 0.100000
2022-03-26 23:11:11,178 epoch 6 - iter 30/107 - loss 0.11970859 - samples/sec: 203.79 - lr: 0.100000
2022-03-26 23:11:12,723 epoch 6 - iter 40/107 - loss 0.12048299 - samples/sec: 207.24 - lr: 0.100000
2022-03-26 23:11:14,324 epoch 6 - iter 50/107 - loss 0.11885900 - samples/sec: 199.92 - lr: 0.100000
2022-03-26 23:11:15,923 epoch 6 - iter 60/107 - loss 0.12375275 - samples/sec: 200.23 - lr: 0.100000
2022-03-26 23:11:17,584 epoch 6 - iter 70/107 - loss 0.12205138 - samples/sec: 192.87 - lr: 0.100000
2022-03-26 23:11:19,112 epoch 6 - iter 80/107 - loss 0.12249984 - samples/sec: 209.56 - lr: 0.100000
2022-03-26 23:11:20,630 epoch 6 - iter 90/107 - loss 0.12165160 - samples/sec: 211.01 - lr: 0.100000
2022-03-26 23:11:22,165 epoch 6 - iter 100/107 - loss 0.12244382 - samples/sec: 208.53 - lr: 0.100000
2022-03-26 23:11:23,161 ----------------------------------------------------------------------------------------------------
2022-03-26 23:11:23,161 EPOCH 6 done: loss 0.1214 - lr 0.100000
2022-03-26 23:11:28,758 Evaluating as a multi-label problem: False
2022-03-26 23:11:28,768 DEV : loss 0.2651173174381256 - f1-score (micro avg)  0.3779
2022-03-26 23:11:28,843 BAD EPOCHS (no improvement): 3
2022-03-26 23:11:28,846 ----------------------------------------------------------------------------------------------------
2022-03-26 23:11:30,528 epoch 7 - iter 10/107 - loss 0.11180262 - samples/sec: 190.40 - lr: 0.100000
2022-03-26 23:11:32,158 epoch 7 - iter 20/107 - loss 0.11172254 - samples/sec: 196.39 - lr: 0.100000
2022-03-26 23:11:33,773 epoch 7 - iter 30/107 - loss 0.11619805 - samples/sec: 198.26 - lr: 0.100000
2022-03-26 23:11:35,337 epoch 7 - iter 40/107 - loss 0.10944131 - samples/sec: 204.67 - lr: 0.100000
2022-03-26 23:11:36,876 epoch 7 - iter 50/107 - loss 0.10991378 - samples/sec: 208.05 - lr: 0.100000
2022-03-26 23:11:38,455 epoch 7 - iter 60/107 - loss 0.11189571 - samples/sec: 202.86 - lr: 0.100000
2022-03-26 23:11:40,105 epoch 7 - iter 70/107 - loss 0.11027860 - samples/sec: 194.04 - lr: 0.100000
2022-03-26 23:11:41,704 epoch 7 - iter 80/107 - loss 0.10915155 - samples/sec: 200.27 - lr: 0.100000
2022-03-26 23:11:43,333 epoch 7 - iter 90/107 - loss 0.11166088 - samples/sec: 196.55 - lr: 0.100000
2022-03-26 23:11:44,892 epoch 7 - iter 100/107 - loss 0.11149821 - samples/sec: 205.36 - lr: 0.100000
2022-03-26 23:11:45,860 ----------------------------------------------------------------------------------------------------
2022-03-26 23:11:45,861 EPOCH 7 done: loss 0.1120 - lr 0.100000
2022-03-26 23:11:51,493 Evaluating as a multi-label problem: False
2022-03-26 23:11:51,503 DEV : loss 0.2581440210342407 - f1-score (micro avg)  0.405
2022-03-26 23:11:51,578 Epoch     7: reducing learning rate of group 0 to 5.0000e-02.
2022-03-26 23:11:51,578 BAD EPOCHS (no improvement): 4
2022-03-26 23:11:51,581 ----------------------------------------------------------------------------------------------------
2022-03-26 23:11:53,307 epoch 8 - iter 10/107 - loss 0.11814642 - samples/sec: 185.57 - lr: 0.050000
2022-03-26 23:11:54,916 epoch 8 - iter 20/107 - loss 0.10964283 - samples/sec: 198.89 - lr: 0.050000
2022-03-26 23:11:56,517 epoch 8 - iter 30/107 - loss 0.11593558 - samples/sec: 200.10 - lr: 0.050000
2022-03-26 23:11:58,049 epoch 8 - iter 40/107 - loss 0.10755560 - samples/sec: 208.97 - lr: 0.050000
2022-03-26 23:11:59,655 epoch 8 - iter 50/107 - loss 0.10350358 - samples/sec: 199.39 - lr: 0.050000
2022-03-26 23:12:01,288 epoch 8 - iter 60/107 - loss 0.10227619 - samples/sec: 196.01 - lr: 0.050000
2022-03-26 23:12:02,873 epoch 8 - iter 70/107 - loss 0.10200650 - samples/sec: 202.00 - lr: 0.050000
2022-03-26 23:12:04,380 epoch 8 - iter 80/107 - loss 0.09997725 - samples/sec: 212.46 - lr: 0.050000
2022-03-26 23:12:05,912 epoch 8 - iter 90/107 - loss 0.10168054 - samples/sec: 209.09 - lr: 0.050000
2022-03-26 23:12:07,506 epoch 8 - iter 100/107 - loss 0.10250607 - samples/sec: 200.88 - lr: 0.050000
2022-03-26 23:12:08,453 ----------------------------------------------------------------------------------------------------
2022-03-26 23:12:08,453 EPOCH 8 done: loss 0.1020 - lr 0.050000
2022-03-26 23:12:14,023 Evaluating as a multi-label problem: False
2022-03-26 23:12:14,034 DEV : loss 0.21109430491924286 - f1-score (micro avg)  0.481
2022-03-26 23:12:14,108 BAD EPOCHS (no improvement): 1
2022-03-26 23:12:14,111 ----------------------------------------------------------------------------------------------------
2022-03-26 23:12:15,825 epoch 9 - iter 10/107 - loss 0.08565115 - samples/sec: 186.87 - lr: 0.050000
2022-03-26 23:12:17,405 epoch 9 - iter 20/107 - loss 0.08410404 - samples/sec: 202.63 - lr: 0.050000
2022-03-26 23:12:18,962 epoch 9 - iter 30/107 - loss 0.09428059 - samples/sec: 205.67 - lr: 0.050000
2022-03-26 23:12:20,554 epoch 9 - iter 40/107 - loss 0.09389510 - samples/sec: 201.13 - lr: 0.050000
2022-03-26 23:12:22,010 epoch 9 - iter 50/107 - loss 0.09761263 - samples/sec: 219.86 - lr: 0.050000
2022-03-26 23:12:23,536 epoch 9 - iter 60/107 - loss 0.09522369 - samples/sec: 209.78 - lr: 0.050000
2022-03-26 23:12:25,179 epoch 9 - iter 70/107 - loss 0.09733963 - samples/sec: 194.93 - lr: 0.050000
2022-03-26 23:12:26,796 epoch 9 - iter 80/107 - loss 0.09499869 - samples/sec: 198.04 - lr: 0.050000
2022-03-26 23:12:28,392 epoch 9 - iter 90/107 - loss 0.09625477 - samples/sec: 200.59 - lr: 0.050000
2022-03-26 23:12:30,001 epoch 9 - iter 100/107 - loss 0.09401787 - samples/sec: 198.98 - lr: 0.050000
2022-03-26 23:12:30,957 ----------------------------------------------------------------------------------------------------
2022-03-26 23:12:30,957 EPOCH 9 done: loss 0.0929 - lr 0.050000
2022-03-26 23:12:36,582 Evaluating as a multi-label problem: False
2022-03-26 23:12:36,593 DEV : loss 0.21327640116214752 - f1-score (micro avg)  0.4834
2022-03-26 23:12:36,667 BAD EPOCHS (no improvement): 2
2022-03-26 23:12:36,669 ----------------------------------------------------------------------------------------------------
2022-03-26 23:12:38,385 epoch 10 - iter 10/107 - loss 0.07663467 - samples/sec: 186.63 - lr: 0.050000
2022-03-26 23:12:40,050 epoch 10 - iter 20/107 - loss 0.08727798 - samples/sec: 192.34 - lr: 0.050000
2022-03-26 23:12:41,609 epoch 10 - iter 30/107 - loss 0.08216325 - samples/sec: 205.35 - lr: 0.050000
2022-03-26 23:12:43,157 epoch 10 - iter 40/107 - loss 0.08528327 - samples/sec: 206.90 - lr: 0.050000
2022-03-26 23:12:44,700 epoch 10 - iter 50/107 - loss 0.08585874 - samples/sec: 207.54 - lr: 0.050000
2022-03-26 23:12:46,196 epoch 10 - iter 60/107 - loss 0.09005632 - samples/sec: 213.91 - lr: 0.050000
2022-03-26 23:12:47,810 epoch 10 - iter 70/107 - loss 0.09176590 - samples/sec: 198.44 - lr: 0.050000
2022-03-26 23:12:49,431 epoch 10 - iter 80/107 - loss 0.08977719 - samples/sec: 197.52 - lr: 0.050000
2022-03-26 23:12:51,006 epoch 10 - iter 90/107 - loss 0.08957458 - samples/sec: 203.24 - lr: 0.050000
2022-03-26 23:12:52,531 epoch 10 - iter 100/107 - loss 0.09156012 - samples/sec: 210.09 - lr: 0.050000
2022-03-26 23:12:53,472 ----------------------------------------------------------------------------------------------------
2022-03-26 23:12:53,473 EPOCH 10 done: loss 0.0908 - lr 0.050000
2022-03-26 23:13:00,553 Evaluating as a multi-label problem: False
2022-03-26 23:13:00,563 DEV : loss 0.21964728832244873 - f1-score (micro avg)  0.4779
2022-03-26 23:13:00,638 BAD EPOCHS (no improvement): 3
2022-03-26 23:13:00,640 ----------------------------------------------------------------------------------------------------
2022-03-26 23:13:02,249 epoch 11 - iter 10/107 - loss 0.08173492 - samples/sec: 199.14 - lr: 0.050000
2022-03-26 23:13:03,817 epoch 11 - iter 20/107 - loss 0.08580405 - samples/sec: 204.22 - lr: 0.050000
2022-03-26 23:13:05,324 epoch 11 - iter 30/107 - loss 0.08899364 - samples/sec: 212.41 - lr: 0.050000
2022-03-26 23:13:06,911 epoch 11 - iter 40/107 - loss 0.08374359 - samples/sec: 201.71 - lr: 0.050000
2022-03-26 23:13:08,483 epoch 11 - iter 50/107 - loss 0.08259601 - samples/sec: 203.68 - lr: 0.050000
2022-03-26 23:13:10,138 epoch 11 - iter 60/107 - loss 0.08708041 - samples/sec: 193.48 - lr: 0.050000
2022-03-26 23:13:11,691 epoch 11 - iter 70/107 - loss 0.08440099 - samples/sec: 206.20 - lr: 0.050000
2022-03-26 23:13:13,254 epoch 11 - iter 80/107 - loss 0.08534887 - samples/sec: 204.87 - lr: 0.050000
2022-03-26 23:13:14,808 epoch 11 - iter 90/107 - loss 0.08794416 - samples/sec: 205.98 - lr: 0.050000
2022-03-26 23:13:16,360 epoch 11 - iter 100/107 - loss 0.08864751 - samples/sec: 206.30 - lr: 0.050000
2022-03-26 23:13:17,376 ----------------------------------------------------------------------------------------------------
2022-03-26 23:13:17,376 EPOCH 11 done: loss 0.0870 - lr 0.050000
2022-03-26 23:13:22,962 Evaluating as a multi-label problem: False
2022-03-26 23:13:22,973 DEV : loss 0.2059590071439743 - f1-score (micro avg)  0.4984
2022-03-26 23:13:23,047 Epoch    11: reducing learning rate of group 0 to 2.5000e-02.
2022-03-26 23:13:23,047 BAD EPOCHS (no improvement): 4
2022-03-26 23:13:23,049 ----------------------------------------------------------------------------------------------------
2022-03-26 23:13:24,719 epoch 12 - iter 10/107 - loss 0.07464041 - samples/sec: 191.74 - lr: 0.025000
2022-03-26 23:13:26,385 epoch 12 - iter 20/107 - loss 0.07571515 - samples/sec: 192.25 - lr: 0.025000
2022-03-26 23:13:28,025 epoch 12 - iter 30/107 - loss 0.07947908 - samples/sec: 195.24 - lr: 0.025000
2022-03-26 23:13:29,655 epoch 12 - iter 40/107 - loss 0.07938082 - samples/sec: 196.35 - lr: 0.025000
2022-03-26 23:13:31,266 epoch 12 - iter 50/107 - loss 0.08081553 - samples/sec: 198.85 - lr: 0.025000
2022-03-26 23:13:32,916 epoch 12 - iter 60/107 - loss 0.08134586 - samples/sec: 193.97 - lr: 0.025000
2022-03-26 23:13:34,441 epoch 12 - iter 70/107 - loss 0.07965509 - samples/sec: 210.05 - lr: 0.025000
2022-03-26 23:13:36,025 epoch 12 - iter 80/107 - loss 0.08075881 - samples/sec: 202.13 - lr: 0.025000
2022-03-26 23:13:37,576 epoch 12 - iter 90/107 - loss 0.07976553 - samples/sec: 206.44 - lr: 0.025000
2022-03-26 23:13:39,112 epoch 12 - iter 100/107 - loss 0.07967519 - samples/sec: 208.47 - lr: 0.025000
2022-03-26 23:13:40,048 ----------------------------------------------------------------------------------------------------
2022-03-26 23:13:40,048 EPOCH 12 done: loss 0.0803 - lr 0.025000
2022-03-26 23:13:45,687 Evaluating as a multi-label problem: False
2022-03-26 23:13:45,698 DEV : loss 0.19357572495937347 - f1-score (micro avg)  0.5032
2022-03-26 23:13:45,774 BAD EPOCHS (no improvement): 1
2022-03-26 23:13:45,776 ----------------------------------------------------------------------------------------------------
2022-03-26 23:13:47,455 epoch 13 - iter 10/107 - loss 0.07003743 - samples/sec: 190.83 - lr: 0.025000
2022-03-26 23:13:49,054 epoch 13 - iter 20/107 - loss 0.06767431 - samples/sec: 200.30 - lr: 0.025000
2022-03-26 23:13:50,627 epoch 13 - iter 30/107 - loss 0.07189409 - samples/sec: 203.49 - lr: 0.025000
2022-03-26 23:13:52,203 epoch 13 - iter 40/107 - loss 0.07337532 - samples/sec: 203.26 - lr: 0.025000
2022-03-26 23:13:53,768 epoch 13 - iter 50/107 - loss 0.06962332 - samples/sec: 204.59 - lr: 0.025000
2022-03-26 23:13:55,342 epoch 13 - iter 60/107 - loss 0.07188906 - samples/sec: 203.41 - lr: 0.025000
2022-03-26 23:13:56,923 epoch 13 - iter 70/107 - loss 0.07319694 - samples/sec: 202.49 - lr: 0.025000
2022-03-26 23:13:58,455 epoch 13 - iter 80/107 - loss 0.07614970 - samples/sec: 209.08 - lr: 0.025000
2022-03-26 23:14:00,003 epoch 13 - iter 90/107 - loss 0.07839421 - samples/sec: 206.85 - lr: 0.025000
2022-03-26 23:14:01,598 epoch 13 - iter 100/107 - loss 0.07980171 - samples/sec: 200.66 - lr: 0.025000
2022-03-26 23:14:02,655 ----------------------------------------------------------------------------------------------------
2022-03-26 23:14:02,655 EPOCH 13 done: loss 0.0792 - lr 0.025000
2022-03-26 23:14:08,342 Evaluating as a multi-label problem: False
2022-03-26 23:14:08,353 DEV : loss 0.21091558039188385 - f1-score (micro avg)  0.4816
2022-03-26 23:14:08,427 BAD EPOCHS (no improvement): 2
2022-03-26 23:14:08,430 ----------------------------------------------------------------------------------------------------
2022-03-26 23:14:10,088 epoch 14 - iter 10/107 - loss 0.07169395 - samples/sec: 193.23 - lr: 0.025000
2022-03-26 23:14:11,719 epoch 14 - iter 20/107 - loss 0.07052974 - samples/sec: 196.31 - lr: 0.025000
2022-03-26 23:14:13,271 epoch 14 - iter 30/107 - loss 0.06925493 - samples/sec: 206.28 - lr: 0.025000
2022-03-26 23:14:14,822 epoch 14 - iter 40/107 - loss 0.07274168 - samples/sec: 206.48 - lr: 0.025000
2022-03-26 23:14:16,355 epoch 14 - iter 50/107 - loss 0.07481806 - samples/sec: 208.86 - lr: 0.025000
2022-03-26 23:14:17,924 epoch 14 - iter 60/107 - loss 0.07245330 - samples/sec: 204.04 - lr: 0.025000
2022-03-26 23:14:19,518 epoch 14 - iter 70/107 - loss 0.07449042 - samples/sec: 200.90 - lr: 0.025000
2022-03-26 23:14:21,109 epoch 14 - iter 80/107 - loss 0.07538820 - samples/sec: 201.19 - lr: 0.025000
2022-03-26 23:14:22,698 epoch 14 - iter 90/107 - loss 0.07648877 - samples/sec: 201.50 - lr: 0.025000
2022-03-26 23:14:24,261 epoch 14 - iter 100/107 - loss 0.07603126 - samples/sec: 204.87 - lr: 0.025000
2022-03-26 23:14:25,206 ----------------------------------------------------------------------------------------------------
2022-03-26 23:14:25,206 EPOCH 14 done: loss 0.0764 - lr 0.025000
2022-03-26 23:14:30,791 Evaluating as a multi-label problem: False
2022-03-26 23:14:30,801 DEV : loss 0.2046155035495758 - f1-score (micro avg)  0.4984
2022-03-26 23:14:30,877 BAD EPOCHS (no improvement): 3
2022-03-26 23:14:30,880 ----------------------------------------------------------------------------------------------------
2022-03-26 23:14:32,483 epoch 15 - iter 10/107 - loss 0.08953773 - samples/sec: 199.76 - lr: 0.025000
2022-03-26 23:14:34,072 epoch 15 - iter 20/107 - loss 0.08830322 - samples/sec: 201.61 - lr: 0.025000
2022-03-26 23:14:35,684 epoch 15 - iter 30/107 - loss 0.08283992 - samples/sec: 198.57 - lr: 0.025000
2022-03-26 23:14:37,288 epoch 15 - iter 40/107 - loss 0.08095102 - samples/sec: 199.64 - lr: 0.025000
2022-03-26 23:14:38,857 epoch 15 - iter 50/107 - loss 0.07692720 - samples/sec: 204.08 - lr: 0.025000
2022-03-26 23:14:40,481 epoch 15 - iter 60/107 - loss 0.07581256 - samples/sec: 197.17 - lr: 0.025000
2022-03-26 23:14:42,056 epoch 15 - iter 70/107 - loss 0.07283056 - samples/sec: 203.37 - lr: 0.025000
2022-03-26 23:14:43,557 epoch 15 - iter 80/107 - loss 0.07498834 - samples/sec: 213.21 - lr: 0.025000
2022-03-26 23:14:45,082 epoch 15 - iter 90/107 - loss 0.07579471 - samples/sec: 210.04 - lr: 0.025000
2022-03-26 23:14:46,608 epoch 15 - iter 100/107 - loss 0.07584675 - samples/sec: 209.85 - lr: 0.025000
2022-03-26 23:14:47,546 ----------------------------------------------------------------------------------------------------
2022-03-26 23:14:47,546 EPOCH 15 done: loss 0.0758 - lr 0.025000
2022-03-26 23:14:53,135 Evaluating as a multi-label problem: False
2022-03-26 23:14:53,145 DEV : loss 0.21612954139709473 - f1-score (micro avg)  0.4846
2022-03-26 23:14:53,222 Epoch    15: reducing learning rate of group 0 to 1.2500e-02.
2022-03-26 23:14:53,222 BAD EPOCHS (no improvement): 4
2022-03-26 23:14:53,225 ----------------------------------------------------------------------------------------------------
2022-03-26 23:14:54,953 epoch 16 - iter 10/107 - loss 0.06722873 - samples/sec: 185.29 - lr: 0.012500
2022-03-26 23:14:56,573 epoch 16 - iter 20/107 - loss 0.06724305 - samples/sec: 197.64 - lr: 0.012500
2022-03-26 23:14:58,158 epoch 16 - iter 30/107 - loss 0.06891720 - samples/sec: 201.98 - lr: 0.012500
2022-03-26 23:14:59,726 epoch 16 - iter 40/107 - loss 0.06994366 - samples/sec: 204.30 - lr: 0.012500
2022-03-26 23:15:01,324 epoch 16 - iter 50/107 - loss 0.06937120 - samples/sec: 200.35 - lr: 0.012500
2022-03-26 23:15:02,912 epoch 16 - iter 60/107 - loss 0.07207002 - samples/sec: 201.56 - lr: 0.012500
2022-03-26 23:15:04,471 epoch 16 - iter 70/107 - loss 0.07251361 - samples/sec: 205.38 - lr: 0.012500
2022-03-26 23:15:06,060 epoch 16 - iter 80/107 - loss 0.07284088 - samples/sec: 201.57 - lr: 0.012500
2022-03-26 23:15:07,658 epoch 16 - iter 90/107 - loss 0.07187306 - samples/sec: 200.40 - lr: 0.012500
2022-03-26 23:15:09,185 epoch 16 - iter 100/107 - loss 0.07305762 - samples/sec: 209.60 - lr: 0.012500
2022-03-26 23:15:10,091 ----------------------------------------------------------------------------------------------------
2022-03-26 23:15:10,091 EPOCH 16 done: loss 0.0732 - lr 0.012500
2022-03-26 23:15:15,948 Evaluating as a multi-label problem: False
2022-03-26 23:15:15,959 DEV : loss 0.2048555314540863 - f1-score (micro avg)  0.4897
2022-03-26 23:15:16,036 BAD EPOCHS (no improvement): 1
2022-03-26 23:15:16,266 ----------------------------------------------------------------------------------------------------
2022-03-26 23:15:17,969 epoch 17 - iter 10/107 - loss 0.07572557 - samples/sec: 188.15 - lr: 0.012500
2022-03-26 23:15:19,510 epoch 17 - iter 20/107 - loss 0.07228457 - samples/sec: 207.88 - lr: 0.012500
2022-03-26 23:15:21,095 epoch 17 - iter 30/107 - loss 0.06972848 - samples/sec: 202.00 - lr: 0.012500
2022-03-26 23:15:22,695 epoch 17 - iter 40/107 - loss 0.06744533 - samples/sec: 200.17 - lr: 0.012500
2022-03-26 23:15:24,226 epoch 17 - iter 50/107 - loss 0.06790240 - samples/sec: 209.13 - lr: 0.012500
2022-03-26 23:15:25,768 epoch 17 - iter 60/107 - loss 0.06727834 - samples/sec: 207.58 - lr: 0.012500
2022-03-26 23:15:27,317 epoch 17 - iter 70/107 - loss 0.06856348 - samples/sec: 206.78 - lr: 0.012500
2022-03-26 23:15:28,934 epoch 17 - iter 80/107 - loss 0.07056120 - samples/sec: 197.94 - lr: 0.012500
2022-03-26 23:15:30,511 epoch 17 - iter 90/107 - loss 0.07169476 - samples/sec: 203.11 - lr: 0.012500
2022-03-26 23:15:32,165 epoch 17 - iter 100/107 - loss 0.07227597 - samples/sec: 193.60 - lr: 0.012500
2022-03-26 23:15:33,182 ----------------------------------------------------------------------------------------------------
2022-03-26 23:15:33,182 EPOCH 17 done: loss 0.0721 - lr 0.012500
2022-03-26 23:15:38,799 Evaluating as a multi-label problem: False
2022-03-26 23:15:38,810 DEV : loss 0.19931963086128235 - f1-score (micro avg)  0.498
2022-03-26 23:15:38,886 BAD EPOCHS (no improvement): 2
2022-03-26 23:15:38,889 ----------------------------------------------------------------------------------------------------
2022-03-26 23:15:40,595 epoch 18 - iter 10/107 - loss 0.07576925 - samples/sec: 187.77 - lr: 0.012500
2022-03-26 23:15:42,212 epoch 18 - iter 20/107 - loss 0.07128150 - samples/sec: 198.06 - lr: 0.012500
2022-03-26 23:15:43,792 epoch 18 - iter 30/107 - loss 0.06931547 - samples/sec: 202.68 - lr: 0.012500
2022-03-26 23:15:45,289 epoch 18 - iter 40/107 - loss 0.06911703 - samples/sec: 213.85 - lr: 0.012500
2022-03-26 23:15:46,895 epoch 18 - iter 50/107 - loss 0.07370842 - samples/sec: 199.37 - lr: 0.012500
2022-03-26 23:15:48,364 epoch 18 - iter 60/107 - loss 0.07243703 - samples/sec: 217.91 - lr: 0.012500
2022-03-26 23:15:49,941 epoch 18 - iter 70/107 - loss 0.07064885 - samples/sec: 203.04 - lr: 0.012500
2022-03-26 23:15:51,483 epoch 18 - iter 80/107 - loss 0.07154904 - samples/sec: 207.67 - lr: 0.012500
2022-03-26 23:15:52,988 epoch 18 - iter 90/107 - loss 0.07116551 - samples/sec: 212.83 - lr: 0.012500
2022-03-26 23:15:54,497 epoch 18 - iter 100/107 - loss 0.07045221 - samples/sec: 212.11 - lr: 0.012500
2022-03-26 23:15:55,485 ----------------------------------------------------------------------------------------------------
2022-03-26 23:15:55,485 EPOCH 18 done: loss 0.0707 - lr 0.012500
2022-03-26 23:16:00,970 Evaluating as a multi-label problem: False
2022-03-26 23:16:00,980 DEV : loss 0.20348438620567322 - f1-score (micro avg)  0.5099
2022-03-26 23:16:01,054 BAD EPOCHS (no improvement): 3
2022-03-26 23:16:01,056 ----------------------------------------------------------------------------------------------------
2022-03-26 23:16:02,687 epoch 19 - iter 10/107 - loss 0.07477335 - samples/sec: 196.29 - lr: 0.012500
2022-03-26 23:16:04,277 epoch 19 - iter 20/107 - loss 0.07024681 - samples/sec: 201.40 - lr: 0.012500
2022-03-26 23:16:05,817 epoch 19 - iter 30/107 - loss 0.06851264 - samples/sec: 207.96 - lr: 0.012500
2022-03-26 23:16:07,459 epoch 19 - iter 40/107 - loss 0.06782854 - samples/sec: 195.07 - lr: 0.012500
2022-03-26 23:16:09,012 epoch 19 - iter 50/107 - loss 0.06618636 - samples/sec: 206.22 - lr: 0.012500
2022-03-26 23:16:10,546 epoch 19 - iter 60/107 - loss 0.06649004 - samples/sec: 208.63 - lr: 0.012500
2022-03-26 23:16:12,142 epoch 19 - iter 70/107 - loss 0.06679875 - samples/sec: 200.69 - lr: 0.012500
2022-03-26 23:16:13,670 epoch 19 - iter 80/107 - loss 0.06732067 - samples/sec: 209.60 - lr: 0.012500
2022-03-26 23:16:15,162 epoch 19 - iter 90/107 - loss 0.06838879 - samples/sec: 214.52 - lr: 0.012500
2022-03-26 23:16:16,783 epoch 19 - iter 100/107 - loss 0.07050633 - samples/sec: 197.59 - lr: 0.012500
2022-03-26 23:16:17,737 ----------------------------------------------------------------------------------------------------
2022-03-26 23:16:17,738 EPOCH 19 done: loss 0.0704 - lr 0.012500
2022-03-26 23:16:23,310 Evaluating as a multi-label problem: False
2022-03-26 23:16:23,321 DEV : loss 0.20117047429084778 - f1-score (micro avg)  0.5098
2022-03-26 23:16:23,394 Epoch    19: reducing learning rate of group 0 to 6.2500e-03.
2022-03-26 23:16:23,394 BAD EPOCHS (no improvement): 4
2022-03-26 23:16:23,397 ----------------------------------------------------------------------------------------------------
2022-03-26 23:16:25,069 epoch 20 - iter 10/107 - loss 0.08531548 - samples/sec: 191.50 - lr: 0.006250
2022-03-26 23:16:26,714 epoch 20 - iter 20/107 - loss 0.07606574 - samples/sec: 194.71 - lr: 0.006250
2022-03-26 23:16:28,346 epoch 20 - iter 30/107 - loss 0.07299575 - samples/sec: 196.20 - lr: 0.006250
2022-03-26 23:16:29,908 epoch 20 - iter 40/107 - loss 0.07014365 - samples/sec: 204.94 - lr: 0.006250
2022-03-26 23:16:31,430 epoch 20 - iter 50/107 - loss 0.06996199 - samples/sec: 210.42 - lr: 0.006250
2022-03-26 23:16:33,121 epoch 20 - iter 60/107 - loss 0.06961758 - samples/sec: 189.28 - lr: 0.006250
2022-03-26 23:16:34,687 epoch 20 - iter 70/107 - loss 0.07012313 - samples/sec: 204.42 - lr: 0.006250
2022-03-26 23:16:36,216 epoch 20 - iter 80/107 - loss 0.06914622 - samples/sec: 209.49 - lr: 0.006250
2022-03-26 23:16:37,786 epoch 20 - iter 90/107 - loss 0.06818196 - samples/sec: 203.86 - lr: 0.006250
2022-03-26 23:16:39,363 epoch 20 - iter 100/107 - loss 0.06901044 - samples/sec: 203.11 - lr: 0.006250
2022-03-26 23:16:40,302 ----------------------------------------------------------------------------------------------------
2022-03-26 23:16:40,302 EPOCH 20 done: loss 0.0681 - lr 0.006250
2022-03-26 23:16:45,926 Evaluating as a multi-label problem: False
2022-03-26 23:16:45,937 DEV : loss 0.20427097380161285 - f1-score (micro avg)  0.502
2022-03-26 23:16:46,011 BAD EPOCHS (no improvement): 1
2022-03-26 23:16:46,014 ----------------------------------------------------------------------------------------------------
2022-03-26 23:16:47,772 epoch 21 - iter 10/107 - loss 0.06934734 - samples/sec: 182.13 - lr: 0.006250
2022-03-26 23:16:49,321 epoch 21 - iter 20/107 - loss 0.06952771 - samples/sec: 206.69 - lr: 0.006250
2022-03-26 23:16:50,861 epoch 21 - iter 30/107 - loss 0.06921472 - samples/sec: 208.01 - lr: 0.006250
2022-03-26 23:16:52,425 epoch 21 - iter 40/107 - loss 0.06845921 - samples/sec: 204.68 - lr: 0.006250
2022-03-26 23:16:54,008 epoch 21 - iter 50/107 - loss 0.06542139 - samples/sec: 202.35 - lr: 0.006250
2022-03-26 23:16:55,602 epoch 21 - iter 60/107 - loss 0.06602985 - samples/sec: 200.85 - lr: 0.006250
2022-03-26 23:16:57,116 epoch 21 - iter 70/107 - loss 0.06515812 - samples/sec: 211.55 - lr: 0.006250
2022-03-26 23:16:58,643 epoch 21 - iter 80/107 - loss 0.06462888 - samples/sec: 209.72 - lr: 0.006250
2022-03-26 23:17:00,136 epoch 21 - iter 90/107 - loss 0.06646767 - samples/sec: 214.46 - lr: 0.006250
2022-03-26 23:17:01,725 epoch 21 - iter 100/107 - loss 0.06888528 - samples/sec: 201.53 - lr: 0.006250
2022-03-26 23:17:02,692 ----------------------------------------------------------------------------------------------------
2022-03-26 23:17:02,692 EPOCH 21 done: loss 0.0695 - lr 0.006250
2022-03-26 23:17:08,317 Evaluating as a multi-label problem: False
2022-03-26 23:17:08,328 DEV : loss 0.19760170578956604 - f1-score (micro avg)  0.512
2022-03-26 23:17:08,402 BAD EPOCHS (no improvement): 2
2022-03-26 23:17:08,437 ----------------------------------------------------------------------------------------------------
2022-03-26 23:17:10,090 epoch 22 - iter 10/107 - loss 0.06908561 - samples/sec: 193.76 - lr: 0.006250
2022-03-26 23:17:11,698 epoch 22 - iter 20/107 - loss 0.06348748 - samples/sec: 199.08 - lr: 0.006250
2022-03-26 23:17:13,299 epoch 22 - iter 30/107 - loss 0.06511049 - samples/sec: 200.03 - lr: 0.006250
2022-03-26 23:17:14,811 epoch 22 - iter 40/107 - loss 0.06450216 - samples/sec: 211.76 - lr: 0.006250
2022-03-26 23:17:16,457 epoch 22 - iter 50/107 - loss 0.05961741 - samples/sec: 194.53 - lr: 0.006250
2022-03-26 23:17:18,029 epoch 22 - iter 60/107 - loss 0.06361196 - samples/sec: 203.70 - lr: 0.006250
2022-03-26 23:17:19,641 epoch 22 - iter 70/107 - loss 0.06295141 - samples/sec: 198.65 - lr: 0.006250
2022-03-26 23:17:21,235 epoch 22 - iter 80/107 - loss 0.06311284 - samples/sec: 200.77 - lr: 0.006250
2022-03-26 23:17:22,878 epoch 22 - iter 90/107 - loss 0.06390055 - samples/sec: 194.95 - lr: 0.006250
2022-03-26 23:17:24,439 epoch 22 - iter 100/107 - loss 0.06442626 - samples/sec: 205.12 - lr: 0.006250
2022-03-26 23:17:25,373 ----------------------------------------------------------------------------------------------------
2022-03-26 23:17:25,374 EPOCH 22 done: loss 0.0645 - lr 0.006250
2022-03-26 23:17:30,953 Evaluating as a multi-label problem: False
2022-03-26 23:17:30,964 DEV : loss 0.2025763988494873 - f1-score (micro avg)  0.5012
2022-03-26 23:17:31,039 BAD EPOCHS (no improvement): 3
2022-03-26 23:17:31,041 ----------------------------------------------------------------------------------------------------
2022-03-26 23:17:32,745 epoch 23 - iter 10/107 - loss 0.06406074 - samples/sec: 187.90 - lr: 0.006250
2022-03-26 23:17:34,368 epoch 23 - iter 20/107 - loss 0.06347097 - samples/sec: 197.29 - lr: 0.006250
2022-03-26 23:17:35,922 epoch 23 - iter 30/107 - loss 0.06564861 - samples/sec: 206.06 - lr: 0.006250
2022-03-26 23:17:37,486 epoch 23 - iter 40/107 - loss 0.06616719 - samples/sec: 204.79 - lr: 0.006250
2022-03-26 23:17:38,999 epoch 23 - iter 50/107 - loss 0.06785930 - samples/sec: 211.60 - lr: 0.006250
2022-03-26 23:17:40,570 epoch 23 - iter 60/107 - loss 0.06647506 - samples/sec: 203.76 - lr: 0.006250
2022-03-26 23:17:42,075 epoch 23 - iter 70/107 - loss 0.06558104 - samples/sec: 212.80 - lr: 0.006250
2022-03-26 23:17:43,604 epoch 23 - iter 80/107 - loss 0.06523352 - samples/sec: 209.52 - lr: 0.006250
2022-03-26 23:17:45,148 epoch 23 - iter 90/107 - loss 0.06492530 - samples/sec: 207.33 - lr: 0.006250
2022-03-26 23:17:46,695 epoch 23 - iter 100/107 - loss 0.06408757 - samples/sec: 206.97 - lr: 0.006250
2022-03-26 23:17:47,673 ----------------------------------------------------------------------------------------------------
2022-03-26 23:17:47,673 EPOCH 23 done: loss 0.0651 - lr 0.006250
2022-03-26 23:17:53,220 Evaluating as a multi-label problem: False
2022-03-26 23:17:53,231 DEV : loss 0.20079103112220764 - f1-score (micro avg)  0.4988
2022-03-26 23:17:53,305 Epoch    23: reducing learning rate of group 0 to 3.1250e-03.
2022-03-26 23:17:53,305 BAD EPOCHS (no improvement): 4
2022-03-26 23:17:53,308 ----------------------------------------------------------------------------------------------------
2022-03-26 23:17:54,990 epoch 24 - iter 10/107 - loss 0.06655333 - samples/sec: 190.42 - lr: 0.003125
2022-03-26 23:17:56,558 epoch 24 - iter 20/107 - loss 0.06122931 - samples/sec: 204.21 - lr: 0.003125
2022-03-26 23:17:58,046 epoch 24 - iter 30/107 - loss 0.06345972 - samples/sec: 215.09 - lr: 0.003125
2022-03-26 23:17:59,649 epoch 24 - iter 40/107 - loss 0.06306374 - samples/sec: 199.84 - lr: 0.003125
2022-03-26 23:18:01,204 epoch 24 - iter 50/107 - loss 0.06134589 - samples/sec: 205.83 - lr: 0.003125
2022-03-26 23:18:02,734 epoch 24 - iter 60/107 - loss 0.05897963 - samples/sec: 209.30 - lr: 0.003125
2022-03-26 23:18:04,339 epoch 24 - iter 70/107 - loss 0.06106220 - samples/sec: 199.43 - lr: 0.003125
2022-03-26 23:18:05,950 epoch 24 - iter 80/107 - loss 0.06246579 - samples/sec: 198.82 - lr: 0.003125
2022-03-26 23:18:07,537 epoch 24 - iter 90/107 - loss 0.06336311 - samples/sec: 201.74 - lr: 0.003125
2022-03-26 23:18:09,097 epoch 24 - iter 100/107 - loss 0.06394196 - samples/sec: 205.21 - lr: 0.003125
2022-03-26 23:18:10,085 ----------------------------------------------------------------------------------------------------
2022-03-26 23:18:10,085 EPOCH 24 done: loss 0.0654 - lr 0.003125
2022-03-26 23:18:15,667 Evaluating as a multi-label problem: False
2022-03-26 23:18:15,678 DEV : loss 0.1991073191165924 - f1-score (micro avg)  0.5054
2022-03-26 23:18:15,752 BAD EPOCHS (no improvement): 1
2022-03-26 23:18:15,754 ----------------------------------------------------------------------------------------------------
2022-03-26 23:18:17,405 epoch 25 - iter 10/107 - loss 0.05126190 - samples/sec: 193.97 - lr: 0.003125
2022-03-26 23:18:18,890 epoch 25 - iter 20/107 - loss 0.05872609 - samples/sec: 215.64 - lr: 0.003125
2022-03-26 23:18:20,421 epoch 25 - iter 30/107 - loss 0.05978452 - samples/sec: 209.16 - lr: 0.003125
2022-03-26 23:18:21,977 epoch 25 - iter 40/107 - loss 0.06233548 - samples/sec: 205.80 - lr: 0.003125
2022-03-26 23:18:23,516 epoch 25 - iter 50/107 - loss 0.06345573 - samples/sec: 208.04 - lr: 0.003125
2022-03-26 23:18:25,114 epoch 25 - iter 60/107 - loss 0.06343473 - samples/sec: 200.40 - lr: 0.003125
2022-03-26 23:18:26,645 epoch 25 - iter 70/107 - loss 0.06242783 - samples/sec: 209.15 - lr: 0.003125
2022-03-26 23:18:28,237 epoch 25 - iter 80/107 - loss 0.06214816 - samples/sec: 201.08 - lr: 0.003125
2022-03-26 23:18:29,828 epoch 25 - iter 90/107 - loss 0.06458719 - samples/sec: 201.31 - lr: 0.003125
2022-03-26 23:18:31,392 epoch 25 - iter 100/107 - loss 0.06546000 - samples/sec: 204.65 - lr: 0.003125
2022-03-26 23:18:32,325 ----------------------------------------------------------------------------------------------------
2022-03-26 23:18:32,325 EPOCH 25 done: loss 0.0660 - lr 0.003125
2022-03-26 23:18:39,309 Evaluating as a multi-label problem: False
2022-03-26 23:18:39,320 DEV : loss 0.20076896250247955 - f1-score (micro avg)  0.5016
2022-03-26 23:18:39,393 BAD EPOCHS (no improvement): 2
2022-03-26 23:18:39,396 ----------------------------------------------------------------------------------------------------
2022-03-26 23:18:41,062 epoch 26 - iter 10/107 - loss 0.06402907 - samples/sec: 192.32 - lr: 0.003125
2022-03-26 23:18:42,703 epoch 26 - iter 20/107 - loss 0.06564145 - samples/sec: 195.04 - lr: 0.003125
2022-03-26 23:18:44,258 epoch 26 - iter 30/107 - loss 0.06171087 - samples/sec: 205.98 - lr: 0.003125
2022-03-26 23:18:45,849 epoch 26 - iter 40/107 - loss 0.06370404 - samples/sec: 201.25 - lr: 0.003125
2022-03-26 23:18:47,354 epoch 26 - iter 50/107 - loss 0.06433694 - samples/sec: 212.70 - lr: 0.003125
2022-03-26 23:18:48,960 epoch 26 - iter 60/107 - loss 0.06417739 - samples/sec: 199.36 - lr: 0.003125
2022-03-26 23:18:50,521 epoch 26 - iter 70/107 - loss 0.06324252 - samples/sec: 205.13 - lr: 0.003125
2022-03-26 23:18:52,069 epoch 26 - iter 80/107 - loss 0.06299012 - samples/sec: 206.82 - lr: 0.003125
2022-03-26 23:18:53,660 epoch 26 - iter 90/107 - loss 0.06414823 - samples/sec: 201.30 - lr: 0.003125
2022-03-26 23:18:55,240 epoch 26 - iter 100/107 - loss 0.06495505 - samples/sec: 202.57 - lr: 0.003125
2022-03-26 23:18:56,202 ----------------------------------------------------------------------------------------------------
2022-03-26 23:18:56,202 EPOCH 26 done: loss 0.0656 - lr 0.003125
2022-03-26 23:19:01,773 Evaluating as a multi-label problem: False
2022-03-26 23:19:01,784 DEV : loss 0.20086313784122467 - f1-score (micro avg)  0.5106
2022-03-26 23:19:01,857 BAD EPOCHS (no improvement): 3
2022-03-26 23:19:01,860 ----------------------------------------------------------------------------------------------------
2022-03-26 23:19:03,583 epoch 27 - iter 10/107 - loss 0.07423807 - samples/sec: 185.79 - lr: 0.003125
2022-03-26 23:19:05,218 epoch 27 - iter 20/107 - loss 0.06835925 - samples/sec: 195.83 - lr: 0.003125
2022-03-26 23:19:06,823 epoch 27 - iter 30/107 - loss 0.06938546 - samples/sec: 199.45 - lr: 0.003125
2022-03-26 23:19:08,404 epoch 27 - iter 40/107 - loss 0.06791261 - samples/sec: 202.58 - lr: 0.003125
2022-03-26 23:19:09,967 epoch 27 - iter 50/107 - loss 0.06757204 - samples/sec: 204.80 - lr: 0.003125
2022-03-26 23:19:11,477 epoch 27 - iter 60/107 - loss 0.06558927 - samples/sec: 212.13 - lr: 0.003125
2022-03-26 23:19:12,994 epoch 27 - iter 70/107 - loss 0.06601596 - samples/sec: 211.05 - lr: 0.003125
2022-03-26 23:19:14,524 epoch 27 - iter 80/107 - loss 0.06546146 - samples/sec: 209.29 - lr: 0.003125
2022-03-26 23:19:16,047 epoch 27 - iter 90/107 - loss 0.06420379 - samples/sec: 210.16 - lr: 0.003125
2022-03-26 23:19:17,590 epoch 27 - iter 100/107 - loss 0.06374858 - samples/sec: 207.55 - lr: 0.003125
2022-03-26 23:19:18,540 ----------------------------------------------------------------------------------------------------
2022-03-26 23:19:18,540 EPOCH 27 done: loss 0.0642 - lr 0.003125
2022-03-26 23:19:24,118 Evaluating as a multi-label problem: False
2022-03-26 23:19:24,129 DEV : loss 0.20477207005023956 - f1-score (micro avg)  0.4984
2022-03-26 23:19:24,202 Epoch    27: reducing learning rate of group 0 to 1.5625e-03.
2022-03-26 23:19:24,203 BAD EPOCHS (no improvement): 4
2022-03-26 23:19:24,205 ----------------------------------------------------------------------------------------------------
2022-03-26 23:19:25,892 epoch 28 - iter 10/107 - loss 0.05753464 - samples/sec: 189.82 - lr: 0.001563
2022-03-26 23:19:27,467 epoch 28 - iter 20/107 - loss 0.05476809 - samples/sec: 203.33 - lr: 0.001563
2022-03-26 23:19:29,038 epoch 28 - iter 30/107 - loss 0.05818155 - samples/sec: 203.80 - lr: 0.001563
2022-03-26 23:19:30,610 epoch 28 - iter 40/107 - loss 0.05959658 - samples/sec: 203.74 - lr: 0.001563
2022-03-26 23:19:32,160 epoch 28 - iter 50/107 - loss 0.05980506 - samples/sec: 206.56 - lr: 0.001563
2022-03-26 23:19:33,693 epoch 28 - iter 60/107 - loss 0.06029266 - samples/sec: 208.92 - lr: 0.001563
2022-03-26 23:19:35,342 epoch 28 - iter 70/107 - loss 0.05931933 - samples/sec: 194.08 - lr: 0.001563
2022-03-26 23:19:36,878 epoch 28 - iter 80/107 - loss 0.06040236 - samples/sec: 208.48 - lr: 0.001563
2022-03-26 23:19:38,459 epoch 28 - iter 90/107 - loss 0.06018559 - samples/sec: 202.50 - lr: 0.001563
2022-03-26 23:19:40,052 epoch 28 - iter 100/107 - loss 0.06111589 - samples/sec: 201.04 - lr: 0.001563
2022-03-26 23:19:41,003 ----------------------------------------------------------------------------------------------------
2022-03-26 23:19:41,003 EPOCH 28 done: loss 0.0616 - lr 0.001563
2022-03-26 23:19:46,604 Evaluating as a multi-label problem: False
2022-03-26 23:19:46,615 DEV : loss 0.2023281306028366 - f1-score (micro avg)  0.5063
2022-03-26 23:19:46,688 BAD EPOCHS (no improvement): 1
2022-03-26 23:19:46,691 ----------------------------------------------------------------------------------------------------
2022-03-26 23:19:48,350 epoch 29 - iter 10/107 - loss 0.06000972 - samples/sec: 193.05 - lr: 0.001563
2022-03-26 23:19:49,943 epoch 29 - iter 20/107 - loss 0.06305406 - samples/sec: 200.97 - lr: 0.001563
2022-03-26 23:19:51,500 epoch 29 - iter 30/107 - loss 0.06089326 - samples/sec: 205.63 - lr: 0.001563
2022-03-26 23:19:53,134 epoch 29 - iter 40/107 - loss 0.06056580 - samples/sec: 195.99 - lr: 0.001563
2022-03-26 23:19:54,750 epoch 29 - iter 50/107 - loss 0.06179278 - samples/sec: 198.14 - lr: 0.001563
2022-03-26 23:19:56,297 epoch 29 - iter 60/107 - loss 0.06490128 - samples/sec: 206.95 - lr: 0.001563
2022-03-26 23:19:57,843 epoch 29 - iter 70/107 - loss 0.06628140 - samples/sec: 207.09 - lr: 0.001563
2022-03-26 23:19:59,384 epoch 29 - iter 80/107 - loss 0.06391094 - samples/sec: 207.81 - lr: 0.001563
2022-03-26 23:20:00,954 epoch 29 - iter 90/107 - loss 0.06432236 - samples/sec: 203.90 - lr: 0.001563
2022-03-26 23:20:02,473 epoch 29 - iter 100/107 - loss 0.06469622 - samples/sec: 210.80 - lr: 0.001563
2022-03-26 23:20:03,377 ----------------------------------------------------------------------------------------------------
2022-03-26 23:20:03,377 EPOCH 29 done: loss 0.0648 - lr 0.001563
2022-03-26 23:20:08,909 Evaluating as a multi-label problem: False
2022-03-26 23:20:08,920 DEV : loss 0.20199693739414215 - f1-score (micro avg)  0.5098
2022-03-26 23:20:08,994 BAD EPOCHS (no improvement): 2
2022-03-26 23:20:08,997 ----------------------------------------------------------------------------------------------------
2022-03-26 23:20:10,737 epoch 30 - iter 10/107 - loss 0.06757881 - samples/sec: 184.15 - lr: 0.001563
2022-03-26 23:20:12,254 epoch 30 - iter 20/107 - loss 0.06489767 - samples/sec: 211.04 - lr: 0.001563
2022-03-26 23:20:13,727 epoch 30 - iter 30/107 - loss 0.06551280 - samples/sec: 217.29 - lr: 0.001563
2022-03-26 23:20:15,246 epoch 30 - iter 40/107 - loss 0.06470107 - samples/sec: 210.88 - lr: 0.001563
2022-03-26 23:20:16,777 epoch 30 - iter 50/107 - loss 0.06630105 - samples/sec: 209.15 - lr: 0.001563
2022-03-26 23:20:18,289 epoch 30 - iter 60/107 - loss 0.06328682 - samples/sec: 211.74 - lr: 0.001563
2022-03-26 23:20:19,789 epoch 30 - iter 70/107 - loss 0.06462339 - samples/sec: 213.46 - lr: 0.001563
2022-03-26 23:20:21,416 epoch 30 - iter 80/107 - loss 0.06522840 - samples/sec: 196.81 - lr: 0.001563
2022-03-26 23:20:22,938 epoch 30 - iter 90/107 - loss 0.06552755 - samples/sec: 210.35 - lr: 0.001563
2022-03-26 23:20:24,538 epoch 30 - iter 100/107 - loss 0.06636235 - samples/sec: 200.09 - lr: 0.001563
2022-03-26 23:20:25,475 ----------------------------------------------------------------------------------------------------
2022-03-26 23:20:25,475 EPOCH 30 done: loss 0.0664 - lr 0.001563
2022-03-26 23:20:31,010 Evaluating as a multi-label problem: False
2022-03-26 23:20:31,021 DEV : loss 0.2045513242483139 - f1-score (micro avg)  0.5036
2022-03-26 23:20:31,096 BAD EPOCHS (no improvement): 3
2022-03-26 23:20:31,099 ----------------------------------------------------------------------------------------------------
2022-03-26 23:20:32,768 epoch 31 - iter 10/107 - loss 0.06400306 - samples/sec: 191.86 - lr: 0.001563
2022-03-26 23:20:34,405 epoch 31 - iter 20/107 - loss 0.06245500 - samples/sec: 195.63 - lr: 0.001563
2022-03-26 23:20:35,903 epoch 31 - iter 30/107 - loss 0.06340772 - samples/sec: 213.76 - lr: 0.001563
2022-03-26 23:20:37,432 epoch 31 - iter 40/107 - loss 0.06455346 - samples/sec: 209.32 - lr: 0.001563
2022-03-26 23:20:39,035 epoch 31 - iter 50/107 - loss 0.06486508 - samples/sec: 199.77 - lr: 0.001563
2022-03-26 23:20:40,627 epoch 31 - iter 60/107 - loss 0.06539045 - samples/sec: 201.13 - lr: 0.001563
2022-03-26 23:20:42,162 epoch 31 - iter 70/107 - loss 0.06488092 - samples/sec: 208.52 - lr: 0.001563
2022-03-26 23:20:43,731 epoch 31 - iter 80/107 - loss 0.06592825 - samples/sec: 204.16 - lr: 0.001563
2022-03-26 23:20:45,236 epoch 31 - iter 90/107 - loss 0.06637023 - samples/sec: 212.76 - lr: 0.001563
2022-03-26 23:20:46,718 epoch 31 - iter 100/107 - loss 0.06501900 - samples/sec: 216.03 - lr: 0.001563
2022-03-26 23:20:47,626 ----------------------------------------------------------------------------------------------------
2022-03-26 23:20:47,626 EPOCH 31 done: loss 0.0656 - lr 0.001563
2022-03-26 23:20:52,867 Evaluating as a multi-label problem: False
2022-03-26 23:20:52,878 DEV : loss 0.20273475348949432 - f1-score (micro avg)  0.5067
2022-03-26 23:20:52,955 Epoch    31: reducing learning rate of group 0 to 7.8125e-04.
2022-03-26 23:20:52,955 BAD EPOCHS (no improvement): 4
2022-03-26 23:20:52,958 ----------------------------------------------------------------------------------------------------
2022-03-26 23:20:54,534 epoch 32 - iter 10/107 - loss 0.08320974 - samples/sec: 203.22 - lr: 0.000781
2022-03-26 23:20:56,058 epoch 32 - iter 20/107 - loss 0.07285998 - samples/sec: 210.18 - lr: 0.000781
2022-03-26 23:20:57,545 epoch 32 - iter 30/107 - loss 0.06991812 - samples/sec: 215.39 - lr: 0.000781
2022-03-26 23:20:59,008 epoch 32 - iter 40/107 - loss 0.06678844 - samples/sec: 218.76 - lr: 0.000781
2022-03-26 23:21:00,518 epoch 32 - iter 50/107 - loss 0.06739520 - samples/sec: 212.14 - lr: 0.000781
2022-03-26 23:21:02,085 epoch 32 - iter 60/107 - loss 0.06659717 - samples/sec: 204.31 - lr: 0.000781
2022-03-26 23:21:03,650 epoch 32 - iter 70/107 - loss 0.06596984 - samples/sec: 204.59 - lr: 0.000781
2022-03-26 23:21:05,189 epoch 32 - iter 80/107 - loss 0.06310754 - samples/sec: 208.04 - lr: 0.000781
2022-03-26 23:21:06,720 epoch 32 - iter 90/107 - loss 0.06362205 - samples/sec: 209.11 - lr: 0.000781
2022-03-26 23:21:08,233 epoch 32 - iter 100/107 - loss 0.06341885 - samples/sec: 211.61 - lr: 0.000781
2022-03-26 23:21:09,195 ----------------------------------------------------------------------------------------------------
2022-03-26 23:21:09,195 EPOCH 32 done: loss 0.0638 - lr 0.000781
2022-03-26 23:21:14,781 Evaluating as a multi-label problem: False
2022-03-26 23:21:14,792 DEV : loss 0.2047266662120819 - f1-score (micro avg)  0.4996
2022-03-26 23:21:14,866 BAD EPOCHS (no improvement): 1
2022-03-26 23:21:14,869 ----------------------------------------------------------------------------------------------------
2022-03-26 23:21:16,659 epoch 33 - iter 10/107 - loss 0.05688926 - samples/sec: 178.89 - lr: 0.000781
2022-03-26 23:21:18,330 epoch 33 - iter 20/107 - loss 0.05593423 - samples/sec: 191.63 - lr: 0.000781
2022-03-26 23:21:19,904 epoch 33 - iter 30/107 - loss 0.06068433 - samples/sec: 203.46 - lr: 0.000781
2022-03-26 23:21:21,510 epoch 33 - iter 40/107 - loss 0.06175393 - samples/sec: 199.35 - lr: 0.000781
2022-03-26 23:21:23,053 epoch 33 - iter 50/107 - loss 0.06233757 - samples/sec: 207.58 - lr: 0.000781
2022-03-26 23:21:24,585 epoch 33 - iter 60/107 - loss 0.06204960 - samples/sec: 208.91 - lr: 0.000781
2022-03-26 23:21:26,120 epoch 33 - iter 70/107 - loss 0.06442891 - samples/sec: 208.61 - lr: 0.000781
2022-03-26 23:21:27,709 epoch 33 - iter 80/107 - loss 0.06467495 - samples/sec: 201.53 - lr: 0.000781
2022-03-26 23:21:29,247 epoch 33 - iter 90/107 - loss 0.06466502 - samples/sec: 208.16 - lr: 0.000781
2022-03-26 23:21:30,749 epoch 33 - iter 100/107 - loss 0.06490918 - samples/sec: 213.15 - lr: 0.000781
2022-03-26 23:21:31,700 ----------------------------------------------------------------------------------------------------
2022-03-26 23:21:31,700 EPOCH 33 done: loss 0.0645 - lr 0.000781
2022-03-26 23:21:37,260 Evaluating as a multi-label problem: False
2022-03-26 23:21:37,271 DEV : loss 0.2039058804512024 - f1-score (micro avg)  0.5004
2022-03-26 23:21:37,344 BAD EPOCHS (no improvement): 2
2022-03-26 23:21:37,347 ----------------------------------------------------------------------------------------------------
2022-03-26 23:21:38,963 epoch 34 - iter 10/107 - loss 0.06294985 - samples/sec: 198.19 - lr: 0.000781
2022-03-26 23:21:40,514 epoch 34 - iter 20/107 - loss 0.06231904 - samples/sec: 206.43 - lr: 0.000781
2022-03-26 23:21:42,100 epoch 34 - iter 30/107 - loss 0.05847572 - samples/sec: 201.92 - lr: 0.000781
2022-03-26 23:21:43,655 epoch 34 - iter 40/107 - loss 0.06057221 - samples/sec: 205.97 - lr: 0.000781
2022-03-26 23:21:45,127 epoch 34 - iter 50/107 - loss 0.06173303 - samples/sec: 217.49 - lr: 0.000781
2022-03-26 23:21:46,681 epoch 34 - iter 60/107 - loss 0.06243075 - samples/sec: 206.10 - lr: 0.000781
2022-03-26 23:21:48,297 epoch 34 - iter 70/107 - loss 0.06342417 - samples/sec: 198.13 - lr: 0.000781
2022-03-26 23:21:49,846 epoch 34 - iter 80/107 - loss 0.06279862 - samples/sec: 206.73 - lr: 0.000781
2022-03-26 23:21:51,369 epoch 34 - iter 90/107 - loss 0.06340813 - samples/sec: 210.22 - lr: 0.000781
2022-03-26 23:21:52,959 epoch 34 - iter 100/107 - loss 0.06388389 - samples/sec: 201.38 - lr: 0.000781
2022-03-26 23:21:53,928 ----------------------------------------------------------------------------------------------------
2022-03-26 23:21:53,929 EPOCH 34 done: loss 0.0638 - lr 0.000781
2022-03-26 23:21:59,467 Evaluating as a multi-label problem: False
2022-03-26 23:21:59,478 DEV : loss 0.2031182199716568 - f1-score (micro avg)  0.5031
2022-03-26 23:21:59,555 BAD EPOCHS (no improvement): 3
2022-03-26 23:21:59,558 ----------------------------------------------------------------------------------------------------
2022-03-26 23:22:01,205 epoch 35 - iter 10/107 - loss 0.06232934 - samples/sec: 194.47 - lr: 0.000781
2022-03-26 23:22:02,770 epoch 35 - iter 20/107 - loss 0.06422417 - samples/sec: 204.57 - lr: 0.000781
2022-03-26 23:22:04,438 epoch 35 - iter 30/107 - loss 0.06453499 - samples/sec: 191.90 - lr: 0.000781
2022-03-26 23:22:05,938 epoch 35 - iter 40/107 - loss 0.06446353 - samples/sec: 213.50 - lr: 0.000781
2022-03-26 23:22:07,458 epoch 35 - iter 50/107 - loss 0.06481264 - samples/sec: 210.73 - lr: 0.000781
2022-03-26 23:22:09,060 epoch 35 - iter 60/107 - loss 0.06462702 - samples/sec: 199.85 - lr: 0.000781
2022-03-26 23:22:10,620 epoch 35 - iter 70/107 - loss 0.06415277 - samples/sec: 205.21 - lr: 0.000781
2022-03-26 23:22:12,174 epoch 35 - iter 80/107 - loss 0.06298343 - samples/sec: 205.97 - lr: 0.000781
2022-03-26 23:22:13,699 epoch 35 - iter 90/107 - loss 0.06360911 - samples/sec: 210.05 - lr: 0.000781
2022-03-26 23:22:15,242 epoch 35 - iter 100/107 - loss 0.06407751 - samples/sec: 207.42 - lr: 0.000781
2022-03-26 23:22:16,166 ----------------------------------------------------------------------------------------------------
2022-03-26 23:22:16,167 EPOCH 35 done: loss 0.0636 - lr 0.000781
2022-03-26 23:22:21,740 Evaluating as a multi-label problem: False
2022-03-26 23:22:21,751 DEV : loss 0.20323652029037476 - f1-score (micro avg)  0.5039
2022-03-26 23:22:21,825 Epoch    35: reducing learning rate of group 0 to 3.9063e-04.
2022-03-26 23:22:21,825 BAD EPOCHS (no improvement): 4
2022-03-26 23:22:21,828 ----------------------------------------------------------------------------------------------------
2022-03-26 23:22:23,577 epoch 36 - iter 10/107 - loss 0.06134859 - samples/sec: 183.09 - lr: 0.000391
2022-03-26 23:22:25,223 epoch 36 - iter 20/107 - loss 0.05910012 - samples/sec: 194.52 - lr: 0.000391
2022-03-26 23:22:26,761 epoch 36 - iter 30/107 - loss 0.05767548 - samples/sec: 208.27 - lr: 0.000391
2022-03-26 23:22:28,280 epoch 36 - iter 40/107 - loss 0.05812700 - samples/sec: 210.72 - lr: 0.000391
2022-03-26 23:22:29,782 epoch 36 - iter 50/107 - loss 0.05822547 - samples/sec: 213.22 - lr: 0.000391
2022-03-26 23:22:31,307 epoch 36 - iter 60/107 - loss 0.05924529 - samples/sec: 209.92 - lr: 0.000391
2022-03-26 23:22:32,935 epoch 36 - iter 70/107 - loss 0.05977176 - samples/sec: 196.73 - lr: 0.000391
2022-03-26 23:22:34,507 epoch 36 - iter 80/107 - loss 0.06070038 - samples/sec: 203.79 - lr: 0.000391
2022-03-26 23:22:36,055 epoch 36 - iter 90/107 - loss 0.06090126 - samples/sec: 206.81 - lr: 0.000391
2022-03-26 23:22:37,684 epoch 36 - iter 100/107 - loss 0.06325829 - samples/sec: 196.55 - lr: 0.000391
2022-03-26 23:22:38,655 ----------------------------------------------------------------------------------------------------
2022-03-26 23:22:38,655 EPOCH 36 done: loss 0.0641 - lr 0.000391
2022-03-26 23:22:44,234 Evaluating as a multi-label problem: False
2022-03-26 23:22:44,245 DEV : loss 0.20346827805042267 - f1-score (micro avg)  0.5016
2022-03-26 23:22:44,319 BAD EPOCHS (no improvement): 1
2022-03-26 23:22:44,322 ----------------------------------------------------------------------------------------------------
2022-03-26 23:22:45,927 epoch 37 - iter 10/107 - loss 0.06953393 - samples/sec: 199.66 - lr: 0.000391
2022-03-26 23:22:47,502 epoch 37 - iter 20/107 - loss 0.06998473 - samples/sec: 203.22 - lr: 0.000391
2022-03-26 23:22:49,055 epoch 37 - iter 30/107 - loss 0.06554520 - samples/sec: 206.19 - lr: 0.000391
2022-03-26 23:22:50,555 epoch 37 - iter 40/107 - loss 0.06619285 - samples/sec: 213.56 - lr: 0.000391
2022-03-26 23:22:52,185 epoch 37 - iter 50/107 - loss 0.06666177 - samples/sec: 196.36 - lr: 0.000391
2022-03-26 23:22:53,834 epoch 37 - iter 60/107 - loss 0.06555828 - samples/sec: 194.22 - lr: 0.000391
2022-03-26 23:22:55,404 epoch 37 - iter 70/107 - loss 0.06482028 - samples/sec: 203.89 - lr: 0.000391
2022-03-26 23:22:56,983 epoch 37 - iter 80/107 - loss 0.06329441 - samples/sec: 202.84 - lr: 0.000391
2022-03-26 23:22:58,538 epoch 37 - iter 90/107 - loss 0.06230464 - samples/sec: 205.81 - lr: 0.000391
2022-03-26 23:23:00,109 epoch 37 - iter 100/107 - loss 0.06213653 - samples/sec: 203.86 - lr: 0.000391
2022-03-26 23:23:01,059 ----------------------------------------------------------------------------------------------------
2022-03-26 23:23:01,059 EPOCH 37 done: loss 0.0621 - lr 0.000391
2022-03-26 23:23:06,629 Evaluating as a multi-label problem: False
2022-03-26 23:23:06,639 DEV : loss 0.20415180921554565 - f1-score (micro avg)  0.5032
2022-03-26 23:23:06,713 BAD EPOCHS (no improvement): 2
2022-03-26 23:23:06,716 ----------------------------------------------------------------------------------------------------
2022-03-26 23:23:08,367 epoch 38 - iter 10/107 - loss 0.07343389 - samples/sec: 193.97 - lr: 0.000391
2022-03-26 23:23:10,030 epoch 38 - iter 20/107 - loss 0.06672148 - samples/sec: 192.57 - lr: 0.000391
2022-03-26 23:23:11,595 epoch 38 - iter 30/107 - loss 0.06501383 - samples/sec: 204.51 - lr: 0.000391
2022-03-26 23:23:13,131 epoch 38 - iter 40/107 - loss 0.06584524 - samples/sec: 208.52 - lr: 0.000391
2022-03-26 23:23:14,707 epoch 38 - iter 50/107 - loss 0.06568127 - samples/sec: 203.21 - lr: 0.000391
2022-03-26 23:23:16,282 epoch 38 - iter 60/107 - loss 0.06610078 - samples/sec: 203.29 - lr: 0.000391
2022-03-26 23:23:17,802 epoch 38 - iter 70/107 - loss 0.06523893 - samples/sec: 210.58 - lr: 0.000391
2022-03-26 23:23:19,300 epoch 38 - iter 80/107 - loss 0.06394893 - samples/sec: 213.80 - lr: 0.000391
2022-03-26 23:23:20,825 epoch 38 - iter 90/107 - loss 0.06309698 - samples/sec: 209.96 - lr: 0.000391
2022-03-26 23:23:22,396 epoch 38 - iter 100/107 - loss 0.06484467 - samples/sec: 203.82 - lr: 0.000391
2022-03-26 23:23:23,360 ----------------------------------------------------------------------------------------------------
2022-03-26 23:23:23,360 EPOCH 38 done: loss 0.0643 - lr 0.000391
2022-03-26 23:23:28,966 Evaluating as a multi-label problem: False
2022-03-26 23:23:28,977 DEV : loss 0.20293325185775757 - f1-score (micro avg)  0.5031
2022-03-26 23:23:29,051 BAD EPOCHS (no improvement): 3
2022-03-26 23:23:29,054 ----------------------------------------------------------------------------------------------------
2022-03-26 23:23:30,730 epoch 39 - iter 10/107 - loss 0.05077636 - samples/sec: 191.14 - lr: 0.000391
2022-03-26 23:23:32,313 epoch 39 - iter 20/107 - loss 0.05459805 - samples/sec: 202.30 - lr: 0.000391
2022-03-26 23:23:33,917 epoch 39 - iter 30/107 - loss 0.05715063 - samples/sec: 199.51 - lr: 0.000391
2022-03-26 23:23:35,468 epoch 39 - iter 40/107 - loss 0.05749188 - samples/sec: 206.53 - lr: 0.000391
2022-03-26 23:23:37,020 epoch 39 - iter 50/107 - loss 0.05955368 - samples/sec: 206.35 - lr: 0.000391
2022-03-26 23:23:38,574 epoch 39 - iter 60/107 - loss 0.06020280 - samples/sec: 205.96 - lr: 0.000391
2022-03-26 23:23:40,187 epoch 39 - iter 70/107 - loss 0.06143466 - samples/sec: 198.50 - lr: 0.000391
2022-03-26 23:23:41,758 epoch 39 - iter 80/107 - loss 0.06249956 - samples/sec: 203.79 - lr: 0.000391
2022-03-26 23:23:43,403 epoch 39 - iter 90/107 - loss 0.06322888 - samples/sec: 194.66 - lr: 0.000391
2022-03-26 23:23:44,975 epoch 39 - iter 100/107 - loss 0.06246938 - samples/sec: 203.70 - lr: 0.000391
2022-03-26 23:23:45,987 ----------------------------------------------------------------------------------------------------
2022-03-26 23:23:45,987 EPOCH 39 done: loss 0.0625 - lr 0.000391
2022-03-26 23:23:51,592 Evaluating as a multi-label problem: False
2022-03-26 23:23:51,602 DEV : loss 0.2028830349445343 - f1-score (micro avg)  0.5027
2022-03-26 23:23:51,677 Epoch    39: reducing learning rate of group 0 to 1.9531e-04.
2022-03-26 23:23:51,677 BAD EPOCHS (no improvement): 4
2022-03-26 23:23:51,680 ----------------------------------------------------------------------------------------------------
2022-03-26 23:23:53,296 epoch 40 - iter 10/107 - loss 0.07611829 - samples/sec: 198.10 - lr: 0.000195
2022-03-26 23:23:54,856 epoch 40 - iter 20/107 - loss 0.06499243 - samples/sec: 205.31 - lr: 0.000195
2022-03-26 23:23:56,431 epoch 40 - iter 30/107 - loss 0.06473595 - samples/sec: 203.32 - lr: 0.000195
2022-03-26 23:23:58,078 epoch 40 - iter 40/107 - loss 0.06263958 - samples/sec: 194.40 - lr: 0.000195
2022-03-26 23:23:59,684 epoch 40 - iter 50/107 - loss 0.06312911 - samples/sec: 199.37 - lr: 0.000195
2022-03-26 23:24:01,278 epoch 40 - iter 60/107 - loss 0.06171246 - samples/sec: 200.82 - lr: 0.000195
2022-03-26 23:24:02,803 epoch 40 - iter 70/107 - loss 0.06231128 - samples/sec: 209.94 - lr: 0.000195
2022-03-26 23:24:04,342 epoch 40 - iter 80/107 - loss 0.06307779 - samples/sec: 208.04 - lr: 0.000195
2022-03-26 23:24:05,927 epoch 40 - iter 90/107 - loss 0.06351562 - samples/sec: 202.05 - lr: 0.000195
2022-03-26 23:24:07,506 epoch 40 - iter 100/107 - loss 0.06305019 - samples/sec: 202.73 - lr: 0.000195
2022-03-26 23:24:08,481 ----------------------------------------------------------------------------------------------------
2022-03-26 23:24:08,482 EPOCH 40 done: loss 0.0632 - lr 0.000195
2022-03-26 23:24:14,054 Evaluating as a multi-label problem: False
2022-03-26 23:24:14,065 DEV : loss 0.2034408003091812 - f1-score (micro avg)  0.5028
2022-03-26 23:24:14,140 BAD EPOCHS (no improvement): 1
2022-03-26 23:24:14,143 ----------------------------------------------------------------------------------------------------
2022-03-26 23:24:15,810 epoch 41 - iter 10/107 - loss 0.05381080 - samples/sec: 192.18 - lr: 0.000195
2022-03-26 23:24:17,389 epoch 41 - iter 20/107 - loss 0.05932677 - samples/sec: 202.83 - lr: 0.000195
2022-03-26 23:24:18,982 epoch 41 - iter 30/107 - loss 0.05855063 - samples/sec: 200.92 - lr: 0.000195
2022-03-26 23:24:20,556 epoch 41 - iter 40/107 - loss 0.06201725 - samples/sec: 203.51 - lr: 0.000195
2022-03-26 23:24:22,128 epoch 41 - iter 50/107 - loss 0.06162736 - samples/sec: 203.59 - lr: 0.000195
2022-03-26 23:24:23,717 epoch 41 - iter 60/107 - loss 0.05963629 - samples/sec: 201.57 - lr: 0.000195
2022-03-26 23:24:25,264 epoch 41 - iter 70/107 - loss 0.06208002 - samples/sec: 206.95 - lr: 0.000195
2022-03-26 23:24:28,385 epoch 41 - iter 80/107 - loss 0.06031030 - samples/sec: 102.56 - lr: 0.000195
2022-03-26 23:24:30,054 epoch 41 - iter 90/107 - loss 0.06199831 - samples/sec: 191.77 - lr: 0.000195
2022-03-26 23:24:31,649 epoch 41 - iter 100/107 - loss 0.06259064 - samples/sec: 200.77 - lr: 0.000195
2022-03-26 23:24:32,615 ----------------------------------------------------------------------------------------------------
2022-03-26 23:24:32,615 EPOCH 41 done: loss 0.0622 - lr 0.000195
2022-03-26 23:24:38,193 Evaluating as a multi-label problem: False
2022-03-26 23:24:38,204 DEV : loss 0.20342743396759033 - f1-score (micro avg)  0.502
2022-03-26 23:24:38,277 BAD EPOCHS (no improvement): 2
2022-03-26 23:24:38,280 ----------------------------------------------------------------------------------------------------
2022-03-26 23:24:39,937 epoch 42 - iter 10/107 - loss 0.07402464 - samples/sec: 193.34 - lr: 0.000195
2022-03-26 23:24:41,527 epoch 42 - iter 20/107 - loss 0.06496583 - samples/sec: 201.38 - lr: 0.000195
2022-03-26 23:24:43,112 epoch 42 - iter 30/107 - loss 0.06787979 - samples/sec: 202.03 - lr: 0.000195
2022-03-26 23:24:44,652 epoch 42 - iter 40/107 - loss 0.06383310 - samples/sec: 207.83 - lr: 0.000195
2022-03-26 23:24:46,148 epoch 42 - iter 50/107 - loss 0.06351317 - samples/sec: 214.02 - lr: 0.000195
2022-03-26 23:24:47,674 epoch 42 - iter 60/107 - loss 0.06275084 - samples/sec: 209.92 - lr: 0.000195
2022-03-26 23:24:49,289 epoch 42 - iter 70/107 - loss 0.06233782 - samples/sec: 198.16 - lr: 0.000195
2022-03-26 23:24:50,889 epoch 42 - iter 80/107 - loss 0.06160205 - samples/sec: 200.21 - lr: 0.000195
2022-03-26 23:24:52,499 epoch 42 - iter 90/107 - loss 0.06153108 - samples/sec: 198.79 - lr: 0.000195
2022-03-26 23:24:54,099 epoch 42 - iter 100/107 - loss 0.06176695 - samples/sec: 200.13 - lr: 0.000195
2022-03-26 23:24:55,044 ----------------------------------------------------------------------------------------------------
2022-03-26 23:24:55,044 EPOCH 42 done: loss 0.0615 - lr 0.000195
2022-03-26 23:25:00,650 Evaluating as a multi-label problem: False
2022-03-26 23:25:00,661 DEV : loss 0.20328718423843384 - f1-score (micro avg)  0.5035
2022-03-26 23:25:00,734 BAD EPOCHS (no improvement): 3
2022-03-26 23:25:00,737 ----------------------------------------------------------------------------------------------------
2022-03-26 23:25:02,412 epoch 43 - iter 10/107 - loss 0.07651282 - samples/sec: 191.36 - lr: 0.000195
2022-03-26 23:25:03,989 epoch 43 - iter 20/107 - loss 0.07264766 - samples/sec: 203.04 - lr: 0.000195
2022-03-26 23:25:05,558 epoch 43 - iter 30/107 - loss 0.06680270 - samples/sec: 204.08 - lr: 0.000195
2022-03-26 23:25:07,075 epoch 43 - iter 40/107 - loss 0.07059040 - samples/sec: 211.10 - lr: 0.000195
2022-03-26 23:25:08,579 epoch 43 - iter 50/107 - loss 0.06961135 - samples/sec: 212.86 - lr: 0.000195
2022-03-26 23:25:10,124 epoch 43 - iter 60/107 - loss 0.06549904 - samples/sec: 207.27 - lr: 0.000195
2022-03-26 23:25:11,746 epoch 43 - iter 70/107 - loss 0.06468110 - samples/sec: 197.30 - lr: 0.000195
2022-03-26 23:25:13,289 epoch 43 - iter 80/107 - loss 0.06431237 - samples/sec: 207.61 - lr: 0.000195
2022-03-26 23:25:14,866 epoch 43 - iter 90/107 - loss 0.06333890 - samples/sec: 203.05 - lr: 0.000195
2022-03-26 23:25:16,516 epoch 43 - iter 100/107 - loss 0.06263504 - samples/sec: 193.96 - lr: 0.000195
2022-03-26 23:25:17,489 ----------------------------------------------------------------------------------------------------
2022-03-26 23:25:17,489 EPOCH 43 done: loss 0.0631 - lr 0.000195
2022-03-26 23:25:23,086 Evaluating as a multi-label problem: False
2022-03-26 23:25:23,097 DEV : loss 0.2037125825881958 - f1-score (micro avg)  0.502
2022-03-26 23:25:23,171 Epoch    43: reducing learning rate of group 0 to 9.7656e-05.
2022-03-26 23:25:23,171 BAD EPOCHS (no improvement): 4
2022-03-26 23:25:23,174 ----------------------------------------------------------------------------------------------------
2022-03-26 23:25:23,174 ----------------------------------------------------------------------------------------------------
2022-03-26 23:25:23,174 learning rate too small - quitting training!
2022-03-26 23:25:23,174 ----------------------------------------------------------------------------------------------------
2022-03-26 23:25:47,075 ----------------------------------------------------------------------------------------------------
2022-03-26 23:25:47,076 loading file resources/taggers/model_04_r5_run_3/best-model.pt
2022-03-26 23:26:01,610 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-03-26 23:26:19,466 Evaluating as a multi-label problem: False
2022-03-26 23:26:19,479 0.5318	0.2947	0.3792	0.2544
2022-03-26 23:26:19,479 
Results:
- F-score (micro) 0.3792
- F-score (macro) 0.1915
- Accuracy 0.2544

By class:
               precision    recall  f1-score   support

       person     0.5245    0.5734    0.5479       429
     location     0.6091    0.4467    0.5154       150
        group     0.5000    0.0182    0.0351       165
creative-work     0.0000    0.0000    0.0000       142
      product     0.0000    0.0000    0.0000       127
  corporation     0.1538    0.0303    0.0506        66

    micro avg     0.5318    0.2947    0.3792      1079
    macro avg     0.2979    0.1781    0.1915      1079
 weighted avg     0.3791    0.2947    0.2979      1079

2022-03-26 23:26:19,479 ----------------------------------------------------------------------------------------------------
