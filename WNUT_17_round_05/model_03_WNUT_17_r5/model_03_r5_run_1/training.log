2022-03-26 21:40:43,054 ----------------------------------------------------------------------------------------------------
2022-03-26 21:40:43,054 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4922, out_features=4922, bias=True)
  (rnn): LSTM(4922, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-03-26 21:40:43,055 ----------------------------------------------------------------------------------------------------
2022-03-26 21:40:43,055 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-03-26 21:40:43,055 ----------------------------------------------------------------------------------------------------
2022-03-26 21:40:43,055 Parameters:
2022-03-26 21:40:43,057  - learning_rate: "0.100000"
2022-03-26 21:40:43,057  - mini_batch_size: "32"
2022-03-26 21:40:43,058  - patience: "3"
2022-03-26 21:40:43,058  - anneal_factor: "0.5"
2022-03-26 21:40:43,058  - max_epochs: "150"
2022-03-26 21:40:43,058  - shuffle: "True"
2022-03-26 21:40:43,058  - train_with_dev: "False"
2022-03-26 21:40:43,058  - batch_growth_annealing: "False"
2022-03-26 21:40:43,058 ----------------------------------------------------------------------------------------------------
2022-03-26 21:40:43,058 Model training base path: "resources/taggers/model_03_r5_run_1"
2022-03-26 21:40:43,058 ----------------------------------------------------------------------------------------------------
2022-03-26 21:40:43,058 Device: cuda:2
2022-03-26 21:40:43,059 ----------------------------------------------------------------------------------------------------
2022-03-26 21:40:43,059 Embeddings storage mode: cpu
2022-03-26 21:40:43,059 ----------------------------------------------------------------------------------------------------
2022-03-26 21:40:46,483 epoch 1 - iter 10/107 - loss 1.24374309 - samples/sec: 93.51 - lr: 0.100000
2022-03-26 21:40:49,953 epoch 1 - iter 20/107 - loss 0.76900354 - samples/sec: 92.23 - lr: 0.100000
2022-03-26 21:40:53,470 epoch 1 - iter 30/107 - loss 0.61032712 - samples/sec: 91.02 - lr: 0.100000
2022-03-26 21:40:56,965 epoch 1 - iter 40/107 - loss 0.52298429 - samples/sec: 91.58 - lr: 0.100000
2022-03-26 21:41:00,467 epoch 1 - iter 50/107 - loss 0.46354480 - samples/sec: 91.41 - lr: 0.100000
2022-03-26 21:41:03,973 epoch 1 - iter 60/107 - loss 0.43376870 - samples/sec: 91.32 - lr: 0.100000
2022-03-26 21:41:07,510 epoch 1 - iter 70/107 - loss 0.41206228 - samples/sec: 90.50 - lr: 0.100000
2022-03-26 21:41:10,843 epoch 1 - iter 80/107 - loss 0.40115143 - samples/sec: 96.02 - lr: 0.100000
2022-03-26 21:41:13,964 epoch 1 - iter 90/107 - loss 0.39162719 - samples/sec: 102.56 - lr: 0.100000
2022-03-26 21:41:17,323 epoch 1 - iter 100/107 - loss 0.38169666 - samples/sec: 95.31 - lr: 0.100000
2022-03-26 21:41:19,327 ----------------------------------------------------------------------------------------------------
2022-03-26 21:41:19,327 EPOCH 1 done: loss 0.3729 - lr 0.100000
2022-03-26 21:41:31,370 Evaluating as a multi-label problem: False
2022-03-26 21:41:31,382 DEV : loss 0.35804349184036255 - f1-score (micro avg)  0.2829
2022-03-26 21:41:31,450 BAD EPOCHS (no improvement): 0
2022-03-26 21:41:31,453 saving best model
2022-03-26 21:42:07,051 ----------------------------------------------------------------------------------------------------
2022-03-26 21:42:13,366 epoch 2 - iter 10/107 - loss 0.16401820 - samples/sec: 50.69 - lr: 0.100000
2022-03-26 21:42:15,705 epoch 2 - iter 20/107 - loss 0.19171840 - samples/sec: 136.86 - lr: 0.100000
2022-03-26 21:42:18,124 epoch 2 - iter 30/107 - loss 0.19197439 - samples/sec: 132.36 - lr: 0.100000
2022-03-26 21:42:20,560 epoch 2 - iter 40/107 - loss 0.20391679 - samples/sec: 131.38 - lr: 0.100000
2022-03-26 21:42:22,982 epoch 2 - iter 50/107 - loss 0.20365683 - samples/sec: 132.18 - lr: 0.100000
2022-03-26 21:42:25,392 epoch 2 - iter 60/107 - loss 0.19945440 - samples/sec: 132.84 - lr: 0.100000
2022-03-26 21:42:27,850 epoch 2 - iter 70/107 - loss 0.20021276 - samples/sec: 130.27 - lr: 0.100000
2022-03-26 21:42:30,304 epoch 2 - iter 80/107 - loss 0.19753350 - samples/sec: 130.45 - lr: 0.100000
2022-03-26 21:42:32,534 epoch 2 - iter 90/107 - loss 0.19936311 - samples/sec: 143.53 - lr: 0.100000
2022-03-26 21:42:34,941 epoch 2 - iter 100/107 - loss 0.19639009 - samples/sec: 133.02 - lr: 0.100000
2022-03-26 21:42:36,413 ----------------------------------------------------------------------------------------------------
2022-03-26 21:42:36,413 EPOCH 2 done: loss 0.1972 - lr 0.100000
2022-03-26 21:42:43,826 Evaluating as a multi-label problem: False
2022-03-26 21:42:43,837 DEV : loss 0.3179571330547333 - f1-score (micro avg)  0.3597
2022-03-26 21:42:43,909 BAD EPOCHS (no improvement): 0
2022-03-26 21:42:43,912 saving best model
2022-03-26 21:43:19,937 ----------------------------------------------------------------------------------------------------
2022-03-26 21:43:22,762 epoch 3 - iter 10/107 - loss 0.15088024 - samples/sec: 113.37 - lr: 0.100000
2022-03-26 21:43:25,476 epoch 3 - iter 20/107 - loss 0.16422300 - samples/sec: 117.96 - lr: 0.100000
2022-03-26 21:43:28,128 epoch 3 - iter 30/107 - loss 0.17082744 - samples/sec: 120.71 - lr: 0.100000
2022-03-26 21:43:30,935 epoch 3 - iter 40/107 - loss 0.16734925 - samples/sec: 114.06 - lr: 0.100000
2022-03-26 21:43:33,623 epoch 3 - iter 50/107 - loss 0.16286997 - samples/sec: 119.11 - lr: 0.100000
2022-03-26 21:43:36,376 epoch 3 - iter 60/107 - loss 0.15981949 - samples/sec: 116.31 - lr: 0.100000
2022-03-26 21:43:39,207 epoch 3 - iter 70/107 - loss 0.16109454 - samples/sec: 113.09 - lr: 0.100000
2022-03-26 21:43:41,863 epoch 3 - iter 80/107 - loss 0.16181684 - samples/sec: 120.54 - lr: 0.100000
2022-03-26 21:43:44,512 epoch 3 - iter 90/107 - loss 0.16506964 - samples/sec: 120.83 - lr: 0.100000
2022-03-26 21:43:47,249 epoch 3 - iter 100/107 - loss 0.16382244 - samples/sec: 116.99 - lr: 0.100000
2022-03-26 21:43:48,884 ----------------------------------------------------------------------------------------------------
2022-03-26 21:43:48,884 EPOCH 3 done: loss 0.1642 - lr 0.100000
2022-03-26 21:43:57,689 Evaluating as a multi-label problem: False
2022-03-26 21:43:57,701 DEV : loss 0.32350897789001465 - f1-score (micro avg)  0.3409
2022-03-26 21:43:57,797 BAD EPOCHS (no improvement): 1
2022-03-26 21:43:57,800 ----------------------------------------------------------------------------------------------------
2022-03-26 21:44:00,605 epoch 4 - iter 10/107 - loss 0.16422964 - samples/sec: 114.17 - lr: 0.100000
2022-03-26 21:44:03,411 epoch 4 - iter 20/107 - loss 0.15086569 - samples/sec: 114.08 - lr: 0.100000
2022-03-26 21:44:06,097 epoch 4 - iter 30/107 - loss 0.15492997 - samples/sec: 119.17 - lr: 0.100000
2022-03-26 21:44:08,742 epoch 4 - iter 40/107 - loss 0.15399951 - samples/sec: 121.01 - lr: 0.100000
2022-03-26 21:44:11,394 epoch 4 - iter 50/107 - loss 0.15691554 - samples/sec: 120.73 - lr: 0.100000
2022-03-26 21:44:14,143 epoch 4 - iter 60/107 - loss 0.15419673 - samples/sec: 116.50 - lr: 0.100000
2022-03-26 21:44:16,835 epoch 4 - iter 70/107 - loss 0.15131792 - samples/sec: 118.92 - lr: 0.100000
2022-03-26 21:44:19,501 epoch 4 - iter 80/107 - loss 0.15372363 - samples/sec: 120.05 - lr: 0.100000
2022-03-26 21:44:22,184 epoch 4 - iter 90/107 - loss 0.15245620 - samples/sec: 119.34 - lr: 0.100000
2022-03-26 21:44:24,940 epoch 4 - iter 100/107 - loss 0.14930128 - samples/sec: 116.15 - lr: 0.100000
2022-03-26 21:44:26,522 ----------------------------------------------------------------------------------------------------
2022-03-26 21:44:26,522 EPOCH 4 done: loss 0.1482 - lr 0.100000
2022-03-26 21:44:35,285 Evaluating as a multi-label problem: False
2022-03-26 21:44:35,296 DEV : loss 0.2288314402103424 - f1-score (micro avg)  0.4949
2022-03-26 21:44:35,387 BAD EPOCHS (no improvement): 0
2022-03-26 21:44:35,390 saving best model
2022-03-26 21:45:12,199 ----------------------------------------------------------------------------------------------------
2022-03-26 21:45:14,830 epoch 5 - iter 10/107 - loss 0.13073106 - samples/sec: 121.74 - lr: 0.100000
2022-03-26 21:45:17,661 epoch 5 - iter 20/107 - loss 0.13132188 - samples/sec: 113.08 - lr: 0.100000
2022-03-26 21:45:20,351 epoch 5 - iter 30/107 - loss 0.12336366 - samples/sec: 118.99 - lr: 0.100000
2022-03-26 21:45:23,055 epoch 5 - iter 40/107 - loss 0.12515756 - samples/sec: 118.43 - lr: 0.100000
2022-03-26 21:45:25,746 epoch 5 - iter 50/107 - loss 0.12487988 - samples/sec: 118.97 - lr: 0.100000
2022-03-26 21:45:28,485 epoch 5 - iter 60/107 - loss 0.12629791 - samples/sec: 116.90 - lr: 0.100000
2022-03-26 21:45:31,192 epoch 5 - iter 70/107 - loss 0.13337759 - samples/sec: 118.25 - lr: 0.100000
2022-03-26 21:45:33,835 epoch 5 - iter 80/107 - loss 0.13269513 - samples/sec: 121.10 - lr: 0.100000
2022-03-26 21:45:36,580 epoch 5 - iter 90/107 - loss 0.13467462 - samples/sec: 116.64 - lr: 0.100000
2022-03-26 21:45:39,205 epoch 5 - iter 100/107 - loss 0.13301597 - samples/sec: 121.97 - lr: 0.100000
2022-03-26 21:45:40,898 ----------------------------------------------------------------------------------------------------
2022-03-26 21:45:40,898 EPOCH 5 done: loss 0.1314 - lr 0.100000
2022-03-26 21:45:49,628 Evaluating as a multi-label problem: False
2022-03-26 21:45:49,639 DEV : loss 0.2883363664150238 - f1-score (micro avg)  0.382
2022-03-26 21:45:49,728 BAD EPOCHS (no improvement): 1
2022-03-26 21:45:49,740 ----------------------------------------------------------------------------------------------------
2022-03-26 21:45:52,356 epoch 6 - iter 10/107 - loss 0.10253163 - samples/sec: 122.42 - lr: 0.100000
2022-03-26 21:45:55,122 epoch 6 - iter 20/107 - loss 0.11061419 - samples/sec: 115.72 - lr: 0.100000
2022-03-26 21:45:57,747 epoch 6 - iter 30/107 - loss 0.10934874 - samples/sec: 121.97 - lr: 0.100000
2022-03-26 21:46:00,346 epoch 6 - iter 40/107 - loss 0.11095184 - samples/sec: 123.18 - lr: 0.100000
2022-03-26 21:46:03,117 epoch 6 - iter 50/107 - loss 0.11107631 - samples/sec: 115.53 - lr: 0.100000
2022-03-26 21:46:05,709 epoch 6 - iter 60/107 - loss 0.11579138 - samples/sec: 123.51 - lr: 0.100000
2022-03-26 21:46:08,278 epoch 6 - iter 70/107 - loss 0.11558898 - samples/sec: 124.61 - lr: 0.100000
2022-03-26 21:46:10,794 epoch 6 - iter 80/107 - loss 0.11536603 - samples/sec: 127.25 - lr: 0.100000
2022-03-26 21:46:13,244 epoch 6 - iter 90/107 - loss 0.11615505 - samples/sec: 130.67 - lr: 0.100000
2022-03-26 21:46:15,641 epoch 6 - iter 100/107 - loss 0.11842812 - samples/sec: 133.51 - lr: 0.100000
2022-03-26 21:46:16,956 ----------------------------------------------------------------------------------------------------
2022-03-26 21:46:16,956 EPOCH 6 done: loss 0.1189 - lr 0.100000
2022-03-26 21:46:24,392 Evaluating as a multi-label problem: False
2022-03-26 21:46:24,403 DEV : loss 0.2081330120563507 - f1-score (micro avg)  0.4793
2022-03-26 21:46:24,475 BAD EPOCHS (no improvement): 2
2022-03-26 21:46:24,478 ----------------------------------------------------------------------------------------------------
2022-03-26 21:46:27,009 epoch 7 - iter 10/107 - loss 0.11227783 - samples/sec: 126.48 - lr: 0.100000
2022-03-26 21:46:29,315 epoch 7 - iter 20/107 - loss 0.11504267 - samples/sec: 138.88 - lr: 0.100000
2022-03-26 21:46:31,784 epoch 7 - iter 30/107 - loss 0.10918818 - samples/sec: 129.64 - lr: 0.100000
2022-03-26 21:46:34,175 epoch 7 - iter 40/107 - loss 0.10847340 - samples/sec: 133.88 - lr: 0.100000
2022-03-26 21:46:36,548 epoch 7 - iter 50/107 - loss 0.11337395 - samples/sec: 134.92 - lr: 0.100000
2022-03-26 21:46:38,960 epoch 7 - iter 60/107 - loss 0.11059212 - samples/sec: 132.73 - lr: 0.100000
2022-03-26 21:46:41,432 epoch 7 - iter 70/107 - loss 0.11285347 - samples/sec: 129.49 - lr: 0.100000
2022-03-26 21:46:43,828 epoch 7 - iter 80/107 - loss 0.11376971 - samples/sec: 133.65 - lr: 0.100000
2022-03-26 21:46:46,298 epoch 7 - iter 90/107 - loss 0.11204617 - samples/sec: 129.57 - lr: 0.100000
2022-03-26 21:46:48,617 epoch 7 - iter 100/107 - loss 0.11373668 - samples/sec: 138.07 - lr: 0.100000
2022-03-26 21:46:50,098 ----------------------------------------------------------------------------------------------------
2022-03-26 21:46:50,098 EPOCH 7 done: loss 0.1121 - lr 0.100000
2022-03-26 21:46:57,568 Evaluating as a multi-label problem: False
2022-03-26 21:46:57,578 DEV : loss 0.25298044085502625 - f1-score (micro avg)  0.4286
2022-03-26 21:46:57,648 BAD EPOCHS (no improvement): 3
2022-03-26 21:46:57,651 ----------------------------------------------------------------------------------------------------
2022-03-26 21:47:00,070 epoch 8 - iter 10/107 - loss 0.11475674 - samples/sec: 132.35 - lr: 0.100000
2022-03-26 21:47:02,472 epoch 8 - iter 20/107 - loss 0.11572569 - samples/sec: 133.27 - lr: 0.100000
2022-03-26 21:47:04,896 epoch 8 - iter 30/107 - loss 0.11140932 - samples/sec: 132.07 - lr: 0.100000
2022-03-26 21:47:07,244 epoch 8 - iter 40/107 - loss 0.10934248 - samples/sec: 136.34 - lr: 0.100000
2022-03-26 21:47:09,695 epoch 8 - iter 50/107 - loss 0.11090250 - samples/sec: 130.61 - lr: 0.100000
2022-03-26 21:47:12,071 epoch 8 - iter 60/107 - loss 0.10869916 - samples/sec: 134.74 - lr: 0.100000
2022-03-26 21:47:14,415 epoch 8 - iter 70/107 - loss 0.10796258 - samples/sec: 136.57 - lr: 0.100000
2022-03-26 21:47:16,885 epoch 8 - iter 80/107 - loss 0.10980358 - samples/sec: 129.60 - lr: 0.100000
2022-03-26 21:47:19,297 epoch 8 - iter 90/107 - loss 0.10630120 - samples/sec: 132.77 - lr: 0.100000
2022-03-26 21:47:21,651 epoch 8 - iter 100/107 - loss 0.10547781 - samples/sec: 135.94 - lr: 0.100000
2022-03-26 21:47:23,105 ----------------------------------------------------------------------------------------------------
2022-03-26 21:47:23,105 EPOCH 8 done: loss 0.1045 - lr 0.100000
2022-03-26 21:47:30,589 Evaluating as a multi-label problem: False
2022-03-26 21:47:30,600 DEV : loss 0.2690243124961853 - f1-score (micro avg)  0.4145
2022-03-26 21:47:30,670 Epoch     8: reducing learning rate of group 0 to 5.0000e-02.
2022-03-26 21:47:30,670 BAD EPOCHS (no improvement): 4
2022-03-26 21:47:30,673 ----------------------------------------------------------------------------------------------------
2022-03-26 21:47:33,153 epoch 9 - iter 10/107 - loss 0.10024671 - samples/sec: 129.25 - lr: 0.050000
2022-03-26 21:47:35,633 epoch 9 - iter 20/107 - loss 0.09449140 - samples/sec: 129.06 - lr: 0.050000
2022-03-26 21:47:37,955 epoch 9 - iter 30/107 - loss 0.09810388 - samples/sec: 137.86 - lr: 0.050000
2022-03-26 21:47:40,336 epoch 9 - iter 40/107 - loss 0.09520692 - samples/sec: 134.44 - lr: 0.050000
2022-03-26 21:47:42,706 epoch 9 - iter 50/107 - loss 0.09633232 - samples/sec: 135.09 - lr: 0.050000
2022-03-26 21:47:45,089 epoch 9 - iter 60/107 - loss 0.09443375 - samples/sec: 134.35 - lr: 0.050000
2022-03-26 21:47:47,441 epoch 9 - iter 70/107 - loss 0.09494317 - samples/sec: 136.13 - lr: 0.050000
2022-03-26 21:47:49,880 epoch 9 - iter 80/107 - loss 0.09201081 - samples/sec: 131.24 - lr: 0.050000
2022-03-26 21:47:52,248 epoch 9 - iter 90/107 - loss 0.09363252 - samples/sec: 135.19 - lr: 0.050000
2022-03-26 21:47:54,613 epoch 9 - iter 100/107 - loss 0.09289292 - samples/sec: 135.37 - lr: 0.050000
2022-03-26 21:47:56,087 ----------------------------------------------------------------------------------------------------
2022-03-26 21:47:56,087 EPOCH 9 done: loss 0.0924 - lr 0.050000
2022-03-26 21:48:03,504 Evaluating as a multi-label problem: False
2022-03-26 21:48:03,515 DEV : loss 0.20652706921100616 - f1-score (micro avg)  0.4755
2022-03-26 21:48:03,585 BAD EPOCHS (no improvement): 1
2022-03-26 21:48:03,588 ----------------------------------------------------------------------------------------------------
2022-03-26 21:48:06,062 epoch 10 - iter 10/107 - loss 0.09021990 - samples/sec: 129.45 - lr: 0.050000
2022-03-26 21:48:08,415 epoch 10 - iter 20/107 - loss 0.08733744 - samples/sec: 136.02 - lr: 0.050000
2022-03-26 21:48:10,861 epoch 10 - iter 30/107 - loss 0.08797345 - samples/sec: 130.89 - lr: 0.050000
2022-03-26 21:48:13,339 epoch 10 - iter 40/107 - loss 0.08470882 - samples/sec: 129.21 - lr: 0.050000
2022-03-26 21:48:15,710 epoch 10 - iter 50/107 - loss 0.08672489 - samples/sec: 134.99 - lr: 0.050000
2022-03-26 21:48:18,015 epoch 10 - iter 60/107 - loss 0.08854288 - samples/sec: 138.88 - lr: 0.050000
2022-03-26 21:48:20,303 epoch 10 - iter 70/107 - loss 0.08743168 - samples/sec: 139.92 - lr: 0.050000
2022-03-26 21:48:22,668 epoch 10 - iter 80/107 - loss 0.08541206 - samples/sec: 135.37 - lr: 0.050000
2022-03-26 21:48:25,113 epoch 10 - iter 90/107 - loss 0.08525385 - samples/sec: 130.95 - lr: 0.050000
2022-03-26 21:48:27,477 epoch 10 - iter 100/107 - loss 0.08524568 - samples/sec: 135.39 - lr: 0.050000
2022-03-26 21:48:28,986 ----------------------------------------------------------------------------------------------------
2022-03-26 21:48:28,986 EPOCH 10 done: loss 0.0851 - lr 0.050000
2022-03-26 21:48:36,374 Evaluating as a multi-label problem: False
2022-03-26 21:48:36,384 DEV : loss 0.2045382410287857 - f1-score (micro avg)  0.5063
2022-03-26 21:48:36,455 BAD EPOCHS (no improvement): 0
2022-03-26 21:48:36,457 saving best model
2022-03-26 21:49:13,228 ----------------------------------------------------------------------------------------------------
2022-03-26 21:49:15,672 epoch 11 - iter 10/107 - loss 0.08983981 - samples/sec: 131.04 - lr: 0.050000
2022-03-26 21:49:18,109 epoch 11 - iter 20/107 - loss 0.10169601 - samples/sec: 131.39 - lr: 0.050000
2022-03-26 21:49:20,588 epoch 11 - iter 30/107 - loss 0.08851798 - samples/sec: 129.14 - lr: 0.050000
2022-03-26 21:49:23,012 epoch 11 - iter 40/107 - loss 0.08587704 - samples/sec: 132.07 - lr: 0.050000
2022-03-26 21:49:25,390 epoch 11 - iter 50/107 - loss 0.08611594 - samples/sec: 134.61 - lr: 0.050000
2022-03-26 21:49:27,739 epoch 11 - iter 60/107 - loss 0.08637576 - samples/sec: 136.32 - lr: 0.050000
2022-03-26 21:49:30,109 epoch 11 - iter 70/107 - loss 0.08616658 - samples/sec: 135.04 - lr: 0.050000
2022-03-26 21:49:32,377 epoch 11 - iter 80/107 - loss 0.08670003 - samples/sec: 141.18 - lr: 0.050000
2022-03-26 21:49:34,822 epoch 11 - iter 90/107 - loss 0.08711166 - samples/sec: 130.93 - lr: 0.050000
2022-03-26 21:49:37,426 epoch 11 - iter 100/107 - loss 0.08532603 - samples/sec: 122.94 - lr: 0.050000
2022-03-26 21:49:39,132 ----------------------------------------------------------------------------------------------------
2022-03-26 21:49:39,132 EPOCH 11 done: loss 0.0844 - lr 0.050000
2022-03-26 21:49:47,948 Evaluating as a multi-label problem: False
2022-03-26 21:49:47,960 DEV : loss 0.18907271325588226 - f1-score (micro avg)  0.5328
2022-03-26 21:49:48,051 BAD EPOCHS (no improvement): 0
2022-03-26 21:49:48,054 saving best model
2022-03-26 21:50:25,198 ----------------------------------------------------------------------------------------------------
2022-03-26 21:50:27,659 epoch 12 - iter 10/107 - loss 0.08843778 - samples/sec: 130.12 - lr: 0.050000
2022-03-26 21:50:30,077 epoch 12 - iter 20/107 - loss 0.07682828 - samples/sec: 132.40 - lr: 0.050000
2022-03-26 21:50:32,497 epoch 12 - iter 30/107 - loss 0.07287643 - samples/sec: 132.29 - lr: 0.050000
2022-03-26 21:50:34,940 epoch 12 - iter 40/107 - loss 0.07255001 - samples/sec: 131.04 - lr: 0.050000
2022-03-26 21:50:37,363 epoch 12 - iter 50/107 - loss 0.07748917 - samples/sec: 132.14 - lr: 0.050000
2022-03-26 21:50:39,812 epoch 12 - iter 60/107 - loss 0.07854303 - samples/sec: 130.74 - lr: 0.050000
2022-03-26 21:50:42,271 epoch 12 - iter 70/107 - loss 0.07913696 - samples/sec: 130.20 - lr: 0.050000
2022-03-26 21:50:44,560 epoch 12 - iter 80/107 - loss 0.08071389 - samples/sec: 139.84 - lr: 0.050000
2022-03-26 21:50:46,991 epoch 12 - iter 90/107 - loss 0.08141692 - samples/sec: 131.68 - lr: 0.050000
2022-03-26 21:50:49,426 epoch 12 - iter 100/107 - loss 0.08137577 - samples/sec: 131.46 - lr: 0.050000
2022-03-26 21:50:50,891 ----------------------------------------------------------------------------------------------------
2022-03-26 21:50:50,891 EPOCH 12 done: loss 0.0819 - lr 0.050000
2022-03-26 21:50:58,409 Evaluating as a multi-label problem: False
2022-03-26 21:50:58,420 DEV : loss 0.19421063363552094 - f1-score (micro avg)  0.5255
2022-03-26 21:50:58,491 BAD EPOCHS (no improvement): 1
2022-03-26 21:50:58,523 ----------------------------------------------------------------------------------------------------
2022-03-26 21:51:00,943 epoch 13 - iter 10/107 - loss 0.06954403 - samples/sec: 132.32 - lr: 0.050000
2022-03-26 21:51:03,286 epoch 13 - iter 20/107 - loss 0.07689351 - samples/sec: 136.63 - lr: 0.050000
2022-03-26 21:51:05,651 epoch 13 - iter 30/107 - loss 0.08513121 - samples/sec: 135.33 - lr: 0.050000
2022-03-26 21:51:08,126 epoch 13 - iter 40/107 - loss 0.08353584 - samples/sec: 129.37 - lr: 0.050000
2022-03-26 21:51:10,493 epoch 13 - iter 50/107 - loss 0.08586906 - samples/sec: 135.26 - lr: 0.050000
2022-03-26 21:51:12,944 epoch 13 - iter 60/107 - loss 0.08480879 - samples/sec: 130.60 - lr: 0.050000
2022-03-26 21:51:15,391 epoch 13 - iter 70/107 - loss 0.08197222 - samples/sec: 130.81 - lr: 0.050000
2022-03-26 21:51:17,766 epoch 13 - iter 80/107 - loss 0.07963475 - samples/sec: 134.79 - lr: 0.050000
2022-03-26 21:51:20,299 epoch 13 - iter 90/107 - loss 0.07901032 - samples/sec: 126.41 - lr: 0.050000
2022-03-26 21:51:22,657 epoch 13 - iter 100/107 - loss 0.07816310 - samples/sec: 135.77 - lr: 0.050000
2022-03-26 21:51:24,128 ----------------------------------------------------------------------------------------------------
2022-03-26 21:51:24,128 EPOCH 13 done: loss 0.0774 - lr 0.050000
2022-03-26 21:51:31,406 Evaluating as a multi-label problem: False
2022-03-26 21:51:31,418 DEV : loss 0.1983908861875534 - f1-score (micro avg)  0.5207
2022-03-26 21:51:31,491 BAD EPOCHS (no improvement): 2
2022-03-26 21:51:31,494 ----------------------------------------------------------------------------------------------------
2022-03-26 21:51:33,781 epoch 14 - iter 10/107 - loss 0.09163163 - samples/sec: 139.99 - lr: 0.050000
2022-03-26 21:51:36,037 epoch 14 - iter 20/107 - loss 0.07721750 - samples/sec: 141.91 - lr: 0.050000
2022-03-26 21:51:38,406 epoch 14 - iter 30/107 - loss 0.07378424 - samples/sec: 135.17 - lr: 0.050000
2022-03-26 21:51:40,834 epoch 14 - iter 40/107 - loss 0.07045206 - samples/sec: 131.83 - lr: 0.050000
2022-03-26 21:51:43,152 epoch 14 - iter 50/107 - loss 0.07209349 - samples/sec: 138.11 - lr: 0.050000
2022-03-26 21:51:45,630 epoch 14 - iter 60/107 - loss 0.07184716 - samples/sec: 129.17 - lr: 0.050000
2022-03-26 21:51:47,944 epoch 14 - iter 70/107 - loss 0.07256547 - samples/sec: 138.35 - lr: 0.050000
2022-03-26 21:51:50,388 epoch 14 - iter 80/107 - loss 0.07173754 - samples/sec: 130.96 - lr: 0.050000
2022-03-26 21:51:52,885 epoch 14 - iter 90/107 - loss 0.07074228 - samples/sec: 128.21 - lr: 0.050000
2022-03-26 21:51:55,245 epoch 14 - iter 100/107 - loss 0.07289132 - samples/sec: 135.68 - lr: 0.050000
2022-03-26 21:51:56,772 ----------------------------------------------------------------------------------------------------
2022-03-26 21:51:56,772 EPOCH 14 done: loss 0.0738 - lr 0.050000
2022-03-26 21:52:04,275 Evaluating as a multi-label problem: False
2022-03-26 21:52:04,285 DEV : loss 0.21028146147727966 - f1-score (micro avg)  0.4812
2022-03-26 21:52:04,356 BAD EPOCHS (no improvement): 3
2022-03-26 21:52:04,359 ----------------------------------------------------------------------------------------------------
2022-03-26 21:52:06,746 epoch 15 - iter 10/107 - loss 0.06253519 - samples/sec: 134.11 - lr: 0.050000
2022-03-26 21:52:09,194 epoch 15 - iter 20/107 - loss 0.06502753 - samples/sec: 130.78 - lr: 0.050000
2022-03-26 21:52:11,538 epoch 15 - iter 30/107 - loss 0.06876720 - samples/sec: 136.63 - lr: 0.050000
2022-03-26 21:52:13,948 epoch 15 - iter 40/107 - loss 0.07060853 - samples/sec: 132.80 - lr: 0.050000
2022-03-26 21:52:16,328 epoch 15 - iter 50/107 - loss 0.07066634 - samples/sec: 134.55 - lr: 0.050000
2022-03-26 21:52:18,716 epoch 15 - iter 60/107 - loss 0.06944795 - samples/sec: 134.02 - lr: 0.050000
2022-03-26 21:52:21,177 epoch 15 - iter 70/107 - loss 0.06993657 - samples/sec: 130.10 - lr: 0.050000
2022-03-26 21:52:23,624 epoch 15 - iter 80/107 - loss 0.06943371 - samples/sec: 130.83 - lr: 0.050000
2022-03-26 21:52:25,976 epoch 15 - iter 90/107 - loss 0.06822399 - samples/sec: 136.08 - lr: 0.050000
2022-03-26 21:52:28,390 epoch 15 - iter 100/107 - loss 0.06967099 - samples/sec: 132.60 - lr: 0.050000
2022-03-26 21:52:29,878 ----------------------------------------------------------------------------------------------------
2022-03-26 21:52:29,878 EPOCH 15 done: loss 0.0702 - lr 0.050000
2022-03-26 21:52:37,344 Evaluating as a multi-label problem: False
2022-03-26 21:52:37,355 DEV : loss 0.2138613760471344 - f1-score (micro avg)  0.5012
2022-03-26 21:52:37,425 Epoch    15: reducing learning rate of group 0 to 2.5000e-02.
2022-03-26 21:52:37,426 BAD EPOCHS (no improvement): 4
2022-03-26 21:52:37,429 ----------------------------------------------------------------------------------------------------
2022-03-26 21:52:39,862 epoch 16 - iter 10/107 - loss 0.06428303 - samples/sec: 131.62 - lr: 0.025000
2022-03-26 21:52:42,270 epoch 16 - iter 20/107 - loss 0.06453078 - samples/sec: 132.91 - lr: 0.025000
2022-03-26 21:52:44,743 epoch 16 - iter 30/107 - loss 0.06788583 - samples/sec: 129.48 - lr: 0.025000
2022-03-26 21:52:47,085 epoch 16 - iter 40/107 - loss 0.06484570 - samples/sec: 136.70 - lr: 0.025000
2022-03-26 21:52:49,415 epoch 16 - iter 50/107 - loss 0.06444448 - samples/sec: 137.36 - lr: 0.025000
2022-03-26 21:52:51,826 epoch 16 - iter 60/107 - loss 0.06648661 - samples/sec: 132.76 - lr: 0.025000
2022-03-26 21:52:54,159 epoch 16 - iter 70/107 - loss 0.06667531 - samples/sec: 137.25 - lr: 0.025000
2022-03-26 21:52:56,495 epoch 16 - iter 80/107 - loss 0.06767915 - samples/sec: 137.04 - lr: 0.025000
2022-03-26 21:52:58,866 epoch 16 - iter 90/107 - loss 0.06803433 - samples/sec: 135.08 - lr: 0.025000
2022-03-26 21:53:01,377 epoch 16 - iter 100/107 - loss 0.06733850 - samples/sec: 127.45 - lr: 0.025000
2022-03-26 21:53:02,876 ----------------------------------------------------------------------------------------------------
2022-03-26 21:53:02,876 EPOCH 16 done: loss 0.0672 - lr 0.025000
2022-03-26 21:53:10,315 Evaluating as a multi-label problem: False
2022-03-26 21:53:10,326 DEV : loss 0.1965421885251999 - f1-score (micro avg)  0.5155
2022-03-26 21:53:10,398 BAD EPOCHS (no improvement): 1
2022-03-26 21:53:10,400 ----------------------------------------------------------------------------------------------------
2022-03-26 21:53:12,928 epoch 17 - iter 10/107 - loss 0.06961967 - samples/sec: 126.67 - lr: 0.025000
2022-03-26 21:53:15,257 epoch 17 - iter 20/107 - loss 0.06436804 - samples/sec: 137.44 - lr: 0.025000
2022-03-26 21:53:17,690 epoch 17 - iter 30/107 - loss 0.06269157 - samples/sec: 131.57 - lr: 0.025000
2022-03-26 21:53:19,889 epoch 17 - iter 40/107 - loss 0.06342491 - samples/sec: 145.61 - lr: 0.025000
2022-03-26 21:53:22,183 epoch 17 - iter 50/107 - loss 0.06487885 - samples/sec: 139.53 - lr: 0.025000
2022-03-26 21:53:24,553 epoch 17 - iter 60/107 - loss 0.06511349 - samples/sec: 135.09 - lr: 0.025000
2022-03-26 21:53:26,939 epoch 17 - iter 70/107 - loss 0.06615244 - samples/sec: 134.14 - lr: 0.025000
2022-03-26 21:53:29,409 epoch 17 - iter 80/107 - loss 0.06585255 - samples/sec: 129.63 - lr: 0.025000
2022-03-26 21:53:31,867 epoch 17 - iter 90/107 - loss 0.06646091 - samples/sec: 130.23 - lr: 0.025000
2022-03-26 21:53:34,330 epoch 17 - iter 100/107 - loss 0.06531132 - samples/sec: 129.97 - lr: 0.025000
2022-03-26 21:53:35,730 ----------------------------------------------------------------------------------------------------
2022-03-26 21:53:35,730 EPOCH 17 done: loss 0.0650 - lr 0.025000
2022-03-26 21:53:43,234 Evaluating as a multi-label problem: False
2022-03-26 21:53:43,244 DEV : loss 0.20541790127754211 - f1-score (micro avg)  0.4952
2022-03-26 21:53:43,316 BAD EPOCHS (no improvement): 2
2022-03-26 21:53:43,319 ----------------------------------------------------------------------------------------------------
2022-03-26 21:53:45,736 epoch 18 - iter 10/107 - loss 0.05287618 - samples/sec: 132.48 - lr: 0.025000
2022-03-26 21:53:48,145 epoch 18 - iter 20/107 - loss 0.06221029 - samples/sec: 132.90 - lr: 0.025000
2022-03-26 21:53:50,604 epoch 18 - iter 30/107 - loss 0.06323622 - samples/sec: 130.21 - lr: 0.025000
2022-03-26 21:53:53,011 epoch 18 - iter 40/107 - loss 0.06302077 - samples/sec: 133.02 - lr: 0.025000
2022-03-26 21:53:55,392 epoch 18 - iter 50/107 - loss 0.06314637 - samples/sec: 134.45 - lr: 0.025000
2022-03-26 21:53:57,787 epoch 18 - iter 60/107 - loss 0.06103250 - samples/sec: 133.67 - lr: 0.025000
2022-03-26 21:54:00,158 epoch 18 - iter 70/107 - loss 0.06306682 - samples/sec: 134.98 - lr: 0.025000
2022-03-26 21:54:02,645 epoch 18 - iter 80/107 - loss 0.06409029 - samples/sec: 128.76 - lr: 0.025000
2022-03-26 21:54:04,944 epoch 18 - iter 90/107 - loss 0.06385352 - samples/sec: 139.24 - lr: 0.025000
2022-03-26 21:54:07,384 epoch 18 - iter 100/107 - loss 0.06396158 - samples/sec: 131.18 - lr: 0.025000
2022-03-26 21:54:08,799 ----------------------------------------------------------------------------------------------------
2022-03-26 21:54:08,799 EPOCH 18 done: loss 0.0631 - lr 0.025000
2022-03-26 21:54:19,684 Evaluating as a multi-label problem: False
2022-03-26 21:54:19,694 DEV : loss 0.21280361711978912 - f1-score (micro avg)  0.4874
2022-03-26 21:54:19,766 BAD EPOCHS (no improvement): 3
2022-03-26 21:54:19,770 ----------------------------------------------------------------------------------------------------
2022-03-26 21:54:22,130 epoch 19 - iter 10/107 - loss 0.04974004 - samples/sec: 135.65 - lr: 0.025000
2022-03-26 21:54:24,458 epoch 19 - iter 20/107 - loss 0.05923784 - samples/sec: 137.53 - lr: 0.025000
2022-03-26 21:54:26,771 epoch 19 - iter 30/107 - loss 0.06184325 - samples/sec: 138.37 - lr: 0.025000
2022-03-26 21:54:29,179 epoch 19 - iter 40/107 - loss 0.05935017 - samples/sec: 132.94 - lr: 0.025000
2022-03-26 21:54:31,479 epoch 19 - iter 50/107 - loss 0.05994122 - samples/sec: 139.23 - lr: 0.025000
2022-03-26 21:54:33,953 epoch 19 - iter 60/107 - loss 0.06212169 - samples/sec: 129.39 - lr: 0.025000
2022-03-26 21:54:36,353 epoch 19 - iter 70/107 - loss 0.05996632 - samples/sec: 133.38 - lr: 0.025000
2022-03-26 21:54:38,839 epoch 19 - iter 80/107 - loss 0.06051467 - samples/sec: 128.78 - lr: 0.025000
2022-03-26 21:54:41,206 epoch 19 - iter 90/107 - loss 0.06010034 - samples/sec: 135.28 - lr: 0.025000
2022-03-26 21:54:43,607 epoch 19 - iter 100/107 - loss 0.06040528 - samples/sec: 133.30 - lr: 0.025000
2022-03-26 21:54:45,073 ----------------------------------------------------------------------------------------------------
2022-03-26 21:54:45,073 EPOCH 19 done: loss 0.0604 - lr 0.025000
2022-03-26 21:54:52,562 Evaluating as a multi-label problem: False
2022-03-26 21:54:52,574 DEV : loss 0.19373826682567596 - f1-score (micro avg)  0.5073
2022-03-26 21:54:52,647 Epoch    19: reducing learning rate of group 0 to 1.2500e-02.
2022-03-26 21:54:52,647 BAD EPOCHS (no improvement): 4
2022-03-26 21:54:52,650 ----------------------------------------------------------------------------------------------------
2022-03-26 21:54:55,063 epoch 20 - iter 10/107 - loss 0.05875911 - samples/sec: 132.67 - lr: 0.012500
2022-03-26 21:54:57,519 epoch 20 - iter 20/107 - loss 0.05846568 - samples/sec: 130.35 - lr: 0.012500
2022-03-26 21:54:59,873 epoch 20 - iter 30/107 - loss 0.05817488 - samples/sec: 136.02 - lr: 0.012500
2022-03-26 21:55:02,250 epoch 20 - iter 40/107 - loss 0.05650256 - samples/sec: 134.70 - lr: 0.012500
2022-03-26 21:55:04,642 epoch 20 - iter 50/107 - loss 0.05716989 - samples/sec: 133.83 - lr: 0.012500
2022-03-26 21:55:06,893 epoch 20 - iter 60/107 - loss 0.05668201 - samples/sec: 142.20 - lr: 0.012500
2022-03-26 21:55:09,127 epoch 20 - iter 70/107 - loss 0.05779808 - samples/sec: 143.31 - lr: 0.012500
2022-03-26 21:55:11,413 epoch 20 - iter 80/107 - loss 0.05743063 - samples/sec: 140.04 - lr: 0.012500
2022-03-26 21:55:13,700 epoch 20 - iter 90/107 - loss 0.05627587 - samples/sec: 140.00 - lr: 0.012500
2022-03-26 21:55:15,911 epoch 20 - iter 100/107 - loss 0.05603348 - samples/sec: 144.80 - lr: 0.012500
2022-03-26 21:55:17,216 ----------------------------------------------------------------------------------------------------
2022-03-26 21:55:17,216 EPOCH 20 done: loss 0.0564 - lr 0.012500
2022-03-26 21:55:24,540 Evaluating as a multi-label problem: False
2022-03-26 21:55:24,551 DEV : loss 0.21063384413719177 - f1-score (micro avg)  0.4924
2022-03-26 21:55:24,624 BAD EPOCHS (no improvement): 1
2022-03-26 21:55:24,627 ----------------------------------------------------------------------------------------------------
2022-03-26 21:55:27,015 epoch 21 - iter 10/107 - loss 0.05415121 - samples/sec: 134.11 - lr: 0.012500
2022-03-26 21:55:29,457 epoch 21 - iter 20/107 - loss 0.05407102 - samples/sec: 131.12 - lr: 0.012500
2022-03-26 21:55:31,808 epoch 21 - iter 30/107 - loss 0.05668215 - samples/sec: 136.15 - lr: 0.012500
2022-03-26 21:55:34,100 epoch 21 - iter 40/107 - loss 0.05609237 - samples/sec: 139.66 - lr: 0.012500
2022-03-26 21:55:36,516 epoch 21 - iter 50/107 - loss 0.05679593 - samples/sec: 132.49 - lr: 0.012500
2022-03-26 21:55:39,011 epoch 21 - iter 60/107 - loss 0.05578766 - samples/sec: 128.34 - lr: 0.012500
2022-03-26 21:55:41,397 epoch 21 - iter 70/107 - loss 0.05635373 - samples/sec: 134.17 - lr: 0.012500
2022-03-26 21:55:43,786 epoch 21 - iter 80/107 - loss 0.05534979 - samples/sec: 133.97 - lr: 0.012500
2022-03-26 21:55:46,287 epoch 21 - iter 90/107 - loss 0.05496667 - samples/sec: 128.00 - lr: 0.012500
2022-03-26 21:55:48,613 epoch 21 - iter 100/107 - loss 0.05688786 - samples/sec: 137.65 - lr: 0.012500
2022-03-26 21:55:50,056 ----------------------------------------------------------------------------------------------------
2022-03-26 21:55:50,056 EPOCH 21 done: loss 0.0572 - lr 0.012500
2022-03-26 21:55:57,621 Evaluating as a multi-label problem: False
2022-03-26 21:55:57,632 DEV : loss 0.20360861718654633 - f1-score (micro avg)  0.5031
2022-03-26 21:55:57,704 BAD EPOCHS (no improvement): 2
2022-03-26 21:55:57,708 ----------------------------------------------------------------------------------------------------
2022-03-26 21:56:00,205 epoch 22 - iter 10/107 - loss 0.05036499 - samples/sec: 128.20 - lr: 0.012500
2022-03-26 21:56:02,646 epoch 22 - iter 20/107 - loss 0.05402825 - samples/sec: 131.12 - lr: 0.012500
2022-03-26 21:56:05,034 epoch 22 - iter 30/107 - loss 0.05379709 - samples/sec: 134.09 - lr: 0.012500
2022-03-26 21:56:07,414 epoch 22 - iter 40/107 - loss 0.05542006 - samples/sec: 134.47 - lr: 0.012500
2022-03-26 21:56:09,738 epoch 22 - iter 50/107 - loss 0.05450811 - samples/sec: 137.77 - lr: 0.012500
2022-03-26 21:56:12,130 epoch 22 - iter 60/107 - loss 0.05672247 - samples/sec: 133.83 - lr: 0.012500
2022-03-26 21:56:14,476 epoch 22 - iter 70/107 - loss 0.05532249 - samples/sec: 136.50 - lr: 0.012500
2022-03-26 21:56:16,884 epoch 22 - iter 80/107 - loss 0.05576523 - samples/sec: 132.92 - lr: 0.012500
2022-03-26 21:56:19,140 epoch 22 - iter 90/107 - loss 0.05501019 - samples/sec: 141.94 - lr: 0.012500
2022-03-26 21:56:21,515 epoch 22 - iter 100/107 - loss 0.05476811 - samples/sec: 134.77 - lr: 0.012500
2022-03-26 21:56:23,029 ----------------------------------------------------------------------------------------------------
2022-03-26 21:56:23,029 EPOCH 22 done: loss 0.0551 - lr 0.012500
2022-03-26 21:56:30,558 Evaluating as a multi-label problem: False
2022-03-26 21:56:30,569 DEV : loss 0.20988881587982178 - f1-score (micro avg)  0.4957
2022-03-26 21:56:30,642 BAD EPOCHS (no improvement): 3
2022-03-26 21:56:30,646 ----------------------------------------------------------------------------------------------------
2022-03-26 21:56:33,129 epoch 23 - iter 10/107 - loss 0.04623027 - samples/sec: 128.94 - lr: 0.012500
2022-03-26 21:56:35,470 epoch 23 - iter 20/107 - loss 0.05012478 - samples/sec: 136.79 - lr: 0.012500
2022-03-26 21:56:37,919 epoch 23 - iter 30/107 - loss 0.05636876 - samples/sec: 130.69 - lr: 0.012500
2022-03-26 21:56:40,195 epoch 23 - iter 40/107 - loss 0.05413889 - samples/sec: 140.67 - lr: 0.012500
2022-03-26 21:56:42,638 epoch 23 - iter 50/107 - loss 0.05341530 - samples/sec: 131.01 - lr: 0.012500
2022-03-26 21:56:44,993 epoch 23 - iter 60/107 - loss 0.05424277 - samples/sec: 135.95 - lr: 0.012500
2022-03-26 21:56:47,398 epoch 23 - iter 70/107 - loss 0.05354656 - samples/sec: 133.12 - lr: 0.012500
2022-03-26 21:56:49,891 epoch 23 - iter 80/107 - loss 0.05481085 - samples/sec: 128.41 - lr: 0.012500
2022-03-26 21:56:52,209 epoch 23 - iter 90/107 - loss 0.05467788 - samples/sec: 138.07 - lr: 0.012500
2022-03-26 21:56:54,682 epoch 23 - iter 100/107 - loss 0.05511107 - samples/sec: 129.49 - lr: 0.012500
2022-03-26 21:56:56,145 ----------------------------------------------------------------------------------------------------
2022-03-26 21:56:56,145 EPOCH 23 done: loss 0.0549 - lr 0.012500
2022-03-26 21:57:03,603 Evaluating as a multi-label problem: False
2022-03-26 21:57:03,614 DEV : loss 0.2133406102657318 - f1-score (micro avg)  0.5008
2022-03-26 21:57:03,687 Epoch    23: reducing learning rate of group 0 to 6.2500e-03.
2022-03-26 21:57:03,687 BAD EPOCHS (no improvement): 4
2022-03-26 21:57:03,693 ----------------------------------------------------------------------------------------------------
2022-03-26 21:57:06,166 epoch 24 - iter 10/107 - loss 0.04261701 - samples/sec: 129.48 - lr: 0.006250
2022-03-26 21:57:08,511 epoch 24 - iter 20/107 - loss 0.04941999 - samples/sec: 136.48 - lr: 0.006250
2022-03-26 21:57:10,861 epoch 24 - iter 30/107 - loss 0.04967449 - samples/sec: 136.23 - lr: 0.006250
2022-03-26 21:57:13,216 epoch 24 - iter 40/107 - loss 0.05065167 - samples/sec: 135.98 - lr: 0.006250
2022-03-26 21:57:15,601 epoch 24 - iter 50/107 - loss 0.05241841 - samples/sec: 134.24 - lr: 0.006250
2022-03-26 21:57:18,017 epoch 24 - iter 60/107 - loss 0.05389098 - samples/sec: 132.50 - lr: 0.006250
2022-03-26 21:57:20,430 epoch 24 - iter 70/107 - loss 0.05350636 - samples/sec: 132.63 - lr: 0.006250
2022-03-26 21:57:22,827 epoch 24 - iter 80/107 - loss 0.05389315 - samples/sec: 133.56 - lr: 0.006250
2022-03-26 21:57:25,359 epoch 24 - iter 90/107 - loss 0.05471497 - samples/sec: 126.44 - lr: 0.006250
2022-03-26 21:57:27,710 epoch 24 - iter 100/107 - loss 0.05486489 - samples/sec: 136.18 - lr: 0.006250
2022-03-26 21:57:29,171 ----------------------------------------------------------------------------------------------------
2022-03-26 21:57:29,172 EPOCH 24 done: loss 0.0551 - lr 0.006250
2022-03-26 21:57:36,655 Evaluating as a multi-label problem: False
2022-03-26 21:57:36,666 DEV : loss 0.20081153512001038 - f1-score (micro avg)  0.5131
2022-03-26 21:57:36,738 BAD EPOCHS (no improvement): 1
2022-03-26 21:57:36,742 ----------------------------------------------------------------------------------------------------
2022-03-26 21:57:39,137 epoch 25 - iter 10/107 - loss 0.04432338 - samples/sec: 133.64 - lr: 0.006250
2022-03-26 21:57:41,462 epoch 25 - iter 20/107 - loss 0.05336190 - samples/sec: 137.70 - lr: 0.006250
2022-03-26 21:57:43,914 epoch 25 - iter 30/107 - loss 0.05485589 - samples/sec: 130.57 - lr: 0.006250
2022-03-26 21:57:46,400 epoch 25 - iter 40/107 - loss 0.05170794 - samples/sec: 128.77 - lr: 0.006250
2022-03-26 21:57:48,912 epoch 25 - iter 50/107 - loss 0.05167583 - samples/sec: 127.46 - lr: 0.006250
2022-03-26 21:57:51,329 epoch 25 - iter 60/107 - loss 0.05330381 - samples/sec: 132.44 - lr: 0.006250
2022-03-26 21:57:53,694 epoch 25 - iter 70/107 - loss 0.05248713 - samples/sec: 135.36 - lr: 0.006250
2022-03-26 21:57:56,344 epoch 25 - iter 80/107 - loss 0.05337948 - samples/sec: 120.83 - lr: 0.006250
2022-03-26 21:57:58,914 epoch 25 - iter 90/107 - loss 0.05371985 - samples/sec: 124.58 - lr: 0.006250
2022-03-26 21:58:01,475 epoch 25 - iter 100/107 - loss 0.05353888 - samples/sec: 125.00 - lr: 0.006250
2022-03-26 21:58:03,238 ----------------------------------------------------------------------------------------------------
2022-03-26 21:58:03,238 EPOCH 25 done: loss 0.0534 - lr 0.006250
2022-03-26 21:58:12,084 Evaluating as a multi-label problem: False
2022-03-26 21:58:12,096 DEV : loss 0.21219515800476074 - f1-score (micro avg)  0.5004
2022-03-26 21:58:12,190 BAD EPOCHS (no improvement): 2
2022-03-26 21:58:12,194 ----------------------------------------------------------------------------------------------------
2022-03-26 21:58:14,880 epoch 26 - iter 10/107 - loss 0.04300948 - samples/sec: 119.19 - lr: 0.006250
2022-03-26 21:58:17,590 epoch 26 - iter 20/107 - loss 0.04511677 - samples/sec: 118.12 - lr: 0.006250
2022-03-26 21:58:20,110 epoch 26 - iter 30/107 - loss 0.04606057 - samples/sec: 127.05 - lr: 0.006250
2022-03-26 21:58:22,742 epoch 26 - iter 40/107 - loss 0.04909567 - samples/sec: 121.62 - lr: 0.006250
2022-03-26 21:58:25,448 epoch 26 - iter 50/107 - loss 0.05104105 - samples/sec: 118.32 - lr: 0.006250
2022-03-26 21:58:28,197 epoch 26 - iter 60/107 - loss 0.05327888 - samples/sec: 116.43 - lr: 0.006250
2022-03-26 21:58:30,903 epoch 26 - iter 70/107 - loss 0.05380146 - samples/sec: 118.32 - lr: 0.006250
2022-03-26 21:58:33,533 epoch 26 - iter 80/107 - loss 0.05336850 - samples/sec: 121.71 - lr: 0.006250
2022-03-26 21:58:36,132 epoch 26 - iter 90/107 - loss 0.05348023 - samples/sec: 123.15 - lr: 0.006250
2022-03-26 21:58:38,650 epoch 26 - iter 100/107 - loss 0.05302846 - samples/sec: 127.16 - lr: 0.006250
2022-03-26 21:58:40,153 ----------------------------------------------------------------------------------------------------
2022-03-26 21:58:40,154 EPOCH 26 done: loss 0.0527 - lr 0.006250
2022-03-26 21:58:47,697 Evaluating as a multi-label problem: False
2022-03-26 21:58:47,708 DEV : loss 0.20700538158416748 - f1-score (micro avg)  0.5016
2022-03-26 21:58:47,780 BAD EPOCHS (no improvement): 3
2022-03-26 21:58:47,783 ----------------------------------------------------------------------------------------------------
2022-03-26 21:58:50,332 epoch 27 - iter 10/107 - loss 0.05687328 - samples/sec: 125.62 - lr: 0.006250
2022-03-26 21:58:52,830 epoch 27 - iter 20/107 - loss 0.05930029 - samples/sec: 128.16 - lr: 0.006250
2022-03-26 21:58:55,346 epoch 27 - iter 30/107 - loss 0.05568562 - samples/sec: 127.22 - lr: 0.006250
2022-03-26 21:58:57,743 epoch 27 - iter 40/107 - loss 0.05386931 - samples/sec: 133.58 - lr: 0.006250
2022-03-26 21:59:00,199 epoch 27 - iter 50/107 - loss 0.05224530 - samples/sec: 130.36 - lr: 0.006250
2022-03-26 21:59:02,569 epoch 27 - iter 60/107 - loss 0.05134694 - samples/sec: 135.06 - lr: 0.006250
2022-03-26 21:59:04,985 epoch 27 - iter 70/107 - loss 0.05182941 - samples/sec: 132.50 - lr: 0.006250
2022-03-26 21:59:07,382 epoch 27 - iter 80/107 - loss 0.05229051 - samples/sec: 133.56 - lr: 0.006250
2022-03-26 21:59:09,776 epoch 27 - iter 90/107 - loss 0.05186158 - samples/sec: 133.72 - lr: 0.006250
2022-03-26 21:59:12,272 epoch 27 - iter 100/107 - loss 0.05152859 - samples/sec: 128.23 - lr: 0.006250
2022-03-26 21:59:13,714 ----------------------------------------------------------------------------------------------------
2022-03-26 21:59:13,714 EPOCH 27 done: loss 0.0520 - lr 0.006250
2022-03-26 21:59:21,203 Evaluating as a multi-label problem: False
2022-03-26 21:59:21,213 DEV : loss 0.2125745415687561 - f1-score (micro avg)  0.5008
2022-03-26 21:59:21,285 Epoch    27: reducing learning rate of group 0 to 3.1250e-03.
2022-03-26 21:59:21,285 BAD EPOCHS (no improvement): 4
2022-03-26 21:59:21,290 ----------------------------------------------------------------------------------------------------
2022-03-26 21:59:23,760 epoch 28 - iter 10/107 - loss 0.05399940 - samples/sec: 129.63 - lr: 0.003125
2022-03-26 21:59:26,143 epoch 28 - iter 20/107 - loss 0.05247162 - samples/sec: 134.33 - lr: 0.003125
2022-03-26 21:59:28,569 epoch 28 - iter 30/107 - loss 0.05038890 - samples/sec: 132.00 - lr: 0.003125
2022-03-26 21:59:30,939 epoch 28 - iter 40/107 - loss 0.04896384 - samples/sec: 135.08 - lr: 0.003125
2022-03-26 21:59:33,377 epoch 28 - iter 50/107 - loss 0.04945845 - samples/sec: 131.28 - lr: 0.003125
2022-03-26 21:59:35,887 epoch 28 - iter 60/107 - loss 0.05109095 - samples/sec: 127.57 - lr: 0.003125
2022-03-26 21:59:38,369 epoch 28 - iter 70/107 - loss 0.04983350 - samples/sec: 129.00 - lr: 0.003125
2022-03-26 21:59:40,869 epoch 28 - iter 80/107 - loss 0.05131014 - samples/sec: 128.02 - lr: 0.003125
2022-03-26 21:59:43,286 epoch 28 - iter 90/107 - loss 0.05212667 - samples/sec: 132.46 - lr: 0.003125
2022-03-26 21:59:45,695 epoch 28 - iter 100/107 - loss 0.05162470 - samples/sec: 132.87 - lr: 0.003125
2022-03-26 21:59:47,221 ----------------------------------------------------------------------------------------------------
2022-03-26 21:59:47,221 EPOCH 28 done: loss 0.0519 - lr 0.003125
2022-03-26 21:59:54,687 Evaluating as a multi-label problem: False
2022-03-26 21:59:54,698 DEV : loss 0.20445053279399872 - f1-score (micro avg)  0.5128
2022-03-26 21:59:54,770 BAD EPOCHS (no improvement): 1
2022-03-26 21:59:54,773 ----------------------------------------------------------------------------------------------------
2022-03-26 21:59:57,265 epoch 29 - iter 10/107 - loss 0.04721436 - samples/sec: 128.49 - lr: 0.003125
2022-03-26 21:59:59,678 epoch 29 - iter 20/107 - loss 0.04593188 - samples/sec: 132.68 - lr: 0.003125
2022-03-26 22:00:02,132 epoch 29 - iter 30/107 - loss 0.04564113 - samples/sec: 130.46 - lr: 0.003125
2022-03-26 22:00:04,572 epoch 29 - iter 40/107 - loss 0.04742649 - samples/sec: 131.17 - lr: 0.003125
2022-03-26 22:00:07,277 epoch 29 - iter 50/107 - loss 0.04981367 - samples/sec: 118.36 - lr: 0.003125
2022-03-26 22:00:09,984 epoch 29 - iter 60/107 - loss 0.05064560 - samples/sec: 118.24 - lr: 0.003125
2022-03-26 22:00:12,641 epoch 29 - iter 70/107 - loss 0.05152482 - samples/sec: 120.51 - lr: 0.003125
2022-03-26 22:00:15,300 epoch 29 - iter 80/107 - loss 0.05127711 - samples/sec: 120.41 - lr: 0.003125
2022-03-26 22:00:17,828 epoch 29 - iter 90/107 - loss 0.05043553 - samples/sec: 126.61 - lr: 0.003125
2022-03-26 22:00:20,012 epoch 29 - iter 100/107 - loss 0.05084411 - samples/sec: 146.60 - lr: 0.003125
2022-03-26 22:00:21,324 ----------------------------------------------------------------------------------------------------
2022-03-26 22:00:21,324 EPOCH 29 done: loss 0.0508 - lr 0.003125
2022-03-26 22:00:28,687 Evaluating as a multi-label problem: False
2022-03-26 22:00:28,698 DEV : loss 0.20858554542064667 - f1-score (micro avg)  0.5004
2022-03-26 22:00:28,772 BAD EPOCHS (no improvement): 2
2022-03-26 22:00:28,825 ----------------------------------------------------------------------------------------------------
2022-03-26 22:00:31,229 epoch 30 - iter 10/107 - loss 0.04594559 - samples/sec: 133.18 - lr: 0.003125
2022-03-26 22:00:33,750 epoch 30 - iter 20/107 - loss 0.05632867 - samples/sec: 127.01 - lr: 0.003125
2022-03-26 22:00:36,070 epoch 30 - iter 30/107 - loss 0.05223821 - samples/sec: 137.95 - lr: 0.003125
2022-03-26 22:00:38,422 epoch 30 - iter 40/107 - loss 0.05059126 - samples/sec: 136.13 - lr: 0.003125
2022-03-26 22:00:40,855 epoch 30 - iter 50/107 - loss 0.04932278 - samples/sec: 131.57 - lr: 0.003125
2022-03-26 22:00:43,207 epoch 30 - iter 60/107 - loss 0.05141067 - samples/sec: 136.09 - lr: 0.003125
2022-03-26 22:00:45,572 epoch 30 - iter 70/107 - loss 0.05155372 - samples/sec: 135.41 - lr: 0.003125
2022-03-26 22:00:47,992 epoch 30 - iter 80/107 - loss 0.05192953 - samples/sec: 132.25 - lr: 0.003125
2022-03-26 22:00:50,343 epoch 30 - iter 90/107 - loss 0.05151452 - samples/sec: 136.16 - lr: 0.003125
2022-03-26 22:00:52,685 epoch 30 - iter 100/107 - loss 0.05129731 - samples/sec: 136.68 - lr: 0.003125
2022-03-26 22:00:54,145 ----------------------------------------------------------------------------------------------------
2022-03-26 22:00:54,145 EPOCH 30 done: loss 0.0513 - lr 0.003125
2022-03-26 22:01:01,661 Evaluating as a multi-label problem: False
2022-03-26 22:01:01,672 DEV : loss 0.2106894552707672 - f1-score (micro avg)  0.502
2022-03-26 22:01:01,746 BAD EPOCHS (no improvement): 3
2022-03-26 22:01:01,750 ----------------------------------------------------------------------------------------------------
2022-03-26 22:01:04,171 epoch 31 - iter 10/107 - loss 0.04772013 - samples/sec: 132.26 - lr: 0.003125
2022-03-26 22:01:06,528 epoch 31 - iter 20/107 - loss 0.05339776 - samples/sec: 135.86 - lr: 0.003125
2022-03-26 22:01:08,958 epoch 31 - iter 30/107 - loss 0.05272404 - samples/sec: 131.74 - lr: 0.003125
2022-03-26 22:01:11,322 epoch 31 - iter 40/107 - loss 0.05242769 - samples/sec: 135.42 - lr: 0.003125
2022-03-26 22:01:13,709 epoch 31 - iter 50/107 - loss 0.05151751 - samples/sec: 134.10 - lr: 0.003125
2022-03-26 22:01:16,106 epoch 31 - iter 60/107 - loss 0.05038581 - samples/sec: 133.55 - lr: 0.003125
2022-03-26 22:01:18,571 epoch 31 - iter 70/107 - loss 0.05104445 - samples/sec: 129.91 - lr: 0.003125
2022-03-26 22:01:20,938 epoch 31 - iter 80/107 - loss 0.05132120 - samples/sec: 135.23 - lr: 0.003125
2022-03-26 22:01:23,314 epoch 31 - iter 90/107 - loss 0.05049907 - samples/sec: 134.75 - lr: 0.003125
2022-03-26 22:01:25,682 epoch 31 - iter 100/107 - loss 0.05027172 - samples/sec: 135.18 - lr: 0.003125
2022-03-26 22:01:27,164 ----------------------------------------------------------------------------------------------------
2022-03-26 22:01:27,164 EPOCH 31 done: loss 0.0508 - lr 0.003125
2022-03-26 22:01:34,655 Evaluating as a multi-label problem: False
2022-03-26 22:01:34,665 DEV : loss 0.21036487817764282 - f1-score (micro avg)  0.5
2022-03-26 22:01:34,739 Epoch    31: reducing learning rate of group 0 to 1.5625e-03.
2022-03-26 22:01:34,739 BAD EPOCHS (no improvement): 4
2022-03-26 22:01:34,746 ----------------------------------------------------------------------------------------------------
2022-03-26 22:01:37,219 epoch 32 - iter 10/107 - loss 0.05164064 - samples/sec: 129.47 - lr: 0.001563
2022-03-26 22:01:39,597 epoch 32 - iter 20/107 - loss 0.05557532 - samples/sec: 134.66 - lr: 0.001563
2022-03-26 22:01:41,932 epoch 32 - iter 30/107 - loss 0.05035036 - samples/sec: 137.09 - lr: 0.001563
2022-03-26 22:01:44,297 epoch 32 - iter 40/107 - loss 0.05003197 - samples/sec: 135.36 - lr: 0.001563
2022-03-26 22:01:46,775 epoch 32 - iter 50/107 - loss 0.04846369 - samples/sec: 129.20 - lr: 0.001563
2022-03-26 22:01:49,185 epoch 32 - iter 60/107 - loss 0.05039013 - samples/sec: 132.83 - lr: 0.001563
2022-03-26 22:01:51,475 epoch 32 - iter 70/107 - loss 0.04965803 - samples/sec: 139.81 - lr: 0.001563
2022-03-26 22:01:53,966 epoch 32 - iter 80/107 - loss 0.05019930 - samples/sec: 128.54 - lr: 0.001563
2022-03-26 22:01:56,287 epoch 32 - iter 90/107 - loss 0.05045198 - samples/sec: 137.92 - lr: 0.001563
2022-03-26 22:01:58,625 epoch 32 - iter 100/107 - loss 0.05055607 - samples/sec: 136.92 - lr: 0.001563
2022-03-26 22:02:00,049 ----------------------------------------------------------------------------------------------------
2022-03-26 22:02:00,049 EPOCH 32 done: loss 0.0505 - lr 0.001563
2022-03-26 22:02:07,588 Evaluating as a multi-label problem: False
2022-03-26 22:02:07,599 DEV : loss 0.21003113687038422 - f1-score (micro avg)  0.5063
2022-03-26 22:02:07,672 BAD EPOCHS (no improvement): 1
2022-03-26 22:02:07,677 ----------------------------------------------------------------------------------------------------
2022-03-26 22:02:10,106 epoch 33 - iter 10/107 - loss 0.05402015 - samples/sec: 131.82 - lr: 0.001563
2022-03-26 22:02:12,559 epoch 33 - iter 20/107 - loss 0.05019892 - samples/sec: 130.47 - lr: 0.001563
2022-03-26 22:02:14,942 epoch 33 - iter 30/107 - loss 0.05058271 - samples/sec: 134.35 - lr: 0.001563
2022-03-26 22:02:17,307 epoch 33 - iter 40/107 - loss 0.04989647 - samples/sec: 135.36 - lr: 0.001563
2022-03-26 22:02:19,711 epoch 33 - iter 50/107 - loss 0.05056520 - samples/sec: 133.14 - lr: 0.001563
2022-03-26 22:02:21,987 epoch 33 - iter 60/107 - loss 0.05051470 - samples/sec: 140.67 - lr: 0.001563
2022-03-26 22:02:24,261 epoch 33 - iter 70/107 - loss 0.05057201 - samples/sec: 140.82 - lr: 0.001563
2022-03-26 22:02:26,683 epoch 33 - iter 80/107 - loss 0.05107083 - samples/sec: 132.15 - lr: 0.001563
2022-03-26 22:02:29,140 epoch 33 - iter 90/107 - loss 0.05186845 - samples/sec: 130.32 - lr: 0.001563
2022-03-26 22:02:31,609 epoch 33 - iter 100/107 - loss 0.05195319 - samples/sec: 129.65 - lr: 0.001563
2022-03-26 22:02:33,131 ----------------------------------------------------------------------------------------------------
2022-03-26 22:02:33,132 EPOCH 33 done: loss 0.0512 - lr 0.001563
2022-03-26 22:02:40,587 Evaluating as a multi-label problem: False
2022-03-26 22:02:40,598 DEV : loss 0.21001213788986206 - f1-score (micro avg)  0.5035
2022-03-26 22:02:40,671 BAD EPOCHS (no improvement): 2
2022-03-26 22:02:40,676 ----------------------------------------------------------------------------------------------------
2022-03-26 22:02:43,047 epoch 34 - iter 10/107 - loss 0.04890792 - samples/sec: 135.08 - lr: 0.001563
2022-03-26 22:02:45,386 epoch 34 - iter 20/107 - loss 0.04692912 - samples/sec: 136.85 - lr: 0.001563
2022-03-26 22:02:47,786 epoch 34 - iter 30/107 - loss 0.05117868 - samples/sec: 133.36 - lr: 0.001563
2022-03-26 22:02:50,261 epoch 34 - iter 40/107 - loss 0.05086795 - samples/sec: 129.38 - lr: 0.001563
2022-03-26 22:02:52,668 epoch 34 - iter 50/107 - loss 0.05174660 - samples/sec: 132.98 - lr: 0.001563
2022-03-26 22:02:55,102 epoch 34 - iter 60/107 - loss 0.05038284 - samples/sec: 131.52 - lr: 0.001563
2022-03-26 22:02:57,522 epoch 34 - iter 70/107 - loss 0.05063233 - samples/sec: 132.32 - lr: 0.001563
2022-03-26 22:02:59,891 epoch 34 - iter 80/107 - loss 0.04926469 - samples/sec: 135.10 - lr: 0.001563
2022-03-26 22:03:02,371 epoch 34 - iter 90/107 - loss 0.04879120 - samples/sec: 129.11 - lr: 0.001563
2022-03-26 22:03:04,693 epoch 34 - iter 100/107 - loss 0.04919248 - samples/sec: 137.86 - lr: 0.001563
2022-03-26 22:03:06,095 ----------------------------------------------------------------------------------------------------
2022-03-26 22:03:06,095 EPOCH 34 done: loss 0.0492 - lr 0.001563
2022-03-26 22:03:13,565 Evaluating as a multi-label problem: False
2022-03-26 22:03:13,575 DEV : loss 0.21046505868434906 - f1-score (micro avg)  0.4992
2022-03-26 22:03:13,649 BAD EPOCHS (no improvement): 3
2022-03-26 22:03:13,653 ----------------------------------------------------------------------------------------------------
2022-03-26 22:03:15,990 epoch 35 - iter 10/107 - loss 0.05366775 - samples/sec: 136.97 - lr: 0.001563
2022-03-26 22:03:18,263 epoch 35 - iter 20/107 - loss 0.05578583 - samples/sec: 140.88 - lr: 0.001563
2022-03-26 22:03:20,524 epoch 35 - iter 30/107 - loss 0.05380938 - samples/sec: 141.55 - lr: 0.001563
2022-03-26 22:03:22,935 epoch 35 - iter 40/107 - loss 0.05156312 - samples/sec: 132.78 - lr: 0.001563
2022-03-26 22:03:25,406 epoch 35 - iter 50/107 - loss 0.04961954 - samples/sec: 129.58 - lr: 0.001563
2022-03-26 22:03:27,724 epoch 35 - iter 60/107 - loss 0.05175892 - samples/sec: 138.14 - lr: 0.001563
2022-03-26 22:03:30,109 epoch 35 - iter 70/107 - loss 0.05297639 - samples/sec: 134.23 - lr: 0.001563
2022-03-26 22:03:32,418 epoch 35 - iter 80/107 - loss 0.05284930 - samples/sec: 138.67 - lr: 0.001563
2022-03-26 22:03:34,770 epoch 35 - iter 90/107 - loss 0.05149519 - samples/sec: 136.07 - lr: 0.001563
2022-03-26 22:03:37,223 epoch 35 - iter 100/107 - loss 0.05074808 - samples/sec: 130.52 - lr: 0.001563
2022-03-26 22:03:38,815 ----------------------------------------------------------------------------------------------------
2022-03-26 22:03:38,815 EPOCH 35 done: loss 0.0511 - lr 0.001563
2022-03-26 22:03:46,459 Evaluating as a multi-label problem: False
2022-03-26 22:03:46,470 DEV : loss 0.2110413759946823 - f1-score (micro avg)  0.502
2022-03-26 22:03:46,544 Epoch    35: reducing learning rate of group 0 to 7.8125e-04.
2022-03-26 22:03:46,544 BAD EPOCHS (no improvement): 4
2022-03-26 22:03:46,551 ----------------------------------------------------------------------------------------------------
2022-03-26 22:03:48,993 epoch 36 - iter 10/107 - loss 0.05137839 - samples/sec: 131.10 - lr: 0.000781
2022-03-26 22:03:51,448 epoch 36 - iter 20/107 - loss 0.04765850 - samples/sec: 130.40 - lr: 0.000781
2022-03-26 22:03:53,870 epoch 36 - iter 30/107 - loss 0.04818400 - samples/sec: 132.18 - lr: 0.000781
2022-03-26 22:03:56,266 epoch 36 - iter 40/107 - loss 0.05001666 - samples/sec: 133.61 - lr: 0.000781
2022-03-26 22:03:58,724 epoch 36 - iter 50/107 - loss 0.05130783 - samples/sec: 130.22 - lr: 0.000781
2022-03-26 22:04:01,126 epoch 36 - iter 60/107 - loss 0.05144363 - samples/sec: 133.29 - lr: 0.000781
2022-03-26 22:04:03,476 epoch 36 - iter 70/107 - loss 0.05125781 - samples/sec: 136.23 - lr: 0.000781
2022-03-26 22:04:05,855 epoch 36 - iter 80/107 - loss 0.05103933 - samples/sec: 134.54 - lr: 0.000781
2022-03-26 22:04:08,170 epoch 36 - iter 90/107 - loss 0.05099317 - samples/sec: 138.29 - lr: 0.000781
2022-03-26 22:04:10,562 epoch 36 - iter 100/107 - loss 0.05032136 - samples/sec: 133.83 - lr: 0.000781
2022-03-26 22:04:12,110 ----------------------------------------------------------------------------------------------------
2022-03-26 22:04:12,110 EPOCH 36 done: loss 0.0496 - lr 0.000781
2022-03-26 22:04:19,540 Evaluating as a multi-label problem: False
2022-03-26 22:04:19,551 DEV : loss 0.21204309165477753 - f1-score (micro avg)  0.5028
2022-03-26 22:04:19,623 BAD EPOCHS (no improvement): 1
2022-03-26 22:04:19,627 ----------------------------------------------------------------------------------------------------
2022-03-26 22:04:22,023 epoch 37 - iter 10/107 - loss 0.03312758 - samples/sec: 133.64 - lr: 0.000781
2022-03-26 22:04:24,336 epoch 37 - iter 20/107 - loss 0.03715361 - samples/sec: 138.41 - lr: 0.000781
2022-03-26 22:04:26,641 epoch 37 - iter 30/107 - loss 0.03965240 - samples/sec: 138.89 - lr: 0.000781
2022-03-26 22:04:29,046 epoch 37 - iter 40/107 - loss 0.04564723 - samples/sec: 133.10 - lr: 0.000781
2022-03-26 22:04:31,478 epoch 37 - iter 50/107 - loss 0.04706238 - samples/sec: 131.66 - lr: 0.000781
2022-03-26 22:04:33,878 epoch 37 - iter 60/107 - loss 0.04905312 - samples/sec: 133.36 - lr: 0.000781
2022-03-26 22:04:36,189 epoch 37 - iter 70/107 - loss 0.04876994 - samples/sec: 138.53 - lr: 0.000781
2022-03-26 22:04:38,619 epoch 37 - iter 80/107 - loss 0.04949360 - samples/sec: 131.77 - lr: 0.000781
2022-03-26 22:04:41,075 epoch 37 - iter 90/107 - loss 0.04914740 - samples/sec: 130.32 - lr: 0.000781
2022-03-26 22:04:43,453 epoch 37 - iter 100/107 - loss 0.05135317 - samples/sec: 134.63 - lr: 0.000781
2022-03-26 22:04:44,935 ----------------------------------------------------------------------------------------------------
2022-03-26 22:04:44,935 EPOCH 37 done: loss 0.0509 - lr 0.000781
2022-03-26 22:04:52,397 Evaluating as a multi-label problem: False
2022-03-26 22:04:52,408 DEV : loss 0.21046271920204163 - f1-score (micro avg)  0.5035
2022-03-26 22:04:52,480 BAD EPOCHS (no improvement): 2
2022-03-26 22:04:52,485 ----------------------------------------------------------------------------------------------------
2022-03-26 22:04:54,910 epoch 38 - iter 10/107 - loss 0.04618318 - samples/sec: 132.00 - lr: 0.000781
2022-03-26 22:04:57,248 epoch 38 - iter 20/107 - loss 0.04908280 - samples/sec: 136.96 - lr: 0.000781
2022-03-26 22:04:59,675 epoch 38 - iter 30/107 - loss 0.05147771 - samples/sec: 131.86 - lr: 0.000781
2022-03-26 22:05:02,041 epoch 38 - iter 40/107 - loss 0.04837434 - samples/sec: 135.36 - lr: 0.000781
2022-03-26 22:05:04,475 epoch 38 - iter 50/107 - loss 0.04852427 - samples/sec: 131.52 - lr: 0.000781
2022-03-26 22:05:06,811 epoch 38 - iter 60/107 - loss 0.04760426 - samples/sec: 137.08 - lr: 0.000781
2022-03-26 22:05:09,135 epoch 38 - iter 70/107 - loss 0.04964390 - samples/sec: 137.72 - lr: 0.000781
2022-03-26 22:05:11,577 epoch 38 - iter 80/107 - loss 0.05046791 - samples/sec: 131.10 - lr: 0.000781
2022-03-26 22:05:13,931 epoch 38 - iter 90/107 - loss 0.05049344 - samples/sec: 136.02 - lr: 0.000781
2022-03-26 22:05:16,313 epoch 38 - iter 100/107 - loss 0.05116711 - samples/sec: 134.39 - lr: 0.000781
2022-03-26 22:05:17,804 ----------------------------------------------------------------------------------------------------
2022-03-26 22:05:17,804 EPOCH 38 done: loss 0.0512 - lr 0.000781
2022-03-26 22:05:25,331 Evaluating as a multi-label problem: False
2022-03-26 22:05:25,342 DEV : loss 0.2102138251066208 - f1-score (micro avg)  0.5016
2022-03-26 22:05:25,414 BAD EPOCHS (no improvement): 3
2022-03-26 22:05:25,418 ----------------------------------------------------------------------------------------------------
2022-03-26 22:05:27,767 epoch 39 - iter 10/107 - loss 0.05450219 - samples/sec: 136.28 - lr: 0.000781
2022-03-26 22:05:30,114 epoch 39 - iter 20/107 - loss 0.05494342 - samples/sec: 136.40 - lr: 0.000781
2022-03-26 22:05:35,956 epoch 39 - iter 30/107 - loss 0.05074946 - samples/sec: 54.79 - lr: 0.000781
2022-03-26 22:05:38,331 epoch 39 - iter 40/107 - loss 0.05113910 - samples/sec: 134.78 - lr: 0.000781
2022-03-26 22:05:40,764 epoch 39 - iter 50/107 - loss 0.05184599 - samples/sec: 131.60 - lr: 0.000781
2022-03-26 22:05:43,191 epoch 39 - iter 60/107 - loss 0.05089673 - samples/sec: 131.90 - lr: 0.000781
2022-03-26 22:05:45,572 epoch 39 - iter 70/107 - loss 0.05122141 - samples/sec: 134.42 - lr: 0.000781
2022-03-26 22:05:47,963 epoch 39 - iter 80/107 - loss 0.05139706 - samples/sec: 133.91 - lr: 0.000781
2022-03-26 22:05:50,382 epoch 39 - iter 90/107 - loss 0.05045044 - samples/sec: 132.35 - lr: 0.000781
2022-03-26 22:05:52,789 epoch 39 - iter 100/107 - loss 0.05082842 - samples/sec: 133.03 - lr: 0.000781
2022-03-26 22:05:54,221 ----------------------------------------------------------------------------------------------------
2022-03-26 22:05:54,221 EPOCH 39 done: loss 0.0506 - lr 0.000781
2022-03-26 22:06:01,696 Evaluating as a multi-label problem: False
2022-03-26 22:06:01,707 DEV : loss 0.20862774550914764 - f1-score (micro avg)  0.5074
2022-03-26 22:06:01,779 Epoch    39: reducing learning rate of group 0 to 3.9063e-04.
2022-03-26 22:06:01,779 BAD EPOCHS (no improvement): 4
2022-03-26 22:06:01,784 ----------------------------------------------------------------------------------------------------
2022-03-26 22:06:04,170 epoch 40 - iter 10/107 - loss 0.06060575 - samples/sec: 134.17 - lr: 0.000391
2022-03-26 22:06:06,533 epoch 40 - iter 20/107 - loss 0.05664423 - samples/sec: 135.52 - lr: 0.000391
2022-03-26 22:06:08,834 epoch 40 - iter 30/107 - loss 0.05590487 - samples/sec: 139.07 - lr: 0.000391
2022-03-26 22:06:11,228 epoch 40 - iter 40/107 - loss 0.05201295 - samples/sec: 133.76 - lr: 0.000391
2022-03-26 22:06:13,675 epoch 40 - iter 50/107 - loss 0.04988444 - samples/sec: 130.80 - lr: 0.000391
2022-03-26 22:06:15,947 epoch 40 - iter 60/107 - loss 0.04855316 - samples/sec: 140.95 - lr: 0.000391
2022-03-26 22:06:18,236 epoch 40 - iter 70/107 - loss 0.04876148 - samples/sec: 139.80 - lr: 0.000391
2022-03-26 22:06:20,461 epoch 40 - iter 80/107 - loss 0.04901051 - samples/sec: 143.91 - lr: 0.000391
2022-03-26 22:06:22,638 epoch 40 - iter 90/107 - loss 0.04944250 - samples/sec: 147.09 - lr: 0.000391
2022-03-26 22:06:24,934 epoch 40 - iter 100/107 - loss 0.04970014 - samples/sec: 139.38 - lr: 0.000391
2022-03-26 22:06:26,362 ----------------------------------------------------------------------------------------------------
2022-03-26 22:06:26,362 EPOCH 40 done: loss 0.0502 - lr 0.000391
2022-03-26 22:06:33,872 Evaluating as a multi-label problem: False
2022-03-26 22:06:33,883 DEV : loss 0.2088349312543869 - f1-score (micro avg)  0.5059
2022-03-26 22:06:33,955 BAD EPOCHS (no improvement): 1
2022-03-26 22:06:33,960 ----------------------------------------------------------------------------------------------------
2022-03-26 22:06:36,319 epoch 41 - iter 10/107 - loss 0.04477317 - samples/sec: 135.75 - lr: 0.000391
2022-03-26 22:06:38,657 epoch 41 - iter 20/107 - loss 0.04519241 - samples/sec: 136.93 - lr: 0.000391
2022-03-26 22:06:41,032 epoch 41 - iter 30/107 - loss 0.04962819 - samples/sec: 134.78 - lr: 0.000391
2022-03-26 22:06:43,492 epoch 41 - iter 40/107 - loss 0.05306712 - samples/sec: 130.13 - lr: 0.000391
2022-03-26 22:06:45,839 epoch 41 - iter 50/107 - loss 0.05243101 - samples/sec: 136.44 - lr: 0.000391
2022-03-26 22:06:48,167 epoch 41 - iter 60/107 - loss 0.05158836 - samples/sec: 137.53 - lr: 0.000391
2022-03-26 22:06:50,553 epoch 41 - iter 70/107 - loss 0.05339565 - samples/sec: 134.17 - lr: 0.000391
2022-03-26 22:06:53,063 epoch 41 - iter 80/107 - loss 0.05194856 - samples/sec: 127.49 - lr: 0.000391
2022-03-26 22:06:55,518 epoch 41 - iter 90/107 - loss 0.05079680 - samples/sec: 130.43 - lr: 0.000391
2022-03-26 22:06:57,863 epoch 41 - iter 100/107 - loss 0.05108890 - samples/sec: 136.50 - lr: 0.000391
2022-03-26 22:06:59,345 ----------------------------------------------------------------------------------------------------
2022-03-26 22:06:59,345 EPOCH 41 done: loss 0.0507 - lr 0.000391
2022-03-26 22:07:06,898 Evaluating as a multi-label problem: False
2022-03-26 22:07:06,909 DEV : loss 0.20885029435157776 - f1-score (micro avg)  0.5059
2022-03-26 22:07:06,981 BAD EPOCHS (no improvement): 2
2022-03-26 22:07:06,986 ----------------------------------------------------------------------------------------------------
2022-03-26 22:07:09,374 epoch 42 - iter 10/107 - loss 0.04246488 - samples/sec: 134.09 - lr: 0.000391
2022-03-26 22:07:11,802 epoch 42 - iter 20/107 - loss 0.04373750 - samples/sec: 131.82 - lr: 0.000391
2022-03-26 22:07:14,149 epoch 42 - iter 30/107 - loss 0.04255961 - samples/sec: 136.40 - lr: 0.000391
2022-03-26 22:07:16,544 epoch 42 - iter 40/107 - loss 0.04870384 - samples/sec: 133.70 - lr: 0.000391
2022-03-26 22:07:18,916 epoch 42 - iter 50/107 - loss 0.05014975 - samples/sec: 134.92 - lr: 0.000391
2022-03-26 22:07:21,342 epoch 42 - iter 60/107 - loss 0.04928385 - samples/sec: 131.99 - lr: 0.000391
2022-03-26 22:07:23,719 epoch 42 - iter 70/107 - loss 0.04964287 - samples/sec: 134.69 - lr: 0.000391
2022-03-26 22:07:26,111 epoch 42 - iter 80/107 - loss 0.04879286 - samples/sec: 133.84 - lr: 0.000391
2022-03-26 22:07:28,491 epoch 42 - iter 90/107 - loss 0.04918802 - samples/sec: 134.55 - lr: 0.000391
2022-03-26 22:07:30,889 epoch 42 - iter 100/107 - loss 0.04918674 - samples/sec: 133.47 - lr: 0.000391
2022-03-26 22:07:32,413 ----------------------------------------------------------------------------------------------------
2022-03-26 22:07:32,414 EPOCH 42 done: loss 0.0490 - lr 0.000391
2022-03-26 22:07:39,867 Evaluating as a multi-label problem: False
2022-03-26 22:07:39,879 DEV : loss 0.2092301994562149 - f1-score (micro avg)  0.5062
2022-03-26 22:07:39,953 BAD EPOCHS (no improvement): 3
2022-03-26 22:07:39,956 ----------------------------------------------------------------------------------------------------
2022-03-26 22:07:42,366 epoch 43 - iter 10/107 - loss 0.03938430 - samples/sec: 132.90 - lr: 0.000391
2022-03-26 22:07:44,792 epoch 43 - iter 20/107 - loss 0.04596983 - samples/sec: 131.95 - lr: 0.000391
2022-03-26 22:07:47,193 epoch 43 - iter 30/107 - loss 0.04725279 - samples/sec: 133.32 - lr: 0.000391
2022-03-26 22:07:49,537 epoch 43 - iter 40/107 - loss 0.04717826 - samples/sec: 136.59 - lr: 0.000391
2022-03-26 22:07:51,827 epoch 43 - iter 50/107 - loss 0.04965924 - samples/sec: 139.80 - lr: 0.000391
2022-03-26 22:07:54,271 epoch 43 - iter 60/107 - loss 0.04861151 - samples/sec: 130.98 - lr: 0.000391
2022-03-26 22:07:56,676 epoch 43 - iter 70/107 - loss 0.05002509 - samples/sec: 133.13 - lr: 0.000391
2022-03-26 22:07:59,142 epoch 43 - iter 80/107 - loss 0.05015415 - samples/sec: 129.80 - lr: 0.000391
2022-03-26 22:08:01,486 epoch 43 - iter 90/107 - loss 0.04967717 - samples/sec: 136.56 - lr: 0.000391
2022-03-26 22:08:03,916 epoch 43 - iter 100/107 - loss 0.04956366 - samples/sec: 131.73 - lr: 0.000391
2022-03-26 22:08:05,354 ----------------------------------------------------------------------------------------------------
2022-03-26 22:08:05,354 EPOCH 43 done: loss 0.0493 - lr 0.000391
2022-03-26 22:08:12,836 Evaluating as a multi-label problem: False
2022-03-26 22:08:12,846 DEV : loss 0.20970329642295837 - f1-score (micro avg)  0.5062
2022-03-26 22:08:12,923 Epoch    43: reducing learning rate of group 0 to 1.9531e-04.
2022-03-26 22:08:12,924 BAD EPOCHS (no improvement): 4
2022-03-26 22:08:12,931 ----------------------------------------------------------------------------------------------------
2022-03-26 22:08:15,274 epoch 44 - iter 10/107 - loss 0.04709091 - samples/sec: 136.72 - lr: 0.000195
2022-03-26 22:08:17,615 epoch 44 - iter 20/107 - loss 0.04561491 - samples/sec: 136.73 - lr: 0.000195
2022-03-26 22:08:19,835 epoch 44 - iter 30/107 - loss 0.04734731 - samples/sec: 144.21 - lr: 0.000195
2022-03-26 22:08:22,210 epoch 44 - iter 40/107 - loss 0.04664166 - samples/sec: 134.80 - lr: 0.000195
2022-03-26 22:08:24,598 epoch 44 - iter 50/107 - loss 0.04736429 - samples/sec: 134.04 - lr: 0.000195
2022-03-26 22:08:26,973 epoch 44 - iter 60/107 - loss 0.04757984 - samples/sec: 134.82 - lr: 0.000195
2022-03-26 22:08:29,399 epoch 44 - iter 70/107 - loss 0.04837855 - samples/sec: 131.95 - lr: 0.000195
2022-03-26 22:08:31,814 epoch 44 - iter 80/107 - loss 0.04840069 - samples/sec: 132.53 - lr: 0.000195
2022-03-26 22:08:34,201 epoch 44 - iter 90/107 - loss 0.04946771 - samples/sec: 134.14 - lr: 0.000195
2022-03-26 22:08:36,604 epoch 44 - iter 100/107 - loss 0.04974058 - samples/sec: 133.24 - lr: 0.000195
2022-03-26 22:08:38,088 ----------------------------------------------------------------------------------------------------
2022-03-26 22:08:38,088 EPOCH 44 done: loss 0.0500 - lr 0.000195
2022-03-26 22:08:45,608 Evaluating as a multi-label problem: False
2022-03-26 22:08:45,619 DEV : loss 0.20932748913764954 - f1-score (micro avg)  0.507
2022-03-26 22:08:45,691 BAD EPOCHS (no improvement): 1
2022-03-26 22:08:45,695 ----------------------------------------------------------------------------------------------------
2022-03-26 22:08:48,122 epoch 45 - iter 10/107 - loss 0.05983984 - samples/sec: 131.89 - lr: 0.000195
2022-03-26 22:08:50,456 epoch 45 - iter 20/107 - loss 0.05373868 - samples/sec: 137.16 - lr: 0.000195
2022-03-26 22:08:52,884 epoch 45 - iter 30/107 - loss 0.05163130 - samples/sec: 131.88 - lr: 0.000195
2022-03-26 22:08:55,337 epoch 45 - iter 40/107 - loss 0.05054365 - samples/sec: 130.47 - lr: 0.000195
2022-03-26 22:08:57,776 epoch 45 - iter 50/107 - loss 0.04989112 - samples/sec: 131.30 - lr: 0.000195
2022-03-26 22:09:00,198 epoch 45 - iter 60/107 - loss 0.04875062 - samples/sec: 132.17 - lr: 0.000195
2022-03-26 22:09:02,549 epoch 45 - iter 70/107 - loss 0.04881760 - samples/sec: 136.19 - lr: 0.000195
2022-03-26 22:09:04,862 epoch 45 - iter 80/107 - loss 0.04868583 - samples/sec: 138.38 - lr: 0.000195
2022-03-26 22:09:07,218 epoch 45 - iter 90/107 - loss 0.04921568 - samples/sec: 135.91 - lr: 0.000195
2022-03-26 22:09:09,610 epoch 45 - iter 100/107 - loss 0.05122823 - samples/sec: 133.85 - lr: 0.000195
2022-03-26 22:09:11,062 ----------------------------------------------------------------------------------------------------
2022-03-26 22:09:11,062 EPOCH 45 done: loss 0.0510 - lr 0.000195
2022-03-26 22:09:18,603 Evaluating as a multi-label problem: False
2022-03-26 22:09:18,614 DEV : loss 0.20941083133220673 - f1-score (micro avg)  0.5051
2022-03-26 22:09:18,691 BAD EPOCHS (no improvement): 2
2022-03-26 22:09:18,695 ----------------------------------------------------------------------------------------------------
2022-03-26 22:09:21,078 epoch 46 - iter 10/107 - loss 0.03795528 - samples/sec: 134.40 - lr: 0.000195
2022-03-26 22:09:23,401 epoch 46 - iter 20/107 - loss 0.04775297 - samples/sec: 137.77 - lr: 0.000195
2022-03-26 22:09:25,806 epoch 46 - iter 30/107 - loss 0.05138302 - samples/sec: 133.11 - lr: 0.000195
2022-03-26 22:09:28,194 epoch 46 - iter 40/107 - loss 0.05171667 - samples/sec: 134.07 - lr: 0.000195
2022-03-26 22:09:30,577 epoch 46 - iter 50/107 - loss 0.05053320 - samples/sec: 134.35 - lr: 0.000195
2022-03-26 22:09:32,982 epoch 46 - iter 60/107 - loss 0.05132211 - samples/sec: 133.09 - lr: 0.000195
2022-03-26 22:09:35,366 epoch 46 - iter 70/107 - loss 0.04963158 - samples/sec: 134.28 - lr: 0.000195
2022-03-26 22:09:37,667 epoch 46 - iter 80/107 - loss 0.05009632 - samples/sec: 139.11 - lr: 0.000195
2022-03-26 22:09:40,212 epoch 46 - iter 90/107 - loss 0.04904783 - samples/sec: 125.82 - lr: 0.000195
2022-03-26 22:09:42,578 epoch 46 - iter 100/107 - loss 0.04955797 - samples/sec: 135.26 - lr: 0.000195
2022-03-26 22:09:44,033 ----------------------------------------------------------------------------------------------------
2022-03-26 22:09:44,033 EPOCH 46 done: loss 0.0494 - lr 0.000195
2022-03-26 22:09:51,546 Evaluating as a multi-label problem: False
2022-03-26 22:09:51,557 DEV : loss 0.2100594937801361 - f1-score (micro avg)  0.5043
2022-03-26 22:09:51,632 BAD EPOCHS (no improvement): 3
2022-03-26 22:09:51,635 ----------------------------------------------------------------------------------------------------
2022-03-26 22:09:54,080 epoch 47 - iter 10/107 - loss 0.03759822 - samples/sec: 130.98 - lr: 0.000195
2022-03-26 22:09:56,483 epoch 47 - iter 20/107 - loss 0.04290028 - samples/sec: 133.27 - lr: 0.000195
2022-03-26 22:09:58,880 epoch 47 - iter 30/107 - loss 0.04497740 - samples/sec: 133.57 - lr: 0.000195
2022-03-26 22:10:01,339 epoch 47 - iter 40/107 - loss 0.04712611 - samples/sec: 130.19 - lr: 0.000195
2022-03-26 22:10:03,626 epoch 47 - iter 50/107 - loss 0.04741398 - samples/sec: 139.95 - lr: 0.000195
2022-03-26 22:10:06,061 epoch 47 - iter 60/107 - loss 0.04838491 - samples/sec: 131.46 - lr: 0.000195
2022-03-26 22:10:08,401 epoch 47 - iter 70/107 - loss 0.04934501 - samples/sec: 136.81 - lr: 0.000195
2022-03-26 22:10:10,877 epoch 47 - iter 80/107 - loss 0.04944892 - samples/sec: 129.29 - lr: 0.000195
2022-03-26 22:10:13,200 epoch 47 - iter 90/107 - loss 0.04879936 - samples/sec: 137.84 - lr: 0.000195
2022-03-26 22:10:15,508 epoch 47 - iter 100/107 - loss 0.04873144 - samples/sec: 138.67 - lr: 0.000195
2022-03-26 22:10:16,971 ----------------------------------------------------------------------------------------------------
2022-03-26 22:10:16,971 EPOCH 47 done: loss 0.0487 - lr 0.000195
2022-03-26 22:10:24,479 Evaluating as a multi-label problem: False
2022-03-26 22:10:24,489 DEV : loss 0.2097213864326477 - f1-score (micro avg)  0.5047
2022-03-26 22:10:24,562 Epoch    47: reducing learning rate of group 0 to 9.7656e-05.
2022-03-26 22:10:24,562 BAD EPOCHS (no improvement): 4
2022-03-26 22:10:24,569 ----------------------------------------------------------------------------------------------------
2022-03-26 22:10:24,569 ----------------------------------------------------------------------------------------------------
2022-03-26 22:10:24,571 learning rate too small - quitting training!
2022-03-26 22:10:24,571 ----------------------------------------------------------------------------------------------------
2022-03-26 22:10:59,729 ----------------------------------------------------------------------------------------------------
2022-03-26 22:10:59,730 loading file resources/taggers/model_03_r5_run_1/best-model.pt
2022-03-26 22:11:24,371 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-03-26 22:11:44,814 Evaluating as a multi-label problem: False
2022-03-26 22:11:44,827 0.6427	0.3234	0.4303	0.2923
2022-03-26 22:11:44,827 
Results:
- F-score (micro) 0.4303
- F-score (macro) 0.3075
- Accuracy 0.2923

By class:
               precision    recall  f1-score   support

       person     0.7026    0.5012    0.5850       429
     location     0.6260    0.5133    0.5641       150
        group     0.5800    0.1758    0.2698       165
creative-work     0.7222    0.0915    0.1625       142
      product     0.4667    0.0551    0.0986       127
  corporation     0.2581    0.1212    0.1649        66

    micro avg     0.6427    0.3234    0.4303      1079
    macro avg     0.5593    0.2430    0.3075      1079
 weighted avg     0.6208    0.3234    0.3954      1079

2022-03-26 22:11:44,830 ----------------------------------------------------------------------------------------------------
