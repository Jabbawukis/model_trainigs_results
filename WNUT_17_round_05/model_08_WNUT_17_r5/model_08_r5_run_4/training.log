2022-03-28 10:48:16,466 ----------------------------------------------------------------------------------------------------
2022-03-28 10:48:16,466 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): GazetteerEmbeddings()
    (list_embedding_1): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_3): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4857, out_features=4857, bias=True)
  (rnn): LSTM(4857, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-03-28 10:48:16,467 ----------------------------------------------------------------------------------------------------
2022-03-28 10:48:16,468 Corpus: "Corpus: 3394 train + 1009 dev + 1287 test sentences"
2022-03-28 10:48:16,468 ----------------------------------------------------------------------------------------------------
2022-03-28 10:48:16,469 Parameters:
2022-03-28 10:48:16,469  - learning_rate: "0.100000"
2022-03-28 10:48:16,470  - mini_batch_size: "32"
2022-03-28 10:48:16,470  - patience: "3"
2022-03-28 10:48:16,470  - anneal_factor: "0.5"
2022-03-28 10:48:16,470  - max_epochs: "150"
2022-03-28 10:48:16,470  - shuffle: "True"
2022-03-28 10:48:16,470  - train_with_dev: "False"
2022-03-28 10:48:16,471  - batch_growth_annealing: "False"
2022-03-28 10:48:16,471 ----------------------------------------------------------------------------------------------------
2022-03-28 10:48:16,471 Model training base path: "resources/taggers/model_08_r5_run_1"
2022-03-28 10:48:16,471 ----------------------------------------------------------------------------------------------------
2022-03-28 10:48:16,471 Device: cuda:2
2022-03-28 10:48:16,471 ----------------------------------------------------------------------------------------------------
2022-03-28 10:48:16,471 Embeddings storage mode: cpu
2022-03-28 10:48:16,471 ----------------------------------------------------------------------------------------------------
2022-03-28 10:48:19,642 epoch 1 - iter 10/107 - loss 0.77028359 - samples/sec: 100.95 - lr: 0.100000
2022-03-28 10:48:22,815 epoch 1 - iter 20/107 - loss 0.52652959 - samples/sec: 100.88 - lr: 0.100000
2022-03-28 10:48:26,004 epoch 1 - iter 30/107 - loss 0.44162420 - samples/sec: 100.38 - lr: 0.100000
2022-03-28 10:48:29,184 epoch 1 - iter 40/107 - loss 0.39474704 - samples/sec: 100.65 - lr: 0.100000
2022-03-28 10:48:32,397 epoch 1 - iter 50/107 - loss 0.35693542 - samples/sec: 99.63 - lr: 0.100000
2022-03-28 10:48:36,756 epoch 1 - iter 60/107 - loss 0.34424804 - samples/sec: 73.44 - lr: 0.100000
2022-03-28 10:48:39,999 epoch 1 - iter 70/107 - loss 0.33290656 - samples/sec: 98.70 - lr: 0.100000
2022-03-28 10:48:43,117 epoch 1 - iter 80/107 - loss 0.33046306 - samples/sec: 102.64 - lr: 0.100000
2022-03-28 10:48:46,083 epoch 1 - iter 90/107 - loss 0.32751075 - samples/sec: 107.94 - lr: 0.100000
2022-03-28 10:48:49,133 epoch 1 - iter 100/107 - loss 0.32252616 - samples/sec: 104.95 - lr: 0.100000
2022-03-28 10:48:51,020 ----------------------------------------------------------------------------------------------------
2022-03-28 10:48:51,020 EPOCH 1 done: loss 0.3162 - lr 0.100000
2022-03-28 10:49:02,177 Evaluating as a multi-label problem: False
2022-03-28 10:49:02,188 DEV : loss 0.38920536637306213 - f1-score (micro avg)  0.1734
2022-03-28 10:49:02,272 BAD EPOCHS (no improvement): 0
2022-03-28 10:49:02,275 saving best model
2022-03-28 10:49:17,418 ----------------------------------------------------------------------------------------------------
2022-03-28 10:49:23,322 epoch 2 - iter 10/107 - loss 0.19602136 - samples/sec: 54.21 - lr: 0.100000
2022-03-28 10:49:25,358 epoch 2 - iter 20/107 - loss 0.19200873 - samples/sec: 157.32 - lr: 0.100000
2022-03-28 10:49:27,234 epoch 2 - iter 30/107 - loss 0.19150000 - samples/sec: 170.61 - lr: 0.100000
2022-03-28 10:49:29,169 epoch 2 - iter 40/107 - loss 0.19528264 - samples/sec: 165.53 - lr: 0.100000
2022-03-28 10:49:31,121 epoch 2 - iter 50/107 - loss 0.20137904 - samples/sec: 163.95 - lr: 0.100000
2022-03-28 10:49:33,106 epoch 2 - iter 60/107 - loss 0.19308663 - samples/sec: 161.34 - lr: 0.100000
2022-03-28 10:49:35,068 epoch 2 - iter 70/107 - loss 0.19467731 - samples/sec: 163.16 - lr: 0.100000
2022-03-28 10:49:37,166 epoch 2 - iter 80/107 - loss 0.19238587 - samples/sec: 152.56 - lr: 0.100000
2022-03-28 10:49:39,177 epoch 2 - iter 90/107 - loss 0.18806260 - samples/sec: 159.20 - lr: 0.100000
2022-03-28 10:49:41,165 epoch 2 - iter 100/107 - loss 0.19010138 - samples/sec: 161.06 - lr: 0.100000
2022-03-28 10:49:42,356 ----------------------------------------------------------------------------------------------------
2022-03-28 10:49:42,356 EPOCH 2 done: loss 0.1893 - lr 0.100000
2022-03-28 10:49:48,649 Evaluating as a multi-label problem: False
2022-03-28 10:49:48,660 DEV : loss 0.2631389796733856 - f1-score (micro avg)  0.4596
2022-03-28 10:49:48,747 BAD EPOCHS (no improvement): 0
2022-03-28 10:49:48,763 saving best model
2022-03-28 10:50:03,668 ----------------------------------------------------------------------------------------------------
2022-03-28 10:50:05,835 epoch 3 - iter 10/107 - loss 0.19151462 - samples/sec: 147.85 - lr: 0.100000
2022-03-28 10:50:07,859 epoch 3 - iter 20/107 - loss 0.17315217 - samples/sec: 158.10 - lr: 0.100000
2022-03-28 10:50:09,806 epoch 3 - iter 30/107 - loss 0.16673832 - samples/sec: 164.45 - lr: 0.100000
2022-03-28 10:50:11,724 epoch 3 - iter 40/107 - loss 0.16640283 - samples/sec: 166.95 - lr: 0.100000
2022-03-28 10:50:13,645 epoch 3 - iter 50/107 - loss 0.17125408 - samples/sec: 166.68 - lr: 0.100000
2022-03-28 10:50:15,527 epoch 3 - iter 60/107 - loss 0.17294188 - samples/sec: 170.11 - lr: 0.100000
2022-03-28 10:50:17,382 epoch 3 - iter 70/107 - loss 0.16921504 - samples/sec: 172.63 - lr: 0.100000
2022-03-28 10:50:19,235 epoch 3 - iter 80/107 - loss 0.16629716 - samples/sec: 172.81 - lr: 0.100000
2022-03-28 10:50:21,191 epoch 3 - iter 90/107 - loss 0.16168279 - samples/sec: 163.64 - lr: 0.100000
2022-03-28 10:50:23,225 epoch 3 - iter 100/107 - loss 0.15968573 - samples/sec: 157.40 - lr: 0.100000
2022-03-28 10:50:24,478 ----------------------------------------------------------------------------------------------------
2022-03-28 10:50:24,479 EPOCH 3 done: loss 0.1602 - lr 0.100000
2022-03-28 10:50:30,818 Evaluating as a multi-label problem: False
2022-03-28 10:50:30,829 DEV : loss 0.260699987411499 - f1-score (micro avg)  0.4554
2022-03-28 10:50:30,912 BAD EPOCHS (no improvement): 1
2022-03-28 10:50:30,924 ----------------------------------------------------------------------------------------------------
2022-03-28 10:50:33,072 epoch 4 - iter 10/107 - loss 0.13370934 - samples/sec: 149.03 - lr: 0.100000
2022-03-28 10:50:35,148 epoch 4 - iter 20/107 - loss 0.14194005 - samples/sec: 154.21 - lr: 0.100000
2022-03-28 10:50:37,153 epoch 4 - iter 30/107 - loss 0.13967929 - samples/sec: 159.68 - lr: 0.100000
2022-03-28 10:50:39,212 epoch 4 - iter 40/107 - loss 0.14460853 - samples/sec: 155.50 - lr: 0.100000
2022-03-28 10:50:41,314 epoch 4 - iter 50/107 - loss 0.14323399 - samples/sec: 152.30 - lr: 0.100000
2022-03-28 10:50:43,346 epoch 4 - iter 60/107 - loss 0.13924575 - samples/sec: 157.55 - lr: 0.100000
2022-03-28 10:50:45,500 epoch 4 - iter 70/107 - loss 0.13950371 - samples/sec: 148.65 - lr: 0.100000
2022-03-28 10:50:47,535 epoch 4 - iter 80/107 - loss 0.13823965 - samples/sec: 157.33 - lr: 0.100000
2022-03-28 10:50:49,490 epoch 4 - iter 90/107 - loss 0.13729180 - samples/sec: 163.69 - lr: 0.100000
2022-03-28 10:50:51,447 epoch 4 - iter 100/107 - loss 0.13994740 - samples/sec: 163.65 - lr: 0.100000
2022-03-28 10:50:52,651 ----------------------------------------------------------------------------------------------------
2022-03-28 10:50:52,651 EPOCH 4 done: loss 0.1404 - lr 0.100000
2022-03-28 10:50:58,909 Evaluating as a multi-label problem: False
2022-03-28 10:50:58,919 DEV : loss 0.2307649701833725 - f1-score (micro avg)  0.4901
2022-03-28 10:50:59,002 BAD EPOCHS (no improvement): 0
2022-03-28 10:50:59,005 saving best model
2022-03-28 10:51:14,275 ----------------------------------------------------------------------------------------------------
2022-03-28 10:51:16,216 epoch 5 - iter 10/107 - loss 0.12778141 - samples/sec: 165.03 - lr: 0.100000
2022-03-28 10:51:18,199 epoch 5 - iter 20/107 - loss 0.14824177 - samples/sec: 161.42 - lr: 0.100000
2022-03-28 10:51:20,157 epoch 5 - iter 30/107 - loss 0.14282993 - samples/sec: 163.53 - lr: 0.100000
2022-03-28 10:51:22,204 epoch 5 - iter 40/107 - loss 0.13710319 - samples/sec: 156.43 - lr: 0.100000
2022-03-28 10:51:24,169 epoch 5 - iter 50/107 - loss 0.13679952 - samples/sec: 162.86 - lr: 0.100000
2022-03-28 10:51:26,207 epoch 5 - iter 60/107 - loss 0.13091269 - samples/sec: 157.10 - lr: 0.100000
2022-03-28 10:51:28,269 epoch 5 - iter 70/107 - loss 0.13107787 - samples/sec: 155.29 - lr: 0.100000
2022-03-28 10:51:30,297 epoch 5 - iter 80/107 - loss 0.13080275 - samples/sec: 157.83 - lr: 0.100000
2022-03-28 10:51:32,282 epoch 5 - iter 90/107 - loss 0.12925115 - samples/sec: 161.35 - lr: 0.100000
2022-03-28 10:51:34,258 epoch 5 - iter 100/107 - loss 0.12898762 - samples/sec: 162.02 - lr: 0.100000
2022-03-28 10:51:35,557 ----------------------------------------------------------------------------------------------------
2022-03-28 10:51:35,557 EPOCH 5 done: loss 0.1263 - lr 0.100000
2022-03-28 10:51:42,832 Evaluating as a multi-label problem: False
2022-03-28 10:51:42,843 DEV : loss 0.2527503967285156 - f1-score (micro avg)  0.4915
2022-03-28 10:51:42,931 BAD EPOCHS (no improvement): 0
2022-03-28 10:51:42,934 saving best model
2022-03-28 10:51:57,736 ----------------------------------------------------------------------------------------------------
2022-03-28 10:51:59,788 epoch 6 - iter 10/107 - loss 0.12661833 - samples/sec: 156.06 - lr: 0.100000
2022-03-28 10:52:01,724 epoch 6 - iter 20/107 - loss 0.11995941 - samples/sec: 165.43 - lr: 0.100000
2022-03-28 10:52:03,702 epoch 6 - iter 30/107 - loss 0.11597216 - samples/sec: 161.86 - lr: 0.100000
2022-03-28 10:52:05,703 epoch 6 - iter 40/107 - loss 0.11788817 - samples/sec: 159.98 - lr: 0.100000
2022-03-28 10:52:07,714 epoch 6 - iter 50/107 - loss 0.11545550 - samples/sec: 159.19 - lr: 0.100000
2022-03-28 10:52:09,653 epoch 6 - iter 60/107 - loss 0.11586623 - samples/sec: 165.13 - lr: 0.100000
2022-03-28 10:52:11,715 epoch 6 - iter 70/107 - loss 0.11909929 - samples/sec: 155.27 - lr: 0.100000
2022-03-28 10:52:13,698 epoch 6 - iter 80/107 - loss 0.12232647 - samples/sec: 161.45 - lr: 0.100000
2022-03-28 10:52:15,775 epoch 6 - iter 90/107 - loss 0.11953471 - samples/sec: 154.12 - lr: 0.100000
2022-03-28 10:52:17,801 epoch 6 - iter 100/107 - loss 0.11857438 - samples/sec: 157.98 - lr: 0.100000
2022-03-28 10:52:19,057 ----------------------------------------------------------------------------------------------------
2022-03-28 10:52:19,057 EPOCH 6 done: loss 0.1200 - lr 0.100000
2022-03-28 10:52:25,327 Evaluating as a multi-label problem: False
2022-03-28 10:52:25,338 DEV : loss 0.21276317536830902 - f1-score (micro avg)  0.4878
2022-03-28 10:52:25,423 BAD EPOCHS (no improvement): 1
2022-03-28 10:52:25,425 ----------------------------------------------------------------------------------------------------
2022-03-28 10:52:27,434 epoch 7 - iter 10/107 - loss 0.11019122 - samples/sec: 159.37 - lr: 0.100000
2022-03-28 10:52:29,369 epoch 7 - iter 20/107 - loss 0.10984063 - samples/sec: 165.48 - lr: 0.100000
2022-03-28 10:52:31,368 epoch 7 - iter 30/107 - loss 0.10135856 - samples/sec: 160.12 - lr: 0.100000
2022-03-28 10:52:33,397 epoch 7 - iter 40/107 - loss 0.10113381 - samples/sec: 157.84 - lr: 0.100000
2022-03-28 10:52:35,354 epoch 7 - iter 50/107 - loss 0.10043065 - samples/sec: 163.62 - lr: 0.100000
2022-03-28 10:52:37,332 epoch 7 - iter 60/107 - loss 0.10176939 - samples/sec: 161.82 - lr: 0.100000
2022-03-28 10:52:39,382 epoch 7 - iter 70/107 - loss 0.10188476 - samples/sec: 156.21 - lr: 0.100000
2022-03-28 10:52:41,376 epoch 7 - iter 80/107 - loss 0.10530306 - samples/sec: 160.56 - lr: 0.100000
2022-03-28 10:52:43,446 epoch 7 - iter 90/107 - loss 0.10768828 - samples/sec: 154.63 - lr: 0.100000
2022-03-28 10:52:45,483 epoch 7 - iter 100/107 - loss 0.10883933 - samples/sec: 157.18 - lr: 0.100000
2022-03-28 10:52:46,756 ----------------------------------------------------------------------------------------------------
2022-03-28 10:52:46,756 EPOCH 7 done: loss 0.1084 - lr 0.100000
2022-03-28 10:52:53,014 Evaluating as a multi-label problem: False
2022-03-28 10:52:53,025 DEV : loss 0.24222800135612488 - f1-score (micro avg)  0.4756
2022-03-28 10:52:53,109 BAD EPOCHS (no improvement): 2
2022-03-28 10:52:53,112 ----------------------------------------------------------------------------------------------------
2022-03-28 10:52:55,139 epoch 8 - iter 10/107 - loss 0.11655941 - samples/sec: 157.90 - lr: 0.100000
2022-03-28 10:52:57,178 epoch 8 - iter 20/107 - loss 0.09903777 - samples/sec: 157.01 - lr: 0.100000
2022-03-28 10:52:59,181 epoch 8 - iter 30/107 - loss 0.09720661 - samples/sec: 159.89 - lr: 0.100000
2022-03-28 10:53:01,243 epoch 8 - iter 40/107 - loss 0.09703344 - samples/sec: 155.20 - lr: 0.100000
2022-03-28 10:53:03,249 epoch 8 - iter 50/107 - loss 0.09857309 - samples/sec: 159.63 - lr: 0.100000
2022-03-28 10:53:05,263 epoch 8 - iter 60/107 - loss 0.09844573 - samples/sec: 158.94 - lr: 0.100000
2022-03-28 10:53:07,309 epoch 8 - iter 70/107 - loss 0.10136712 - samples/sec: 156.52 - lr: 0.100000
2022-03-28 10:53:09,414 epoch 8 - iter 80/107 - loss 0.10257453 - samples/sec: 152.03 - lr: 0.100000
2022-03-28 10:53:11,431 epoch 8 - iter 90/107 - loss 0.10215362 - samples/sec: 158.79 - lr: 0.100000
2022-03-28 10:53:13,471 epoch 8 - iter 100/107 - loss 0.10251342 - samples/sec: 156.91 - lr: 0.100000
2022-03-28 10:53:14,679 ----------------------------------------------------------------------------------------------------
2022-03-28 10:53:14,680 EPOCH 8 done: loss 0.1056 - lr 0.100000
2022-03-28 10:53:20,785 Evaluating as a multi-label problem: False
2022-03-28 10:53:20,796 DEV : loss 0.18446902930736542 - f1-score (micro avg)  0.5405
2022-03-28 10:53:20,882 BAD EPOCHS (no improvement): 0
2022-03-28 10:53:20,885 saving best model
2022-03-28 10:53:35,769 ----------------------------------------------------------------------------------------------------
2022-03-28 10:53:37,811 epoch 9 - iter 10/107 - loss 0.09561221 - samples/sec: 156.81 - lr: 0.100000
2022-03-28 10:53:39,812 epoch 9 - iter 20/107 - loss 0.10217625 - samples/sec: 160.03 - lr: 0.100000
2022-03-28 10:53:41,796 epoch 9 - iter 30/107 - loss 0.09982578 - samples/sec: 161.33 - lr: 0.100000
2022-03-28 10:53:43,780 epoch 9 - iter 40/107 - loss 0.09827598 - samples/sec: 161.42 - lr: 0.100000
2022-03-28 10:53:45,912 epoch 9 - iter 50/107 - loss 0.09685656 - samples/sec: 150.16 - lr: 0.100000
2022-03-28 10:53:47,957 epoch 9 - iter 60/107 - loss 0.09631349 - samples/sec: 156.55 - lr: 0.100000
2022-03-28 10:53:50,034 epoch 9 - iter 70/107 - loss 0.09682506 - samples/sec: 154.14 - lr: 0.100000
2022-03-28 10:53:52,027 epoch 9 - iter 80/107 - loss 0.09831180 - samples/sec: 160.62 - lr: 0.100000
2022-03-28 10:53:54,083 epoch 9 - iter 90/107 - loss 0.09646747 - samples/sec: 155.74 - lr: 0.100000
2022-03-28 10:53:56,117 epoch 9 - iter 100/107 - loss 0.09616520 - samples/sec: 157.38 - lr: 0.100000
2022-03-28 10:53:57,350 ----------------------------------------------------------------------------------------------------
2022-03-28 10:53:57,350 EPOCH 9 done: loss 0.0954 - lr 0.100000
2022-03-28 10:54:03,664 Evaluating as a multi-label problem: False
2022-03-28 10:54:03,676 DEV : loss 0.22925466299057007 - f1-score (micro avg)  0.4859
2022-03-28 10:54:03,762 BAD EPOCHS (no improvement): 1
2022-03-28 10:54:03,765 ----------------------------------------------------------------------------------------------------
2022-03-28 10:54:05,805 epoch 10 - iter 10/107 - loss 0.10684125 - samples/sec: 156.92 - lr: 0.100000
2022-03-28 10:54:07,857 epoch 10 - iter 20/107 - loss 0.09818800 - samples/sec: 156.10 - lr: 0.100000
2022-03-28 10:54:09,923 epoch 10 - iter 30/107 - loss 0.09910542 - samples/sec: 154.91 - lr: 0.100000
2022-03-28 10:54:11,970 epoch 10 - iter 40/107 - loss 0.09580834 - samples/sec: 156.42 - lr: 0.100000
2022-03-28 10:54:13,992 epoch 10 - iter 50/107 - loss 0.09229383 - samples/sec: 158.38 - lr: 0.100000
2022-03-28 10:54:15,998 epoch 10 - iter 60/107 - loss 0.09110135 - samples/sec: 159.57 - lr: 0.100000
2022-03-28 10:54:17,942 epoch 10 - iter 70/107 - loss 0.09412507 - samples/sec: 164.63 - lr: 0.100000
2022-03-28 10:54:19,924 epoch 10 - iter 80/107 - loss 0.09235801 - samples/sec: 161.61 - lr: 0.100000
2022-03-28 10:54:21,910 epoch 10 - iter 90/107 - loss 0.09130790 - samples/sec: 161.14 - lr: 0.100000
2022-03-28 10:54:23,809 epoch 10 - iter 100/107 - loss 0.09229325 - samples/sec: 168.66 - lr: 0.100000
2022-03-28 10:54:25,077 ----------------------------------------------------------------------------------------------------
2022-03-28 10:54:25,077 EPOCH 10 done: loss 0.0918 - lr 0.100000
2022-03-28 10:54:31,404 Evaluating as a multi-label problem: False
2022-03-28 10:54:31,415 DEV : loss 0.20466695725917816 - f1-score (micro avg)  0.4843
2022-03-28 10:54:31,499 BAD EPOCHS (no improvement): 2
2022-03-28 10:54:31,501 ----------------------------------------------------------------------------------------------------
2022-03-28 10:54:33,626 epoch 11 - iter 10/107 - loss 0.08203076 - samples/sec: 150.70 - lr: 0.100000
2022-03-28 10:54:35,672 epoch 11 - iter 20/107 - loss 0.07901578 - samples/sec: 156.47 - lr: 0.100000
2022-03-28 10:54:37,684 epoch 11 - iter 30/107 - loss 0.08215467 - samples/sec: 159.10 - lr: 0.100000
2022-03-28 10:54:39,645 epoch 11 - iter 40/107 - loss 0.08139190 - samples/sec: 163.31 - lr: 0.100000
2022-03-28 10:54:41,704 epoch 11 - iter 50/107 - loss 0.08291012 - samples/sec: 155.46 - lr: 0.100000
2022-03-28 10:54:43,675 epoch 11 - iter 60/107 - loss 0.08357722 - samples/sec: 162.47 - lr: 0.100000
2022-03-28 10:54:45,782 epoch 11 - iter 70/107 - loss 0.08161128 - samples/sec: 151.91 - lr: 0.100000
2022-03-28 10:54:47,777 epoch 11 - iter 80/107 - loss 0.08281477 - samples/sec: 160.47 - lr: 0.100000
2022-03-28 10:54:49,836 epoch 11 - iter 90/107 - loss 0.08305254 - samples/sec: 155.51 - lr: 0.100000
2022-03-28 10:54:51,836 epoch 11 - iter 100/107 - loss 0.08417670 - samples/sec: 160.11 - lr: 0.100000
2022-03-28 10:54:53,099 ----------------------------------------------------------------------------------------------------
2022-03-28 10:54:53,099 EPOCH 11 done: loss 0.0848 - lr 0.100000
2022-03-28 10:55:00,689 Evaluating as a multi-label problem: False
2022-03-28 10:55:00,699 DEV : loss 0.21677172183990479 - f1-score (micro avg)  0.4901
2022-03-28 10:55:00,784 BAD EPOCHS (no improvement): 3
2022-03-28 10:55:00,786 ----------------------------------------------------------------------------------------------------
2022-03-28 10:55:02,865 epoch 12 - iter 10/107 - loss 0.07908430 - samples/sec: 154.00 - lr: 0.100000
2022-03-28 10:55:04,835 epoch 12 - iter 20/107 - loss 0.07099823 - samples/sec: 162.50 - lr: 0.100000
2022-03-28 10:55:06,765 epoch 12 - iter 30/107 - loss 0.06966378 - samples/sec: 165.90 - lr: 0.100000
2022-03-28 10:55:08,644 epoch 12 - iter 40/107 - loss 0.07614382 - samples/sec: 170.40 - lr: 0.100000
2022-03-28 10:55:10,594 epoch 12 - iter 50/107 - loss 0.07994924 - samples/sec: 164.21 - lr: 0.100000
2022-03-28 10:55:12,521 epoch 12 - iter 60/107 - loss 0.08262671 - samples/sec: 166.15 - lr: 0.100000
2022-03-28 10:55:14,378 epoch 12 - iter 70/107 - loss 0.08200940 - samples/sec: 172.35 - lr: 0.100000
2022-03-28 10:55:16,271 epoch 12 - iter 80/107 - loss 0.08217872 - samples/sec: 169.11 - lr: 0.100000
2022-03-28 10:55:18,193 epoch 12 - iter 90/107 - loss 0.08226341 - samples/sec: 166.63 - lr: 0.100000
2022-03-28 10:55:20,083 epoch 12 - iter 100/107 - loss 0.08268594 - samples/sec: 169.34 - lr: 0.100000
2022-03-28 10:55:21,262 ----------------------------------------------------------------------------------------------------
2022-03-28 10:55:21,262 EPOCH 12 done: loss 0.0834 - lr 0.100000
2022-03-28 10:55:27,434 Evaluating as a multi-label problem: False
2022-03-28 10:55:27,445 DEV : loss 0.20193028450012207 - f1-score (micro avg)  0.5192
2022-03-28 10:55:27,531 Epoch    12: reducing learning rate of group 0 to 5.0000e-02.
2022-03-28 10:55:27,531 BAD EPOCHS (no improvement): 4
2022-03-28 10:55:27,534 ----------------------------------------------------------------------------------------------------
2022-03-28 10:55:29,610 epoch 13 - iter 10/107 - loss 0.08623822 - samples/sec: 154.18 - lr: 0.050000
2022-03-28 10:55:31,573 epoch 13 - iter 20/107 - loss 0.07915452 - samples/sec: 163.13 - lr: 0.050000
2022-03-28 10:55:33,569 epoch 13 - iter 30/107 - loss 0.07265031 - samples/sec: 160.40 - lr: 0.050000
2022-03-28 10:55:35,604 epoch 13 - iter 40/107 - loss 0.07415999 - samples/sec: 157.32 - lr: 0.050000
2022-03-28 10:55:37,597 epoch 13 - iter 50/107 - loss 0.07142099 - samples/sec: 160.64 - lr: 0.050000
2022-03-28 10:55:39,626 epoch 13 - iter 60/107 - loss 0.07231162 - samples/sec: 157.84 - lr: 0.050000
2022-03-28 10:55:41,621 epoch 13 - iter 70/107 - loss 0.07340674 - samples/sec: 160.44 - lr: 0.050000
2022-03-28 10:55:43,671 epoch 13 - iter 80/107 - loss 0.07145965 - samples/sec: 156.17 - lr: 0.050000
2022-03-28 10:55:45,811 epoch 13 - iter 90/107 - loss 0.07146244 - samples/sec: 149.63 - lr: 0.050000
2022-03-28 10:55:47,828 epoch 13 - iter 100/107 - loss 0.07107842 - samples/sec: 158.71 - lr: 0.050000
2022-03-28 10:55:49,099 ----------------------------------------------------------------------------------------------------
2022-03-28 10:55:49,099 EPOCH 13 done: loss 0.0707 - lr 0.050000
2022-03-28 10:55:55,374 Evaluating as a multi-label problem: False
2022-03-28 10:55:55,386 DEV : loss 0.20614799857139587 - f1-score (micro avg)  0.5101
2022-03-28 10:55:55,471 BAD EPOCHS (no improvement): 1
2022-03-28 10:55:55,474 ----------------------------------------------------------------------------------------------------
2022-03-28 10:55:57,546 epoch 14 - iter 10/107 - loss 0.06349864 - samples/sec: 154.50 - lr: 0.050000
2022-03-28 10:55:59,581 epoch 14 - iter 20/107 - loss 0.06661072 - samples/sec: 157.36 - lr: 0.050000
2022-03-28 10:56:01,618 epoch 14 - iter 30/107 - loss 0.06586939 - samples/sec: 157.11 - lr: 0.050000
2022-03-28 10:56:03,661 epoch 14 - iter 40/107 - loss 0.06466173 - samples/sec: 156.75 - lr: 0.050000
2022-03-28 10:56:05,657 epoch 14 - iter 50/107 - loss 0.06417776 - samples/sec: 160.40 - lr: 0.050000
2022-03-28 10:56:07,666 epoch 14 - iter 60/107 - loss 0.06406937 - samples/sec: 159.34 - lr: 0.050000
2022-03-28 10:56:09,705 epoch 14 - iter 70/107 - loss 0.06564538 - samples/sec: 157.03 - lr: 0.050000
2022-03-28 10:56:11,687 epoch 14 - iter 80/107 - loss 0.06443992 - samples/sec: 161.50 - lr: 0.050000
2022-03-28 10:56:13,618 epoch 14 - iter 90/107 - loss 0.06547549 - samples/sec: 165.81 - lr: 0.050000
2022-03-28 10:56:15,632 epoch 14 - iter 100/107 - loss 0.06628093 - samples/sec: 159.00 - lr: 0.050000
2022-03-28 10:56:16,901 ----------------------------------------------------------------------------------------------------
2022-03-28 10:56:16,901 EPOCH 14 done: loss 0.0663 - lr 0.050000
2022-03-28 10:56:23,220 Evaluating as a multi-label problem: False
2022-03-28 10:56:23,230 DEV : loss 0.22330613434314728 - f1-score (micro avg)  0.4972
2022-03-28 10:56:23,317 BAD EPOCHS (no improvement): 2
2022-03-28 10:56:23,320 ----------------------------------------------------------------------------------------------------
2022-03-28 10:56:25,353 epoch 15 - iter 10/107 - loss 0.06937302 - samples/sec: 157.47 - lr: 0.050000
2022-03-28 10:56:27,404 epoch 15 - iter 20/107 - loss 0.06941366 - samples/sec: 156.16 - lr: 0.050000
2022-03-28 10:56:29,313 epoch 15 - iter 30/107 - loss 0.06413035 - samples/sec: 167.73 - lr: 0.050000
2022-03-28 10:56:31,228 epoch 15 - iter 40/107 - loss 0.06590457 - samples/sec: 167.17 - lr: 0.050000
2022-03-28 10:56:33,195 epoch 15 - iter 50/107 - loss 0.06616448 - samples/sec: 162.73 - lr: 0.050000
2022-03-28 10:56:35,113 epoch 15 - iter 60/107 - loss 0.06512472 - samples/sec: 166.94 - lr: 0.050000
2022-03-28 10:56:37,139 epoch 15 - iter 70/107 - loss 0.06348925 - samples/sec: 158.03 - lr: 0.050000
2022-03-28 10:56:39,191 epoch 15 - iter 80/107 - loss 0.06201980 - samples/sec: 155.98 - lr: 0.050000
2022-03-28 10:56:41,169 epoch 15 - iter 90/107 - loss 0.06395219 - samples/sec: 161.85 - lr: 0.050000
2022-03-28 10:56:43,177 epoch 15 - iter 100/107 - loss 0.06351162 - samples/sec: 159.49 - lr: 0.050000
2022-03-28 10:56:44,424 ----------------------------------------------------------------------------------------------------
2022-03-28 10:56:44,424 EPOCH 15 done: loss 0.0652 - lr 0.050000
2022-03-28 10:56:50,720 Evaluating as a multi-label problem: False
2022-03-28 10:56:50,732 DEV : loss 0.20317041873931885 - f1-score (micro avg)  0.5165
2022-03-28 10:56:50,817 BAD EPOCHS (no improvement): 3
2022-03-28 10:56:50,820 ----------------------------------------------------------------------------------------------------
2022-03-28 10:56:52,960 epoch 16 - iter 10/107 - loss 0.05640445 - samples/sec: 149.60 - lr: 0.050000
2022-03-28 10:56:54,966 epoch 16 - iter 20/107 - loss 0.05543838 - samples/sec: 159.57 - lr: 0.050000
2022-03-28 10:56:57,022 epoch 16 - iter 30/107 - loss 0.05392427 - samples/sec: 155.72 - lr: 0.050000
2022-03-28 10:56:59,042 epoch 16 - iter 40/107 - loss 0.05798570 - samples/sec: 158.53 - lr: 0.050000
2022-03-28 10:57:01,063 epoch 16 - iter 50/107 - loss 0.05880303 - samples/sec: 158.40 - lr: 0.050000
2022-03-28 10:57:03,051 epoch 16 - iter 60/107 - loss 0.05880956 - samples/sec: 161.05 - lr: 0.050000
2022-03-28 10:57:04,974 epoch 16 - iter 70/107 - loss 0.05950533 - samples/sec: 166.49 - lr: 0.050000
2022-03-28 10:57:06,967 epoch 16 - iter 80/107 - loss 0.05942364 - samples/sec: 160.58 - lr: 0.050000
2022-03-28 10:57:08,962 epoch 16 - iter 90/107 - loss 0.06116989 - samples/sec: 160.53 - lr: 0.050000
2022-03-28 10:57:11,002 epoch 16 - iter 100/107 - loss 0.06266369 - samples/sec: 156.92 - lr: 0.050000
2022-03-28 10:57:12,271 ----------------------------------------------------------------------------------------------------
2022-03-28 10:57:12,271 EPOCH 16 done: loss 0.0621 - lr 0.050000
2022-03-28 10:57:18,557 Evaluating as a multi-label problem: False
2022-03-28 10:57:18,568 DEV : loss 0.19342438876628876 - f1-score (micro avg)  0.516
2022-03-28 10:57:18,652 Epoch    16: reducing learning rate of group 0 to 2.5000e-02.
2022-03-28 10:57:18,652 BAD EPOCHS (no improvement): 4
2022-03-28 10:57:18,655 ----------------------------------------------------------------------------------------------------
2022-03-28 10:57:20,769 epoch 17 - iter 10/107 - loss 0.06395235 - samples/sec: 151.46 - lr: 0.025000
2022-03-28 10:57:22,790 epoch 17 - iter 20/107 - loss 0.06396985 - samples/sec: 158.46 - lr: 0.025000
2022-03-28 10:57:24,720 epoch 17 - iter 30/107 - loss 0.05960989 - samples/sec: 165.86 - lr: 0.025000
2022-03-28 10:57:26,673 epoch 17 - iter 40/107 - loss 0.05985508 - samples/sec: 163.95 - lr: 0.025000
2022-03-28 10:57:28,616 epoch 17 - iter 50/107 - loss 0.05819062 - samples/sec: 164.71 - lr: 0.025000
2022-03-28 10:57:30,642 epoch 17 - iter 60/107 - loss 0.06003569 - samples/sec: 158.02 - lr: 0.025000
2022-03-28 10:57:32,724 epoch 17 - iter 70/107 - loss 0.05872539 - samples/sec: 153.83 - lr: 0.025000
2022-03-28 10:57:34,804 epoch 17 - iter 80/107 - loss 0.05920901 - samples/sec: 153.89 - lr: 0.025000
2022-03-28 10:57:36,785 epoch 17 - iter 90/107 - loss 0.05750727 - samples/sec: 161.63 - lr: 0.025000
2022-03-28 10:57:38,770 epoch 17 - iter 100/107 - loss 0.05701469 - samples/sec: 161.24 - lr: 0.025000
2022-03-28 10:57:39,966 ----------------------------------------------------------------------------------------------------
2022-03-28 10:57:39,966 EPOCH 17 done: loss 0.0575 - lr 0.025000
2022-03-28 10:57:47,493 Evaluating as a multi-label problem: False
2022-03-28 10:57:47,503 DEV : loss 0.20207279920578003 - f1-score (micro avg)  0.5213
2022-03-28 10:57:47,590 BAD EPOCHS (no improvement): 1
2022-03-28 10:57:47,593 ----------------------------------------------------------------------------------------------------
2022-03-28 10:57:49,685 epoch 18 - iter 10/107 - loss 0.05001426 - samples/sec: 153.09 - lr: 0.025000
2022-03-28 10:57:51,626 epoch 18 - iter 20/107 - loss 0.05233605 - samples/sec: 164.96 - lr: 0.025000
2022-03-28 10:57:53,590 epoch 18 - iter 30/107 - loss 0.05172258 - samples/sec: 162.95 - lr: 0.025000
2022-03-28 10:57:55,596 epoch 18 - iter 40/107 - loss 0.05270428 - samples/sec: 159.67 - lr: 0.025000
2022-03-28 10:57:57,651 epoch 18 - iter 50/107 - loss 0.05230204 - samples/sec: 155.81 - lr: 0.025000
2022-03-28 10:57:59,617 epoch 18 - iter 60/107 - loss 0.05305233 - samples/sec: 162.84 - lr: 0.025000
2022-03-28 10:58:01,618 epoch 18 - iter 70/107 - loss 0.05475837 - samples/sec: 160.02 - lr: 0.025000
2022-03-28 10:58:03,611 epoch 18 - iter 80/107 - loss 0.05605170 - samples/sec: 160.64 - lr: 0.025000
2022-03-28 10:58:05,590 epoch 18 - iter 90/107 - loss 0.05603291 - samples/sec: 161.78 - lr: 0.025000
2022-03-28 10:58:07,589 epoch 18 - iter 100/107 - loss 0.05565348 - samples/sec: 160.13 - lr: 0.025000
2022-03-28 10:58:08,783 ----------------------------------------------------------------------------------------------------
2022-03-28 10:58:08,783 EPOCH 18 done: loss 0.0559 - lr 0.025000
2022-03-28 10:58:14,996 Evaluating as a multi-label problem: False
2022-03-28 10:58:15,007 DEV : loss 0.211767315864563 - f1-score (micro avg)  0.4947
2022-03-28 10:58:15,091 BAD EPOCHS (no improvement): 2
2022-03-28 10:58:15,094 ----------------------------------------------------------------------------------------------------
2022-03-28 10:58:17,158 epoch 19 - iter 10/107 - loss 0.04858739 - samples/sec: 155.12 - lr: 0.025000
2022-03-28 10:58:19,061 epoch 19 - iter 20/107 - loss 0.05111261 - samples/sec: 168.25 - lr: 0.025000
2022-03-28 10:58:20,947 epoch 19 - iter 30/107 - loss 0.05338024 - samples/sec: 169.76 - lr: 0.025000
2022-03-28 10:58:22,788 epoch 19 - iter 40/107 - loss 0.05177508 - samples/sec: 173.89 - lr: 0.025000
2022-03-28 10:58:24,702 epoch 19 - iter 50/107 - loss 0.05168083 - samples/sec: 167.27 - lr: 0.025000
2022-03-28 10:58:26,729 epoch 19 - iter 60/107 - loss 0.05466931 - samples/sec: 157.97 - lr: 0.025000
2022-03-28 10:58:28,656 epoch 19 - iter 70/107 - loss 0.05490637 - samples/sec: 166.10 - lr: 0.025000
2022-03-28 10:58:30,602 epoch 19 - iter 80/107 - loss 0.05520623 - samples/sec: 164.50 - lr: 0.025000
2022-03-28 10:58:32,632 epoch 19 - iter 90/107 - loss 0.05458053 - samples/sec: 157.74 - lr: 0.025000
2022-03-28 10:58:34,646 epoch 19 - iter 100/107 - loss 0.05436685 - samples/sec: 158.98 - lr: 0.025000
2022-03-28 10:58:35,850 ----------------------------------------------------------------------------------------------------
2022-03-28 10:58:35,850 EPOCH 19 done: loss 0.0540 - lr 0.025000
2022-03-28 10:58:42,139 Evaluating as a multi-label problem: False
2022-03-28 10:58:42,150 DEV : loss 0.20093700289726257 - f1-score (micro avg)  0.5199
2022-03-28 10:58:42,238 BAD EPOCHS (no improvement): 3
2022-03-28 10:58:42,242 ----------------------------------------------------------------------------------------------------
2022-03-28 10:58:44,263 epoch 20 - iter 10/107 - loss 0.04604043 - samples/sec: 158.43 - lr: 0.025000
2022-03-28 10:58:46,234 epoch 20 - iter 20/107 - loss 0.04491700 - samples/sec: 162.47 - lr: 0.025000
2022-03-28 10:58:48,193 epoch 20 - iter 30/107 - loss 0.05214539 - samples/sec: 163.44 - lr: 0.025000
2022-03-28 10:58:50,213 epoch 20 - iter 40/107 - loss 0.05086060 - samples/sec: 158.55 - lr: 0.025000
2022-03-28 10:58:52,234 epoch 20 - iter 50/107 - loss 0.05246627 - samples/sec: 158.38 - lr: 0.025000
2022-03-28 10:58:54,217 epoch 20 - iter 60/107 - loss 0.05270079 - samples/sec: 161.43 - lr: 0.025000
2022-03-28 10:58:56,162 epoch 20 - iter 70/107 - loss 0.05256988 - samples/sec: 164.64 - lr: 0.025000
2022-03-28 10:58:58,133 epoch 20 - iter 80/107 - loss 0.05175766 - samples/sec: 162.42 - lr: 0.025000
2022-03-28 10:59:00,052 epoch 20 - iter 90/107 - loss 0.05158503 - samples/sec: 166.87 - lr: 0.025000
2022-03-28 10:59:02,003 epoch 20 - iter 100/107 - loss 0.05200759 - samples/sec: 164.08 - lr: 0.025000
2022-03-28 10:59:03,180 ----------------------------------------------------------------------------------------------------
2022-03-28 10:59:03,180 EPOCH 20 done: loss 0.0519 - lr 0.025000
2022-03-28 10:59:09,535 Evaluating as a multi-label problem: False
2022-03-28 10:59:09,546 DEV : loss 0.20068275928497314 - f1-score (micro avg)  0.5244
2022-03-28 10:59:09,632 Epoch    20: reducing learning rate of group 0 to 1.2500e-02.
2022-03-28 10:59:09,632 BAD EPOCHS (no improvement): 4
2022-03-28 10:59:09,635 ----------------------------------------------------------------------------------------------------
2022-03-28 10:59:11,746 epoch 21 - iter 10/107 - loss 0.05106348 - samples/sec: 151.68 - lr: 0.012500
2022-03-28 10:59:13,750 epoch 21 - iter 20/107 - loss 0.05001268 - samples/sec: 159.75 - lr: 0.012500
2022-03-28 10:59:15,799 epoch 21 - iter 30/107 - loss 0.05065888 - samples/sec: 156.22 - lr: 0.012500
2022-03-28 10:59:17,859 epoch 21 - iter 40/107 - loss 0.04981548 - samples/sec: 155.44 - lr: 0.012500
2022-03-28 10:59:19,942 epoch 21 - iter 50/107 - loss 0.04930664 - samples/sec: 153.65 - lr: 0.012500
2022-03-28 10:59:21,854 epoch 21 - iter 60/107 - loss 0.05110790 - samples/sec: 167.49 - lr: 0.012500
2022-03-28 10:59:23,774 epoch 21 - iter 70/107 - loss 0.05076241 - samples/sec: 166.68 - lr: 0.012500
2022-03-28 10:59:25,755 epoch 21 - iter 80/107 - loss 0.05166243 - samples/sec: 161.64 - lr: 0.012500
2022-03-28 10:59:27,740 epoch 21 - iter 90/107 - loss 0.05118407 - samples/sec: 161.27 - lr: 0.012500
2022-03-28 10:59:29,639 epoch 21 - iter 100/107 - loss 0.05113571 - samples/sec: 168.60 - lr: 0.012500
2022-03-28 10:59:30,817 ----------------------------------------------------------------------------------------------------
2022-03-28 10:59:30,817 EPOCH 21 done: loss 0.0508 - lr 0.012500
2022-03-28 10:59:37,036 Evaluating as a multi-label problem: False
2022-03-28 10:59:37,047 DEV : loss 0.20343215763568878 - f1-score (micro avg)  0.5253
2022-03-28 10:59:37,137 BAD EPOCHS (no improvement): 1
2022-03-28 10:59:37,140 ----------------------------------------------------------------------------------------------------
2022-03-28 10:59:39,210 epoch 22 - iter 10/107 - loss 0.05206373 - samples/sec: 154.66 - lr: 0.012500
2022-03-28 10:59:41,212 epoch 22 - iter 20/107 - loss 0.05476876 - samples/sec: 159.89 - lr: 0.012500
2022-03-28 10:59:43,232 epoch 22 - iter 30/107 - loss 0.05129430 - samples/sec: 158.55 - lr: 0.012500
2022-03-28 10:59:45,227 epoch 22 - iter 40/107 - loss 0.05204960 - samples/sec: 160.45 - lr: 0.012500
2022-03-28 10:59:47,126 epoch 22 - iter 50/107 - loss 0.05055473 - samples/sec: 168.56 - lr: 0.012500
2022-03-28 10:59:49,102 epoch 22 - iter 60/107 - loss 0.05175520 - samples/sec: 162.05 - lr: 0.012500
2022-03-28 10:59:51,143 epoch 22 - iter 70/107 - loss 0.05030849 - samples/sec: 156.87 - lr: 0.012500
2022-03-28 10:59:53,174 epoch 22 - iter 80/107 - loss 0.05005540 - samples/sec: 157.60 - lr: 0.012500
2022-03-28 10:59:55,199 epoch 22 - iter 90/107 - loss 0.05037491 - samples/sec: 158.15 - lr: 0.012500
2022-03-28 10:59:57,122 epoch 22 - iter 100/107 - loss 0.05005952 - samples/sec: 166.49 - lr: 0.012500
2022-03-28 10:59:58,330 ----------------------------------------------------------------------------------------------------
2022-03-28 10:59:58,330 EPOCH 22 done: loss 0.0501 - lr 0.012500
2022-03-28 11:00:04,601 Evaluating as a multi-label problem: False
2022-03-28 11:00:04,611 DEV : loss 0.20146317780017853 - f1-score (micro avg)  0.5266
2022-03-28 11:00:04,697 BAD EPOCHS (no improvement): 2
2022-03-28 11:00:04,700 ----------------------------------------------------------------------------------------------------
2022-03-28 11:00:06,725 epoch 23 - iter 10/107 - loss 0.05616886 - samples/sec: 158.15 - lr: 0.012500
2022-03-28 11:00:08,627 epoch 23 - iter 20/107 - loss 0.04868663 - samples/sec: 168.32 - lr: 0.012500
2022-03-28 11:00:10,601 epoch 23 - iter 30/107 - loss 0.04959608 - samples/sec: 162.14 - lr: 0.012500
2022-03-28 11:00:12,565 epoch 23 - iter 40/107 - loss 0.05015315 - samples/sec: 163.06 - lr: 0.012500
2022-03-28 11:00:14,490 epoch 23 - iter 50/107 - loss 0.05057750 - samples/sec: 166.28 - lr: 0.012500
2022-03-28 11:00:16,493 epoch 23 - iter 60/107 - loss 0.05167203 - samples/sec: 159.85 - lr: 0.012500
2022-03-28 11:00:18,565 epoch 23 - iter 70/107 - loss 0.05000195 - samples/sec: 154.54 - lr: 0.012500
2022-03-28 11:00:20,540 epoch 23 - iter 80/107 - loss 0.04971939 - samples/sec: 162.12 - lr: 0.012500
2022-03-28 11:00:22,448 epoch 23 - iter 90/107 - loss 0.04954770 - samples/sec: 167.81 - lr: 0.012500
2022-03-28 11:00:24,438 epoch 23 - iter 100/107 - loss 0.04882946 - samples/sec: 160.87 - lr: 0.012500
2022-03-28 11:00:25,660 ----------------------------------------------------------------------------------------------------
2022-03-28 11:00:25,660 EPOCH 23 done: loss 0.0494 - lr 0.012500
2022-03-28 11:00:33,187 Evaluating as a multi-label problem: False
2022-03-28 11:00:33,198 DEV : loss 0.19848880171775818 - f1-score (micro avg)  0.535
2022-03-28 11:00:33,282 BAD EPOCHS (no improvement): 3
2022-03-28 11:00:33,285 ----------------------------------------------------------------------------------------------------
2022-03-28 11:00:35,334 epoch 24 - iter 10/107 - loss 0.03572535 - samples/sec: 156.20 - lr: 0.012500
2022-03-28 11:00:37,346 epoch 24 - iter 20/107 - loss 0.04187866 - samples/sec: 159.16 - lr: 0.012500
2022-03-28 11:00:39,309 epoch 24 - iter 30/107 - loss 0.04499091 - samples/sec: 163.08 - lr: 0.012500
2022-03-28 11:00:41,325 epoch 24 - iter 40/107 - loss 0.04657879 - samples/sec: 158.82 - lr: 0.012500
2022-03-28 11:00:43,298 epoch 24 - iter 50/107 - loss 0.04847278 - samples/sec: 162.24 - lr: 0.012500
2022-03-28 11:00:45,323 epoch 24 - iter 60/107 - loss 0.05053686 - samples/sec: 158.09 - lr: 0.012500
2022-03-28 11:00:47,336 epoch 24 - iter 70/107 - loss 0.05081803 - samples/sec: 159.07 - lr: 0.012500
2022-03-28 11:00:49,331 epoch 24 - iter 80/107 - loss 0.04951473 - samples/sec: 160.49 - lr: 0.012500
2022-03-28 11:00:51,361 epoch 24 - iter 90/107 - loss 0.04901593 - samples/sec: 157.68 - lr: 0.012500
2022-03-28 11:00:53,231 epoch 24 - iter 100/107 - loss 0.04940502 - samples/sec: 171.19 - lr: 0.012500
2022-03-28 11:00:54,514 ----------------------------------------------------------------------------------------------------
2022-03-28 11:00:54,514 EPOCH 24 done: loss 0.0489 - lr 0.012500
2022-03-28 11:01:00,805 Evaluating as a multi-label problem: False
2022-03-28 11:01:00,816 DEV : loss 0.20738177001476288 - f1-score (micro avg)  0.5264
2022-03-28 11:01:00,905 Epoch    24: reducing learning rate of group 0 to 6.2500e-03.
2022-03-28 11:01:00,905 BAD EPOCHS (no improvement): 4
2022-03-28 11:01:00,909 ----------------------------------------------------------------------------------------------------
2022-03-28 11:01:02,961 epoch 25 - iter 10/107 - loss 0.05692488 - samples/sec: 156.10 - lr: 0.006250
2022-03-28 11:01:04,846 epoch 25 - iter 20/107 - loss 0.05297929 - samples/sec: 169.89 - lr: 0.006250
2022-03-28 11:01:06,795 epoch 25 - iter 30/107 - loss 0.04985556 - samples/sec: 164.21 - lr: 0.006250
2022-03-28 11:01:08,786 epoch 25 - iter 40/107 - loss 0.05070505 - samples/sec: 160.83 - lr: 0.006250
2022-03-28 11:01:10,798 epoch 25 - iter 50/107 - loss 0.04641246 - samples/sec: 159.15 - lr: 0.006250
2022-03-28 11:01:12,770 epoch 25 - iter 60/107 - loss 0.04786647 - samples/sec: 162.29 - lr: 0.006250
2022-03-28 11:01:14,789 epoch 25 - iter 70/107 - loss 0.04777847 - samples/sec: 158.59 - lr: 0.006250
2022-03-28 11:01:16,808 epoch 25 - iter 80/107 - loss 0.04807066 - samples/sec: 158.62 - lr: 0.006250
2022-03-28 11:01:18,767 epoch 25 - iter 90/107 - loss 0.04895112 - samples/sec: 163.42 - lr: 0.006250
2022-03-28 11:01:20,659 epoch 25 - iter 100/107 - loss 0.04805499 - samples/sec: 169.22 - lr: 0.006250
2022-03-28 11:01:21,835 ----------------------------------------------------------------------------------------------------
2022-03-28 11:01:21,835 EPOCH 25 done: loss 0.0481 - lr 0.006250
2022-03-28 11:01:28,122 Evaluating as a multi-label problem: False
2022-03-28 11:01:28,133 DEV : loss 0.20599158108234406 - f1-score (micro avg)  0.5325
2022-03-28 11:01:28,219 BAD EPOCHS (no improvement): 1
2022-03-28 11:01:28,222 ----------------------------------------------------------------------------------------------------
2022-03-28 11:01:30,278 epoch 26 - iter 10/107 - loss 0.04235633 - samples/sec: 155.77 - lr: 0.006250
2022-03-28 11:01:32,290 epoch 26 - iter 20/107 - loss 0.04664490 - samples/sec: 159.09 - lr: 0.006250
2022-03-28 11:01:34,190 epoch 26 - iter 30/107 - loss 0.04502201 - samples/sec: 168.53 - lr: 0.006250
2022-03-28 11:01:36,034 epoch 26 - iter 40/107 - loss 0.04211751 - samples/sec: 173.59 - lr: 0.006250
2022-03-28 11:01:37,834 epoch 26 - iter 50/107 - loss 0.04150192 - samples/sec: 177.87 - lr: 0.006250
2022-03-28 11:01:39,613 epoch 26 - iter 60/107 - loss 0.04374831 - samples/sec: 180.02 - lr: 0.006250
2022-03-28 11:01:41,511 epoch 26 - iter 70/107 - loss 0.04398425 - samples/sec: 168.64 - lr: 0.006250
2022-03-28 11:01:43,378 epoch 26 - iter 80/107 - loss 0.04470015 - samples/sec: 171.51 - lr: 0.006250
2022-03-28 11:01:45,228 epoch 26 - iter 90/107 - loss 0.04600363 - samples/sec: 173.05 - lr: 0.006250
2022-03-28 11:01:47,163 epoch 26 - iter 100/107 - loss 0.04520565 - samples/sec: 165.51 - lr: 0.006250
2022-03-28 11:01:48,373 ----------------------------------------------------------------------------------------------------
2022-03-28 11:01:48,373 EPOCH 26 done: loss 0.0453 - lr 0.006250
2022-03-28 11:01:54,510 Evaluating as a multi-label problem: False
2022-03-28 11:01:54,522 DEV : loss 0.20562593638896942 - f1-score (micro avg)  0.5335
2022-03-28 11:01:54,612 BAD EPOCHS (no improvement): 2
2022-03-28 11:01:54,614 ----------------------------------------------------------------------------------------------------
2022-03-28 11:01:56,646 epoch 27 - iter 10/107 - loss 0.04285313 - samples/sec: 157.59 - lr: 0.006250
2022-03-28 11:01:58,637 epoch 27 - iter 20/107 - loss 0.04566706 - samples/sec: 160.82 - lr: 0.006250
2022-03-28 11:02:00,632 epoch 27 - iter 30/107 - loss 0.04972708 - samples/sec: 160.51 - lr: 0.006250
2022-03-28 11:02:02,560 epoch 27 - iter 40/107 - loss 0.04842266 - samples/sec: 166.04 - lr: 0.006250
2022-03-28 11:02:04,458 epoch 27 - iter 50/107 - loss 0.04891230 - samples/sec: 168.70 - lr: 0.006250
2022-03-28 11:02:06,419 epoch 27 - iter 60/107 - loss 0.04989559 - samples/sec: 163.25 - lr: 0.006250
2022-03-28 11:02:08,332 epoch 27 - iter 70/107 - loss 0.04979589 - samples/sec: 167.36 - lr: 0.006250
2022-03-28 11:02:10,270 epoch 27 - iter 80/107 - loss 0.04924196 - samples/sec: 165.17 - lr: 0.006250
2022-03-28 11:02:12,201 epoch 27 - iter 90/107 - loss 0.04870105 - samples/sec: 165.80 - lr: 0.006250
2022-03-28 11:02:14,187 epoch 27 - iter 100/107 - loss 0.04814975 - samples/sec: 161.20 - lr: 0.006250
2022-03-28 11:02:15,397 ----------------------------------------------------------------------------------------------------
2022-03-28 11:02:15,397 EPOCH 27 done: loss 0.0480 - lr 0.006250
2022-03-28 11:02:21,681 Evaluating as a multi-label problem: False
2022-03-28 11:02:21,692 DEV : loss 0.20624442398548126 - f1-score (micro avg)  0.5296
2022-03-28 11:02:21,779 BAD EPOCHS (no improvement): 3
2022-03-28 11:02:21,782 ----------------------------------------------------------------------------------------------------
2022-03-28 11:02:23,834 epoch 28 - iter 10/107 - loss 0.05401509 - samples/sec: 156.04 - lr: 0.006250
2022-03-28 11:02:25,784 epoch 28 - iter 20/107 - loss 0.05061379 - samples/sec: 164.15 - lr: 0.006250
2022-03-28 11:02:27,783 epoch 28 - iter 30/107 - loss 0.04625382 - samples/sec: 160.17 - lr: 0.006250
2022-03-28 11:02:29,665 epoch 28 - iter 40/107 - loss 0.04482784 - samples/sec: 170.08 - lr: 0.006250
2022-03-28 11:02:31,633 epoch 28 - iter 50/107 - loss 0.04378335 - samples/sec: 162.67 - lr: 0.006250
2022-03-28 11:02:33,608 epoch 28 - iter 60/107 - loss 0.04317900 - samples/sec: 162.18 - lr: 0.006250
2022-03-28 11:02:35,636 epoch 28 - iter 70/107 - loss 0.04424444 - samples/sec: 157.83 - lr: 0.006250
2022-03-28 11:02:37,624 epoch 28 - iter 80/107 - loss 0.04520765 - samples/sec: 161.07 - lr: 0.006250
2022-03-28 11:02:39,623 epoch 28 - iter 90/107 - loss 0.04487606 - samples/sec: 160.20 - lr: 0.006250
2022-03-28 11:02:41,590 epoch 28 - iter 100/107 - loss 0.04638625 - samples/sec: 162.70 - lr: 0.006250
2022-03-28 11:02:42,762 ----------------------------------------------------------------------------------------------------
2022-03-28 11:02:42,762 EPOCH 28 done: loss 0.0469 - lr 0.006250
2022-03-28 11:02:48,997 Evaluating as a multi-label problem: False
2022-03-28 11:02:49,008 DEV : loss 0.1997174471616745 - f1-score (micro avg)  0.5338
2022-03-28 11:02:49,092 Epoch    28: reducing learning rate of group 0 to 3.1250e-03.
2022-03-28 11:02:49,092 BAD EPOCHS (no improvement): 4
2022-03-28 11:02:49,096 ----------------------------------------------------------------------------------------------------
2022-03-28 11:02:51,067 epoch 29 - iter 10/107 - loss 0.04479711 - samples/sec: 162.40 - lr: 0.003125
2022-03-28 11:02:53,064 epoch 29 - iter 20/107 - loss 0.04441986 - samples/sec: 160.37 - lr: 0.003125
2022-03-28 11:02:55,015 epoch 29 - iter 30/107 - loss 0.04450330 - samples/sec: 164.10 - lr: 0.003125
2022-03-28 11:02:56,976 epoch 29 - iter 40/107 - loss 0.04355292 - samples/sec: 163.24 - lr: 0.003125
2022-03-28 11:02:59,037 epoch 29 - iter 50/107 - loss 0.04538318 - samples/sec: 155.35 - lr: 0.003125
2022-03-28 11:03:01,096 epoch 29 - iter 60/107 - loss 0.04460621 - samples/sec: 155.49 - lr: 0.003125
2022-03-28 11:03:03,029 epoch 29 - iter 70/107 - loss 0.04313007 - samples/sec: 165.56 - lr: 0.003125
2022-03-28 11:03:05,080 epoch 29 - iter 80/107 - loss 0.04404607 - samples/sec: 156.11 - lr: 0.003125
2022-03-28 11:03:07,071 epoch 29 - iter 90/107 - loss 0.04549921 - samples/sec: 160.82 - lr: 0.003125
2022-03-28 11:03:10,329 epoch 29 - iter 100/107 - loss 0.04528950 - samples/sec: 98.23 - lr: 0.003125
2022-03-28 11:03:11,511 ----------------------------------------------------------------------------------------------------
2022-03-28 11:03:11,511 EPOCH 29 done: loss 0.0449 - lr 0.003125
2022-03-28 11:03:17,746 Evaluating as a multi-label problem: False
2022-03-28 11:03:17,756 DEV : loss 0.2028910219669342 - f1-score (micro avg)  0.5327
2022-03-28 11:03:17,846 BAD EPOCHS (no improvement): 1
2022-03-28 11:03:17,849 ----------------------------------------------------------------------------------------------------
2022-03-28 11:03:19,710 epoch 30 - iter 10/107 - loss 0.03525387 - samples/sec: 172.05 - lr: 0.003125
2022-03-28 11:03:21,568 epoch 30 - iter 20/107 - loss 0.04416382 - samples/sec: 172.34 - lr: 0.003125
2022-03-28 11:03:23,509 epoch 30 - iter 30/107 - loss 0.04412376 - samples/sec: 164.95 - lr: 0.003125
2022-03-28 11:03:25,515 epoch 30 - iter 40/107 - loss 0.04668185 - samples/sec: 159.63 - lr: 0.003125
2022-03-28 11:03:27,427 epoch 30 - iter 50/107 - loss 0.04660567 - samples/sec: 167.45 - lr: 0.003125
2022-03-28 11:03:29,326 epoch 30 - iter 60/107 - loss 0.04606513 - samples/sec: 168.54 - lr: 0.003125
2022-03-28 11:03:31,262 epoch 30 - iter 70/107 - loss 0.04477868 - samples/sec: 165.36 - lr: 0.003125
2022-03-28 11:03:33,211 epoch 30 - iter 80/107 - loss 0.04548193 - samples/sec: 164.29 - lr: 0.003125
2022-03-28 11:03:35,192 epoch 30 - iter 90/107 - loss 0.04591534 - samples/sec: 161.63 - lr: 0.003125
2022-03-28 11:03:37,168 epoch 30 - iter 100/107 - loss 0.04604028 - samples/sec: 162.00 - lr: 0.003125
2022-03-28 11:03:38,393 ----------------------------------------------------------------------------------------------------
2022-03-28 11:03:38,393 EPOCH 30 done: loss 0.0453 - lr 0.003125
2022-03-28 11:03:44,676 Evaluating as a multi-label problem: False
2022-03-28 11:03:44,687 DEV : loss 0.20512759685516357 - f1-score (micro avg)  0.5348
2022-03-28 11:03:44,774 BAD EPOCHS (no improvement): 2
2022-03-28 11:03:44,778 ----------------------------------------------------------------------------------------------------
2022-03-28 11:03:46,839 epoch 31 - iter 10/107 - loss 0.05442003 - samples/sec: 155.38 - lr: 0.003125
2022-03-28 11:03:48,827 epoch 31 - iter 20/107 - loss 0.04909456 - samples/sec: 161.05 - lr: 0.003125
2022-03-28 11:03:50,840 epoch 31 - iter 30/107 - loss 0.04757045 - samples/sec: 158.99 - lr: 0.003125
2022-03-28 11:03:52,712 epoch 31 - iter 40/107 - loss 0.04722370 - samples/sec: 171.07 - lr: 0.003125
2022-03-28 11:03:54,667 epoch 31 - iter 50/107 - loss 0.04780745 - samples/sec: 163.73 - lr: 0.003125
2022-03-28 11:03:56,648 epoch 31 - iter 60/107 - loss 0.04709043 - samples/sec: 161.65 - lr: 0.003125
2022-03-28 11:03:58,544 epoch 31 - iter 70/107 - loss 0.04736507 - samples/sec: 168.87 - lr: 0.003125
2022-03-28 11:04:00,483 epoch 31 - iter 80/107 - loss 0.04853058 - samples/sec: 165.08 - lr: 0.003125
2022-03-28 11:04:02,507 epoch 31 - iter 90/107 - loss 0.04764885 - samples/sec: 158.18 - lr: 0.003125
2022-03-28 11:04:04,503 epoch 31 - iter 100/107 - loss 0.04764613 - samples/sec: 160.41 - lr: 0.003125
2022-03-28 11:04:05,735 ----------------------------------------------------------------------------------------------------
2022-03-28 11:04:05,735 EPOCH 31 done: loss 0.0470 - lr 0.003125
2022-03-28 11:04:11,981 Evaluating as a multi-label problem: False
2022-03-28 11:04:11,992 DEV : loss 0.20710024237632751 - f1-score (micro avg)  0.5337
2022-03-28 11:04:12,082 BAD EPOCHS (no improvement): 3
2022-03-28 11:04:12,085 ----------------------------------------------------------------------------------------------------
2022-03-28 11:04:14,081 epoch 32 - iter 10/107 - loss 0.04307902 - samples/sec: 160.38 - lr: 0.003125
2022-03-28 11:04:16,073 epoch 32 - iter 20/107 - loss 0.04272220 - samples/sec: 160.76 - lr: 0.003125
2022-03-28 11:04:18,015 epoch 32 - iter 30/107 - loss 0.04355023 - samples/sec: 164.89 - lr: 0.003125
2022-03-28 11:04:20,018 epoch 32 - iter 40/107 - loss 0.04328672 - samples/sec: 159.83 - lr: 0.003125
2022-03-28 11:04:21,999 epoch 32 - iter 50/107 - loss 0.04286396 - samples/sec: 161.62 - lr: 0.003125
2022-03-28 11:04:23,961 epoch 32 - iter 60/107 - loss 0.04173969 - samples/sec: 163.13 - lr: 0.003125
2022-03-28 11:04:25,955 epoch 32 - iter 70/107 - loss 0.04173191 - samples/sec: 160.55 - lr: 0.003125
2022-03-28 11:04:27,984 epoch 32 - iter 80/107 - loss 0.04317641 - samples/sec: 157.78 - lr: 0.003125
2022-03-28 11:04:29,894 epoch 32 - iter 90/107 - loss 0.04450307 - samples/sec: 167.61 - lr: 0.003125
2022-03-28 11:04:31,898 epoch 32 - iter 100/107 - loss 0.04510286 - samples/sec: 159.77 - lr: 0.003125
2022-03-28 11:04:33,028 ----------------------------------------------------------------------------------------------------
2022-03-28 11:04:33,028 EPOCH 32 done: loss 0.0461 - lr 0.003125
2022-03-28 11:04:39,322 Evaluating as a multi-label problem: False
2022-03-28 11:04:39,332 DEV : loss 0.20037347078323364 - f1-score (micro avg)  0.5357
2022-03-28 11:04:39,417 Epoch    32: reducing learning rate of group 0 to 1.5625e-03.
2022-03-28 11:04:39,418 BAD EPOCHS (no improvement): 4
2022-03-28 11:04:39,420 ----------------------------------------------------------------------------------------------------
2022-03-28 11:04:41,437 epoch 33 - iter 10/107 - loss 0.04140213 - samples/sec: 158.81 - lr: 0.001563
2022-03-28 11:04:43,330 epoch 33 - iter 20/107 - loss 0.03471098 - samples/sec: 169.06 - lr: 0.001563
2022-03-28 11:04:45,250 epoch 33 - iter 30/107 - loss 0.03569270 - samples/sec: 166.81 - lr: 0.001563
2022-03-28 11:04:47,196 epoch 33 - iter 40/107 - loss 0.03983280 - samples/sec: 164.51 - lr: 0.001563
2022-03-28 11:04:49,154 epoch 33 - iter 50/107 - loss 0.04115027 - samples/sec: 163.44 - lr: 0.001563
2022-03-28 11:04:51,156 epoch 33 - iter 60/107 - loss 0.04227044 - samples/sec: 159.93 - lr: 0.001563
2022-03-28 11:04:53,175 epoch 33 - iter 70/107 - loss 0.04385436 - samples/sec: 158.61 - lr: 0.001563
2022-03-28 11:04:55,113 epoch 33 - iter 80/107 - loss 0.04421578 - samples/sec: 165.22 - lr: 0.001563
2022-03-28 11:04:57,079 epoch 33 - iter 90/107 - loss 0.04501892 - samples/sec: 162.83 - lr: 0.001563
2022-03-28 11:04:59,099 epoch 33 - iter 100/107 - loss 0.04539864 - samples/sec: 158.47 - lr: 0.001563
2022-03-28 11:05:00,336 ----------------------------------------------------------------------------------------------------
2022-03-28 11:05:00,336 EPOCH 33 done: loss 0.0449 - lr 0.001563
2022-03-28 11:05:06,578 Evaluating as a multi-label problem: False
2022-03-28 11:05:06,589 DEV : loss 0.2019524723291397 - f1-score (micro avg)  0.5373
2022-03-28 11:05:06,674 BAD EPOCHS (no improvement): 1
2022-03-28 11:05:06,678 ----------------------------------------------------------------------------------------------------
2022-03-28 11:05:08,562 epoch 34 - iter 10/107 - loss 0.05165857 - samples/sec: 169.96 - lr: 0.001563
2022-03-28 11:05:10,442 epoch 34 - iter 20/107 - loss 0.04816807 - samples/sec: 170.27 - lr: 0.001563
2022-03-28 11:05:12,438 epoch 34 - iter 30/107 - loss 0.04472423 - samples/sec: 160.39 - lr: 0.001563
2022-03-28 11:05:14,408 epoch 34 - iter 40/107 - loss 0.04398190 - samples/sec: 162.55 - lr: 0.001563
2022-03-28 11:05:16,285 epoch 34 - iter 50/107 - loss 0.04319273 - samples/sec: 170.52 - lr: 0.001563
2022-03-28 11:05:18,114 epoch 34 - iter 60/107 - loss 0.04432425 - samples/sec: 175.08 - lr: 0.001563
2022-03-28 11:05:19,998 epoch 34 - iter 70/107 - loss 0.04541349 - samples/sec: 169.96 - lr: 0.001563
2022-03-28 11:05:21,923 epoch 34 - iter 80/107 - loss 0.04538192 - samples/sec: 166.31 - lr: 0.001563
2022-03-28 11:05:23,715 epoch 34 - iter 90/107 - loss 0.04594343 - samples/sec: 178.64 - lr: 0.001563
2022-03-28 11:05:25,549 epoch 34 - iter 100/107 - loss 0.04496835 - samples/sec: 174.61 - lr: 0.001563
2022-03-28 11:05:26,760 ----------------------------------------------------------------------------------------------------
2022-03-28 11:05:26,760 EPOCH 34 done: loss 0.0451 - lr 0.001563
2022-03-28 11:05:33,064 Evaluating as a multi-label problem: False
2022-03-28 11:05:33,074 DEV : loss 0.20360900461673737 - f1-score (micro avg)  0.537
2022-03-28 11:05:33,160 BAD EPOCHS (no improvement): 2
2022-03-28 11:05:33,163 ----------------------------------------------------------------------------------------------------
2022-03-28 11:05:35,203 epoch 35 - iter 10/107 - loss 0.04525576 - samples/sec: 157.01 - lr: 0.001563
2022-03-28 11:05:37,157 epoch 35 - iter 20/107 - loss 0.04058335 - samples/sec: 163.80 - lr: 0.001563
2022-03-28 11:05:39,037 epoch 35 - iter 30/107 - loss 0.03842323 - samples/sec: 170.36 - lr: 0.001563
2022-03-28 11:05:40,980 epoch 35 - iter 40/107 - loss 0.04205824 - samples/sec: 164.80 - lr: 0.001563
2022-03-28 11:05:42,942 epoch 35 - iter 50/107 - loss 0.04288114 - samples/sec: 163.14 - lr: 0.001563
2022-03-28 11:05:46,211 epoch 35 - iter 60/107 - loss 0.04389065 - samples/sec: 97.92 - lr: 0.001563
2022-03-28 11:05:48,219 epoch 35 - iter 70/107 - loss 0.04380346 - samples/sec: 159.44 - lr: 0.001563
2022-03-28 11:05:50,174 epoch 35 - iter 80/107 - loss 0.04386927 - samples/sec: 163.75 - lr: 0.001563
2022-03-28 11:05:52,103 epoch 35 - iter 90/107 - loss 0.04316800 - samples/sec: 166.01 - lr: 0.001563
2022-03-28 11:05:54,147 epoch 35 - iter 100/107 - loss 0.04417700 - samples/sec: 156.60 - lr: 0.001563
2022-03-28 11:05:55,460 ----------------------------------------------------------------------------------------------------
2022-03-28 11:05:55,460 EPOCH 35 done: loss 0.0439 - lr 0.001563
2022-03-28 11:06:01,794 Evaluating as a multi-label problem: False
2022-03-28 11:06:01,805 DEV : loss 0.2062716782093048 - f1-score (micro avg)  0.5333
2022-03-28 11:06:01,894 BAD EPOCHS (no improvement): 3
2022-03-28 11:06:01,896 ----------------------------------------------------------------------------------------------------
2022-03-28 11:06:04,066 epoch 36 - iter 10/107 - loss 0.05245666 - samples/sec: 147.56 - lr: 0.001563
2022-03-28 11:06:06,077 epoch 36 - iter 20/107 - loss 0.04394432 - samples/sec: 159.20 - lr: 0.001563
2022-03-28 11:06:08,110 epoch 36 - iter 30/107 - loss 0.04208164 - samples/sec: 157.52 - lr: 0.001563
2022-03-28 11:06:10,062 epoch 36 - iter 40/107 - loss 0.04424602 - samples/sec: 163.97 - lr: 0.001563
2022-03-28 11:06:12,013 epoch 36 - iter 50/107 - loss 0.04410938 - samples/sec: 164.15 - lr: 0.001563
2022-03-28 11:06:13,925 epoch 36 - iter 60/107 - loss 0.04327112 - samples/sec: 167.42 - lr: 0.001563
2022-03-28 11:06:15,848 epoch 36 - iter 70/107 - loss 0.04187378 - samples/sec: 166.51 - lr: 0.001563
2022-03-28 11:06:17,838 epoch 36 - iter 80/107 - loss 0.04249883 - samples/sec: 160.82 - lr: 0.001563
2022-03-28 11:06:19,872 epoch 36 - iter 90/107 - loss 0.04277078 - samples/sec: 157.39 - lr: 0.001563
2022-03-28 11:06:21,869 epoch 36 - iter 100/107 - loss 0.04331836 - samples/sec: 160.34 - lr: 0.001563
2022-03-28 11:06:23,071 ----------------------------------------------------------------------------------------------------
2022-03-28 11:06:23,071 EPOCH 36 done: loss 0.0434 - lr 0.001563
2022-03-28 11:06:29,368 Evaluating as a multi-label problem: False
2022-03-28 11:06:29,380 DEV : loss 0.20534181594848633 - f1-score (micro avg)  0.5329
2022-03-28 11:06:29,465 Epoch    36: reducing learning rate of group 0 to 7.8125e-04.
2022-03-28 11:06:29,465 BAD EPOCHS (no improvement): 4
2022-03-28 11:06:29,470 ----------------------------------------------------------------------------------------------------
2022-03-28 11:06:31,546 epoch 37 - iter 10/107 - loss 0.04478053 - samples/sec: 154.22 - lr: 0.000781
2022-03-28 11:06:33,572 epoch 37 - iter 20/107 - loss 0.04464298 - samples/sec: 158.04 - lr: 0.000781
2022-03-28 11:06:35,469 epoch 37 - iter 30/107 - loss 0.04482011 - samples/sec: 168.76 - lr: 0.000781
2022-03-28 11:06:37,353 epoch 37 - iter 40/107 - loss 0.04372077 - samples/sec: 169.93 - lr: 0.000781
2022-03-28 11:06:39,287 epoch 37 - iter 50/107 - loss 0.04237891 - samples/sec: 165.55 - lr: 0.000781
2022-03-28 11:06:41,235 epoch 37 - iter 60/107 - loss 0.04414243 - samples/sec: 164.34 - lr: 0.000781
2022-03-28 11:06:43,103 epoch 37 - iter 70/107 - loss 0.04463635 - samples/sec: 171.42 - lr: 0.000781
2022-03-28 11:06:45,057 epoch 37 - iter 80/107 - loss 0.04502797 - samples/sec: 163.81 - lr: 0.000781
2022-03-28 11:06:47,025 epoch 37 - iter 90/107 - loss 0.04506919 - samples/sec: 162.71 - lr: 0.000781
2022-03-28 11:06:49,075 epoch 37 - iter 100/107 - loss 0.04545497 - samples/sec: 156.18 - lr: 0.000781
2022-03-28 11:06:50,342 ----------------------------------------------------------------------------------------------------
2022-03-28 11:06:50,342 EPOCH 37 done: loss 0.0451 - lr 0.000781
2022-03-28 11:06:56,591 Evaluating as a multi-label problem: False
2022-03-28 11:06:56,601 DEV : loss 0.20501990616321564 - f1-score (micro avg)  0.5356
2022-03-28 11:06:56,687 BAD EPOCHS (no improvement): 1
2022-03-28 11:06:56,689 ----------------------------------------------------------------------------------------------------
2022-03-28 11:06:58,716 epoch 38 - iter 10/107 - loss 0.04848930 - samples/sec: 157.96 - lr: 0.000781
2022-03-28 11:07:00,703 epoch 38 - iter 20/107 - loss 0.04393815 - samples/sec: 161.16 - lr: 0.000781
2022-03-28 11:07:02,781 epoch 38 - iter 30/107 - loss 0.04614894 - samples/sec: 154.09 - lr: 0.000781
2022-03-28 11:07:04,784 epoch 38 - iter 40/107 - loss 0.04748605 - samples/sec: 159.80 - lr: 0.000781
2022-03-28 11:07:06,755 epoch 38 - iter 50/107 - loss 0.04804528 - samples/sec: 162.48 - lr: 0.000781
2022-03-28 11:07:08,757 epoch 38 - iter 60/107 - loss 0.04843769 - samples/sec: 159.90 - lr: 0.000781
2022-03-28 11:07:10,763 epoch 38 - iter 70/107 - loss 0.04708109 - samples/sec: 159.55 - lr: 0.000781
2022-03-28 11:07:12,711 epoch 38 - iter 80/107 - loss 0.04541141 - samples/sec: 164.42 - lr: 0.000781
2022-03-28 11:07:14,691 epoch 38 - iter 90/107 - loss 0.04527179 - samples/sec: 161.74 - lr: 0.000781
2022-03-28 11:07:16,617 epoch 38 - iter 100/107 - loss 0.04501638 - samples/sec: 166.21 - lr: 0.000781
2022-03-28 11:07:17,768 ----------------------------------------------------------------------------------------------------
2022-03-28 11:07:17,769 EPOCH 38 done: loss 0.0455 - lr 0.000781
2022-03-28 11:07:23,967 Evaluating as a multi-label problem: False
2022-03-28 11:07:23,978 DEV : loss 0.2056400328874588 - f1-score (micro avg)  0.5345
2022-03-28 11:07:24,063 BAD EPOCHS (no improvement): 2
2022-03-28 11:07:24,066 ----------------------------------------------------------------------------------------------------
2022-03-28 11:07:26,054 epoch 39 - iter 10/107 - loss 0.04343511 - samples/sec: 161.11 - lr: 0.000781
2022-03-28 11:07:28,026 epoch 39 - iter 20/107 - loss 0.04864691 - samples/sec: 162.28 - lr: 0.000781
2022-03-28 11:07:29,970 epoch 39 - iter 30/107 - loss 0.04683720 - samples/sec: 164.72 - lr: 0.000781
2022-03-28 11:07:31,927 epoch 39 - iter 40/107 - loss 0.04480920 - samples/sec: 163.57 - lr: 0.000781
2022-03-28 11:07:33,978 epoch 39 - iter 50/107 - loss 0.04496128 - samples/sec: 156.09 - lr: 0.000781
2022-03-28 11:07:36,012 epoch 39 - iter 60/107 - loss 0.04391489 - samples/sec: 157.43 - lr: 0.000781
2022-03-28 11:07:37,977 epoch 39 - iter 70/107 - loss 0.04446167 - samples/sec: 162.94 - lr: 0.000781
2022-03-28 11:07:39,954 epoch 39 - iter 80/107 - loss 0.04425959 - samples/sec: 161.88 - lr: 0.000781
2022-03-28 11:07:42,005 epoch 39 - iter 90/107 - loss 0.04521167 - samples/sec: 156.13 - lr: 0.000781
2022-03-28 11:07:43,891 epoch 39 - iter 100/107 - loss 0.04501121 - samples/sec: 169.76 - lr: 0.000781
2022-03-28 11:07:45,088 ----------------------------------------------------------------------------------------------------
2022-03-28 11:07:45,088 EPOCH 39 done: loss 0.0448 - lr 0.000781
2022-03-28 11:07:51,347 Evaluating as a multi-label problem: False
2022-03-28 11:07:51,357 DEV : loss 0.2059178501367569 - f1-score (micro avg)  0.5356
2022-03-28 11:07:51,443 BAD EPOCHS (no improvement): 3
2022-03-28 11:07:51,446 ----------------------------------------------------------------------------------------------------
2022-03-28 11:07:53,455 epoch 40 - iter 10/107 - loss 0.04408915 - samples/sec: 159.39 - lr: 0.000781
2022-03-28 11:07:55,470 epoch 40 - iter 20/107 - loss 0.04584743 - samples/sec: 158.87 - lr: 0.000781
2022-03-28 11:07:57,433 epoch 40 - iter 30/107 - loss 0.04486360 - samples/sec: 163.11 - lr: 0.000781
2022-03-28 11:07:59,389 epoch 40 - iter 40/107 - loss 0.04390227 - samples/sec: 163.66 - lr: 0.000781
2022-03-28 11:08:01,381 epoch 40 - iter 50/107 - loss 0.04258359 - samples/sec: 160.74 - lr: 0.000781
2022-03-28 11:08:03,390 epoch 40 - iter 60/107 - loss 0.04449496 - samples/sec: 159.41 - lr: 0.000781
2022-03-28 11:08:05,298 epoch 40 - iter 70/107 - loss 0.04595230 - samples/sec: 167.77 - lr: 0.000781
2022-03-28 11:08:07,292 epoch 40 - iter 80/107 - loss 0.04507664 - samples/sec: 160.54 - lr: 0.000781
2022-03-28 11:08:09,223 epoch 40 - iter 90/107 - loss 0.04474645 - samples/sec: 165.80 - lr: 0.000781
2022-03-28 11:08:11,212 epoch 40 - iter 100/107 - loss 0.04368197 - samples/sec: 160.94 - lr: 0.000781
2022-03-28 11:08:12,385 ----------------------------------------------------------------------------------------------------
2022-03-28 11:08:12,385 EPOCH 40 done: loss 0.0442 - lr 0.000781
2022-03-28 11:08:18,531 Evaluating as a multi-label problem: False
2022-03-28 11:08:18,542 DEV : loss 0.20638923346996307 - f1-score (micro avg)  0.5323
2022-03-28 11:08:18,628 Epoch    40: reducing learning rate of group 0 to 3.9063e-04.
2022-03-28 11:08:18,629 BAD EPOCHS (no improvement): 4
2022-03-28 11:08:18,631 ----------------------------------------------------------------------------------------------------
2022-03-28 11:08:20,622 epoch 41 - iter 10/107 - loss 0.04350529 - samples/sec: 160.83 - lr: 0.000391
2022-03-28 11:08:22,609 epoch 41 - iter 20/107 - loss 0.04434146 - samples/sec: 161.15 - lr: 0.000391
2022-03-28 11:08:24,581 epoch 41 - iter 30/107 - loss 0.04655254 - samples/sec: 162.31 - lr: 0.000391
2022-03-28 11:08:27,786 epoch 41 - iter 40/107 - loss 0.04379594 - samples/sec: 99.89 - lr: 0.000391
2022-03-28 11:08:29,809 epoch 41 - iter 50/107 - loss 0.04499868 - samples/sec: 158.24 - lr: 0.000391
2022-03-28 11:08:31,731 epoch 41 - iter 60/107 - loss 0.04454569 - samples/sec: 166.59 - lr: 0.000391
2022-03-28 11:08:33,699 epoch 41 - iter 70/107 - loss 0.04513737 - samples/sec: 162.63 - lr: 0.000391
2022-03-28 11:08:35,560 epoch 41 - iter 80/107 - loss 0.04471348 - samples/sec: 172.08 - lr: 0.000391
2022-03-28 11:08:37,524 epoch 41 - iter 90/107 - loss 0.04400404 - samples/sec: 162.96 - lr: 0.000391
2022-03-28 11:08:39,484 epoch 41 - iter 100/107 - loss 0.04424075 - samples/sec: 163.35 - lr: 0.000391
2022-03-28 11:08:40,671 ----------------------------------------------------------------------------------------------------
2022-03-28 11:08:40,671 EPOCH 41 done: loss 0.0440 - lr 0.000391
2022-03-28 11:08:46,963 Evaluating as a multi-label problem: False
2022-03-28 11:08:46,975 DEV : loss 0.20594413578510284 - f1-score (micro avg)  0.5326
2022-03-28 11:08:47,061 BAD EPOCHS (no improvement): 1
2022-03-28 11:08:47,064 ----------------------------------------------------------------------------------------------------
2022-03-28 11:08:49,136 epoch 42 - iter 10/107 - loss 0.03540434 - samples/sec: 154.57 - lr: 0.000391
2022-03-28 11:08:51,109 epoch 42 - iter 20/107 - loss 0.03965644 - samples/sec: 162.26 - lr: 0.000391
2022-03-28 11:08:53,134 epoch 42 - iter 30/107 - loss 0.04370857 - samples/sec: 158.08 - lr: 0.000391
2022-03-28 11:08:55,075 epoch 42 - iter 40/107 - loss 0.04493271 - samples/sec: 164.97 - lr: 0.000391
2022-03-28 11:08:57,099 epoch 42 - iter 50/107 - loss 0.04402781 - samples/sec: 158.20 - lr: 0.000391
2022-03-28 11:08:58,946 epoch 42 - iter 60/107 - loss 0.04461010 - samples/sec: 173.37 - lr: 0.000391
2022-03-28 11:09:00,788 epoch 42 - iter 70/107 - loss 0.04442733 - samples/sec: 173.78 - lr: 0.000391
2022-03-28 11:09:02,697 epoch 42 - iter 80/107 - loss 0.04435632 - samples/sec: 167.70 - lr: 0.000391
2022-03-28 11:09:04,675 epoch 42 - iter 90/107 - loss 0.04454585 - samples/sec: 161.84 - lr: 0.000391
2022-03-28 11:09:06,708 epoch 42 - iter 100/107 - loss 0.04414460 - samples/sec: 157.44 - lr: 0.000391
2022-03-28 11:09:07,944 ----------------------------------------------------------------------------------------------------
2022-03-28 11:09:07,944 EPOCH 42 done: loss 0.0445 - lr 0.000391
2022-03-28 11:09:14,213 Evaluating as a multi-label problem: False
2022-03-28 11:09:14,223 DEV : loss 0.20554491877555847 - f1-score (micro avg)  0.5326
2022-03-28 11:09:14,309 BAD EPOCHS (no improvement): 2
2022-03-28 11:09:14,312 ----------------------------------------------------------------------------------------------------
2022-03-28 11:09:16,340 epoch 43 - iter 10/107 - loss 0.05377239 - samples/sec: 157.95 - lr: 0.000391
2022-03-28 11:09:18,328 epoch 43 - iter 20/107 - loss 0.05024144 - samples/sec: 161.00 - lr: 0.000391
2022-03-28 11:09:20,313 epoch 43 - iter 30/107 - loss 0.04718369 - samples/sec: 161.28 - lr: 0.000391
2022-03-28 11:09:22,342 epoch 43 - iter 40/107 - loss 0.04782078 - samples/sec: 157.80 - lr: 0.000391
2022-03-28 11:09:24,322 epoch 43 - iter 50/107 - loss 0.04741340 - samples/sec: 161.69 - lr: 0.000391
2022-03-28 11:09:26,311 epoch 43 - iter 60/107 - loss 0.04755877 - samples/sec: 160.99 - lr: 0.000391
2022-03-28 11:09:28,350 epoch 43 - iter 70/107 - loss 0.04670565 - samples/sec: 156.96 - lr: 0.000391
2022-03-28 11:09:30,309 epoch 43 - iter 80/107 - loss 0.04660202 - samples/sec: 163.46 - lr: 0.000391
2022-03-28 11:09:32,241 epoch 43 - iter 90/107 - loss 0.04601685 - samples/sec: 165.74 - lr: 0.000391
2022-03-28 11:09:34,194 epoch 43 - iter 100/107 - loss 0.04573369 - samples/sec: 163.99 - lr: 0.000391
2022-03-28 11:09:35,388 ----------------------------------------------------------------------------------------------------
2022-03-28 11:09:35,388 EPOCH 43 done: loss 0.0455 - lr 0.000391
2022-03-28 11:09:41,671 Evaluating as a multi-label problem: False
2022-03-28 11:09:41,682 DEV : loss 0.20542964339256287 - f1-score (micro avg)  0.5326
2022-03-28 11:09:41,767 BAD EPOCHS (no improvement): 3
2022-03-28 11:09:41,770 ----------------------------------------------------------------------------------------------------
2022-03-28 11:09:43,846 epoch 44 - iter 10/107 - loss 0.03518507 - samples/sec: 154.23 - lr: 0.000391
2022-03-28 11:09:45,836 epoch 44 - iter 20/107 - loss 0.04349099 - samples/sec: 160.92 - lr: 0.000391
2022-03-28 11:09:47,740 epoch 44 - iter 30/107 - loss 0.04729624 - samples/sec: 168.14 - lr: 0.000391
2022-03-28 11:09:49,833 epoch 44 - iter 40/107 - loss 0.04616201 - samples/sec: 152.91 - lr: 0.000391
2022-03-28 11:09:51,874 epoch 44 - iter 50/107 - loss 0.04800065 - samples/sec: 156.90 - lr: 0.000391
2022-03-28 11:09:54,021 epoch 44 - iter 60/107 - loss 0.04887665 - samples/sec: 149.08 - lr: 0.000391
2022-03-28 11:09:56,011 epoch 44 - iter 70/107 - loss 0.04665066 - samples/sec: 160.87 - lr: 0.000391
2022-03-28 11:09:58,010 epoch 44 - iter 80/107 - loss 0.04693570 - samples/sec: 160.15 - lr: 0.000391
2022-03-28 11:10:00,089 epoch 44 - iter 90/107 - loss 0.04641353 - samples/sec: 154.01 - lr: 0.000391
2022-03-28 11:10:02,115 epoch 44 - iter 100/107 - loss 0.04597080 - samples/sec: 158.05 - lr: 0.000391
2022-03-28 11:10:03,378 ----------------------------------------------------------------------------------------------------
2022-03-28 11:10:03,378 EPOCH 44 done: loss 0.0457 - lr 0.000391
2022-03-28 11:10:09,610 Evaluating as a multi-label problem: False
2022-03-28 11:10:09,620 DEV : loss 0.2053953856229782 - f1-score (micro avg)  0.5326
2022-03-28 11:10:09,707 Epoch    44: reducing learning rate of group 0 to 1.9531e-04.
2022-03-28 11:10:09,707 BAD EPOCHS (no improvement): 4
2022-03-28 11:10:09,710 ----------------------------------------------------------------------------------------------------
2022-03-28 11:10:11,806 epoch 45 - iter 10/107 - loss 0.04404855 - samples/sec: 152.75 - lr: 0.000195
2022-03-28 11:10:13,751 epoch 45 - iter 20/107 - loss 0.03794350 - samples/sec: 164.59 - lr: 0.000195
2022-03-28 11:10:15,719 epoch 45 - iter 30/107 - loss 0.03918314 - samples/sec: 162.67 - lr: 0.000195
2022-03-28 11:10:17,687 epoch 45 - iter 40/107 - loss 0.04127563 - samples/sec: 162.67 - lr: 0.000195
2022-03-28 11:10:19,613 epoch 45 - iter 50/107 - loss 0.04239596 - samples/sec: 166.30 - lr: 0.000195
2022-03-28 11:10:21,540 epoch 45 - iter 60/107 - loss 0.04277454 - samples/sec: 166.13 - lr: 0.000195
2022-03-28 11:10:23,482 epoch 45 - iter 70/107 - loss 0.04335170 - samples/sec: 164.90 - lr: 0.000195
2022-03-28 11:10:25,509 epoch 45 - iter 80/107 - loss 0.04361805 - samples/sec: 158.01 - lr: 0.000195
2022-03-28 11:10:27,493 epoch 45 - iter 90/107 - loss 0.04263535 - samples/sec: 161.36 - lr: 0.000195
2022-03-28 11:10:29,384 epoch 45 - iter 100/107 - loss 0.04375643 - samples/sec: 169.39 - lr: 0.000195
2022-03-28 11:10:30,553 ----------------------------------------------------------------------------------------------------
2022-03-28 11:10:30,553 EPOCH 45 done: loss 0.0431 - lr 0.000195
2022-03-28 11:10:36,761 Evaluating as a multi-label problem: False
2022-03-28 11:10:36,772 DEV : loss 0.20548735558986664 - f1-score (micro avg)  0.5326
2022-03-28 11:10:36,858 BAD EPOCHS (no improvement): 1
2022-03-28 11:10:36,862 ----------------------------------------------------------------------------------------------------
2022-03-28 11:10:39,005 epoch 46 - iter 10/107 - loss 0.04475357 - samples/sec: 149.37 - lr: 0.000195
2022-03-28 11:10:41,035 epoch 46 - iter 20/107 - loss 0.04160494 - samples/sec: 157.68 - lr: 0.000195
2022-03-28 11:10:42,970 epoch 46 - iter 30/107 - loss 0.04448287 - samples/sec: 165.52 - lr: 0.000195
2022-03-28 11:10:44,848 epoch 46 - iter 40/107 - loss 0.04387898 - samples/sec: 170.43 - lr: 0.000195
2022-03-28 11:10:46,824 epoch 46 - iter 50/107 - loss 0.04625193 - samples/sec: 162.02 - lr: 0.000195
2022-03-28 11:10:48,896 epoch 46 - iter 60/107 - loss 0.04575187 - samples/sec: 154.49 - lr: 0.000195
2022-03-28 11:10:50,935 epoch 46 - iter 70/107 - loss 0.04475035 - samples/sec: 157.04 - lr: 0.000195
2022-03-28 11:10:52,919 epoch 46 - iter 80/107 - loss 0.04577785 - samples/sec: 161.34 - lr: 0.000195
2022-03-28 11:10:54,996 epoch 46 - iter 90/107 - loss 0.04543664 - samples/sec: 154.16 - lr: 0.000195
2022-03-28 11:10:56,959 epoch 46 - iter 100/107 - loss 0.04556103 - samples/sec: 163.08 - lr: 0.000195
2022-03-28 11:10:58,132 ----------------------------------------------------------------------------------------------------
2022-03-28 11:10:58,132 EPOCH 46 done: loss 0.0453 - lr 0.000195
2022-03-28 11:11:04,439 Evaluating as a multi-label problem: False
2022-03-28 11:11:04,450 DEV : loss 0.20533578097820282 - f1-score (micro avg)  0.5326
2022-03-28 11:11:04,539 BAD EPOCHS (no improvement): 2
2022-03-28 11:11:04,543 ----------------------------------------------------------------------------------------------------
2022-03-28 11:11:07,939 epoch 47 - iter 10/107 - loss 0.04115291 - samples/sec: 94.26 - lr: 0.000195
2022-03-28 11:11:09,850 epoch 47 - iter 20/107 - loss 0.04433379 - samples/sec: 167.56 - lr: 0.000195
2022-03-28 11:11:11,790 epoch 47 - iter 30/107 - loss 0.04368541 - samples/sec: 165.02 - lr: 0.000195
2022-03-28 11:11:13,761 epoch 47 - iter 40/107 - loss 0.04596695 - samples/sec: 162.40 - lr: 0.000195
2022-03-28 11:11:15,675 epoch 47 - iter 50/107 - loss 0.04486556 - samples/sec: 167.31 - lr: 0.000195
2022-03-28 11:11:17,591 epoch 47 - iter 60/107 - loss 0.04358263 - samples/sec: 167.12 - lr: 0.000195
2022-03-28 11:11:19,450 epoch 47 - iter 70/107 - loss 0.04436630 - samples/sec: 172.22 - lr: 0.000195
2022-03-28 11:11:21,342 epoch 47 - iter 80/107 - loss 0.04358236 - samples/sec: 169.13 - lr: 0.000195
2022-03-28 11:11:23,273 epoch 47 - iter 90/107 - loss 0.04365098 - samples/sec: 165.80 - lr: 0.000195
2022-03-28 11:11:25,294 epoch 47 - iter 100/107 - loss 0.04469842 - samples/sec: 158.46 - lr: 0.000195
2022-03-28 11:11:26,616 ----------------------------------------------------------------------------------------------------
2022-03-28 11:11:26,616 EPOCH 47 done: loss 0.0443 - lr 0.000195
2022-03-28 11:11:32,951 Evaluating as a multi-label problem: False
2022-03-28 11:11:32,962 DEV : loss 0.20528848469257355 - f1-score (micro avg)  0.5337
2022-03-28 11:11:33,048 BAD EPOCHS (no improvement): 3
2022-03-28 11:11:33,051 ----------------------------------------------------------------------------------------------------
2022-03-28 11:11:35,153 epoch 48 - iter 10/107 - loss 0.04273894 - samples/sec: 152.36 - lr: 0.000195
2022-03-28 11:11:37,140 epoch 48 - iter 20/107 - loss 0.03795341 - samples/sec: 161.10 - lr: 0.000195
2022-03-28 11:11:39,132 epoch 48 - iter 30/107 - loss 0.03778740 - samples/sec: 160.76 - lr: 0.000195
2022-03-28 11:11:41,034 epoch 48 - iter 40/107 - loss 0.03843653 - samples/sec: 168.31 - lr: 0.000195
2022-03-28 11:11:42,852 epoch 48 - iter 50/107 - loss 0.03944312 - samples/sec: 176.13 - lr: 0.000195
2022-03-28 11:11:44,770 epoch 48 - iter 60/107 - loss 0.03955468 - samples/sec: 166.90 - lr: 0.000195
2022-03-28 11:11:46,570 epoch 48 - iter 70/107 - loss 0.03964752 - samples/sec: 177.87 - lr: 0.000195
2022-03-28 11:11:48,514 epoch 48 - iter 80/107 - loss 0.03937844 - samples/sec: 164.69 - lr: 0.000195
2022-03-28 11:11:50,446 epoch 48 - iter 90/107 - loss 0.04120347 - samples/sec: 165.76 - lr: 0.000195
2022-03-28 11:11:52,344 epoch 48 - iter 100/107 - loss 0.04189556 - samples/sec: 168.67 - lr: 0.000195
2022-03-28 11:11:53,530 ----------------------------------------------------------------------------------------------------
2022-03-28 11:11:53,530 EPOCH 48 done: loss 0.0425 - lr 0.000195
2022-03-28 11:12:00,161 Evaluating as a multi-label problem: False
2022-03-28 11:12:00,172 DEV : loss 0.2054915726184845 - f1-score (micro avg)  0.5337
2022-03-28 11:12:00,258 Epoch    48: reducing learning rate of group 0 to 9.7656e-05.
2022-03-28 11:12:00,258 BAD EPOCHS (no improvement): 4
2022-03-28 11:12:00,260 ----------------------------------------------------------------------------------------------------
2022-03-28 11:12:00,260 ----------------------------------------------------------------------------------------------------
2022-03-28 11:12:00,260 learning rate too small - quitting training!
2022-03-28 11:12:00,260 ----------------------------------------------------------------------------------------------------
2022-03-28 11:12:15,386 ----------------------------------------------------------------------------------------------------
2022-03-28 11:12:15,386 loading file resources/taggers/model_08_r5_run_1/best-model.pt
2022-03-28 11:12:22,865 SequenceTagger predicts: Dictionary with 27 tags: O, S-person, B-person, E-person, I-person, S-location, B-location, E-location, I-location, S-group, B-group, E-group, I-group, S-corporation, B-corporation, E-corporation, I-corporation, S-product, B-product, E-product, I-product, S-creative-work, B-creative-work, E-creative-work, I-creative-work, <START>, <STOP>
2022-03-28 11:12:41,115 Evaluating as a multi-label problem: False
2022-03-28 11:12:41,127 0.6624	0.3383	0.4479	0.3039
2022-03-28 11:12:41,128 
Results:
- F-score (micro) 0.4479
- F-score (macro) 0.3311
- Accuracy 0.3039

By class:
               precision    recall  f1-score   support

       person     0.7500    0.5245    0.6173       429
     location     0.6754    0.5133    0.5833       150
        group     0.4839    0.1818    0.2643       165
creative-work     0.4444    0.0845    0.1420       142
      product     0.4286    0.0709    0.1216       127
  corporation     0.4444    0.1818    0.2581        66

    micro avg     0.6624    0.3383    0.4479      1079
    macro avg     0.5378    0.2595    0.3311      1079
 weighted avg     0.6022    0.3383    0.4157      1079

2022-03-28 11:12:41,128 ----------------------------------------------------------------------------------------------------
